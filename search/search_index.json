{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Calculus","text":"<p>A fun simulation-filled interactive intelligent AP Statistics textbook that is designed to maximize the probability that you will get college credit for this course and have a blast using the textbook.</p>"},{"location":"about/","title":"About This Course","text":""},{"location":"about/#why-statistics-matters-now-more-than-ever","title":"Why Statistics Matters Now More Than Ever","text":"<p>Statistics is one of the fastest-growing subjects in mathematics education worldwide. In our data-driven world, understanding how to collect, analyze, and interpret information has never been more valuable. Here are some numbers that demonstrate its reach:</p> <p>In the United States (2026 projections):</p> <ul> <li>Over 250,000 students take the AP Statistics exam each year<sup>1</sup></li> <li>AP Statistics has grown faster than almost any other AP subject over the past decade</li> <li>Approximately 1.5 million college students enroll in introductory statistics courses annually<sup>2</sup></li> <li>Statistics is now required for majors ranging from biology to business to psychology</li> </ul> <p>Worldwide:</p> <ul> <li>An estimated 10 million students study introductory statistics globally each year</li> <li>Data literacy is increasingly recognized as essential for citizenship in the 21st century</li> <li>Statistics serves as a gateway to careers in data science, healthcare, social science, business analytics, and research</li> </ul> <p>These numbers represent millions of students working to master the same concepts you'll learn in this course. You're joining a global community of learners building the foundation for making sense of an increasingly data-rich world.</p> <p>Sylvia Says</p> <p>Did you know that traditional statistics textbooks at many US colleges and universities cost between $150 and $250?<sup>3</sup> That's a lot of acorns! And here's the real kicker\u2014those expensive books don't even have interactive MicroSims to help you see what's happening with your data.</p> <p>I believe every student deserves access to high-quality statistics education, regardless of their budget. That's why this entire textbook is free and open source, with over 20 interactive simulations that let you explore statistics concepts hands-on. No paywalls, no access codes, no \"edition 12 with slightly rearranged homework problems.\"</p> <p>Let me help you master statistics without breaking the bank. Together, we've got this!</p>"},{"location":"about/#learning-through-interactive-visualization","title":"Learning Through Interactive Visualization","text":"<p>This course takes a fundamentally different approach to teaching statistics. Instead of drowning in formulas and abstract notation, you will build deep intuition through interactive MicroSimulations. These browser-based visualizations let you experiment with data, distributions, sampling, and inference in real-time.</p> <p>Watch how changing sample size affects the variability of your statistics. See the Central Limit Theorem come to life before your eyes. Explore how different bin widths reveal different stories in your histograms. Manipulate two-way tables and watch conditional distributions update instantly. These are not passive animations\u2014they are hands-on laboratories where you control the parameters and discover the concepts yourself.</p>"},{"location":"about/#you-will-have-fun","title":"You Will Have Fun","text":"<p>Yes, you read that right. This course is designed to be genuinely enjoyable. The MicroSims turn abstract concepts into interactive playgrounds. The connections to real-world applications give every topic immediate relevance. And the satisfaction of truly understanding how to think critically about data is deeply rewarding.</p> <p>Whether you aspire to conduct medical research, analyze business trends, understand political polling, evaluate scientific claims, or simply want to be a more informed citizen in our data-saturated world\u2014this course will give you the tools, the intuition, and the confidence to succeed.</p> <p>Statistics isn't just about numbers. It's about telling stories with data, making decisions under uncertainty, and understanding the world around us. That's what makes it so powerful\u2014and so much fun.</p> <p>Let's explore the beauty of statistics together!</p>"},{"location":"about/#background","title":"Background","text":"<p>The concepts covered by this book align with the College Board's AP Statistics Course and Exam Description. Our goal is to maximize the probability that you will earn college credit for your hard work.</p> <p>This intelligent textbook was generated using Claude Code Skills in February 2026. We put a strong focus on creating high-quality MicroSims that bring abstract concepts to life and on developing Sylvia the Statistical Squirrel as a friendly guide who makes statistics approachable and fun.</p> <p>\u2014 Dan McCreary, February 6th, 2026</p>"},{"location":"about/#references","title":"References","text":"<ol> <li> <p>College Board. AP Statistics Exam Data. AP Students.\u00a0\u21a9</p> </li> <li> <p>American Statistical Association. Statistics Education Research. GAISE Reports.\u00a0\u21a9</p> </li> <li> <p>OpenStax. The cost of traditional textbooks. Note that introductory statistics texts from major publishers typically range from \\(150-\\)250.\u00a0\u21a9</p> </li> </ol>"},{"location":"course-description/","title":"AP Statistics","text":""},{"location":"course-description/#audience","title":"Audience","text":"<p>This course is designed for high-school students who are preparing for the AP Statistics examination and who wish to earn college credit or advanced placement for an introductory, non-calculus-based statistics course. It is appropriate for students interested in mathematics, science, social science, business, health sciences, engineering, data science, and any field where data-driven reasoning is essential.</p> <p>The course emphasizes statistical thinking, data analysis, and interpretation, rather than algebraic manipulation or formal proofs.</p>"},{"location":"course-description/#prerequisites","title":"Prerequisites","text":"<p>Students should have successfully completed:</p> <ul> <li>A full sequence of high-school algebra (Algebra I and II)</li> <li>Experience with linear functions, systems of equations, and basic function interpretation</li> <li>Comfort with graphing and numerical reasoning</li> </ul> <p>Calculus is not required and is not used in this course.</p>"},{"location":"course-description/#overview","title":"Overview","text":"<p>AP Statistics introduces students to the major concepts and tools used for collecting, analyzing, and drawing conclusions from data. The course follows the framework defined by the :contentReference[oaicite:0]{index=0} and is designed to be equivalent to a one-semester, introductory college statistics course.</p> <p>Students learn to explore data, design studies, understand probability, model randomness, and perform statistical inference. A strong emphasis is placed on real-world data, conceptual understanding, communication of results, and statistical reasoning rather than formula memorization.</p> <p>Throughout the course, students are expected to justify conclusions, assess assumptions, interpret results in context, and recognize the limitations of statistical methods.</p>"},{"location":"course-description/#units-of-study","title":"Units of Study","text":"<ol> <li>Exploring One-Variable Data</li> <li>Graphical and numerical summaries of distributions</li> <li>Shape, center, spread, and outliers</li> <li> <p>Normal distributions and standardization</p> </li> <li> <p>Exploring Two-Variable Data</p> </li> <li>Categorical vs. categorical data</li> <li>Scatterplots and correlation</li> <li> <p>Linear regression and residual analysis</p> </li> <li> <p>Collecting Data</p> </li> <li>Sampling methods and bias</li> <li>Observational studies vs. experiments</li> <li> <p>Random assignment and causation</p> </li> <li> <p>Probability, Random Variables, and Distributions</p> </li> <li>Simulation of random events</li> <li>Probability rules</li> <li>Discrete random variables and expected value</li> <li> <p>Binomial and geometric distributions</p> </li> <li> <p>Sampling Distributions</p> </li> <li>Sampling variability</li> <li>Sampling distributions of proportions and means</li> <li> <p>Central Limit Theorem</p> </li> <li> <p>Inference for Categorical Data: Proportions</p> </li> <li>Confidence intervals for proportions</li> <li>Hypothesis tests for one and two proportions</li> <li> <p>Type I and Type II errors</p> </li> <li> <p>Inference for Quantitative Data: Means</p> </li> <li>Confidence intervals for means</li> <li>One-sample and two-sample t-tests</li> <li> <p>Paired data analysis</p> </li> <li> <p>Inference for Categorical Data: Chi-Square</p> </li> <li>Goodness-of-fit tests</li> <li> <p>Tests for homogeneity and independence</p> </li> <li> <p>Inference for Quantitative Data: Slopes</p> </li> <li>Confidence intervals and hypothesis tests for regression slopes</li> <li>Interpreting linear relationships in context</li> </ol>"},{"location":"course-description/#concepts-covered","title":"Concepts Covered","text":"<ul> <li>Data visualization and descriptive statistics</li> <li>Measures of center and variability</li> <li>Linear relationships and regression modeling</li> <li>Study design and data collection methods</li> <li>Probability rules and simulation</li> <li>Random variables and probability distributions</li> <li>Sampling distributions and the Central Limit Theorem</li> <li>Statistical inference:</li> <li>Confidence intervals</li> <li>Hypothesis testing</li> <li>p-values and significance</li> <li>Interpretation of statistical results in real-world contexts</li> <li>Communication of statistical conclusions using proper notation and language</li> </ul>"},{"location":"course-description/#concepts-not-covered","title":"Concepts NOT Covered","text":"<p>The following topics are intentionally excluded from AP Statistics:</p> <ul> <li>Calculus-based probability or inference</li> <li>Multivariable calculus or optimization</li> <li>Bayesian inference</li> <li>Time series analysis</li> <li>Multivariate regression</li> <li>Nonparametric inference methods</li> <li>Advanced probability theory (e.g., continuous distributions beyond the normal)</li> <li>Machine learning or predictive modeling</li> <li>Statistical proofs and theoretical derivations</li> </ul>"},{"location":"course-description/#learning-objectives-sorted-by-the-six-levels-of-the-2001-bloom-taxonomy","title":"Learning Objectives Sorted by the Six Levels of the 2001 Bloom Taxonomy","text":""},{"location":"course-description/#remember","title":"Remember","text":"<ul> <li>Recall definitions of key statistical terms</li> <li>Identify types of variables and data</li> <li>Recognize common statistical symbols and notation</li> <li>Recall formulas for basic statistics and probability rules</li> </ul>"},{"location":"course-description/#understand","title":"Understand","text":"<ul> <li>Explain the meaning of center, spread, and shape of distributions</li> <li>Interpret graphical displays of data</li> <li>Describe the purpose of sampling and randomization</li> <li>Explain what confidence intervals and p-values represent</li> </ul>"},{"location":"course-description/#apply","title":"Apply","text":"<ul> <li>Construct and interpret graphs and numerical summaries</li> <li>Calculate probabilities using rules and simulations</li> <li>Perform confidence interval calculations</li> <li>Conduct hypothesis tests using appropriate procedures</li> <li>Use technology to analyze data sets</li> </ul>"},{"location":"course-description/#analyze","title":"Analyze","text":"<ul> <li>Compare distributions using graphical and numerical methods</li> <li>Distinguish between correlation and causation</li> <li>Evaluate the design of studies for bias and validity</li> <li>Analyze residual plots to assess model fit</li> <li>Determine whether assumptions for inference are satisfied</li> </ul>"},{"location":"course-description/#evaluate","title":"Evaluate","text":"<ul> <li>Assess the appropriateness of statistical methods</li> <li>Critique conclusions drawn from data analyses</li> <li>Judge the strength of evidence provided by statistical tests</li> <li>Evaluate the limitations of statistical studies</li> <li>Interpret results in context and assess practical significance</li> </ul>"},{"location":"course-description/#create","title":"Create","text":"<ul> <li>Design sampling plans and experiments</li> <li>Develop statistical arguments supported by data</li> <li>Write clear, well-structured statistical reports</li> <li>Communicate findings using appropriate graphs, language, and notation</li> <li>Propose improvements to data collection or analysis methods</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"license/#commercial-licensing","title":"Commercial Licensing","text":"<p>Commercial rights are reserved by the copyright holder. For commercial licensing, publication inquiries, or permission to use this work in commercial contexts, please contact Dan McCreary on LinkedIn.</p>"},{"location":"chapters/","title":"Chapters","text":"<p>This textbook is organized into 19 chapters covering 300 concepts from the AP Statistics curriculum.</p>"},{"location":"chapters/#chapter-overview","title":"Chapter Overview","text":"<ol> <li>Introduction to Statistics - Foundations of statistics including data types, variables, populations, and samples.</li> <li>Displaying Categorical Data - Frequency tables, bar graphs, pie charts, and two-way tables.</li> <li>Displaying Quantitative Data - Histograms, stemplots, dotplots, and describing distributions.</li> <li>Numerical Summaries - Measures of center, spread, quartiles, and boxplots.</li> <li>Standardization and Normal Distributions - Z-scores, normal curves, and probability calculations.</li> <li>Scatterplots and Association - Bivariate relationships, correlation, and strength of association.</li> <li>Linear Regression - Least squares regression, residuals, and coefficient of determination.</li> <li>Causation and Study Design - Lurking variables, confounding, observational studies vs experiments.</li> <li>Probability Fundamentals - Basic probability rules, events, and probability calculations.</li> <li>Conditional Probability and Independence - Conditional probability, tree diagrams, and Bayes' intuition.</li> <li>Sampling and Bias - Sampling methods, sources of bias, and survey design.</li> <li>Experimental Design - Treatments, randomization, blinding, and experimental principles.</li> <li>Random Variables - Discrete random variables, expected value, binomial and geometric distributions.</li> <li>Sampling Distributions - Sampling variability, Central Limit Theorem, and distribution of sample statistics.</li> <li>Confidence Intervals - Point estimates, margin of error, and interpreting confidence intervals.</li> <li>Hypothesis Testing - Null and alternative hypotheses, p-values, Type I and II errors.</li> <li>Inference for Means - T-procedures, one-sample and two-sample tests for means.</li> <li>Chi-Square and Regression Inference - Goodness-of-fit, homogeneity, independence tests, and inference for slope.</li> <li>Communication and Synthesis - Statistical and practical significance, effect sizes, and AP exam strategies.</li> </ol>"},{"location":"chapters/#how-to-use-this-textbook","title":"How to Use This Textbook","text":"<p>Each chapter builds on concepts from previous chapters. The learning graph ensures that prerequisite concepts are always introduced before they are needed. Work through the chapters in order for the most effective learning experience.</p> <p>Note: Each chapter includes a list of concepts covered. Make sure to complete prerequisites before moving to advanced chapters.</p>"},{"location":"chapters/01-introduction-to-statistics/","title":"Introduction to Statistics","text":""},{"location":"chapters/01-introduction-to-statistics/#summary","title":"Summary","text":"<p>This chapter introduces the foundational concepts of statistics that form the basis for all subsequent learning. Students will learn about data, variables, populations, samples, and the key distinction between parameters and statistics. These concepts are essential building blocks for understanding how we collect, organize, and analyze data.</p>"},{"location":"chapters/01-introduction-to-statistics/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 16 concepts from the learning graph:</p> <ol> <li>Statistics</li> <li>Data</li> <li>Variable</li> <li>Observation</li> <li>Dataset</li> <li>Categorical Variable</li> <li>Quantitative Variable</li> <li>Discrete Variable</li> <li>Continuous Variable</li> <li>Population</li> <li>Sample</li> <li>Parameter</li> <li>Statistic</li> <li>Distribution</li> <li>Explanatory Variable</li> <li>Response Variable</li> </ol>"},{"location":"chapters/01-introduction-to-statistics/#prerequisites","title":"Prerequisites","text":"<p>This chapter assumes only the prerequisites listed in the course description. No prior statistics knowledge is required.</p>"},{"location":"chapters/01-introduction-to-statistics/#welcome-to-the-world-of-statistics","title":"Welcome to the World of Statistics!","text":"<p>Hey there, future data detective! I'm Sylvia, and I'll be your guide through the wonderful world of statistics. Before you roll your eyes and wonder if this is going to be all numbers and formulas, let me tell you a secret: statistics is actually about telling stories with data. And who doesn't love a good story?</p> <p>Think about it. Every time you check the weather forecast, scroll through social media analytics, or wonder why your favorite team keeps losing despite having the \"best players,\" you're brushing up against statistics. It's the superpower that helps us make sense of a messy, complicated world full of information.</p> <p>My tail's tingling already because we're about to crack open the toolbox that professional researchers, doctors, sports analysts, and even your school administrators use every single day. By the end of this course, you'll see the world differently. Trust me on this one.</p>"},{"location":"chapters/01-introduction-to-statistics/#what-is-statistics","title":"What Is Statistics?","text":"<p>Let's start with the big question: what exactly is statistics? At its core, statistics is the science of collecting, organizing, analyzing, and interpreting data to make decisions or predictions. That's a mouthful, so let's break it down.</p> <p>Statistics helps us answer questions like:</p> <ul> <li>Does a new medication actually work better than the old one?</li> <li>Are teenagers really spending more time on their phones than they did five years ago?</li> <li>What's the chance that it will rain on your outdoor graduation ceremony?</li> </ul> <p>Every one of these questions involves uncertainty. We can't know everything about the world, but statistics gives us the tools to draw reasonable conclusions from the information we can gather. Pretty cool, right?</p> Statistical Task What It Means Real-World Example Collecting Gathering information systematically Conducting a survey about lunch preferences Organizing Arranging information for easy analysis Creating a spreadsheet of survey responses Analyzing Finding patterns and relationships Calculating what percentage prefer pizza Interpreting Drawing meaningful conclusions Deciding whether to change the lunch menu"},{"location":"chapters/01-introduction-to-statistics/#data-the-raw-material-of-statistics","title":"Data: The Raw Material of Statistics","text":"<p>Now let's talk about data, the stuff that statistics runs on. Data are pieces of information collected about individuals, events, or objects. Notice I said \"data are\" not \"data is.\" Technically, data is plural (the singular is datum), though you'll hear people use it both ways.</p> <p>Here's a way to think about it: if statistics is baking, data are your ingredients. You can't make a cake without flour and eggs, and you can't do statistics without data. The quality of your conclusions depends entirely on the quality of your data, just like the quality of your cake depends on fresh ingredients.</p> <p>Data can come from anywhere:</p> <ul> <li>Survey responses from your classmates</li> <li>Measurements from a science experiment</li> <li>Records from a hospital database</li> <li>Numbers from a fitness tracker</li> <li>Social media engagement metrics</li> </ul> <p>Acorn for your thoughts?</p> <p>Sylvia says: \"Data is everywhere once you start looking for it! I track data about my acorn collection every autumn: which trees produce the most, what time of day is best for gathering, even weather conditions. That's right, I'm basically a tiny, fluffy data scientist.\"</p>"},{"location":"chapters/01-introduction-to-statistics/#variables-the-characteristics-we-measure","title":"Variables: The Characteristics We Measure","text":"<p>When we collect data, we're measuring variables. A variable is any characteristic that can take on different values. Height is a variable because different people have different heights. Eye color is a variable because people have blue, brown, green, hazel, or other colored eyes.</p> <p>Think of variables as the questions you're asking about each individual in your study. If you're studying students at your school, you might ask:</p> <ul> <li>How old are you? (Age is a variable)</li> <li>What's your favorite subject? (Favorite subject is a variable)</li> <li>How many hours did you sleep last night? (Sleep hours is a variable)</li> <li>Do you participate in sports? (Sports participation is a variable)</li> </ul> <p>The name \"variable\" makes sense when you think about it: the values vary from person to person, from object to object, or from time to time.</p>"},{"location":"chapters/01-introduction-to-statistics/#diagram-variable-types-concept-map","title":"Diagram: Variable Types Concept Map","text":"Variable Types Concept Map <p>Type: infographic</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: classify</p> <p>Learning Objective: Students will be able to classify variables into categorical and quantitative types, and further subdivide quantitative variables into discrete and continuous.</p> <p>Purpose: Create an interactive concept map showing the hierarchy of variable types with examples</p> <p>Layout: Hierarchical tree structure starting from \"Variable\" at the top, branching into Categorical and Quantitative, with Quantitative further branching into Discrete and Continuous</p> <p>Interactive elements: - Hover over each node to see definition and 3-4 examples - Click on a node to highlight its branch and dim others - Nodes should expand/contract on click to show/hide examples</p> <p>Node content: 1. Variable (root): \"Any characteristic that can take different values\"    - Examples appear on hover: height, favorite color, age, political party</p> <ol> <li>Categorical Variable: \"Variable whose values are category names or labels\"</li> <li> <p>Examples: hair color, zip code, blood type, brand preference, yes/no responses</p> </li> <li> <p>Quantitative Variable: \"Variable whose values are numerical measurements or counts\"</p> </li> <li> <p>Examples: height, weight, temperature, test scores, income</p> </li> <li> <p>Discrete Variable: \"Quantitative variable that can only take specific values, usually counts\"</p> </li> <li> <p>Examples: number of siblings, cars owned, text messages sent, goals scored</p> </li> <li> <p>Continuous Variable: \"Quantitative variable that can take any value within a range\"</p> </li> <li>Examples: height, weight, time, temperature, blood pressure</li> </ol> <p>Visual styling: - Root node: purple/blue - Categorical branch: green - Quantitative branch: orange - Discrete: light orange - Continuous: darker orange - Connecting lines with arrows showing hierarchy</p> <p>Canvas size: Responsive, approximately 600x400px Implementation: p5.js with hover detection and click handlers</p>"},{"location":"chapters/01-introduction-to-statistics/#observations-and-datasets-organizing-our-information","title":"Observations and Datasets: Organizing Our Information","text":"<p>When we collect data, each individual thing we measure is called an observation (also called a case or a record). If you survey 30 students about their study habits, each student represents one observation.</p> <p>An observation contains the values of all variables for one individual. Think of it like a row in a spreadsheet: everything we know about one person, one event, or one object.</p> <p>When we put all our observations together, we get a dataset. A dataset is an organized collection of data, typically arranged in rows (observations) and columns (variables). Here's what a simple dataset might look like:</p> Student Hours of Sleep Favorite Subject GPA Plays Sports Maria 7.5 Math 3.8 Yes James 6.0 History 3.2 Yes Aisha 8.0 Science 3.9 No Tyler 5.5 Art 2.8 Yes Lin 7.0 Math 3.6 No <p>In this dataset:</p> <ul> <li>Each row is one observation (one student)</li> <li>Each column is one variable (Sleep, Subject, GPA, Sports)</li> <li>We have 5 observations and 4 variables</li> <li>The values are the actual data points (7.5 hours, Math, 3.8, Yes)</li> </ul>"},{"location":"chapters/01-introduction-to-statistics/#categorical-variables-when-values-are-categories","title":"Categorical Variables: When Values Are Categories","text":"<p>Not all variables involve numbers. A categorical variable (also called a qualitative variable) places individuals into groups or categories. The values are labels or names, not numbers that you'd want to calculate with.</p> <p>Examples of categorical variables include:</p> <ul> <li>Gender (male, female, non-binary)</li> <li>Blood type (A, B, AB, O)</li> <li>Favorite music genre (pop, rock, hip-hop, country, classical)</li> <li>State of residence (California Quantitative variables (also called numerical variables) take on numerical values that have meaning. You can do math with them. It makes sense to calculate an average height or a total number of points scored.</li> </ul> <p>Here's a quick comparison:</p> Categorical Variables Quantitative Variables Eye color Height in inches Political party Annual income Car brand Temperature Zip code Number of pets Grade level (A, B, C) Grade percentage (87%, 92%) <p>Wait, did you notice that zip code is categorical even though it's made of numbers? Good catch! Here's the thing: zip codes are labels, not quantities. You wouldn't average two zip codes or say that zip code 90210 is \"greater than\" zip code 10001 in any meaningful way. If the numbers are just labels, the variable is categorical.</p> <p>The Number Trap</p> <p>Just because something looks like a number doesn't mean it's quantitative! Jersey numbers, social security numbers, phone numbers, and zip codes are all categorical because the numbers serve as labels, not measurements. Ask yourself: \"Does it make sense to calculate an average of these values?\" If not, it's probably categorical.</p>"},{"location":"chapters/01-introduction-to-statistics/#discrete-vs-continuous-splitting-quantitative-variables","title":"Discrete vs. Continuous: Splitting Quantitative Variables","text":"<p>Quantitative variables come in two flavors: discrete and continuous.</p> <p>Discrete variables can only take on specific, separated values, usually whole numbers or counts. You can list all possible values (at least in theory). Between any two values, there are only a limited number of possibilities, or sometimes none at all.</p> <p>Examples of discrete variables:</p> <ul> <li>Number of siblings (0, 1, 2, 3, ...)</li> <li>Number of cars in a parking lot</li> <li>Number of text messages sent today</li> <li>Points scored in a game</li> <li>Number of AP classes taken</li> </ul> <p>Continuous variables can take on any value within a range. Between any two values, there are infinitely many possible values. These typically arise from measurements rather than counts.</p> <p>Examples of continuous variables:</p> <ul> <li>Height (you could be 67.3 inches, 67.31 inches, 67.314 inches...)</li> <li>Weight</li> <li>Temperature</li> <li>Time to run a mile</li> <li>Blood pressure</li> </ul> <p>Here's a helpful tip: if you're counting things, the variable is usually discrete. If you're measuring things, it's usually continuous.</p>"},{"location":"chapters/01-introduction-to-statistics/#diagram-discrete-vs-continuous-number-line","title":"Diagram: Discrete vs Continuous Number Line","text":"Discrete vs Continuous Number Line Interactive <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: compare</p> <p>Learning Objective: Students will distinguish between discrete and continuous variables by visualizing how values can be plotted on a number line.</p> <p>Data Visibility Requirements: - Stage 1: Show two parallel number lines, one for discrete and one for continuous - Stage 2: For discrete, show only specific points (integers) that can be selected - Stage 3: For continuous, show that any point can be selected including decimals</p> <p>Instructional Rationale: Comparison visualization is appropriate because the Understand/compare objective requires learners to see the fundamental difference between variables that have gaps versus those that don't. Side-by-side display enables direct visual comparison.</p> <p>Visual elements: - Two horizontal number lines, stacked vertically - Top line labeled \"Discrete: Number of Pets\" (range 0-10) - Bottom line labeled \"Continuous: Height in Inches\" (range 60-72) - Discrete line shows only integer points as clickable dots - Continuous line shows a smooth gradient bar</p> <p>Interactive controls: - On discrete line: click to place markers only on integer values - On continuous line: click anywhere to place a marker at exact position - Display shows the exact value where user clicked - Reset button clears all markers - Toggle to show/hide example values</p> <p>Default parameters: - Both lines start empty - Example mode shows 3-4 sample points on each</p> <p>Behavior: - When user clicks on discrete line between integers, snap to nearest integer with visual feedback - When user clicks on continuous line, display value to 2 decimal places - Highlight that continuous line accepts any value, discrete only specific values</p> <p>Canvas size: Responsive, approximately 600x300px Implementation: p5.js with mouse click detection</p>"},{"location":"chapters/01-introduction-to-statistics/#populations-and-samples-who-are-we-studying","title":"Populations and Samples: Who Are We Studying?","text":"<p>Now let's talk about one of the most important distinctions in statistics: the difference between a population and a sample.</p> <p>A population is the entire group of individuals that you want to study or make conclusions about. It includes everyone or everything that fits your criteria. Notice the word \"entire\" there; populations can be huge!</p> <p>Examples of populations:</p> <ul> <li>All students currently enrolled in U.S. high schools</li> <li>Every car manufactured by Toyota in 2024</li> <li>All adults in California with diabetes</li> <li>Every tweet posted in the last 24 hours</li> </ul> <p>Here's the challenge: we almost never can study an entire population. It would take too long, cost too much, or be physically impossible. Imagine trying to survey every single high school student in America. That's millions of people!</p> <p>This is where samples come to the rescue. A sample is a subset of the population that we actually collect data from. We study the sample and use what we learn to make conclusions about the larger population.</p> <p>Think of it like taste-testing soup. You don't drink the whole pot to know if it needs more salt. You take a small spoonful (a sample) and use that to judge the whole pot (the population). Statistics works the same way.</p>"},{"location":"chapters/01-introduction-to-statistics/#diagram-population-and-sample-visualization","title":"Diagram: Population and Sample Visualization","text":"Population and Sample Visualization <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: explain</p> <p>Learning Objective: Students will explain the relationship between a population and a sample by interactively selecting sample members from a population.</p> <p>Data Visibility Requirements: - Stage 1: Show a large group of individuals representing a population (50-100 icons) - Stage 2: User selects individuals to form a sample - Stage 3: Show the sample highlighted and separated, with count statistics</p> <p>Instructional Rationale: Interactive selection enables learners to experience the sampling process directly, making the abstract concept concrete. Seeing both population and sample simultaneously reinforces their relationship.</p> <p>Visual elements: - Large rectangular area representing the population (labeled \"Population: All Students at Lincoln High School\") - 80-100 small person icons scattered in the population area - Icons have random but realistic height and shirt color variation - Selected icons become highlighted/circled - Side panel shows current sample with selected individuals</p> <p>Interactive controls: - Click individual icons to add/remove from sample - \"Random Sample\" button selects 10 random individuals - \"Clear Sample\" button resets selection - Slider to adjust sample size for random selection (5-25) - Display shows: Population size, Sample size, Sample percentage</p> <p>Behavior: - Population icons subtly different to represent variability - Selected icons move to a \"Sample\" area on right side or become highlighted - Statistics update in real-time as sample changes - Animation when random sample is selected</p> <p>Color scheme: - Unselected individuals: muted blue/gray - Selected individuals: bright orange with glow effect - Population area: light blue background - Sample area: light orange background</p> <p>Canvas size: Responsive, approximately 700x450px Implementation: p5.js</p>"},{"location":"chapters/01-introduction-to-statistics/#why-sampling-matters","title":"Why Sampling Matters","text":"<p>You might wonder why we can't just study the whole population. There are several practical reasons:</p> <ol> <li>Time: Surveying millions of people takes forever</li> <li>Money: Data collection is expensive</li> <li>Impossibility: Some populations are infinite or inaccessible</li> <li>Destruction: Testing all light bulbs until they burn out destroys your inventory!</li> </ol> <p>The goal of statistics is to learn about the population by studying a sample. But here's the catch: for our conclusions to be valid, the sample needs to represent the population well. A good sample is like a miniature version of the population. We'll learn much more about sampling methods in a later chapter.</p> <p>Sylvia's Sampling Story</p> <p>\"I once tried to figure out which trees in Oak Valley produced the most acorns. Checking every single tree would have taken all autumn! So I picked 20 trees spread across different parts of the valley. My sample told me where to focus my collection efforts, and I had the best-stocked winter den in squirrel history. That's the power of sampling!\"</p>"},{"location":"chapters/01-introduction-to-statistics/#parameters-vs-statistics-numbers-that-describe","title":"Parameters vs. Statistics: Numbers That Describe","text":"<p>Now we arrive at a distinction that trips up a lot of students, but once you get it, it'll stick with you forever. Ready? Let's crack this nut!</p> <p>A parameter is a number that describes something about the population. A statistic is a number that describes something about the sample.</p> <p>Both parameters and statistics are numerical summaries, but they describe different groups:</p> Term Describes Example Parameter Population The average height of ALL adults in the U.S. Statistic Sample The average height of 500 adults we measured <p>Here's the key insight: we usually don't know the true population parameter because we can't study everyone. What we can calculate is the sample statistic. Then we use that statistic to estimate or make inferences about the unknown parameter.</p> <p>The reason this matters is that statistics come with uncertainty. If you survey a different sample of 500 people, you'll likely get a slightly different average. The sample statistic is our best guess at the population parameter, but it's still just a guess based on incomplete information.</p>"},{"location":"chapters/01-introduction-to-statistics/#diagram-parameter-vs-statistic-comparison","title":"Diagram: Parameter vs Statistic Comparison","text":"Parameter vs Statistic Interactive Comparison <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate</p> <p>Learning Objective: Students will calculate sample statistics and compare them to population parameters, understanding why statistics vary but parameters are fixed.</p> <p>Data Visibility Requirements: - Stage 1: Show a population of 200 values with the true parameter displayed - Stage 2: Draw a sample and calculate its statistic - Stage 3: Compare the statistic to the parameter, show the difference</p> <p>Instructional Rationale: Calculation and comparison is appropriate because the Apply objective requires learners to actively compute statistics and observe how they differ from the fixed parameter. Multiple samples reinforce variability.</p> <p>Visual elements: - Left side: Population visualization as a histogram or dot plot - Population parameter (mean) shown as a vertical line - Right side: Sample visualization (same type of plot) - Sample statistic shown as a vertical line - Comparison panel showing both values and the difference</p> <p>Interactive controls: - \"Draw New Sample\" button to randomly select sample from population - Sample size slider (10, 25, 50, 100) - Counter showing number of samples drawn - Running display of all statistics from previous samples - Reset button</p> <p>Default parameters: - Population: 200 values with mean = 70 (perhaps representing heights) - Initial sample size: 25 - Show population mean = 70 (parameter, marked with Greek letter mu)</p> <p>Behavior: - Each click generates new random sample - Calculate and display sample mean (statistic, marked with x-bar) - Show difference between statistic and parameter - Build up history of sample means to see variability - Larger samples tend to give statistics closer to parameter</p> <p>Canvas size: Responsive, approximately 700x350px Implementation: p5.js with random sampling from predefined population</p>"},{"location":"chapters/01-introduction-to-statistics/#understanding-distribution","title":"Understanding Distribution","text":"<p>The word distribution is one you'll hear constantly in statistics, so let's make sure you understand it from the start. A distribution describes the pattern of values that a variable takes on. It tells us what values are possible and how often each value occurs.</p> <p>Think about the heights of students in your school. The distribution would show:</p> <ul> <li>What's the shortest height?</li> <li>What's the tallest height?</li> <li>What's the most common height?</li> <li>Are heights clustered together or spread out?</li> <li>Is the pattern symmetric or lopsided?</li> </ul> <p>We can display distributions using tables, graphs, or mathematical formulas. For now, just know that when statisticians talk about \"the distribution of a variable,\" they're talking about the overall pattern or shape of that variable across all individuals.</p> <p>Some key questions a distribution answers:</p> <ul> <li>Where is the center? What's typical or average?</li> <li>How spread out are the values? Are they tightly clustered or widely scattered?</li> <li>What shape does the pattern make? Is it symmetric, skewed, or something else?</li> <li>Are there unusual values? Any outliers or surprises?</li> </ul> <p>We'll explore distributions in much more depth in the next chapter when we start graphing and summarizing data.</p>"},{"location":"chapters/01-introduction-to-statistics/#explanatory-and-response-variables-exploring-relationships","title":"Explanatory and Response Variables: Exploring Relationships","text":"<p>When statisticians investigate relationships between two variables, they often think about cause and effect, or at least which variable might influence which. This leads to two important roles that variables can play.</p> <p>The explanatory variable (also called the independent variable or predictor) is the variable we think might explain or influence changes in another variable. It's the potential cause or the variable we might manipulate.</p> <p>The response variable (also called the dependent variable or outcome) is the variable we think might be affected or influenced. It's the potential effect or the variable we measure as an outcome.</p> <p>Here are some examples:</p> Research Question Explanatory Variable Response Variable Does studying more improve test scores? Hours studied Test score Does exercise affect heart rate? Minutes of exercise Heart rate Does temperature affect ice cream sales? Temperature Ice cream sales Does fertilizer affect plant growth? Amount of fertilizer Plant height <p>When you set up a scatterplot (which we'll learn about later), the explanatory variable typically goes on the x-axis (horizontal) and the response variable goes on the y-axis (vertical).</p> <p>A word of caution: just because we call something an \"explanatory variable\" doesn't mean it actually causes changes in the response. Finding an association between two variables is not the same as proving causation. We'll explore this crucial distinction later in the course.</p>"},{"location":"chapters/01-introduction-to-statistics/#putting-it-all-together","title":"Putting It All Together","text":"<p>Let's consolidate everything with a comprehensive example. Imagine a researcher wants to study whether sleep affects academic performance in high school students.</p> <p>Population: All high school students in the United States (approximately 15 million students)</p> <p>Sample: 500 randomly selected high school students from across the country</p> <p>Variables collected for each student:</p> <ul> <li>Hours of sleep per night (quantitative, continuous)</li> <li>GPA (quantitative, continuous)</li> <li>Grade level (categorical: freshman, sophomore, junior, senior)</li> <li>Number of AP classes (quantitative, discrete)</li> <li>Gender (categorical)</li> <li>Do they play sports? (categorical: yes/no)</li> </ul> <p>Observations: Each of the 500 students is one observation</p> <p>Dataset: The spreadsheet containing all 500 students and their values for each variable</p> <p>Parameter: The true average sleep hours for ALL U.S. high school students (unknown)</p> <p>Statistic: The average sleep hours calculated from our 500-student sample (known, calculated)</p> <p>Distribution: The pattern of sleep hours across our sample (most students cluster around 6-7 hours, some get more, some get less)</p> <p>Explanatory variable: Hours of sleep (we think it might influence performance)</p> <p>Response variable: GPA (we're measuring this as the outcome)</p>"},{"location":"chapters/01-introduction-to-statistics/#diagram-complete-study-design-map","title":"Diagram: Complete Study Design Map","text":"Interactive Study Design Concept Map <p>Type: infographic</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: organize</p> <p>Learning Objective: Students will organize all chapter concepts into a coherent mental framework by seeing how population, sample, variables, parameters, and statistics relate in a real study.</p> <p>Purpose: Create an interactive concept map that shows how all the foundational statistics concepts connect in the context of a real research study</p> <p>Layout: Central hub-and-spoke design with the \"Study\" at center, branching to major concepts, with sub-branches for details</p> <p>Interactive elements: - Click on any concept to see its definition and example from the sleep study - Hover to highlight related concepts and connections - Expandable nodes that reveal deeper information - Connection lines that animate to show information flow</p> <p>Concept nodes: 1. Population (center-left): \"All U.S. high school students\"    - Shows an icon representing millions of students</p> <ol> <li>Sample (below Population): \"500 randomly selected students\"</li> <li> <p>Arrow from Population to Sample labeled \"Select from\"</p> </li> <li> <p>Variables (center-right): Branches to:</p> </li> <li>Categorical: Grade level, Gender, Sports participation</li> <li>Quantitative: GPA, Sleep hours, AP classes</li> <li> <p>Further branches to Discrete and Continuous</p> </li> <li> <p>Parameter (connected to Population): \"True average sleep = ?\"</p> </li> <li> <p>Shows mystery/unknown symbol</p> </li> <li> <p>Statistic (connected to Sample): \"Sample average sleep = 6.8 hours\"</p> </li> <li> <p>Shows calculated value</p> </li> <li> <p>Distribution (connected to both): \"Pattern of sleep hours\"</p> </li> <li> <p>Small histogram preview</p> </li> <li> <p>Explanatory/Response (bottom):</p> </li> <li>Sleep hours (explanatory) arrow pointing to GPA (response)</li> </ol> <p>Color scheme: - Population/Parameter: Blue tones - Sample/Statistic: Orange tones - Variables: Green tones - Relationships: Purple connections</p> <p>Animation: - On load, nodes appear sequentially with connections drawing in - Pulse effect on related nodes when one is selected</p> <p>Canvas size: Responsive, approximately 750x500px Implementation: p5.js with vis-network-style interaction</p>"},{"location":"chapters/01-introduction-to-statistics/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":"<p>Before we wrap up, let's tackle some common pitfalls that students encounter with these foundational concepts:</p> <p>Mistake 1: Confusing parameter and statistic Remember: Parameters describe Populations (both start with P), and Statistics describe Samples (both start with S).</p> <p>Mistake 2: Thinking numerical means quantitative Numbers that serve as labels (like zip codes, jersey numbers, or phone numbers) are categorical, not quantitative. Ask yourself: \"Does averaging make sense?\"</p> <p>Mistake 3: Forgetting that samples vary Different samples give different statistics. That's not a bug in statistics; it's a feature we learn to work with!</p> <p>Mistake 4: Assuming explanatory means causal Just because we call a variable \"explanatory\" doesn't mean it actually causes changes in the response. Correlation is not causation!</p> <p>Mistake 5: Mixing up discrete and continuous Discrete = counting (0, 1, 2, 3...), Continuous = measuring (can be any value, including fractions/decimals)</p>"},{"location":"chapters/01-introduction-to-statistics/#key-takeaways","title":"Key Takeaways","text":"<p>Let's squirrel away the big ideas from this chapter:</p> <ol> <li> <p>Statistics is the science of learning from data through collection, organization, analysis, and interpretation.</p> </li> <li> <p>Data are pieces of information collected about individuals or things.</p> </li> <li> <p>Variables are characteristics that can take different values. They can be:</p> </li> <li>Categorical (categories/labels) or Quantitative (numbers with meaning)</li> <li> <p>If quantitative: Discrete (counts) or Continuous (measurements)</p> </li> <li> <p>An observation is the data collected for one individual; a dataset is all observations together.</p> </li> <li> <p>A population is everyone/everything you want to study; a sample is the subset you actually study.</p> </li> <li> <p>A parameter describes a population; a statistic describes a sample. We use statistics to estimate parameters.</p> </li> <li> <p>A distribution describes the pattern of values a variable takes.</p> </li> <li> <p>Explanatory variables might influence response variables, but association is not causation.</p> </li> </ol> Check Your Understanding <p>A researcher surveys 150 customers leaving a grocery store, asking about their age, whether they used coupons (yes/no), and how much they spent. She wants to understand shopping habits of all customers at the store.</p> <ol> <li>What is the population?</li> <li>What is the sample?</li> <li>Identify a categorical variable.</li> <li>Identify a quantitative variable. Is it discrete or continuous?</li> <li>If she calculates the average amount spent by the 150 customers, is that a parameter or statistic?</li> </ol> <p>Answers: 1. Population: All customers at the grocery store 2. Sample: The 150 customers surveyed 3. Categorical variable: Coupon use (yes/no) 4. Quantitative variable: Amount spent (continuous - any dollar amount possible); Age could also work (often treated as discrete when measured in whole years) 5. Statistic - it describes the sample, not the entire population</p> <p>You've just learned the vocabulary that statisticians use every day. These aren't just definitions to memorize; they're the foundation for everything that follows. In the next chapter, we'll start exploring data visually with graphs and numerically with summary statistics.</p> <p>Now that's a data point worth collecting!</p>"},{"location":"chapters/02-displaying-categorical-data/","title":"Displaying Categorical Data","text":""},{"location":"chapters/02-displaying-categorical-data/#summary","title":"Summary","text":"<p>This chapter focuses on methods for displaying and analyzing categorical data. Students will learn how to create and interpret frequency tables, bar graphs, pie charts, and two-way tables. The chapter also introduces the concept of association between categorical variables, preparing students for more advanced analysis later in the course.</p>"},{"location":"chapters/02-displaying-categorical-data/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 14 concepts from the learning graph:</p> <ol> <li>Frequency Table</li> <li>Relative Frequency</li> <li>Cumulative Frequency</li> <li>Bar Graph</li> <li>Pie Chart</li> <li>Two-Way Table</li> <li>Marginal Distribution</li> <li>Conditional Distribution</li> <li>Calculating Conditionals</li> <li>Association</li> <li>Direction of Association</li> <li>Positive Association</li> <li>Negative Association</li> <li>Strength of Association</li> </ol>"},{"location":"chapters/02-displaying-categorical-data/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Statistics</li> </ul> <p>Welcome back! In Chapter 1, you learned the difference between categorical and quantitative variables. Now we're going to put that knowledge to work. This chapter is all about categorical data---the kind of data that puts things into groups or categories, like favorite pizza topping, eye color, or whether someone prefers cats or dogs.</p> <p>\"Let's crack this nut!\" Sylvia adjusts her glasses excitedly. \"Categorical data is everywhere, and once you know how to organize and display it, you'll start seeing patterns you never noticed before. Trust me---my whole acorn classification system is based on these ideas!\"</p>"},{"location":"chapters/02-displaying-categorical-data/#organizing-data-with-frequency-tables","title":"Organizing Data with Frequency Tables","text":"<p>When you collect categorical data, you often end up with a long list of responses. Imagine asking 50 classmates about their favorite season. You'd get answers like \"Summer, Winter, Fall, Summer, Spring, Summer, Fall...\" and so on. Not exactly easy to make sense of, right?</p> <p>A frequency table organizes this chaos by listing each category and counting how many times it appears. The count for each category is called its frequency.</p> <p>Here's what a frequency table might look like for our favorite season survey:</p> Season Frequency Spring 8 Summer 22 Fall 14 Winter 6 Total 50 <p>That's much cleaner! At a glance, you can see that Summer is the crowd favorite (no surprise there), and Winter has the fewest fans.</p> <p>Sylvia's Data Tip</p> <p>Always include the total at the bottom of your frequency table. It serves as a quick check---if your frequencies don't add up to the total number of observations, something went wrong in your counting!</p>"},{"location":"chapters/02-displaying-categorical-data/#relative-frequency-thinking-in-proportions","title":"Relative Frequency: Thinking in Proportions","text":"<p>Frequencies are helpful, but sometimes raw counts don't tell the whole story. If I told you 22 students picked Summer, you might wonder: \"Is that a lot?\" The answer depends on how many students were surveyed.</p> <p>Relative frequency expresses each category's count as a proportion or percentage of the total. To calculate it, divide each frequency by the total:</p> \\[ \\text{Relative Frequency} = \\frac{\\text{Frequency}}{\\text{Total}} \\] <p>Let's add relative frequencies to our season table:</p> Season Frequency Relative Frequency Percentage Spring 8 8/50 = 0.16 16% Summer 22 22/50 = 0.44 44% Fall 14 14/50 = 0.28 28% Winter 6 6/50 = 0.12 12% Total 50 1.00 100% <p>Now we can say that 44% of students prefer Summer. That percentage means the same thing whether we surveyed 50 students or 5,000---it's the proportion that matters.</p>"},{"location":"chapters/02-displaying-categorical-data/#diagram-frequency-table-explorer","title":"Diagram: Frequency Table Explorer","text":"Frequency Table Explorer MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: Calculate, practice</p> <p>Learning Objective: Students will practice calculating relative frequencies and percentages from raw frequency data, reinforcing the connection between counts and proportions.</p> <p>Instructional Rationale: This Apply-level objective requires students to actively calculate values rather than passively observe. Interactive sliders allow students to modify frequencies and see how relative frequencies change in real-time, building procedural fluency.</p> <p>Canvas Layout:</p> <ul> <li>Drawing area showing an interactive frequency table</li> <li>Category labels on the left (4-5 categories)</li> <li>Frequency sliders for each category (range 0-50)</li> <li>Display columns for: Frequency, Relative Frequency (decimal), Percentage</li> </ul> <p>Visual Elements:</p> <ul> <li>Clean table layout with alternating row colors (light gray/white)</li> <li>Sliders next to each frequency cell</li> <li>Running total displayed at bottom</li> <li>Visual bar extending from each row proportional to relative frequency</li> <li>\"Check\" indicator showing if percentages sum to 100%</li> </ul> <p>Interactive Controls:</p> <ul> <li>Sliders to adjust frequency for each category (0-50)</li> <li>Dropdown to select different example datasets (Favorite Season, Pet Preference, Transportation Mode)</li> <li>Toggle button: Show/Hide calculation steps</li> <li>Reset button to restore default values</li> </ul> <p>Default Parameters:</p> <ul> <li>4 categories with frequencies: 8, 22, 14, 6</li> <li>Decimal places: 2</li> <li>Show percentages: Yes</li> </ul> <p>Behavior:</p> <ul> <li>When slider moves, frequency updates instantly</li> <li>Relative frequency and percentage recalculate automatically</li> <li>Visual bars resize to reflect proportions</li> <li>Total row updates dynamically</li> <li>If frequencies all equal zero, display \"No data\" message</li> </ul> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/02-displaying-categorical-data/#cumulative-frequency-running-totals","title":"Cumulative Frequency: Running Totals","text":"<p>Sometimes you want to know how many observations fall at or below a certain category. This is where cumulative frequency comes in handy. It's a running total that adds up frequencies as you move through the categories.</p> <p>Cumulative frequency works best when your categories have a natural order. For our seasons example, there isn't really a natural order (is Spring \"before\" Summer in any meaningful way?), but consider this example of student grades:</p> Grade Frequency Cumulative Frequency A 12 12 B 18 12 + 18 = 30 C 15 30 + 15 = 45 D 4 45 + 4 = 49 F 1 49 + 1 = 50 <p>The cumulative frequency tells us that 30 students earned a B or higher, and 45 students earned a C or higher. This information can be really useful when you want to know things like \"How many students passed?\" or \"What proportion of students earned at least a B?\"</p> <p>You can also calculate cumulative relative frequency by dividing cumulative frequency by the total, giving you the proportion at or below each category.</p>"},{"location":"chapters/02-displaying-categorical-data/#visualizing-categorical-data","title":"Visualizing Categorical Data","text":"<p>Tables are great for precision, but pictures often communicate patterns more quickly. Let's explore two popular ways to visualize categorical data: bar graphs and pie charts.</p>"},{"location":"chapters/02-displaying-categorical-data/#bar-graphs-comparing-categories","title":"Bar Graphs: Comparing Categories","text":"<p>A bar graph displays each category as a bar, with the height (or length) of the bar representing the frequency or relative frequency of that category. The bars should be separated by gaps to emphasize that categories are distinct, not continuous.</p> <p>Here's what makes a good bar graph:</p> <ul> <li>Each category gets its own bar</li> <li>Bars don't touch (gaps between them)</li> <li>Bar heights represent frequencies or relative frequencies</li> <li>Clear labels on both axes</li> <li>Descriptive title</li> </ul>"},{"location":"chapters/02-displaying-categorical-data/#diagram-interactive-bar-graph-builder","title":"Diagram: Interactive Bar Graph Builder","text":"Interactive Bar Graph Builder MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: Construct, demonstrate</p> <p>Learning Objective: Students will construct bar graphs from categorical data and explore how changes in data affect the visual representation.</p> <p>Instructional Rationale: Building bar graphs reinforces the Apply level of Bloom's taxonomy by having students actively create visual representations. The interactive nature allows immediate feedback on proper bar graph construction.</p> <p>Canvas Layout:</p> <ul> <li>Left side (60%): Bar graph display area</li> <li>Right side (40%): Data input panel and controls</li> </ul> <p>Visual Elements:</p> <ul> <li>Horizontal or vertical bars with customizable colors</li> <li>X-axis with category labels</li> <li>Y-axis with frequency or relative frequency scale</li> <li>Grid lines for easier reading</li> <li>Title area at top</li> </ul> <p>Interactive Controls:</p> <ul> <li>Text inputs for category names (up to 6 categories)</li> <li>Number inputs or sliders for frequencies (0-100)</li> <li>Radio buttons: Frequency vs. Relative Frequency display</li> <li>Radio buttons: Vertical vs. Horizontal bars</li> <li>Color picker for bar color</li> <li>Button: Add Category / Remove Category</li> <li>Reset button</li> </ul> <p>Default Parameters:</p> <ul> <li>4 categories: Spring (8), Summer (22), Fall (14), Winter (6)</li> <li>Vertical bars</li> <li>Bar color: steelblue</li> <li>Display mode: Frequency</li> </ul> <p>Behavior:</p> <ul> <li>Bars update in real-time as data changes</li> <li>Y-axis rescales automatically to fit data</li> <li>When switching to relative frequency, values convert to proportions</li> <li>Category labels rotate if too long</li> <li>Hover over bar shows exact value</li> </ul> <p>Implementation: p5.js with canvas-based UI elements</p> <p>\"Here's something I learned the hard way,\" Sylvia confesses. \"The order of bars in a bar graph usually doesn't matter for categorical data---unless there's a natural ordering like grades or age groups. But it often helps to put bars in order from tallest to shortest. That makes patterns pop!\"</p> <p>A bar graph ordered from most frequent to least frequent is sometimes called a Pareto chart. It helps you quickly identify the most common categories.</p>"},{"location":"chapters/02-displaying-categorical-data/#pie-charts-showing-parts-of-a-whole","title":"Pie Charts: Showing Parts of a Whole","text":"<p>A pie chart is a circle divided into wedges, where each wedge represents a category. The size of each wedge is proportional to the relative frequency of that category.</p> <p>Pie charts emphasize how categories relate to the whole. They work well when:</p> <ul> <li>You have a small number of categories (ideally 5 or fewer)</li> <li>You want to show proportions of a whole</li> <li>The total is meaningful (like 100% of survey respondents)</li> </ul> <p>To create a pie chart, multiply each relative frequency by 360 degrees to find the angle for each wedge:</p> \\[ \\text{Angle} = \\text{Relative Frequency} \\times 360\u00b0 \\] <p>For our season data:</p> Season Relative Frequency Angle Spring 0.16 57.6\u00b0 Summer 0.44 158.4\u00b0 Fall 0.28 100.8\u00b0 Winter 0.12 43.2\u00b0"},{"location":"chapters/02-displaying-categorical-data/#diagram-pie-chart-vs-bar-graph-comparison","title":"Diagram: Pie Chart vs Bar Graph Comparison","text":"Pie Chart vs Bar Graph Comparison MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: Compare, contrast</p> <p>Learning Objective: Students will compare the effectiveness of pie charts versus bar graphs for displaying categorical data and determine when each visualization is most appropriate.</p> <p>Instructional Rationale: Comparing two visualization types develops analytical thinking (Bloom Level 4). Students need to evaluate trade-offs rather than just create visualizations.</p> <p>Canvas Layout:</p> <ul> <li>Top half: Side-by-side display of pie chart (left) and bar graph (right)</li> <li>Bottom area: Data controls and comparison questions</li> </ul> <p>Visual Elements:</p> <ul> <li>Pie chart with labeled wedges and percentages</li> <li>Bar graph with matching colors to pie wedges</li> <li>Legend showing category-color mapping</li> <li>Comparison prompts below visualizations</li> </ul> <p>Interactive Controls:</p> <ul> <li>Data sliders for 4-6 categories (0-50 each)</li> <li>Dropdown to select preset datasets:</li> <li>\"Easy to compare\" (2 categories dominate)</li> <li>\"Similar values\" (all categories close to equal)</li> <li>\"Many categories\" (6 small categories)</li> <li>\"One dominant\" (one category over 60%)</li> <li>Toggle: Show/Hide percentages on pie chart</li> <li>Toggle: Show/Hide values on bar graph</li> </ul> <p>Default Parameters:</p> <ul> <li>4 categories with varied frequencies</li> <li>Percentages shown on pie chart</li> <li>Values shown on bar graph</li> </ul> <p>Behavior:</p> <ul> <li>Both visualizations update simultaneously when data changes</li> <li>When categories have similar sizes, pie becomes harder to read</li> <li>When one category dominates, pie shows it clearly</li> <li>Six or more categories make pie chart cluttered</li> <li>Reveal discussion prompt: \"Which visualization makes comparison easier for this data?\"</li> </ul> <p>Implementation: p5.js with dual visualization canvas</p> <p>Pie Chart Pitfalls</p> <p>Pie charts can be tricky to read when categories have similar sizes. It's hard to tell if a 23% wedge is bigger than a 21% wedge. For precise comparisons, bar graphs are usually better. Also, avoid 3D pie charts---they distort proportions and make accurate reading nearly impossible!</p>"},{"location":"chapters/02-displaying-categorical-data/#when-to-use-which-graph","title":"When to Use Which Graph?","text":"<p>Here's a quick guide for choosing between bar graphs and pie charts:</p> Situation Best Choice Comparing sizes across categories Bar graph Showing parts of a whole Pie chart More than 5 categories Bar graph Categories with similar frequencies Bar graph One category dominates Either works Need precise comparison Bar graph"},{"location":"chapters/02-displaying-categorical-data/#two-way-tables-exploring-relationships","title":"Two-Way Tables: Exploring Relationships","text":"<p>So far, we've looked at one categorical variable at a time. But what happens when we have two categorical variables and want to explore the relationship between them?</p> <p>Enter the two-way table (also called a contingency table). A two-way table displays counts for two categorical variables simultaneously, with one variable defining the rows and another defining the columns.</p> <p>Let's say we surveyed students about their favorite season AND their grade level (underclassmen vs. upperclassmen). Here's what a two-way table might look like:</p> Spring Summer Fall Winter Total Underclassmen 5 12 6 4 27 Upperclassmen 3 10 8 2 23 Total 8 22 14 6 50 <p>This table shows us both how each group answered AND allows us to compare preferences between groups.</p> <p>\"Acorn for your thoughts?\" Sylvia asks. \"Notice those totals on the edges? Those are special---they tell us about each variable separately, as if the other variable didn't exist. We have a fancy name for them!\"</p>"},{"location":"chapters/02-displaying-categorical-data/#marginal-distributions","title":"Marginal Distributions","text":"<p>The marginal distribution is the distribution of one variable alone, found in the margins (edges) of a two-way table. Looking at our table:</p> <ul> <li>The marginal distribution of Season is: Spring (8), Summer (22), Fall (14), Winter (6)</li> <li>The marginal distribution of Grade Level is: Underclassmen (27), Upperclassmen (23)</li> </ul> <p>These marginals are exactly what we'd get if we only asked about one variable. They're called \"marginal\" because they appear in the margins of the table.</p> <p>You can express marginal distributions as:</p> <ul> <li>Raw frequencies (the counts)</li> <li>Relative frequencies (proportions of the total)</li> </ul> Season Marginal Frequency Marginal Relative Frequency Spring 8 8/50 = 0.16 = 16% Summer 22 22/50 = 0.44 = 44% Fall 14 14/50 = 0.28 = 28% Winter 6 6/50 = 0.12 = 12%"},{"location":"chapters/02-displaying-categorical-data/#conditional-distributions","title":"Conditional Distributions","text":"<p>Here's where things get really interesting. What if we want to know the distribution of season preference for just underclassmen? Or just upperclassmen? These are conditional distributions---the distribution of one variable given a specific value of the other variable.</p> <p>To find a conditional distribution, we focus on one row (or column) and calculate relative frequencies within that row (or column).</p> <p>Conditional distribution of Season given Underclassmen:</p> Season Frequency Conditional Relative Frequency Spring 5 5/27 = 0.185 = 18.5% Summer 12 12/27 = 0.444 = 44.4% Fall 6 6/27 = 0.222 = 22.2% Winter 4 4/27 = 0.148 = 14.8% <p>Conditional distribution of Season given Upperclassmen:</p> Season Frequency Conditional Relative Frequency Spring 3 3/23 = 0.130 = 13.0% Summer 10 10/23 = 0.435 = 43.5% Fall 8 8/23 = 0.348 = 34.8% Winter 2 2/23 = 0.087 = 8.7% <p>Notice the key difference: for marginal distributions, we divide by the grand total (50). For conditional distributions, we divide by the row or column total (27 for underclassmen, 23 for upperclassmen).</p>"},{"location":"chapters/02-displaying-categorical-data/#diagram-two-way-table-distribution-calculator","title":"Diagram: Two-Way Table Distribution Calculator","text":"Two-Way Table Distribution Calculator MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: Calculate, execute</p> <p>Learning Objective: Students will calculate marginal and conditional distributions from a two-way table, distinguishing between dividing by grand total versus row/column totals.</p> <p>Instructional Rationale: Calculating different distribution types requires procedural application (Bloom Level 3). The step-by-step display shows the calculation process explicitly.</p> <p>Canvas Layout:</p> <ul> <li>Top (40%): Editable two-way table with row/column totals</li> <li>Middle (30%): Calculation display area showing formulas and results</li> <li>Bottom (30%): Result table with selected distribution</li> </ul> <p>Visual Elements:</p> <ul> <li>2x4 two-way table with editable cells</li> <li>Row and column totals auto-calculated</li> <li>Grand total in bottom-right corner</li> <li>Highlighted cells showing which values are used in current calculation</li> <li>Formula display: \"5/27 = 0.185 = 18.5%\"</li> <li>Result table formatted as distribution</li> </ul> <p>Interactive Controls:</p> <ul> <li>Number inputs for each cell in the two-way table (0-100)</li> <li>Radio button group: \"What distribution do you want?\"</li> <li>Marginal distribution of Row Variable</li> <li>Marginal distribution of Column Variable</li> <li>Conditional distribution of Columns given Row 1</li> <li>Conditional distribution of Columns given Row 2</li> <li>Toggle: Show calculation steps</li> <li>Button: Use example data (Season/Grade Level)</li> <li>Reset button</li> </ul> <p>Default Parameters:</p> <ul> <li>2 rows (Underclassmen, Upperclassmen) x 4 columns (Spring, Summer, Fall, Winter)</li> <li>Default values from chapter example</li> <li>Show calculation steps: On</li> </ul> <p>Behavior:</p> <ul> <li>Cells in use for current calculation are highlighted (yellow background)</li> <li>Denominator (total) is highlighted in blue</li> <li>Formula appears showing: value/total = decimal = percentage</li> <li>Result table updates when data or distribution type changes</li> <li>Error message if all cells are zero</li> </ul> <p>Implementation: p5.js with canvas-based table interface</p>"},{"location":"chapters/02-displaying-categorical-data/#calculating-conditional-probabilities-a-step-by-step-approach","title":"Calculating Conditional Probabilities: A Step-by-Step Approach","text":"<p>Let's practice calculating a conditional distribution systematically. We'll find the conditional distribution of grade level given that a student's favorite season is Fall.</p> <p>Step 1: Identify the condition. We're given that Season = Fall, so we look at the Fall column.</p> <p>Step 2: Find the relevant counts.</p> <ul> <li>Fall total: 14</li> <li>Underclassmen who prefer Fall: 6</li> <li>Upperclassmen who prefer Fall: 8</li> </ul> <p>Step 3: Calculate relative frequencies within that column.</p> <ul> <li>P(Underclassmen | Fall) = 6/14 = 0.429 = 42.9%</li> <li>P(Upperclassmen | Fall) = 8/14 = 0.571 = 57.1%</li> </ul> <p>Step 4: Verify they sum to 1 (or 100%).</p> <ul> <li>0.429 + 0.571 = 1.000 (Check!)</li> </ul> <p>\"Don't worry---every statistician drops an acorn sometimes,\" Sylvia reassures you. \"If your conditional percentages don't add up to 100%, go back and check your denominator. You should be dividing by the row or column total, not the grand total!\"</p>"},{"location":"chapters/02-displaying-categorical-data/#association-between-categorical-variables","title":"Association Between Categorical Variables","text":"<p>Now comes the big question: Is there a relationship between our two variables? Do underclassmen and upperclassmen have different preferences for seasons, or do both groups follow roughly the same pattern?</p> <p>When two categorical variables are related, we say there is an association between them. When there's no relationship---when knowing one variable doesn't help predict the other---we say the variables are independent.</p>"},{"location":"chapters/02-displaying-categorical-data/#detecting-association","title":"Detecting Association","text":"<p>To detect association, we compare conditional distributions. If the conditional distributions are different, there's evidence of association. If they're the same (or very similar), the variables appear to be independent.</p> <p>Let's compare our conditional distributions:</p> Season Underclassmen Upperclassmen Spring 18.5% 13.0% Summer 44.4% 43.5% Fall 22.2% 34.8% Winter 14.8% 8.7% <p>Looking at this comparison, we see some differences. Upperclassmen seem to prefer Fall more than underclassmen do (34.8% vs. 22.2%), and underclassmen have a slightly higher preference for Winter (14.8% vs. 8.7%). These differences suggest there might be some association between grade level and season preference.</p> <p>But here's an important caution: we need to ask whether these differences are big enough to be meaningful or whether they could just be due to random variation. We'll develop formal methods to answer this question later in the course (spoiler: it involves something called a chi-square test!).</p>"},{"location":"chapters/02-displaying-categorical-data/#diagram-association-detector-visualization","title":"Diagram: Association Detector Visualization","text":"Association Detector Visualization MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: Compare, differentiate, examine</p> <p>Learning Objective: Students will compare conditional distributions visually and verbally describe evidence for or against association between two categorical variables.</p> <p>Instructional Rationale: Analyzing association requires comparing patterns (Bloom Level 4). Side-by-side visual comparison makes differences more apparent and prompts analytical thinking.</p> <p>Canvas Layout:</p> <ul> <li>Top (60%): Side-by-side segmented bar charts showing conditional distributions</li> <li>Bottom (40%): Comparison summary and interpretation guidance</li> </ul> <p>Visual Elements:</p> <ul> <li>Two horizontal segmented bar charts (100% stacked bars)</li> <li>Each bar represents one level of the row variable</li> <li>Segments colored by column variable categories</li> <li>Legend showing color-category mapping</li> <li>Difference indicators showing where bars differ most</li> <li>Text summary: \"The conditional distributions appear [similar/different]\"</li> </ul> <p>Interactive Controls:</p> <ul> <li>Editable 2x4 two-way table (number inputs)</li> <li>Dropdown: Select preset examples</li> <li>\"Strong association\" (very different distributions)</li> <li>\"No association\" (identical distributions)</li> <li>\"Moderate association\" (somewhat different)</li> <li>\"Custom data\" (user enters own values)</li> <li>Toggle: Show percentage labels on segments</li> <li>Toggle: Show difference highlighting</li> </ul> <p>Default Parameters:</p> <ul> <li>Season/Grade Level example data</li> <li>Percentage labels shown</li> <li>Difference highlighting on</li> </ul> <p>Behavior:</p> <ul> <li>Segmented bars update when data changes</li> <li>Segments with biggest differences highlighted with indicator</li> <li>Summary text describes whether distributions look similar or different</li> <li>If distributions are identical, displays \"No evidence of association\"</li> <li>Tooltip on hover shows exact percentage for each segment</li> </ul> <p>Implementation: p5.js with canvas-based visualization</p>"},{"location":"chapters/02-displaying-categorical-data/#direction-of-association","title":"Direction of Association","text":"<p>When we find evidence of association, we often want to describe its direction. For categorical variables, direction refers to how the categories tend to pair up.</p> <p>Positive association occurs when increases in one variable tend to go with increases in another (or when certain categories tend to occur together). For example, if people who exercise frequently also tend to eat healthy food, there's a positive association between exercise and diet quality.</p> <p>Negative association occurs when high values of one variable tend to go with low values of another (or when certain categories tend to not occur together). For example, if people who smoke heavily tend to exercise less, there's a negative association between smoking and exercise.</p> <p>\"My tail's tingling---we're onto something important!\" Sylvia exclaims. \"But here's the tricky part: with truly categorical data (like favorite color or type of pet), direction doesn't always make sense. Direction is most meaningful when categories have a natural ordering, like education level (high school, some college, bachelor's, graduate) or satisfaction (very dissatisfied to very satisfied).\"</p>"},{"location":"chapters/02-displaying-categorical-data/#strength-of-association","title":"Strength of Association","text":"<p>Beyond direction, we can describe the strength of association---how closely the variables are related.</p> <ul> <li>Strong association: Conditional distributions are very different from each other. Knowing one variable tells you a lot about the other.</li> <li>Moderate association: Some noticeable differences in conditional distributions.</li> <li>Weak association: Small differences that might just be random variation.</li> <li>No association: Conditional distributions are essentially identical.</li> </ul> <p>Think of it like this: if knowing someone's grade level lets you predict their season preference with high accuracy, the association is strong. If it barely helps at all, the association is weak.</p>"},{"location":"chapters/02-displaying-categorical-data/#diagram-strength-of-association-spectrum","title":"Diagram: Strength of Association Spectrum","text":"Strength of Association Spectrum MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: Classify, interpret, exemplify</p> <p>Learning Objective: Students will interpret and classify associations as strong, moderate, weak, or none by examining visual representations of different two-way tables.</p> <p>Instructional Rationale: Understanding strength of association requires recognizing patterns across examples (Bloom Level 2). Multiple examples with clear labels help students build intuition.</p> <p>Data Visibility Requirements:</p> <ul> <li>Stage 1: Show two-way table with raw counts</li> <li>Stage 2: Show conditional distributions as percentages</li> <li>Stage 3: Show visual comparison (segmented bars)</li> <li>Stage 4: Show strength classification with explanation</li> </ul> <p>Canvas Layout:</p> <ul> <li>Left side (55%): Two-way table and segmented bar visualization</li> <li>Right side (45%): Strength indicator scale and description</li> </ul> <p>Visual Elements:</p> <ul> <li>2x3 or 2x4 two-way table</li> <li>Segmented bar chart showing conditional distributions</li> <li>Vertical \"strength meter\" scale from \"None\" to \"Strong\"</li> <li>Arrow pointing to current position on strength scale</li> <li>Text description explaining why this level of association</li> </ul> <p>Interactive Controls:</p> <ul> <li>Dropdown: Select example dataset</li> <li>\"Perfect association\" (each row has only one column with counts)</li> <li>\"Strong association\" (very different distributions)</li> <li>\"Moderate association\" (noticeable differences)</li> <li>\"Weak association\" (slight differences)</li> <li>\"No association\" (identical distributions)</li> <li>Slider: Gradually transform from \"No association\" to \"Strong association\"</li> <li>Button: Randomize data</li> </ul> <p>Default Parameters:</p> <ul> <li>Moderate association example</li> <li>Transformation slider at 50%</li> </ul> <p>Behavior:</p> <ul> <li>When slider moves, data smoothly transforms between independence and strong association</li> <li>Strength meter updates to reflect current state</li> <li>Description text changes based on strength level</li> <li>Segmented bars animate smoothly during transitions</li> </ul> <p>Implementation: p5.js with animated transitions</p>"},{"location":"chapters/02-displaying-categorical-data/#putting-it-all-together-a-complete-analysis","title":"Putting It All Together: A Complete Analysis","text":"<p>Let's work through a complete example that uses all the concepts from this chapter. Imagine we surveyed 200 high school students about their preferred study location (Library, Home, Coffee Shop) and whether they consider themselves morning people or night owls.</p> Library Home Coffee Shop Total Morning Person 45 30 15 90 Night Owl 25 55 30 110 Total 70 85 45 200 <p>Step 1: Examine the marginal distributions</p> <p>Marginal distribution of Study Location:</p> <ul> <li>Library: 70/200 = 35%</li> <li>Home: 85/200 = 42.5%</li> <li>Coffee Shop: 45/200 = 22.5%</li> </ul> <p>Overall, Home is the most popular study location, followed by Library, then Coffee Shop.</p> <p>Marginal distribution of Sleep Preference:</p> <ul> <li>Morning Person: 90/200 = 45%</li> <li>Night Owl: 110/200 = 55%</li> </ul> <p>There are slightly more night owls than morning people in our sample.</p> <p>Step 2: Calculate conditional distributions</p> <p>Conditional distribution of Location given Morning Person:</p> <ul> <li>Library: 45/90 = 50%</li> <li>Home: 30/90 = 33.3%</li> <li>Coffee Shop: 15/90 = 16.7%</li> </ul> <p>Conditional distribution of Location given Night Owl:</p> <ul> <li>Library: 25/110 = 22.7%</li> <li>Home: 55/110 = 50%</li> <li>Coffee Shop: 30/110 = 27.3%</li> </ul> <p>Step 3: Compare and look for association</p> Location Morning People Night Owls Difference Library 50% 22.7% 27.3 percentage points Home 33.3% 50% 16.7 percentage points Coffee Shop 16.7% 27.3% 10.6 percentage points <p>There are substantial differences! Morning people prefer the library much more (50% vs. 22.7%), while night owls prefer studying at home (50% vs. 33.3%). This suggests a moderate to strong association between sleep preference and study location.</p> <p>Step 4: Describe the association</p> <p>We would describe this as: \"There appears to be a moderate association between sleep preference and preferred study location. Morning people are more likely to prefer studying at the library, while night owls are more likely to prefer studying at home or at a coffee shop.\"</p> <p>Sylvia's Summary</p> <p>\"Time to squirrel away this knowledge! When analyzing two categorical variables:</p> <ol> <li>Start with the marginal distributions to understand each variable separately</li> <li>Calculate conditional distributions to see how one variable behaves within levels of the other</li> <li>Compare conditional distributions to detect association</li> <li>If distributions differ, describe the direction and strength of association</li> </ol> <p>Remember: association doesn't mean causation! Just because morning people prefer the library doesn't mean being a morning person causes library preference. There could be other factors at play!\"</p>"},{"location":"chapters/02-displaying-categorical-data/#key-takeaways","title":"Key Takeaways","text":"<p>Let's summarize the main ideas from this chapter:</p> <ul> <li>A frequency table organizes categorical data by counting occurrences of each category</li> <li>Relative frequency expresses counts as proportions of the total, enabling fair comparisons</li> <li>Cumulative frequency provides running totals, useful for ordered categories</li> <li>Bar graphs display categories as separated bars and work well for comparing frequencies</li> <li>Pie charts show parts of a whole but become hard to read with many categories or similar values</li> <li>Two-way tables display the relationship between two categorical variables</li> <li>Marginal distributions show each variable separately (divide by grand total)</li> <li>Conditional distributions show one variable within levels of another (divide by row or column total)</li> <li>Association exists when conditional distributions differ across levels</li> <li>Direction describes how categories tend to pair up (positive or negative)</li> <li>Strength describes how different the conditional distributions are</li> </ul>"},{"location":"chapters/02-displaying-categorical-data/#diagram-chapter-concept-map","title":"Diagram: Chapter Concept Map","text":"Chapter Concept Map <p>Type: infographic</p> <p>Bloom Taxonomy: Remember (L1) Bloom Verb: Recognize, identify</p> <p>Learning Objective: Students will identify and recall the key concepts from this chapter and their relationships.</p> <p>Purpose: Visual summary showing how all chapter concepts connect to each other.</p> <p>Layout: Hierarchical concept map with main topic at top branching down</p> <p>Nodes:</p> <ul> <li>Root: \"Displaying Categorical Data\"</li> <li>Level 1 branches:</li> <li>\"Organizing Data\" (connects to Frequency Table, Relative Frequency, Cumulative Frequency)</li> <li>\"Single Variable Displays\" (connects to Bar Graph, Pie Chart)</li> <li>\"Two Variable Analysis\" (connects to Two-Way Table)</li> <li> <p>\"Association\" (connects to Direction, Strength)</p> </li> <li> <p>Level 2 connections:</p> </li> <li>Frequency Table \u2192 Relative Frequency \u2192 Cumulative Frequency (sequential)</li> <li>Two-Way Table \u2192 Marginal Distribution, Conditional Distribution</li> <li>Conditional Distribution \u2192 Association</li> <li>Direction \u2192 Positive Association, Negative Association</li> </ul> <p>Visual Style:</p> <ul> <li>Concept nodes as rounded rectangles with concept name</li> <li>Color coding by theme (blue for organization, green for displays, orange for two-variable, purple for association)</li> <li>Arrows showing prerequisite relationships</li> <li>Hover reveals brief definition</li> </ul> <p>Interactive Features:</p> <ul> <li>Hover over node: Show definition tooltip</li> <li>Click node: Highlight all connected concepts</li> <li>Toggle: Show/Hide definitions</li> <li>Navigation: Link to section within chapter</li> </ul> <p>Implementation: vis-network or custom p5.js graph visualization</p>"},{"location":"chapters/02-displaying-categorical-data/#practice-problems","title":"Practice Problems","text":"Practice 1: Creating a Frequency Table <p>A survey asked 40 students about their favorite school subject. The responses were: Math (12), English (8), Science (11), History (5), Art (4)</p> <p>a) Create a frequency table with relative frequencies. b) What percentage of students prefer Math or Science? c) Create a bar graph representing this data.</p> Practice 2: Working with Two-Way Tables <p>A two-way table shows music preference by age group:</p> Pop Rock Classical Hip-Hop Total Under 30 45 20 5 30 100 30 and Over 15 35 25 25 100 Total 60 55 30 55 200 <p>a) What is the marginal distribution of music preference? b) What is the conditional distribution of music preference for people under 30? c) Is there evidence of association between age and music preference? Explain.</p> Practice 3: Describing Association <p>Researchers surveyed 150 pet owners about their pet type (Dog or Cat) and living situation (Apartment or House):</p> Apartment House Total Dog 20 55 75 Cat 50 25 75 Total 70 80 150 <p>a) Calculate the conditional distribution of living situation for dog owners. b) Calculate the conditional distribution of living situation for cat owners. c) Describe the association between pet type and living situation. Include direction and strength.</p> <p>Congratulations on completing Chapter 2! You've learned powerful tools for organizing and visualizing categorical data. In the next chapter, we'll shift our focus to quantitative data and explore different ways to display and describe numerical distributions.</p> <p>\"See you in Chapter 3!\" Sylvia waves, tucking her pencil behind her ear. \"We'll be exploring histograms, stemplots, and all sorts of ways to visualize numbers. It's going to be great!\"</p>"},{"location":"chapters/03-displaying-quantitative-data/","title":"Displaying Quantitative Data","text":""},{"location":"chapters/03-displaying-quantitative-data/#summary","title":"Summary","text":"<p>This chapter teaches students how to display quantitative data using various graphical methods including dotplots, stemplots, and histograms. Students will learn to describe the shape of distributions, identify symmetric and skewed patterns, and recognize outliers. These visualization skills are fundamental for exploratory data analysis.</p>"},{"location":"chapters/03-displaying-quantitative-data/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 13 concepts from the learning graph:</p> <ol> <li>Dotplot</li> <li>Stemplot</li> <li>Histogram</li> <li>Choosing Bin Width</li> <li>Shape of Distribution</li> <li>Symmetric Distribution</li> <li>Skewed Left</li> <li>Skewed Right</li> <li>Unimodal Distribution</li> <li>Bimodal Distribution</li> <li>Uniform Distribution</li> <li>Outlier</li> <li>Identifying Outliers</li> </ol>"},{"location":"chapters/03-displaying-quantitative-data/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Statistics</li> </ul>"},{"location":"chapters/03-displaying-quantitative-data/#why-visualize-data","title":"Why Visualize Data?","text":"<p>Welcome back! In Chapter 1, you learned about the difference between categorical and quantitative variables. Now we're going to roll up our sleeves and actually see what quantitative data looks like. Because here's a little secret that statisticians know: numbers in a table are just... numbers. But put those same numbers into a graph, and suddenly patterns jump out at you like a squirrel spotting an acorn across the park.</p> <p>Sylvia here has a confession: \"When I first started tracking my acorn collection data, I just stared at lists of numbers. How many acorns did I find each day? 23, 18, 45, 12, 31, 28... It meant nothing to me! Then I made my first dotplot, and suddenly I could see that most days I found between 15 and 35 acorns, with a few exceptional days on either end. That's when I fell in love with data visualization.\"</p> <p>In this chapter, you'll learn three powerful ways to display quantitative data:</p> <ul> <li>Dotplots - Simple and precise</li> <li>Stemplots - Quick and shows actual values</li> <li>Histograms - Great for larger datasets</li> </ul> <p>More importantly, you'll learn to describe what you see. Is the data symmetric or skewed? Does it have one peak or two? Are there any unusual values lurking at the edges? Let's crack this nut!</p>"},{"location":"chapters/03-displaying-quantitative-data/#dotplots-your-first-data-portrait","title":"Dotplots: Your First Data Portrait","text":"<p>A dotplot is exactly what it sounds like: you put a dot above a number line for each value in your dataset. If you have repeated values, you stack the dots on top of each other. Simple, right?</p> <p>Let's say your AP Statistics class of 15 students measured how many hours they studied last week. The data looks like this:</p> Student Hours Studied 1 4 2 6 3 5 4 8 5 5 6 7 7 5 8 6 9 3 10 6 11 5 12 9 13 6 14 5 15 7 <p>To create a dotplot, you draw a horizontal number line covering your range of values (3 to 9 hours), then place a dot above the appropriate value for each observation. When multiple students studied the same number of hours, you stack the dots vertically.</p>"},{"location":"chapters/03-displaying-quantitative-data/#diagram-interactive-dotplot-builder","title":"Diagram: Interactive Dotplot Builder","text":"Interactive Dotplot Builder MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Taxonomy Verb: demonstrate</p> <p>Learning Objective: Students will demonstrate how to construct a dotplot by clicking to add data points and observing how the visual representation changes.</p> <p>Instructional Rationale: An Apply-level objective requires students to actively construct rather than passively observe. Clicking to add dots reinforces the one-to-one correspondence between data values and visual elements.</p> <p>Canvas Layout: - Width: 100% of container (responsive) - Height: 450px - Top section (350px): Dotplot visualization area with number line - Bottom section (100px): Controls and data entry</p> <p>Visual Elements: - Horizontal number line from 0 to 15 (adjustable scale) - Grid lines at each integer value - Dots as filled circles (radius 12px) in blue - Dots stack vertically with 2px gap when values repeat - Current dataset displayed as comma-separated values - Count of total observations shown</p> <p>Interactive Controls: - Click anywhere on the number line to add a dot at that value - \"Clear All\" button to reset the dotplot - \"Load Sample Data\" button to populate with study hours example - \"Random Dataset\" button to generate 10-20 random values - Radio buttons to select dot size (small/medium/large)</p> <p>Default Parameters: - Empty dotplot on load - Number line range: 0-15 - Dot color: #4A90D9 (blue) - Medium dot size selected</p> <p>Behavior: - When user clicks on number line, snap to nearest integer and add dot - Dots stack automatically when values repeat - Display running count of observations - Show data values as text below the visualization - Highlight the most recently added dot with a brief animation</p> <p>Implementation: p5.js with canvas-based controls</p> <p>Why use a dotplot? Dotplots are fantastic when you have a small to moderate amount of data (usually fewer than 50 observations) and you want to see every individual value. You can spot patterns, gaps, and clusters at a glance.</p> <p>Sylvia Says</p> <p>\"I use dotplots for my weekly acorn counts because I can see exactly which days were bonanza days and which were duds. When you can see every data point, nothing hides from you!\"</p>"},{"location":"chapters/03-displaying-quantitative-data/#stemplots-data-with-structure","title":"Stemplots: Data with Structure","text":"<p>A stemplot (also called a stem-and-leaf plot) is a clever way to organize data that gives you the best of both worlds: you get a visual shape and you keep the actual values. Think of it as a dotplot that tells you exactly what each dot represents.</p> <p>In a stemplot, each data value is split into a stem (typically all digits except the last one) and a leaf (typically the last digit). The stems are listed vertically, and the leaves are written horizontally next to their stem.</p> <p>Let's use test scores from a recent quiz (out of 100 points):</p> <p>67, 72, 74, 78, 81, 82, 85, 85, 86, 89, 91, 93, 94, 97</p> <p>Here's the stemplot:</p> <pre><code>Stem | Leaf\n  6  | 7\n  7  | 2 4 8\n  8  | 1 2 5 5 6 9\n  9  | 1 3 4 7\n\nKey: 7|2 means 72 points\n</code></pre> <p>Notice how the stemplot looks like a histogram turned on its side! You can see that most scores clustered in the 80s, with a lone score in the 60s.</p> <p>Important conventions for stemplots:</p> <ul> <li>Always include a key that explains how to read the values</li> <li>List leaves in order from smallest to largest (left to right)</li> <li>Every stem should be listed, even if it has no leaves (to show gaps)</li> <li>Use equal spacing between leaves for accurate visual comparison</li> </ul> Feature Dotplot Stemplot Shows individual values No Yes Good for comparing two groups Possible Yes (back-to-back) Best data size 10-50 values 15-100 values Easy to construct by hand Very easy Easy Preserves exact data No Yes"},{"location":"chapters/03-displaying-quantitative-data/#diagram-stemplot-constructor","title":"Diagram: Stemplot Constructor","text":"Stemplot Constructor MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Taxonomy Verb: interpret</p> <p>Learning Objective: Students will interpret how data values are decomposed into stems and leaves, understanding the organizational structure of a stemplot.</p> <p>Instructional Rationale: Step-through visualization with concrete data is appropriate because the Understand/interpret objective requires learners to see exactly how each value maps to its stem-leaf representation. Animation would obscure the digit-splitting process.</p> <p>Data Visibility Requirements: - Stage 1: Show raw data value (e.g., \"85\") - Stage 2: Show decomposition arrow: 85 \u2192 stem: 8, leaf: 5 - Stage 3: Show stem column with \"8\" highlighted - Stage 4: Show leaf \"5\" being placed next to stem \"8\" - Stage 5: Show complete stemplot with new value integrated</p> <p>Canvas Layout: - Width: 100% of container (responsive) - Height: 500px - Left panel (60%): Stemplot display area - Right panel (40%): Data entry and controls</p> <p>Visual Elements: - Vertical stem column with dividing line - Horizontal leaf rows extending from each stem - Current data value being processed highlighted in yellow - Stem-leaf decomposition shown with arrow animation - Key displayed at bottom of stemplot - Sample dataset shown in right panel</p> <p>Interactive Controls: - Text input field to enter new data values (two or three digits) - \"Add Value\" button - \"Step Through\" button to watch decomposition process - \"Auto-Build\" button to animate full construction - \"Clear Stemplot\" button - Dropdown for sample datasets: Quiz Scores, Ages, Heights (cm)</p> <p>Default Parameters: - Empty stemplot on load - Speed slider for auto-build: 500ms-2000ms per value - Show decomposition animation by default</p> <p>Behavior: - When value entered, highlight it and show stem-leaf split - Animate leaf placement in correct sorted position - If leaf position requires shifting existing leaves, show this - Display running statistics: count, min, max - Key updates automatically based on data range</p> <p>Implementation: p5.js with canvas-based controls</p> <p>Back-to-back stemplots are a powerful variation when you want to compare two groups. The stems go in the middle, and leaves extend to both sides. For example, comparing quiz scores between two class periods:</p> <pre><code>Period 1 | Stem | Period 2\n         |   6  | 7\n    8  2 |   7  | 4 8 9\n9 7 5 2  |   8  | 1 5 5 6\n    4 1  |   9  | 1 3\n\nKey: Period 1: 2|7 means 72    Period 2: 7|4 means 74\n</code></pre>"},{"location":"chapters/03-displaying-quantitative-data/#histograms-the-workhorse-of-data-display","title":"Histograms: The Workhorse of Data Display","text":"<p>When you have lots of data, dotplots and stemplots become unwieldy. Imagine trying to draw 500 dots or organize 500 leaves! This is where histograms come to the rescue.</p> <p>A histogram divides the data into bins (also called intervals or classes) and displays the count or frequency of observations in each bin as a bar. Unlike bar graphs for categorical data, histogram bars touch each other because the quantitative variable is continuous.</p> <p>Consider this dataset of 40 test scores:</p> <p>52, 55, 58, 61, 63, 65, 67, 68, 69, 70, 71, 72, 72, 73, 74, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99</p> <p>If we use bins of width 10 (50-59, 60-69, 70-79, etc.), we count how many values fall in each bin:</p> Bin Count 50-59 3 60-69 6 70-79 10 80-89 10 90-99 11 <p>Then we draw bars with heights equal to these counts. The bars touch because there's no gap between 59 and 60, or between 69 and 70.</p>"},{"location":"chapters/03-displaying-quantitative-data/#diagram-interactive-histogram-explorer","title":"Diagram: Interactive Histogram Explorer","text":"Interactive Histogram Explorer MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Taxonomy Verb: examine</p> <p>Learning Objective: Students will examine how changing bin width affects the appearance and interpretation of a histogram, understanding the tradeoffs between detail and pattern visibility.</p> <p>Instructional Rationale: An Analyze-level objective requires students to explore parameter changes and observe effects. Interactive exploration with immediate visual feedback allows students to discover the relationship between bin width and histogram appearance.</p> <p>Canvas Layout: - Width: 100% of container (responsive) - Height: 550px - Main area (400px): Histogram visualization - Control area (150px): Sliders and buttons</p> <p>Visual Elements: - Histogram with bars touching (no gaps) - X-axis with bin labels and tick marks - Y-axis with frequency count - Bin edges shown as vertical lines - Current bin width displayed prominently - Summary statistics panel: n, min, max, range</p> <p>Interactive Controls: - Bin width slider: range from 2 to 20 (for typical 0-100 data) - Number of bins display (calculated from width) - Dropdown to select dataset:   - Test Scores (n=40, range 50-100)   - Heights in inches (n=100, range 58-78)   - Daily Temperatures (n=365, range 20-95)   - Custom (enter comma-separated values) - Checkbox: Show frequency vs relative frequency - Checkbox: Show data points as dots above histogram - \"Reset to Default\" button</p> <p>Default Parameters: - Test Scores dataset loaded - Bin width: 10 - Show frequency (not relative frequency) - Hide individual data points</p> <p>Behavior: - When bin width changes, histogram redraws smoothly - Display warning when bins too narrow: \"Too many bins may show noise\" - Display warning when bins too wide: \"Too few bins may hide patterns\" - Highlight the current bin when hovering - Show count and percentage for hovered bin - Bars colored with gradient from light to dark blue</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/03-displaying-quantitative-data/#choosing-bin-width","title":"Choosing Bin Width","text":"<p>Here's a genuine puzzle in statistics: there's no single \"correct\" bin width for a histogram. Choosing bin width involves balancing two competing goals:</p> <ul> <li>Too narrow bins: You see too much detail, including random noise that doesn't represent real patterns</li> <li>Too wide bins: You lose important features and everything looks too smooth</li> </ul> <p>A common starting rule is to use between 5 and 15 bins for most datasets. Some textbooks suggest using the square root of the sample size as a starting point. But honestly? The best approach is to try several different bin widths and see which one tells the clearest story about your data.</p> <p>Watch Out!</p> <p>Two histograms of the same data can look completely different if they use different bin widths. Always check the x-axis scale and bin width before comparing histograms!</p> <p>Sylvia's advice: \"When I'm choosing bin width for my seasonal acorn data, I always ask myself: 'Does this histogram help me see the pattern, or is it confusing me?' If it looks like a jagged mountain range, my bins are probably too narrow. If it looks like a flat mesa, they're probably too wide. I'm looking for gentle rolling hills that reveal the true shape.\"</p>"},{"location":"chapters/03-displaying-quantitative-data/#the-shape-of-distributions","title":"The Shape of Distributions","text":"<p>Now comes the really fun part: learning to describe what you see! When statisticians look at a distribution (the overall pattern of data in a graph), they describe three key features:</p> <ol> <li>Shape - The overall form of the distribution</li> <li>Center - Where the \"middle\" of the data is located</li> <li>Spread - How variable or spread out the data is</li> </ol> <p>We'll focus on shape in this chapter (center and spread are coming in Chapter 4!). The shape of distribution tells us about the overall pattern in our data.</p>"},{"location":"chapters/03-displaying-quantitative-data/#symmetric-distributions","title":"Symmetric Distributions","text":"<p>A distribution is symmetric if the left side is roughly a mirror image of the right side. If you could fold the histogram down the middle, both sides would match up. Many natural phenomena produce symmetric distributions, including heights of adults, standardized test scores, and the number of petals on daisies.</p>"},{"location":"chapters/03-displaying-quantitative-data/#diagram-symmetric-distribution-identifier","title":"Diagram: Symmetric Distribution Identifier","text":"Symmetric Distribution Identifier <p>Type: microsim</p> <p>Bloom Taxonomy: Remember (L1) Bloom Taxonomy Verb: recognize</p> <p>Learning Objective: Students will recognize symmetric distributions by comparing the visual appearance of the left and right sides of histograms.</p> <p>Instructional Rationale: A Remember-level objective is best served by clear examples with immediate feedback. Students need to build mental models of what symmetry looks like before analyzing more complex shapes.</p> <p>Canvas Layout: - Width: 100% of container (responsive) - Height: 400px - Main area (300px): Histogram display - Bottom area (100px): Classification buttons and feedback</p> <p>Visual Elements: - Histogram with 10-15 bars - Vertical dashed line at center - Fold animation showing left side flipping to right - Green checkmark or red X for feedback - Score counter: Correct / Total</p> <p>Interactive Controls: - \"Symmetric\" button - \"Not Symmetric\" button - \"Next Distribution\" button - \"Show Fold\" button to animate folding - Difficulty selector: Easy (obvious), Medium (subtle), Hard (close calls)</p> <p>Default Parameters: - Easy difficulty selected - Score starts at 0/0 - Random symmetric or asymmetric distribution generated</p> <p>Behavior: - Display random histogram (50% chance symmetric) - When student clicks button, show immediate feedback - \"Show Fold\" animates left side folding over center line - Track correct responses and display running score - After 10 questions, show summary with commonly missed cases</p> <p>Sample Distributions to Include: - Normal-shaped (symmetric) - Slightly skewed (not symmetric) - Bimodal symmetric - Bimodal asymmetric - Uniform (symmetric)</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/03-displaying-quantitative-data/#skewed-distributions","title":"Skewed Distributions","text":"<p>Many real-world datasets are not symmetric. Instead, they have a tail that stretches out in one direction more than the other. We call these distributions skewed.</p> <p>Skewed right (also called positively skewed): The tail stretches toward the higher values (to the right). Common examples include:</p> <ul> <li>Income and wealth data (most people earn modest amounts, but a few earn millions)</li> <li>Home prices (most homes are affordable, but some mansions cost millions)</li> <li>Time to complete a task (most finish quickly, some take much longer)</li> </ul> <p>Skewed left (also called negatively skewed): The tail stretches toward the lower values (to the left). Examples include:</p> <ul> <li>Age at retirement (most retire around 65, but some retire much earlier)</li> <li>Test scores on an easy exam (most score high, but a few score very low)</li> <li>Age at death for adults (most live to old age, but some die young)</li> </ul> <p>Memory Trick</p> <p>\"The skew is where the tail flies to!\" If the tail goes right, it's skewed right. If the tail goes left, it's skewed left. Picture a bird with a long tail feather pointing in the direction of the skew.</p>"},{"location":"chapters/03-displaying-quantitative-data/#diagram-skewness-explorer","title":"Diagram: Skewness Explorer","text":"Skewness Explorer MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Taxonomy Verb: classify</p> <p>Learning Objective: Students will classify distributions as symmetric, skewed left, or skewed right by identifying the direction of the longer tail.</p> <p>Instructional Rationale: Understanding skewness requires seeing multiple examples with varying degrees of asymmetry. Interactive classification with immediate feedback builds recognition skills before formal analysis.</p> <p>Data Visibility Requirements: - Stage 1: Show histogram of dataset - Stage 2: Highlight the \"peak\" region - Stage 3: Show arrows pointing to each tail - Stage 4: Compare tail lengths visually - Stage 5: Reveal classification with explanation</p> <p>Canvas Layout: - Width: 100% of container (responsive) - Height: 480px - Left side (70%): Histogram display with annotations - Right side (30%): Classification panel and context</p> <p>Visual Elements: - Histogram with clear bars - Arrows showing tail directions - Highlighted peak region - Tail length comparison overlay - Real-world context label (e.g., \"Income Data\", \"Test Scores\") - Visual aid showing direction of skew</p> <p>Interactive Controls: - Three classification buttons: \"Skewed Left\", \"Symmetric\", \"Skewed Right\" - \"Show Hint\" button (highlights tails) - \"Show Answer\" button - \"Next Example\" button - Slider to adjust skewness of a sample distribution - Toggle: \"Show real-world examples\" vs \"Random shapes\"</p> <p>Default Parameters: - Start with random distribution - Hints hidden - Real-world context mode</p> <p>Behavior: - Display distribution with context (income, ages, scores, etc.) - When student classifies, show correct answer with explanation - \"Show Hint\" draws arrows on the tails - Slider mode: adjust skewness from -2 to +2 and watch shape change - Track accuracy across examples</p> <p>Sample Contexts: - Household Income (skewed right) - Easy Exam Scores (skewed left) - Heights of Adults (symmetric) - Waiting Time at DMV (skewed right) - Age at Retirement (skewed left) - Weights of Newborns (symmetric)</p> <p>Implementation: p5.js with canvas-based controls</p> <p>Here's a comparison of the three main shapes:</p> Shape Left Tail Right Tail Peak Location Examples Symmetric Short Short (equal) Center Heights, IQ scores Skewed Right Short Long Left side Income, home prices Skewed Left Long Short Right side Easy test scores, retirement age"},{"location":"chapters/03-displaying-quantitative-data/#unimodal-bimodal-and-uniform-distributions","title":"Unimodal, Bimodal, and Uniform Distributions","text":"<p>The mode of a distribution refers to its peak or peaks. Describing the number of modes is another important aspect of shape.</p> <p>A unimodal distribution has a single clear peak. Most of the distributions you'll encounter are unimodal. Think of test scores in a class, heights of students, or Sylvia's daily acorn counts.</p> <p>A bimodal distribution has two distinct peaks. This often suggests that your data comes from two different groups! Examples include:</p> <ul> <li>Heights of adults (separate peaks for males and females)</li> <li>Eruption times at Old Faithful (short eruptions around 2 minutes, long ones around 4.5 minutes)</li> <li>Ages at a community center event (kids and grandparents, but few middle-aged adults)</li> </ul> <p>Why Two Peaks?</p> <p>When you see a bimodal distribution, your first thought should be: \"Is this actually two groups mixed together?\" If so, you might want to analyze them separately!</p> <p>A uniform distribution has no peaks at all; every value (or range of values) occurs with roughly equal frequency. Examples include:</p> <ul> <li>Rolling a fair die (each number 1-6 appears equally often)</li> <li>Birthdays throughout the year (roughly equal in each month)</li> <li>Random number generators (designed to be uniform)</li> </ul>"},{"location":"chapters/03-displaying-quantitative-data/#diagram-distribution-shape-gallery","title":"Diagram: Distribution Shape Gallery","text":"Distribution Shape Gallery <p>Type: infographic</p> <p>Bloom Taxonomy: Remember (L1) Bloom Taxonomy Verb: identify</p> <p>Learning Objective: Students will identify the key characteristics of unimodal, bimodal, and uniform distributions through visual comparison.</p> <p>Purpose: Provide a reference gallery showing the visual characteristics of each distribution type with interactive exploration.</p> <p>Layout: - Width: 100% of container (responsive) - Height: 450px - Three columns, one for each distribution type - Each column shows example histogram with labels</p> <p>Visual Elements: - Three histograms side by side: Unimodal, Bimodal, Uniform - Each histogram labeled with:   - Distribution name   - Key visual feature (peak count)   - Real-world example - Hover over each to see additional examples - Peak regions highlighted with subtle shading</p> <p>Interactive Features: - Click on any histogram to see larger version with more detail - Hover shows tooltip with 2-3 additional real-world examples - \"Shuffle Examples\" button to see different datasets with same shapes - Quiz mode: \"Which type is this?\" with random distribution</p> <p>Color Scheme: - Unimodal: Blue gradient - Bimodal: Purple gradient - Uniform: Green gradient - Consistent styling for visual learning</p> <p>Content for Each Type: Unimodal: - Visual: Clear single peak in center - Examples: Test scores, heights, weights - Key phrase: \"One main cluster\"</p> <p>Bimodal: - Visual: Two distinct peaks with valley between - Examples: Old Faithful eruptions, mixed populations - Key phrase: \"Two separate groups\"</p> <p>Uniform: - Visual: Flat across all values - Examples: Dice rolls, random numbers - Key phrase: \"All values equally likely\"</p> <p>Implementation: p5.js with hover effects and click handling</p>"},{"location":"chapters/03-displaying-quantitative-data/#outliers-the-unusual-suspects","title":"Outliers: The Unusual Suspects","text":"<p>An outlier is an observation that falls notably far from the main pattern of the data. Outliers are important because they can:</p> <ul> <li>Represent genuine unusual cases worth investigating</li> <li>Result from measurement or recording errors</li> <li>Dramatically affect statistical calculations</li> </ul> <p>Sylvia shares a story: \"One autumn, I recorded collecting 247 acorns in a single day. That was WAY more than my usual 20-40. At first, I thought I'd made a counting error. But then I remembered, that was the day the old oak tree by the library finally dropped all its acorns at once! The outlier was real, and it had a fascinating story behind it.\"</p> <p>When you spot an outlier, don't automatically throw it out! Instead, investigate:</p> <ol> <li>Is the value a typo or recording error?</li> <li>Is there a special explanation for this unusual value?</li> <li>Does the outlier represent a different population?</li> </ol>"},{"location":"chapters/03-displaying-quantitative-data/#identifying-outliers-visually","title":"Identifying Outliers Visually","text":"<p>Identifying outliers starts with looking at your graphs. On a dotplot, stemplot, or histogram, outliers appear as:</p> <ul> <li>Isolated dots separated from the main cluster</li> <li>Leaves standing alone on a stem far from others</li> <li>Bars separated by empty bins from the main group</li> </ul> <p>Later in this course, you'll learn a mathematical method called the 1.5 IQR rule for formally identifying outliers. For now, focus on visual identification: if a value stands apart from the crowd, it deserves attention.</p>"},{"location":"chapters/03-displaying-quantitative-data/#diagram-outlier-detective-game","title":"Diagram: Outlier Detective Game","text":"Outlier Detective Game MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Taxonomy Verb: distinguish</p> <p>Learning Objective: Students will distinguish between outliers and non-outliers by examining visual separation from the main distribution and considering context.</p> <p>Instructional Rationale: Identifying outliers requires analytical judgment. Interactive practice with varying degrees of separation helps students develop intuition for what constitutes \"notably far\" from the main pattern.</p> <p>Canvas Layout: - Width: 100% of container (responsive) - Height: 500px - Main area (380px): Interactive dotplot or histogram - Control area (120px): Game interface</p> <p>Visual Elements: - Dotplot or histogram of dataset - Points that can be clicked to select as outliers - Selected points highlighted in red - Score panel showing current round and total score - Context description for each dataset - \"Reveal Answer\" overlay showing correct outliers</p> <p>Interactive Controls: - Click on points/bars to select/deselect as outliers - \"Submit Answer\" button - \"Reveal Correct Answer\" button (after submission) - \"Next Challenge\" button - Difficulty slider: Easy (obvious gaps), Medium (moderate separation), Hard (borderline cases) - Toggle between dotplot and histogram view</p> <p>Default Parameters: - Medium difficulty - Dotplot view - Round 1 of 10</p> <p>Behavior: - Generate dataset with 0-3 outliers - Display context (e.g., \"Heights of basketball players\") - Player clicks to select suspected outliers - On submit: compare to correct answer, show feedback - Award points: +10 for each correct identification, -5 for false positives - After 10 rounds, show final score and common mistakes</p> <p>Sample Datasets with Context: - Test scores (outlier: absent student scored 0) - Ages at birthday party (outlier: parent among children) - Monthly rainfall (outlier: hurricane month) - Commute times (outlier: car broke down) - Heights (outlier: measurement error in wrong units)</p> <p>Scoring Feedback Messages: - Perfect: \"Sharp eye! You spotted all outliers.\" - Missed some: \"Look for values far from the main cluster.\" - False positive: \"That value is unusual but not separated enough.\"</p> <p>Implementation: p5.js with click detection and game state management</p>"},{"location":"chapters/03-displaying-quantitative-data/#why-outliers-matter","title":"Why Outliers Matter","text":"<p>Outliers aren't just statistical curiosities; they can have profound effects on your analysis:</p> <ul> <li>Mean: Extremely sensitive to outliers. One millionaire in a room of minimum-wage workers dramatically increases the average income.</li> <li>Standard deviation: Also very sensitive to outliers.</li> <li>Median: Resistant to outliers. The middle value stays stable even with extreme values at the ends.</li> </ul> <p>This sensitivity is one reason why describing the shape of your distribution matters so much. For skewed distributions with outliers, the median often tells a more representative story than the mean.</p> <p>Consider these two datasets of home prices in a neighborhood:</p> Dataset A Dataset B $250,000 $250,000 $275,000 $275,000 $280,000 $280,000 $290,000 $290,000 $300,000 $2,500,000 <p>Dataset A Mean: $279,000 (reasonable \"typical\" value) Dataset B Mean: $719,000 (misleading due to mansion!)</p> <p>The mansion in Dataset B is an outlier that pulls the mean way up, making it a poor representation of what a \"typical\" house costs in that neighborhood.</p>"},{"location":"chapters/03-displaying-quantitative-data/#putting-it-all-together-describing-distributions","title":"Putting It All Together: Describing Distributions","text":"<p>When you describe a distribution, you should address the \"Big Three\" characteristics. We use the acronym SOCS to remember them (with an extra S for unusual features):</p> <ul> <li>Shape: Is it symmetric, skewed left, or skewed right? Unimodal, bimodal, or uniform?</li> <li>Outliers: Are there any unusual values separated from the main pattern?</li> <li>Center: Where is the \"typical\" value? (We'll calculate this precisely in Chapter 4)</li> <li>Spread: How variable are the data? Are values tightly clustered or widely dispersed? (Also coming in Chapter 4)</li> </ul> <p>Always describe distributions in context. Don't just say \"The distribution is skewed right\"; say \"The distribution of household incomes is skewed right, with most households earning between $40,000 and $80,000, but a long tail stretching up to $200,000 or more.\"</p>"},{"location":"chapters/03-displaying-quantitative-data/#diagram-socs-description-builder","title":"Diagram: SOCS Description Builder","text":"SOCS Description Builder MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Create (L6) Bloom Taxonomy Verb: compose</p> <p>Learning Objective: Students will compose complete distribution descriptions using the SOCS framework, selecting appropriate terminology and writing contextual interpretations.</p> <p>Instructional Rationale: A Create-level objective requires students to produce original descriptions. Building descriptions from components scaffolds the process while still requiring synthesis and contextual interpretation.</p> <p>Canvas Layout: - Width: 100% of container (responsive) - Height: 520px - Left panel (55%): Histogram display with context - Right panel (45%): Description builder interface</p> <p>Visual Elements: - Histogram of dataset with context label - SOCS checklist with dropdown menus - Text preview area showing composed description - Example descriptions for reference - Progress indicator (which SOCS elements completed)</p> <p>Interactive Controls: - Dropdown: Shape (Symmetric / Skewed Left / Skewed Right) - Dropdown: Modality (Unimodal / Bimodal / Uniform) - Dropdown: Outliers (None / Low outliers / High outliers / Both) - Slider or text input: Approximate center value - Slider or text input: Approximate spread description - Text area for additional context notes - \"Generate Description\" button - \"Compare to Expert\" button - \"New Dataset\" button</p> <p>Default Parameters: - Random dataset with context loaded - All dropdowns unselected - Empty text preview</p> <p>Behavior: - Display histogram with context (e.g., \"Waiting times at coffee shop\") - As student makes selections, preview text updates in real-time - Description template: \"The distribution of [context] is [shape] and [modality]. [Outlier statement]. The center appears to be around [value] with [spread description].\" - \"Compare to Expert\" shows model answer for feedback - Track which SOCS elements are addressed</p> <p>Sample Contexts and Expected Descriptions: - Coffee shop wait times: Skewed right, unimodal, one high outlier - Test scores (easy exam): Skewed left, unimodal, low outlier - Heights of mixed group: Symmetric (or bimodal), unimodal, no outliers - Random die rolls: Uniform, no outliers</p> <p>Expert Description Examples: \"The distribution of wait times at the coffee shop is skewed right and unimodal, with most customers waiting between 2 and 5 minutes. There is one outlier at 15 minutes, which may represent a complex order or staffing issue. The center appears to be around 3 minutes.\"</p> <p>Implementation: p5.js with text composition and real-time preview</p>"},{"location":"chapters/03-displaying-quantitative-data/#choosing-the-right-display","title":"Choosing the Right Display","text":"<p>With three display types to choose from, how do you decide which one to use? Here's a handy guide:</p> Situation Best Choice Why Small dataset (&lt; 25 values) Dotplot See every individual value Need exact values preserved Stemplot Shows actual data, not just shape Moderate dataset (20-100 values) Stemplot or Histogram Both work well Large dataset (&gt; 50 values) Histogram Dotplots get too crowded Comparing two groups Back-to-back stemplot Easy side-by-side comparison Quick sketch by hand Stemplot Fastest to draw accurately Presenting to an audience Histogram Most people can read it easily <p>Sylvia's Rule of Thumb</p> <p>\"When in doubt, try more than one! I often make both a stemplot and a histogram of the same data. Sometimes one reveals patterns that the other misses. Different perspectives, different insights!\"</p>"},{"location":"chapters/03-displaying-quantitative-data/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":"<p>As you practice creating and interpreting graphs, watch out for these common pitfalls:</p> <p>When creating histograms:</p> <ul> <li>Don't leave gaps between bars (histogram bars should touch)</li> <li>Don't use unequal bin widths unless you have a specific reason</li> <li>Always label your axes and include a title</li> </ul> <p>When reading distributions:</p> <ul> <li>Don't confuse \"skewed right\" with having more values on the right. Skewness describes the TAIL direction, not where most values are!</li> <li>Don't forget to consider the context when identifying outliers</li> <li>Don't assume every unusual value is an error; some are genuine</li> </ul> <p>When describing distributions:</p> <ul> <li>Don't forget to describe in context (use the variable name and units)</li> <li>Don't skip any of the SOCS elements</li> <li>Don't just list numbers; interpret what they mean</li> </ul>"},{"location":"chapters/03-displaying-quantitative-data/#chapter-summary","title":"Chapter Summary","text":"<p>Let's squirrel away the key ideas from this chapter:</p> <p>Three ways to display quantitative data:</p> <ul> <li>Dotplots: Simple, show every value, best for small datasets</li> <li>Stemplots: Preserve exact values while showing shape, great for moderate datasets</li> <li>Histograms: Use bins to group data, essential for large datasets</li> </ul> <p>Describing shape:</p> <ul> <li>Symmetric: Left and right sides mirror each other</li> <li>Skewed right: Long tail stretches toward higher values</li> <li>Skewed left: Long tail stretches toward lower values</li> <li>Unimodal: One peak</li> <li>Bimodal: Two peaks (often indicates two groups)</li> <li>Uniform: Flat, all values equally likely</li> </ul> <p>Outliers:</p> <ul> <li>Values that fall notably far from the main pattern</li> <li>Can be errors OR genuine unusual cases</li> <li>Always investigate before removing</li> <li>Strongly affect mean and standard deviation</li> </ul> <p>The SOCS framework:</p> <ul> <li>Shape: Symmetric or skewed? Unimodal or bimodal?</li> <li>Outliers: Any unusual values?</li> <li>Center: Where's the typical value?</li> <li>Spread: How variable are the data?</li> </ul> <p>Sylvia's parting words: \"You've learned to see data in a whole new way! A list of numbers is now a story waiting to be told. Is it symmetric or does it lean one way? Is there a lonely outlier with a tale to tell? Next chapter, we'll add numbers to our descriptions and learn to measure center and spread precisely. But for now, practice your graphing skills. Every acorn I count becomes part of a distribution, and now you can see the patterns too!\"</p>"},{"location":"chapters/03-displaying-quantitative-data/#practice-problems","title":"Practice Problems","text":"Question 1: Which display would you choose? <p>You have test scores for 200 students on a standardized exam. Which display type would be most appropriate?</p> <p>Answer: A histogram would be most appropriate. With 200 observations, a dotplot would be too crowded (200 stacked dots!) and a stemplot would have too many leaves. A histogram efficiently summarizes this larger dataset while still showing the overall shape.</p> Question 2: Identify the skewness <p>A dataset of annual income for residents of a city shows most people earning between $35,000 and $75,000, with a small number of residents earning over $500,000. What is the likely shape of this distribution?</p> <p>Answer: This distribution is skewed right (positively skewed). The main cluster of values is at the lower end (\\(35,000-\\)75,000), with a long tail stretching toward the high-income outliers above $500,000. Remember: the skew direction matches where the tail goes, not where most values are.</p> Question 3: Is this an outlier? <p>In a dataset of marathon finish times, most runners complete the race between 3.5 and 5.5 hours. One runner finished in 2.1 hours. Is this an outlier? Should it be removed?</p> <p>Answer: Yes, 2.1 hours is an outlier because it's notably separated from the main cluster of finish times. However, it should NOT be removed! This is likely a legitimate value, an elite runner who finished much faster than recreational runners. This outlier tells us something important about the composition of the race participants.</p> Question 4: Bimodal or not? <p>A histogram of heights for a co-ed volleyball team shows two peaks: one around 5'6\" and another around 6'2\". Is this bimodal distribution surprising? What might explain it?</p> <p>Answer: This bimodal distribution is not surprising at all! The two peaks likely represent the two different populations mixed in the dataset: female players (clustering around 5'6\") and male players (clustering around 6'2\"). When you see a bimodal distribution, ask yourself: \"Could this be two groups combined?\" In this case, it clearly is.</p>"},{"location":"chapters/04-numerical-summaries/","title":"Numerical Summaries","text":""},{"location":"chapters/04-numerical-summaries/#summary","title":"Summary","text":"<p>This chapter introduces the numerical measures used to describe distributions. Students will learn about measures of center (mean, median, mode), measures of spread (range, IQR, standard deviation, variance), and how to calculate and interpret these statistics. The five-number summary and boxplots provide powerful tools for comparing distributions.</p>"},{"location":"chapters/04-numerical-summaries/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 18 concepts from the learning graph:</p> <ol> <li>Center of Distribution</li> <li>Spread of Distribution</li> <li>Mean</li> <li>Median</li> <li>Mode</li> <li>Resistant Measure</li> <li>Comparing Mean and Median</li> <li>Range</li> <li>Interquartile Range</li> <li>Quartiles</li> <li>Five-Number Summary</li> <li>Boxplot</li> <li>Modified Boxplot</li> <li>Comparing Distributions</li> <li>Standard Deviation</li> <li>Variance</li> <li>Calculating Variance</li> <li>Percentile</li> </ol>"},{"location":"chapters/04-numerical-summaries/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Statistics</li> <li>Chapter 3: Displaying Quantitative Data</li> </ul>"},{"location":"chapters/04-numerical-summaries/#introduction-beyond-pictures-to-numbers","title":"Introduction: Beyond Pictures to Numbers","text":"<p>Histograms and stemplots tell a story about your data, but sometimes you need to summarize that story with just a few key numbers. Imagine trying to describe how your class did on a test. You could show everyone a histogram, or you could simply say, \"The average was 78, and most scores fell between 65 and 91.\" Both approaches have value, but numerical summaries give us precision that pictures alone can't provide.</p> <p>\"Let's crack this nut!\" as Sylvia would say. In this chapter, we're building your toolkit for describing any distribution with just a handful of carefully chosen numbers. By the end, you'll be able to look at any dataset and quickly communicate its essential features\u2014where the center is, how spread out the values are, and whether any unusual values deserve special attention.</p> <p>Think of numerical summaries as the vital statistics of your data. Just as a doctor checks your heart rate, blood pressure, and temperature to assess your health, statisticians use measures of center and spread to assess the \"health\" of a distribution.</p>"},{"location":"chapters/04-numerical-summaries/#the-center-of-a-distribution","title":"The Center of a Distribution","text":"<p>When someone asks, \"What's typical?\" for a dataset, they're really asking about the center of the distribution. The center is a single value that represents where the \"middle\" of the data falls. But here's the interesting part\u2014there's more than one way to find the middle, and different methods can give you different answers!</p> <p>The three most common measures of center are the mean, median, and mode. Each one answers the question \"What's typical?\" in a slightly different way, and choosing the right one depends on the shape of your distribution and what you're trying to communicate.</p> Measure What It Represents Best Used When Mean The balance point of the data Distribution is roughly symmetric Median The middle value when data is ordered Distribution is skewed or has outliers Mode The most frequently occurring value Describing categorical data or identifying peaks"},{"location":"chapters/04-numerical-summaries/#the-mean-adding-and-dividing","title":"The Mean: Adding and Dividing","text":"<p>The mean (often called the average) is probably the measure of center you've used most often. To find it, add up all the values and divide by how many values you have. In symbols:</p> \\[ \\bar{x} = \\frac{\\sum x_i}{n} \\] <p>That \\( \\bar{x} \\) (read as \"x-bar\") is the symbol for the sample mean. The Greek letter sigma (\\( \\sum \\)) means \"add up all of these,\" and \\( n \\) is the number of observations.</p> <p>Example: Five students scored 72, 85, 88, 90, and 95 on a quiz.</p> \\[ \\bar{x} = \\frac{72 + 85 + 88 + 90 + 95}{5} = \\frac{430}{5} = 86 \\] <p>The mean score is 86 points. Notice that no one actually scored 86\u2014the mean doesn't have to be a value in your dataset.</p> <p>Here's a helpful way to think about the mean: imagine your data values are weights placed along a number line on a seesaw. The mean is the point where the seesaw balances perfectly. This \"balance point\" interpretation explains why the mean is sensitive to extreme values\u2014a really heavy weight far from the center pulls the balance point in its direction.</p>"},{"location":"chapters/04-numerical-summaries/#diagram-mean-as-balance-point","title":"Diagram: Mean as Balance Point","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Interactive Balance Point Visualization <p>Type: MicroSim</p> <p>Learning objective: Students will understand that the mean represents the balance point of a distribution by manipulating data points and observing how the mean shifts in response (Bloom: Understanding).</p> <p>Visual elements: - A horizontal number line ranging from 0 to 100 - A triangular fulcrum (balance point) that can slide along the number line - Circular \"weights\" representing data points that can be dragged along the number line - The current mean value displayed prominently - A \"balanced/unbalanced\" indicator showing whether the fulcrum is at the mean</p> <p>Interactive controls: - Drag individual data points left or right to see the mean update in real-time - Add new data points by clicking on the number line - Remove data points by double-clicking them - Reset button to restore original dataset - \"Show calculation\" toggle that displays the sum and division</p> <p>Behavior: - When fulcrum is not at the mean, the beam tilts toward the heavier side - Moving a point farther from center causes larger shift in mean - Adding an extreme value dramatically shifts the balance point - Initial dataset: 5 points distributed roughly symmetrically</p> <p>Canvas size: 700 x 300 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-numerical-summaries/#the-median-finding-the-middle","title":"The Median: Finding the Middle","text":"<p>The median is the middle value when you arrange all observations in order from smallest to largest. If you have an odd number of observations, the median is literally the middle one. If you have an even number, the median is the average of the two middle values.</p> <p>Finding the Median:</p> <ol> <li>Arrange all values in order (smallest to largest)</li> <li>Count the observations: \\( n \\)</li> <li>If \\( n \\) is odd: median is the value in position \\( \\frac{n+1}{2} \\)</li> <li>If \\( n \\) is even: median is the average of values in positions \\( \\frac{n}{2} \\) and \\( \\frac{n}{2}+1 \\)</li> </ol> <p>Example (odd n): Quiz scores: 72, 85, 88, 90, 95</p> <p>Already in order. With \\( n = 5 \\) observations, the median is in position \\( \\frac{5+1}{2} = 3 \\).</p> <p>The median is 88.</p> <p>Example (even n): Test scores: 65, 72, 78, 81, 85, 92</p> <p>With \\( n = 6 \\) observations, we average positions 3 and 4.</p> <p>Median \\( = \\frac{78 + 81}{2} = 79.5 \\)</p> <p>Here's the key insight: the median cares only about position, not about how far away the extreme values are. If we changed that 92 to 192, the median would stay exactly the same at 79.5. This makes the median resistant to outliers.</p>"},{"location":"chapters/04-numerical-summaries/#the-mode-most-common-value","title":"The Mode: Most Common Value","text":"<p>The mode is simply the value that appears most frequently in your dataset. A distribution can have:</p> <ul> <li>One mode (unimodal)</li> <li>Two modes (bimodal)</li> <li>Multiple modes (multimodal)</li> <li>No mode (if all values appear equally often)</li> </ul> <p>The mode is the only measure of center that works for categorical data. You can't calculate the mean or median of eye colors, but you can identify that \"brown\" is the most common (the mode).</p> <p>For quantitative data, the mode is less commonly used because many datasets have no repeated values, making the mode undefined or not very meaningful.</p>"},{"location":"chapters/04-numerical-summaries/#the-spread-of-a-distribution","title":"The Spread of a Distribution","text":"<p>Knowing the center isn't enough. Consider two classes where the average test score is 80. In Class A, everyone scored between 78 and 82. In Class B, scores ranged from 45 to 100. These are very different situations! The spread (or variability) tells us how much the data values differ from one another.</p> <p>Think of spread as measuring the \"width\" of your distribution. A small spread means values cluster tightly together; a large spread means values are scattered widely.</p> Measure What It Captures Resistant? Range Distance from min to max No IQR Spread of the middle 50% Yes Standard Deviation Typical distance from mean No Variance Squared distance from mean No"},{"location":"chapters/04-numerical-summaries/#range-the-simplest-measure","title":"Range: The Simplest Measure","text":"<p>The range is the simplest measure of spread:</p> \\[ \\text{Range} = \\text{Maximum} - \\text{Minimum} \\] <p>For the quiz scores 72, 85, 88, 90, 95:</p> \\[ \\text{Range} = 95 - 72 = 23 \\] <p>The range is easy to calculate, but it has a major weakness: it uses only the two most extreme values and ignores everything in between. One outlier can dramatically inflate the range, making it an unreliable measure for many datasets.</p>"},{"location":"chapters/04-numerical-summaries/#quartiles-and-the-interquartile-range","title":"Quartiles and the Interquartile Range","text":"<p>To get a more robust picture of spread, we divide the data into four equal parts using quartiles.</p> <ul> <li>Q1 (First Quartile): 25% of data falls below this value</li> <li>Q2 (Second Quartile): 50% of data falls below this value (this is the median!)</li> <li>Q3 (Third Quartile): 75% of data falls below this value</li> </ul> <p>The Interquartile Range (IQR) measures the spread of the middle 50% of the data:</p> \\[ \\text{IQR} = Q_3 - Q_1 \\] <p>Finding Quartiles (by hand):</p> <ol> <li>Order the data and find the median (Q2)</li> <li>Q1 is the median of the lower half (values below Q2)</li> <li>Q3 is the median of the upper half (values above Q2)</li> </ol> <p>Example: Data: 12, 15, 18, 22, 25, 28, 30, 35, 42</p> <ul> <li>Median (Q2) = 25 (the 5th value of 9)</li> <li>Lower half: 12, 15, 18, 22 \u2192 Q1 = \\( \\frac{15+18}{2} = 16.5 \\)</li> <li>Upper half: 28, 30, 35, 42 \u2192 Q3 = \\( \\frac{30+35}{2} = 32.5 \\)</li> <li>IQR = 32.5 - 16.5 = 16</li> </ul> <p>The IQR tells us that the middle 50% of values spans 16 units. This is far more stable than the range because it's not affected by extreme values at either end.</p>"},{"location":"chapters/04-numerical-summaries/#diagram-understanding-quartiles","title":"Diagram: Understanding Quartiles","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Quartile Division Visualization <p>Type: Interactive Infographic</p> <p>Learning objective: Students will identify and interpret quartiles as values that divide a distribution into four equal parts (Bloom: Understanding).</p> <p>Visual elements: - Horizontal number line with data points displayed as dots - Color-coded regions:   - Red (0-25%): Below Q1   - Orange (25-50%): Q1 to Median   - Yellow (50-75%): Median to Q3   - Green (75-100%): Above Q3 - Vertical lines marking Q1, Median (Q2), and Q3 with labels - Percentage labels showing 25% in each region - Count of data points in each region</p> <p>Interactive controls: - Hover over any region to highlight it and show exact boundaries - Click on Q1, Median, or Q3 markers to see calculation details - Slider to change sample size (10 to 50 points) - \"Randomize data\" button to generate new dataset - Toggle between \"even spacing\" and \"realistic data\" modes</p> <p>Behavior: - Data points smoothly redistribute when sample size changes - Quartile markers animate to new positions - Tooltip shows exact value when hovering over any quartile marker</p> <p>Canvas size: 700 x 250 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-numerical-summaries/#percentiles-beyond-quartiles","title":"Percentiles: Beyond Quartiles","text":"<p>Quartiles divide data into four parts, but we can be even more precise using percentiles. The p-th percentile is the value below which p% of the data falls.</p> <ul> <li>The 25th percentile = Q1</li> <li>The 50th percentile = Median = Q2</li> <li>The 75th percentile = Q3</li> </ul> <p>Percentiles are everywhere in real life:</p> <ul> <li>Standardized test scores (\"You scored in the 85th percentile\")</li> <li>Growth charts at the pediatrician (\"Your child is in the 60th percentile for height\")</li> <li>Income distributions (\"The top 1%\")</li> </ul> <p>If you're in the 85th percentile on a test, it means you scored higher than 85% of test-takers. Note that this says nothing about your actual score\u2014only about how you compare to others.</p>"},{"location":"chapters/04-numerical-summaries/#the-five-number-summary","title":"The Five-Number Summary","text":"<p>The five-number summary provides a compact description of a distribution using just five values:</p> <ol> <li>Minimum \u2013 the smallest value</li> <li>Q1 \u2013 the first quartile (25th percentile)</li> <li>Median \u2013 the middle value (50th percentile)</li> <li>Q3 \u2013 the third quartile (75th percentile)</li> <li>Maximum \u2013 the largest value</li> </ol> <p>These five numbers capture the center (median), the spread of the middle half (Q1 and Q3), and the full extent of the data (min and max).</p> <p>Example: For the dataset 12, 15, 18, 22, 25, 28, 30, 35, 42:</p> Statistic Value Minimum 12 Q1 16.5 Median 25 Q3 32.5 Maximum 42 <p>\"Acorn for your thoughts?\" Here's why this summary is so powerful: with just five numbers, you can sketch the entire shape of a distribution. You know where the center is, how spread out the middle half is, and whether the tails stretch equally in both directions.</p>"},{"location":"chapters/04-numerical-summaries/#boxplots-visualizing-the-five-number-summary","title":"Boxplots: Visualizing the Five-Number Summary","text":"<p>A boxplot (also called a box-and-whisker plot) turns the five-number summary into a picture:</p> <ul> <li>A box stretches from Q1 to Q3</li> <li>A line inside the box marks the median</li> <li>\"Whiskers\" extend from the box to the minimum and maximum</li> </ul>"},{"location":"chapters/04-numerical-summaries/#diagram-anatomy-of-a-boxplot","title":"Diagram: Anatomy of a Boxplot","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Interactive Boxplot Builder <p>Type: MicroSim</p> <p>Learning objective: Students will construct and interpret boxplots by connecting numerical summary statistics to their visual representation (Bloom: Applying, Creating).</p> <p>Visual elements: - Data entry panel showing individual values or editable data points - Live-updating boxplot that responds to data changes - Labels for each component: Min, Q1, Median, Q3, Max, IQR - Horizontal number line with appropriate scale - Shaded box region from Q1 to Q3 - Vertical line at median within the box - Whiskers extending to min and max</p> <p>Interactive controls: - Drag data points to change values - Add/remove data points with click - Toggle labels on/off - Show/hide the five-number summary table - \"Generate random data\" button with distribution type selector (symmetric, right-skewed, left-skewed) - Animation speed slider for building the boxplot step-by-step</p> <p>Behavior: - Boxplot updates in real-time as data changes - Step-by-step mode shows construction process: sort data \u2192 find median \u2192 find quartiles \u2192 draw box \u2192 add whiskers - Highlighting each component when hovered - Color scheme: green cardigan color for box, auburn for median line</p> <p>Canvas size: 750 x 400 pixels, responsive design Implementation: p5.js with canvas-based controls</p> <p>Reading a Boxplot:</p> <ul> <li>The length of the box (Q3 - Q1) equals the IQR\u2014wider boxes mean more spread in the middle 50%</li> <li>The position of the median line within the box reveals skewness:</li> <li>Median closer to Q1? Right-skewed</li> <li>Median closer to Q3? Left-skewed</li> <li>Median in the middle? Roughly symmetric</li> <li>The whisker lengths show the range of each tail</li> </ul>"},{"location":"chapters/04-numerical-summaries/#modified-boxplots-and-outliers","title":"Modified Boxplots and Outliers","text":"<p>A modified boxplot handles outliers more carefully than a standard boxplot. Instead of always extending whiskers to the min and max, modified boxplots follow the 1.5 \u00d7 IQR rule:</p> <ol> <li>Calculate fences:</li> <li>Lower fence: \\( Q_1 - 1.5 \\times \\text{IQR} \\)</li> <li> <p>Upper fence: \\( Q_3 + 1.5 \\times \\text{IQR} \\)</p> </li> <li> <p>Whiskers extend only to the most extreme values within the fences</p> </li> <li> <p>Any values beyond the fences are plotted as individual points (outliers)</p> </li> </ol> <p>Example: For data with Q1 = 20, Q3 = 40: - IQR = 40 - 20 = 20 - Lower fence = 20 - 1.5(20) = -10 - Upper fence = 40 + 1.5(20) = 70</p> <p>Any values below -10 or above 70 would be plotted as outliers.</p> <p>Why 1.5 \u00d7 IQR? Statistician John Tukey chose this multiplier because it works well in practice. For normally distributed data, about 0.7% of observations would be flagged as outliers\u2014unusual enough to warrant investigation, but not so rare that we never see them.</p>"},{"location":"chapters/04-numerical-summaries/#diagram-modified-boxplot-outlier-detection","title":"Diagram: Modified Boxplot Outlier Detection","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Outlier Detection Visualization <p>Type: MicroSim</p> <p>Learning objective: Students will apply the 1.5 \u00d7 IQR rule to identify potential outliers in a dataset (Bloom: Applying, Analyzing).</p> <p>Visual elements: - Dataset displayed as points along a number line - Standard boxplot with box and whiskers - Dashed lines showing fence positions - Outliers displayed as individual points beyond fences - Labels showing: Q1, Q3, IQR, Lower Fence, Upper Fence - Color coding: normal points in green, outliers in red</p> <p>Interactive controls: - Drag existing points to change values - Add new points by clicking on the number line - Multiplier slider (adjustable from 1.0 to 3.0, default 1.5) - \"Show calculations\" toggle displaying fence formulas and values - Checkbox to toggle between standard and modified boxplot view</p> <p>Behavior: - As points are moved, outlier status updates in real-time - Points crossing fence boundaries change color with animation - Whiskers adjust to show the most extreme non-outlier values - Display count of outliers detected</p> <p>Canvas size: 700 x 350 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-numerical-summaries/#comparing-distributions-with-boxplots","title":"Comparing Distributions with Boxplots","text":"<p>One of the greatest strengths of boxplots is comparing multiple groups side by side. When you place boxplots next to each other on the same scale, differences in center, spread, and shape become immediately visible.</p> <p>What to Compare:</p> <ul> <li>Centers: Are the medians at different positions?</li> <li>Spreads: Which group has more variability (longer box, longer whiskers)?</li> <li>Shapes: Are some distributions skewed while others are symmetric?</li> <li>Outliers: Does one group have more unusual values?</li> </ul> <p>Example: Comparing test scores for three different class periods</p> Feature Period 1 Period 2 Period 3 Median 78 82 75 IQR 15 8 22 Outliers None 1 low None <p>Period 2 has both the highest center and the smallest spread\u2014a high-performing, consistent class. Period 3 has the most variability, suggesting a wider range of preparation levels.</p>"},{"location":"chapters/04-numerical-summaries/#diagram-side-by-side-boxplot-comparison","title":"Diagram: Side-by-Side Boxplot Comparison","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Multi-Group Boxplot Comparison Tool <p>Type: MicroSim</p> <p>Learning objective: Students will compare distributions across multiple groups by analyzing side-by-side boxplots (Bloom: Analyzing, Evaluating).</p> <p>Visual elements: - 2-4 parallel boxplots on a common scale - Shared horizontal axis with clear labels - Each boxplot with different color (consistent with Sylvia theme) - Group labels below each boxplot - Optional horizontal reference lines at key values - Summary statistics table showing min, Q1, median, Q3, max, IQR for each group</p> <p>Interactive controls: - Dropdown to select pre-loaded comparison datasets (e.g., \"Test Scores by Period\", \"Heights by Gender\", \"Salaries by Department\") - Toggle to show/hide outliers - Toggle to display connecting lines between medians - Checkbox to overlay all boxplots (transparency mode) - \"Randomize\" button to generate new comparison data</p> <p>Behavior: - Hovering over a boxplot highlights it and dims others - Clicking a boxplot displays its five-number summary prominently - Animation when switching between datasets - Written comparison hints appear based on visible differences</p> <p>Canvas size: 750 x 400 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-numerical-summaries/#standard-deviation-measuring-typical-distance-from-the-mean","title":"Standard Deviation: Measuring Typical Distance from the Mean","text":"<p>While the IQR focuses on the middle 50%, the standard deviation considers how far all values are from the mean. It answers the question: \"On average, how far do data points stray from the center?\"</p> <p>The logic behind standard deviation:</p> <ol> <li>Find how far each value is from the mean (these are called deviations)</li> <li>Square each deviation (to make them all positive)</li> <li>Average the squared deviations (this gives us variance)</li> <li>Take the square root (to return to original units)</li> </ol> <p>The Variance Formula:</p> \\[ s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1} \\] <p>The Standard Deviation Formula:</p> \\[ s = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}} \\] <p>\"My tail's tingling\u2014we're onto something!\" Here's the key insight: standard deviation tells you the typical distance from the mean. If the standard deviation is 10 points, most values are within about 10 points of the average\u2014some closer, some farther, but 10 gives you a reasonable expectation.</p>"},{"location":"chapters/04-numerical-summaries/#why-divide-by-n-1","title":"Why Divide by n-1?","text":"<p>You might wonder why we divide by \\( n-1 \\) instead of \\( n \\). This is called Bessel's correction, and here's the intuition:</p> <p>When we calculate deviations from \\( \\bar{x} \\), we're using the sample mean as our reference point. But \\( \\bar{x} \\) is calculated from the same data, so it's positioned to minimize the sum of squared deviations. This makes our deviations slightly too small on average. Dividing by \\( n-1 \\) instead of \\( n \\) corrects for this underestimation, giving us an unbiased estimate of the true population variance.</p> <p>Don't worry about this technicality too much\u2014just remember to use \\( n-1 \\) when calculating variance and standard deviation for sample data.</p>"},{"location":"chapters/04-numerical-summaries/#calculating-variance-and-standard-deviation","title":"Calculating Variance and Standard Deviation","text":"<p>Let's work through a complete example to see how variance and standard deviation are calculated.</p> <p>Dataset: Quiz scores of 6, 8, 10, 12, 14</p> <p>Step 1: Calculate the mean</p> \\[ \\bar{x} = \\frac{6 + 8 + 10 + 12 + 14}{5} = \\frac{50}{5} = 10 \\] <p>Step 2: Find each deviation from the mean</p> Value (\\( x_i \\)) Deviation (\\( x_i - \\bar{x} \\)) 6 6 - 10 = -4 8 8 - 10 = -2 10 10 - 10 = 0 12 12 - 10 = 2 14 14 - 10 = 4 <p>Notice the deviations sum to zero: \\( (-4) + (-2) + 0 + 2 + 4 = 0 \\). This always happens! That's why we can't just average the deviations directly.</p> <p>Step 3: Square each deviation</p> Deviation Squared Deviation -4 16 -2 4 0 0 2 4 4 16 <p>Step 4: Sum the squared deviations</p> \\[ \\sum(x_i - \\bar{x})^2 = 16 + 4 + 0 + 4 + 16 = 40 \\] <p>Step 5: Calculate variance</p> \\[ s^2 = \\frac{40}{5-1} = \\frac{40}{4} = 10 \\] <p>Step 6: Calculate standard deviation</p> \\[ s = \\sqrt{10} \\approx 3.16 \\] <p>The standard deviation is about 3.16 points. This means quiz scores typically differ from the mean of 10 by about 3 points.</p>"},{"location":"chapters/04-numerical-summaries/#diagram-standard-deviation-calculator","title":"Diagram: Standard Deviation Calculator","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Step-by-Step Variance and Standard Deviation Calculator <p>Type: MicroSim</p> <p>Learning objective: Students will calculate variance and standard deviation by following a systematic procedure and understanding each step's purpose (Bloom: Applying, Understanding).</p> <p>Visual elements: - Data input area (editable list of values) - Step-by-step calculation display:   1. Mean calculation with formula   2. Table of values, deviations, and squared deviations   3. Sum of squared deviations   4. Division by (n-1)   5. Square root for standard deviation - Visual representation: dot plot showing mean and distance to each point - Highlighting of current calculation step</p> <p>Interactive controls: - Editable data values (text input or +/- buttons) - \"Calculate step by step\" button (advances one step at a time) - \"Calculate all\" button (shows complete solution immediately) - \"Reset\" button to start over - \"Generate example\" dropdown with preset datasets - Toggle between population (\\( n \\)) and sample (\\( n-1 \\)) formulas</p> <p>Behavior: - Each step animates into view with explanatory text - Deviations shown as colored lines from points to mean on dot plot - Current step highlighted in the formula - Running calculations displayed with proper mathematical notation - Final answer prominently displayed with interpretation</p> <p>Canvas size: 800 x 500 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-numerical-summaries/#properties-of-standard-deviation","title":"Properties of Standard Deviation","text":"<p>Understanding what standard deviation can and cannot tell you is crucial for interpreting data correctly.</p> <p>Key Properties:</p> <ul> <li>Standard deviation is always \u2265 0</li> <li>Standard deviation = 0 only when all values are identical</li> <li>Standard deviation has the same units as the original data</li> <li>Standard deviation is not resistant to outliers (it uses the mean and squared deviations)</li> </ul> <p>Comparing Standard Deviations:</p> <ul> <li>Larger s \u2192 more spread, more variability</li> <li>Smaller s \u2192 values cluster more tightly around the mean</li> <li>Doubling the spread of data roughly doubles the standard deviation</li> </ul> <p>A Helpful Rule of Thumb:</p> <p>For many distributions, most data (often 68-95%) falls within 2 standard deviations of the mean. If \\( \\bar{x} = 100 \\) and \\( s = 15 \\), expect most values between \\( 100 - 2(15) = 70 \\) and \\( 100 + 2(15) = 130 \\).</p>"},{"location":"chapters/04-numerical-summaries/#resistant-vs-non-resistant-measures","title":"Resistant vs. Non-Resistant Measures","text":"<p>A measure is resistant if it's not strongly affected by extreme values or outliers. Let's compare:</p> Measure Resistant? Why? Mean No Pulled toward outliers (uses all values) Median Yes Only depends on middle position(s) Mode Yes Only counts frequency Range No Uses only extreme values IQR Yes Based on quartiles, ignores extremes Standard Deviation No Uses squared deviations from mean <p>When to Choose Resistant Measures:</p> <p>Use median and IQR when:</p> <ul> <li>The distribution is strongly skewed</li> <li>There are outliers you want to downplay</li> <li>You want to describe the \"typical\" observation</li> </ul> <p>Use mean and standard deviation when:</p> <ul> <li>The distribution is roughly symmetric</li> <li>There are no extreme outliers</li> <li>You plan to do further statistical calculations</li> </ul>"},{"location":"chapters/04-numerical-summaries/#comparing-mean-and-median-what-shape-tells-us","title":"Comparing Mean and Median: What Shape Tells Us","text":"<p>The relationship between the mean and median reveals information about a distribution's shape:</p> <ul> <li>Symmetric distribution: Mean \u2248 Median</li> <li>Right-skewed distribution: Mean &gt; Median (mean is pulled toward the long right tail)</li> <li>Left-skewed distribution: Mean &lt; Median (mean is pulled toward the long left tail)</li> </ul> <p>Example: Income Distributions</p> <p>Income is famously right-skewed. Most people earn modest incomes, but a few earn enormous amounts. Those high earners pull the mean up, so the mean income is typically higher than the median income. That's why reports often use median household income\u2014it better represents the \"typical\" household.</p>"},{"location":"chapters/04-numerical-summaries/#diagram-mean-vs-median-in-different-distributions","title":"Diagram: Mean vs Median in Different Distributions","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Skewness and Center Comparison <p>Type: MicroSim</p> <p>Learning objective: Students will predict the relative positions of mean and median based on distribution shape (Bloom: Analyzing, Evaluating).</p> <p>Visual elements: - Dynamic histogram that can be reshaped - Vertical lines marking mean (one color) and median (different color) positions - Labels showing exact values of mean and median - Text display: \"Mean [&lt;|=|&gt;] Median\" updating based on relationship - Shape label (Symmetric, Right-skewed, Left-skewed)</p> <p>Interactive controls: - Preset buttons: \"Symmetric\", \"Right-skewed\", \"Left-skewed\" - Slider to control degree of skewness - Drag to reshape the histogram directly - Sample size slider (50-500) - \"Add outlier\" buttons for left and right extremes - Reset button</p> <p>Behavior: - Mean and median lines animate to new positions as shape changes - Gap between mean and median widens with increased skewness - Adding outliers visibly pulls the mean while median stays stable - Sound or visual pulse when relationship changes direction</p> <p>Canvas size: 700 x 400 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-numerical-summaries/#choosing-the-right-summary-statistics","title":"Choosing the Right Summary Statistics","text":"<p>\"Time to squirrel away this knowledge!\" Here's a practical guide for choosing your summary statistics:</p> <p>For Describing Center:</p> Distribution Shape Recommended Measure Symmetric, no outliers Mean Skewed or has outliers Median Categorical data Mode <p>For Describing Spread:</p> Distribution Shape Recommended Measure Symmetric, no outliers Standard deviation Skewed or has outliers IQR Need full extent Range (with caution) <p>The Complete Description:</p> <p>For a full numerical description of a single quantitative variable:</p> <ul> <li>If roughly symmetric: Report mean and standard deviation</li> <li>If skewed: Report five-number summary</li> </ul> <p>Always mention sample size (\\( n \\)) and identify any outliers!</p>"},{"location":"chapters/04-numerical-summaries/#putting-it-all-together-a-complete-analysis","title":"Putting It All Together: A Complete Analysis","text":"<p>Let's analyze a real dataset: The ages of 15 customers at a coffee shop one morning.</p> <p>Data: 19, 21, 22, 23, 24, 25, 27, 28, 32, 35, 38, 42, 45, 55, 72</p> <p>Step 1: Calculate measures of center</p> <ul> <li>Mean: \\( \\bar{x} = \\frac{508}{15} \\approx 33.9 \\) years</li> <li>Median: The 8th value (middle of 15) = 28 years</li> <li>Mode: No repeated values, so no mode</li> </ul> <p>Step 2: Calculate the five-number summary</p> Statistic Value Minimum 19 Q1 23 Median 28 Q3 42 Maximum 72 <p>Step 3: Calculate IQR and check for outliers</p> <ul> <li>IQR = 42 - 23 = 19</li> <li>Lower fence: 23 - 1.5(19) = -5.5 (no values below this)</li> <li>Upper fence: 42 + 1.5(19) = 70.5</li> <li>Outlier: 72 exceeds the upper fence!</li> </ul> <p>Step 4: Calculate standard deviation</p> <p>After computing, \\( s \\approx 14.8 \\) years.</p> <p>Step 5: Interpret the results</p> <p>The distribution of customer ages is right-skewed (mean 33.9 &gt; median 28). This makes sense\u2014there's one elderly customer (72) who raises the average. The typical customer is in their late 20s, with most ages ranging from 23 to 42 (the middle 50%). The 72-year-old is an outlier by the 1.5 \u00d7 IQR rule.</p> <p>Best summary: Given the skewness and outlier, report the five-number summary: Min = 19, Q1 = 23, Median = 28, Q3 = 42, Max = 72, with IQR = 19. Note one high outlier at 72.</p>"},{"location":"chapters/04-numerical-summaries/#key-takeaways","title":"Key Takeaways","text":"<p>\"Let's squirrel away the big ideas!\"</p> <ul> <li> <p>Center describes where the \"middle\" of a distribution is. The mean is the balance point; the median is the positional middle; the mode is most frequent.</p> </li> <li> <p>Spread describes how variable the data is. The range spans min to max; the IQR spans the middle 50%; the standard deviation measures typical distance from the mean.</p> </li> <li> <p>Resistant measures (median, IQR) aren't affected by outliers. Non-resistant measures (mean, standard deviation, range) are pulled by extreme values.</p> </li> <li> <p>The five-number summary (min, Q1, median, Q3, max) captures center, spread, and extent in just five values.</p> </li> <li> <p>Boxplots visualize the five-number summary and make comparing distributions easy. Modified boxplots flag outliers using the 1.5 \u00d7 IQR rule.</p> </li> <li> <p>Comparing mean and median reveals skewness: Mean &gt; Median suggests right-skewed; Mean &lt; Median suggests left-skewed.</p> </li> <li> <p>Choose wisely: Use mean and standard deviation for symmetric distributions; use median and IQR for skewed distributions or when outliers are present.</p> </li> </ul>"},{"location":"chapters/04-numerical-summaries/#practice-problems","title":"Practice Problems","text":"<ol> <li> <p>Calculate the mean, median, and mode for: 15, 18, 18, 20, 22, 25, 30</p> </li> <li> <p>A dataset has Q1 = 45, median = 52, and Q3 = 61. What is the IQR? What values would be considered outliers using the 1.5 \u00d7 IQR rule?</p> </li> <li> <p>Two classes took the same test. Class A had a mean of 75 with standard deviation 8. Class B had a mean of 78 with standard deviation 15. Which class performed more consistently? Explain.</p> </li> <li> <p>Here are home prices in thousands: 150, 175, 180, 195, 200, 210, 225, 890. Calculate the mean and median. Which better represents a \"typical\" home price? Why?</p> </li> <li> <p>Create a boxplot for this data and identify any outliers: 12, 15, 17, 19, 22, 23, 25, 26, 28, 45</p> </li> </ol> <p>Now you've got the full toolkit for describing distributions numerically. In the next chapter, we'll explore how to standardize values using z-scores and dive into the beautiful, bell-shaped normal distribution!</p>"},{"location":"chapters/05-standardization-and-normal/","title":"Standardization and Normal Distributions","text":""},{"location":"chapters/05-standardization-and-normal/#summary","title":"Summary","text":"<p>This chapter covers standardization using z-scores and the normal distribution, one of the most important probability distributions in statistics. Students will learn to calculate and interpret z-scores, understand the properties of normal curves, apply the Empirical Rule, and use normal tables and technology to find probabilities. These skills are essential for inference procedures later in the course.</p>"},{"location":"chapters/05-standardization-and-normal/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 18 concepts from the learning graph:</p> <ol> <li>Z-Score</li> <li>Calculating Z-Scores</li> <li>Interpreting Z-Scores</li> <li>Standardization</li> <li>Comparing with Z-Scores</li> <li>Normal Distribution</li> <li>Parameters of Normal</li> <li>Empirical Rule</li> <li>68-95-99.7 Rule</li> <li>Standard Normal Curve</li> <li>Normal Table</li> <li>Finding Normal Probs</li> <li>Inverse Normal Calcs</li> <li>Normal Probability Plot</li> <li>Assessing Normality</li> <li>Density Curve</li> <li>Area Under Curve</li> <li>Technology for Normal</li> </ol>"},{"location":"chapters/05-standardization-and-normal/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 4: Numerical Summaries</li> </ul>"},{"location":"chapters/05-standardization-and-normal/#introduction-a-universal-language-for-data","title":"Introduction: A Universal Language for Data","text":"<p>Imagine you scored 85 on your statistics exam and 78 on your history exam. Which performance was better? At first glance, the statistics score seems higher\u2014but what if the statistics exam had a class average of 90 while the history exam averaged 65? Suddenly, that 78 in history looks pretty impressive!</p> <p>This is the fundamental challenge we're solving in this chapter: how do we compare values from different distributions? The answer lies in a beautiful mathematical technique called standardization, and its partner, the elegant normal distribution.</p> <p>\"My tail's tingling\u2014we're onto something big!\" Sylvia adjusts her glasses. \"When I was comparing acorn counts from different oak species, I had the same problem. A 'good' harvest from a red oak means something totally different than a 'good' harvest from a white oak. Once I learned about z-scores, everything clicked into place. Trust me, this is one of those superpower skills you'll use constantly.\"</p> <p>By the end of this chapter, you'll be able to:</p> <ul> <li>Convert any value into a standardized z-score</li> <li>Compare values from completely different contexts</li> <li>Work with the normal distribution\u2014one of nature's favorite patterns</li> <li>Find probabilities using the famous \"bell curve\"</li> <li>Assess whether your data follows a normal distribution</li> </ul> <p>Let's crack this nut!</p>"},{"location":"chapters/05-standardization-and-normal/#density-curves-smoothing-out-the-histogram","title":"Density Curves: Smoothing Out the Histogram","text":"<p>Before we dive into the normal distribution, we need to understand density curves. Remember how histograms show the distribution of data using bars? A density curve is like a smoothed-out version of a histogram\u2014an idealized mathematical model of how data is distributed.</p> <p>A density curve has two key properties:</p> <ul> <li>It's always on or above the horizontal axis (no negative heights)</li> <li>The total area under the curve equals exactly 1 (representing 100% of the data)</li> </ul> <p>Think of it this way: if a histogram represents how your actual data is distributed, a density curve represents how the population might be distributed if you could collect infinite data. It's a theoretical model, but an incredibly useful one.</p> Feature Histogram Density Curve Based on Actual sample data Mathematical model Shape Bars with widths Smooth curve Total area Depends on bin width Always equals 1 Best for Displaying real data Calculating probabilities"},{"location":"chapters/05-standardization-and-normal/#area-under-the-curve","title":"Area Under the Curve","text":"<p>Here's where density curves become powerful: the area under the curve between any two values represents the proportion (or probability) of observations falling in that range.</p> <p>For example, if the area under a density curve between 60 and 80 is 0.45, that means 45% of observations fall between 60 and 80. This connection between area and probability is fundamental to everything we'll do with normal distributions.</p>"},{"location":"chapters/05-standardization-and-normal/#diagram-density-curve-area-explorer","title":"Diagram: Density Curve Area Explorer","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Interactive Area Under Curve Visualization <p>Type: MicroSim</p> <p>Learning objective: Students will understand that area under a density curve represents probability by shading regions and observing the corresponding proportions (Bloom: Understanding).</p> <p>Visual elements: - Smooth density curve (normal or other shapes available) - Horizontal axis with numerical scale - Shaded region between user-selected boundaries - Area value displayed as decimal and percentage - Reference lines at mean and standard deviation markers</p> <p>Interactive controls: - Two draggable vertical lines to define the shaded region - Dropdown to select curve type (normal, uniform, skewed) - Slider to adjust curve parameters (mean, spread) - \"Show full area = 1\" toggle demonstrating total area property - Reset button</p> <p>Behavior: - Area calculation updates in real-time as boundaries change - Shaded region fills with semi-transparent color - Display shows both exact area and percentage interpretation - When boundaries encompass full curve, area displays as 1.00 (100%)</p> <p>Canvas size: 700 x 350 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/05-standardization-and-normal/#z-scores-the-great-equalizer","title":"Z-Scores: The Great Equalizer","text":"<p>A z-score (also called a standard score) tells you how many standard deviations a value is from the mean. It's the key to standardization\u2014converting values from any distribution into a common scale.</p> <p>The z-score formula is elegantly simple:</p> \\[ z = \\frac{x - \\mu}{\\sigma} \\quad \\text{(for populations)} \\quad \\text{or} \\quad z = \\frac{x - \\bar{x}}{s} \\quad \\text{(for samples)} \\] <p>Where:</p> <ul> <li>\\( x \\) = the individual value you're standardizing</li> <li>\\( \\mu \\) (or \\( \\bar{x} \\)) = the mean</li> <li>\\( \\sigma \\) (or \\( s \\)) = the standard deviation</li> </ul> <p>The result tells you: \"This value is z standard deviations away from the mean.\"</p>"},{"location":"chapters/05-standardization-and-normal/#calculating-z-scores","title":"Calculating Z-Scores","text":"<p>Let's work through an example. Suppose exam scores have a mean of 75 and a standard deviation of 8. What's the z-score for a student who scored 91?</p> \\[ z = \\frac{91 - 75}{8} = \\frac{16}{8} = 2 \\] <p>This student's score is 2 standard deviations above the mean. That's impressive!</p> <p>Now let's find the z-score for a student who scored 67:</p> \\[ z = \\frac{67 - 75}{8} = \\frac{-8}{8} = -1 \\] <p>This score is 1 standard deviation below the mean. The negative sign tells us the value is below average.</p> Original Score Mean Std Dev Z-Score Interpretation 91 75 8 +2.0 2 SDs above mean 75 75 8 0 Exactly at mean 67 75 8 -1.0 1 SD below mean 83 75 8 +1.0 1 SD above mean 59 75 8 -2.0 2 SDs below mean"},{"location":"chapters/05-standardization-and-normal/#interpreting-z-scores","title":"Interpreting Z-Scores","text":"<p>Z-scores have intuitive interpretations:</p> <ul> <li>z = 0: The value equals the mean (perfectly average)</li> <li>Positive z: The value is above the mean</li> <li>Negative z: The value is below the mean</li> <li>|z| &gt; 2: The value is somewhat unusual (more than 2 SDs from mean)</li> <li>|z| &gt; 3: The value is quite rare (more than 3 SDs from mean)</li> </ul> <p>\"Here's a pro tip,\" Sylvia whispers. \"When I'm comparing my acorn collections across different seasons, z-scores let me identify my truly exceptional days. Any day with a z-score above 2? That's a day I remember fondly. Below -2? Let's just say I treated myself to extra seeds that evening.\"</p>"},{"location":"chapters/05-standardization-and-normal/#diagram-z-score-calculator-and-visualizer","title":"Diagram: Z-Score Calculator and Visualizer","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Interactive Z-Score Calculator <p>Type: MicroSim</p> <p>Learning objective: Students will calculate z-scores from raw data and interpret their meaning on a standardized scale (Bloom: Applying).</p> <p>Visual elements: - Input fields for: value (x), mean (\u03bc), standard deviation (\u03c3) - Step-by-step calculation display showing the formula with values substituted - Number line showing original scale on top, z-score scale below - Visual indicator connecting the original value to its z-score position - Color gradient: red for very negative, white for zero, blue for very positive</p> <p>Interactive controls: - Text inputs for x, mean, and standard deviation - \"Calculate\" button (or real-time calculation) - Preset examples dropdown: \"Exam Scores\", \"Heights\", \"Temperatures\" - Toggle to show/hide calculation steps - Slider to animate z-score changes as x varies</p> <p>Behavior: - Z-score updates in real-time as inputs change - Formula displays with current values substituted - Visual number line updates to show position - Interpretation text updates: \"This value is [z] standard deviations [above/below] the mean\" - Warning for unrealistic inputs (negative SD, etc.)</p> <p>Canvas size: 750 x 400 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/05-standardization-and-normal/#standardization-creating-a-common-scale","title":"Standardization: Creating a Common Scale","text":"<p>Standardization is the process of converting all values in a dataset to z-scores. When you standardize a distribution:</p> <ul> <li>The new mean becomes 0</li> <li>The new standard deviation becomes 1</li> <li>The shape of the distribution stays exactly the same</li> </ul> <p>This transformation is incredibly powerful because it puts all data on the same scale, regardless of the original units or spread.</p>"},{"location":"chapters/05-standardization-and-normal/#comparing-with-z-scores","title":"Comparing with Z-Scores","text":"<p>Now we can answer our opening question! Let's say your statistics score was 85 (class mean 90, SD 5) and your history score was 78 (class mean 65, SD 10).</p> <p>Statistics z-score: [ z = \\frac{85 - 90}{5} = \\frac{-5}{5} = -1.0 ]</p> <p>History z-score: [ z = \\frac{78 - 65}{10} = \\frac{13}{10} = +1.3 ]</p> <p>Even though 85 &gt; 78, the z-scores reveal the truth: you performed 1.3 standard deviations above average in history, but 1 standard deviation below average in statistics. Your history performance was actually stronger relative to your classmates!</p> <p>This is the power of z-scores: they enable apples-to-apples comparisons across completely different contexts.</p> Subject Raw Score Class Mean Class SD Z-Score Relative Performance Statistics 85 90 5 -1.0 Below average History 78 65 10 +1.3 Above average <p>\"Acorn for your thoughts?\" Sylvia asks. \"Before z-scores, comparing my spring collection to my fall collection was meaningless\u2014different weather, different tree conditions, different everything. But z-scores showed me that my best relative performance actually came during a drought year when I was 2.5 standard deviations above the seasonal average. Context matters!\"</p>"},{"location":"chapters/05-standardization-and-normal/#the-normal-distribution-natures-favorite-curve","title":"The Normal Distribution: Nature's Favorite Curve","text":"<p>Now we meet the star of the show: the normal distribution (also called the Gaussian distribution or the \"bell curve\"). This symmetric, mound-shaped curve appears everywhere in nature and statistics:</p> <ul> <li>Heights and weights of people</li> <li>Measurement errors in scientific instruments</li> <li>Test scores on well-designed exams</li> <li>Blood pressure readings</li> <li>Manufacturing tolerances</li> </ul> <p>The normal distribution is defined by two parameters:</p> <ul> <li>\u03bc (mu): The mean, which determines the center</li> <li>\u03c3 (sigma): The standard deviation, which determines the spread</li> </ul> <p>These two numbers completely specify a normal distribution. We write \"X follows a normal distribution with mean \u03bc and standard deviation \u03c3\" as:</p> \\[ X \\sim N(\\mu, \\sigma) \\] <p>For example, if adult male heights are normally distributed with mean 70 inches and standard deviation 3 inches, we write: Heights \\( \\sim N(70, 3) \\).</p>"},{"location":"chapters/05-standardization-and-normal/#properties-of-the-normal-curve","title":"Properties of the Normal Curve","text":"<p>Every normal distribution shares these characteristics:</p> <ul> <li>Symmetric about the mean (left and right sides are mirror images)</li> <li>Unimodal (single peak at the mean)</li> <li>Bell-shaped (highest in the middle, tapering toward the tails)</li> <li>Mean = Median = Mode (all three measures of center are equal)</li> <li>The curve extends infinitely in both directions (theoretically)</li> <li>Total area under the curve equals 1</li> </ul> <p>The spread is controlled entirely by \u03c3:</p> <ul> <li>Larger \u03c3 \u2192 wider, flatter curve</li> <li>Smaller \u03c3 \u2192 narrower, taller curve</li> </ul>"},{"location":"chapters/05-standardization-and-normal/#diagram-normal-distribution-parameter-explorer","title":"Diagram: Normal Distribution Parameter Explorer","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Interactive Normal Curve Visualization <p>Type: MicroSim</p> <p>Learning objective: Students will understand how the parameters \u03bc and \u03c3 affect the shape and position of a normal distribution (Bloom: Understanding, Analyzing).</p> <p>Visual elements: - Normal curve plotted on coordinate axes - Shaded area under the curve - Vertical line marking the mean (\u03bc) - Horizontal markers showing \u03bc \u00b1 \u03c3, \u03bc \u00b1 2\u03c3, \u03bc \u00b1 3\u03c3 - Current parameter values displayed: \u03bc = __, \u03c3 = __ - Grid lines for reference</p> <p>Interactive controls: - Slider for mean (\u03bc): range -10 to 10, default 0 - Slider for standard deviation (\u03c3): range 0.5 to 5, default 1 - Checkbox: Show \u03bc \u00b1 \u03c3 markers - Checkbox: Show \u03bc \u00b1 2\u03c3 markers - Checkbox: Show \u03bc \u00b1 3\u03c3 markers - Button: Reset to standard normal (\u03bc=0, \u03c3=1) - Button: Overlay second curve for comparison</p> <p>Behavior: - Curve updates smoothly as sliders move - When \u03c3 decreases, curve gets taller and narrower - When \u03c3 increases, curve gets shorter and wider - When \u03bc changes, entire curve slides left or right - Overlay mode shows two curves in different colors for comparison</p> <p>Canvas size: 750 x 400 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/05-standardization-and-normal/#the-empirical-rule-68-95-997-rule","title":"The Empirical Rule (68-95-99.7 Rule)","text":"<p>For any normal distribution, we know exactly what percentage of data falls within 1, 2, and 3 standard deviations of the mean. This is called the Empirical Rule or the 68-95-99.7 Rule:</p> <ul> <li>68% of data falls within 1 standard deviation of the mean: \\( \\mu \\pm \\sigma \\)</li> <li>95% of data falls within 2 standard deviations of the mean: \\( \\mu \\pm 2\\sigma \\)</li> <li>99.7% of data falls within 3 standard deviations of the mean: \\( \\mu \\pm 3\\sigma \\)</li> </ul> <p>These aren't approximations\u2014for truly normal data, these percentages are exact!</p> Range Percentage Remaining in Tails \u03bc \u00b1 1\u03c3 68% 32% (16% each tail) \u03bc \u00b1 2\u03c3 95% 5% (2.5% each tail) \u03bc \u00b1 3\u03c3 99.7% 0.3% (0.15% each tail)"},{"location":"chapters/05-standardization-and-normal/#applying-the-empirical-rule","title":"Applying the Empirical Rule","text":"<p>Example: SAT scores are approximately normal with mean 1060 and standard deviation 195.</p> <p>Using the Empirical Rule:</p> <ul> <li>68% of scores fall between \\( 1060 - 195 = 865 \\) and \\( 1060 + 195 = 1255 \\)</li> <li>95% of scores fall between \\( 1060 - 2(195) = 670 \\) and \\( 1060 + 2(195) = 1450 \\)</li> <li>99.7% of scores fall between \\( 1060 - 3(195) = 475 \\) and \\( 1060 + 3(195) = 1645 \\)</li> </ul> <p>What percentage of students score above 1450?</p> <p>Since 95% fall between 670 and 1450, the remaining 5% are in the two tails. By symmetry, 2.5% score above 1450.</p> <p>\"Time to squirrel away a memory trick,\" Sylvia suggests. \"I remember 68-95-99.7 by thinking: 68 is like 'six-eight,' which reminds me of one standard deviation. Then 95 for two, and 99.7 (almost all!) for three. It's not perfect, but it works for me!\"</p>"},{"location":"chapters/05-standardization-and-normal/#diagram-empirical-rule-interactive-demonstration","title":"Diagram: Empirical Rule Interactive Demonstration","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> 68-95-99.7 Rule Visualization <p>Type: MicroSim</p> <p>Learning objective: Students will apply the Empirical Rule to find percentages within standard deviation ranges of a normal distribution (Bloom: Applying).</p> <p>Visual elements: - Normal curve with mean at center - Color-coded regions:   - Dark green: within 1 SD (68%)   - Medium green: between 1 and 2 SDs (additional 27%)   - Light green: between 2 and 3 SDs (additional 4.7%)   - Very light: beyond 3 SDs (0.3%) - Percentage labels in each region - Scale showing actual values below, z-scores above</p> <p>Interactive controls: - Input fields for mean and standard deviation - Buttons to highlight: \"Within 1 SD\", \"Within 2 SD\", \"Within 3 SD\" - Toggle to show cumulative percentages vs. region percentages - \"Quiz me\" mode: given a range, student guesses the percentage - Preset scenarios: SAT scores, heights, temperatures</p> <p>Behavior: - When SD range is selected, that region pulses and displays percentage - Actual values on scale update when mean/SD change - Quiz mode: reveal answer after student submits guess - Show running score in quiz mode</p> <p>Canvas size: 800 x 400 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/05-standardization-and-normal/#the-standard-normal-distribution","title":"The Standard Normal Distribution","text":"<p>The standard normal distribution is a special normal distribution with mean 0 and standard deviation 1:</p> \\[ Z \\sim N(0, 1) \\] <p>We use the capital letter Z (rather than X) to indicate a standard normal variable. Any normal distribution can be converted to the standard normal by calculating z-scores\u2014this is why z-scores are so powerful!</p> <p>The standard normal distribution is our reference. All the tables and technology tools are calibrated to it, so we convert our problems to standard normal form, find the answer, and convert back if needed.</p>"},{"location":"chapters/05-standardization-and-normal/#using-the-normal-table","title":"Using the Normal Table","text":"<p>A normal table (also called a z-table) gives the area under the standard normal curve to the left of any z-value. This area represents the proportion of observations less than that z-score.</p> <p>Reading the table: 1. Find your z-score (e.g., z = 1.25) 2. Look up the row for 1.2 and the column for .05 3. The table entry is the area to the left of z = 1.25</p> <p>For z = 1.25, the table shows approximately 0.8944, meaning 89.44% of values in a standard normal distribution are less than z = 1.25.</p> <p>Common z-values to memorize:</p> Z-Score Area to Left Area to Right -3 0.0013 0.9987 -2 0.0228 0.9772 -1 0.1587 0.8413 0 0.5000 0.5000 +1 0.8413 0.1587 +2 0.9772 0.0228 +3 0.9987 0.0013"},{"location":"chapters/05-standardization-and-normal/#finding-normal-probabilities","title":"Finding Normal Probabilities","text":"<p>The process for finding probabilities (areas) under a normal curve follows a consistent pattern:</p> <p>Step 1: Draw and label a normal curve with the given \u03bc and \u03c3</p> <p>Step 2: Mark the value(s) of interest and shade the desired region</p> <p>Step 3: Convert to z-scores using \\( z = \\frac{x - \\mu}{\\sigma} \\)</p> <p>Step 4: Use a table or technology to find the area</p> <p>Step 5: Interpret in context</p>"},{"location":"chapters/05-standardization-and-normal/#types-of-probability-questions","title":"Types of Probability Questions","text":"<p>Type 1: Find P(X &lt; a) \u2014 \"less than\"</p> <p>Shade the region to the left of a. The table gives this directly.</p> <p>Type 2: Find P(X &gt; a) \u2014 \"greater than\"</p> <p>Shade the region to the right of a. Since the table gives left areas: [ P(X &gt; a) = 1 - P(X &lt; a) ]</p> <p>Type 3: Find P(a &lt; X &lt; b) \u2014 \"between\"</p> <p>Shade the region between a and b. Find: [ P(a &lt; X &lt; b) = P(X &lt; b) - P(X &lt; a) ]</p>"},{"location":"chapters/05-standardization-and-normal/#worked-example","title":"Worked Example","text":"<p>Adult women's heights are normally distributed with mean 64.5 inches and standard deviation 2.5 inches. What proportion of women are between 62 and 67 inches tall?</p> <p>Step 1-2: Draw the curve, mark 62 and 67, shade between them.</p> <p>Step 3: Convert to z-scores: [ z_{62} = \\frac{62 - 64.5}{2.5} = \\frac{-2.5}{2.5} = -1.0 ] [ z_{67} = \\frac{67 - 64.5}{2.5} = \\frac{2.5}{2.5} = +1.0 ]</p> <p>Step 4: Find areas: - P(Z &lt; 1.0) = 0.8413 - P(Z &lt; -1.0) = 0.1587 - P(-1 &lt; Z &lt; 1) = 0.8413 - 0.1587 = 0.6826</p> <p>Step 5: About 68.26% of women are between 62 and 67 inches tall.</p> <p>(Notice this matches the Empirical Rule: within 1 SD of the mean contains about 68% of the data!)</p>"},{"location":"chapters/05-standardization-and-normal/#diagram-normal-probability-calculator","title":"Diagram: Normal Probability Calculator","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Step-by-Step Normal Probability Finder <p>Type: MicroSim</p> <p>Learning objective: Students will calculate probabilities for normal distributions by converting to z-scores and finding areas under the curve (Bloom: Applying, Analyzing).</p> <p>Visual elements: - Normal curve with adjustable mean and standard deviation - Shaded region showing the probability being calculated - Display of both original scale and z-score scale - Step-by-step solution panel showing:   1. Problem setup (\u03bc, \u03c3, target value)   2. Z-score calculation with formula   3. Table lookup or area calculation   4. Final probability with interpretation</p> <p>Interactive controls: - Input fields for \u03bc (mean) and \u03c3 (standard deviation) - Input field(s) for boundary values - Radio buttons: P(X &lt; a), P(X &gt; a), P(a &lt; X &lt; b) - \"Solve step by step\" button (shows one step at a time) - \"Show full solution\" button - \"New problem\" button generating random scenarios</p> <p>Behavior: - Curve and shading update as inputs change - Each step highlights the relevant calculation - Z-score calculation shows formula with values substituted - Final answer shown with interpretation sentence - Option to generate practice problems</p> <p>Canvas size: 850 x 500 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/05-standardization-and-normal/#inverse-normal-calculations","title":"Inverse Normal Calculations","text":"<p>Sometimes we work backwards: instead of finding a probability given a value, we find a value given a probability. These are called inverse normal calculations.</p> <p>Example: What height separates the tallest 10% of women from the rest?</p> <p>We want to find x such that P(X &gt; x) = 0.10, which means P(X &lt; x) = 0.90.</p> <p>Step 1: Find the z-score with area 0.90 to its left. Looking in the table body for 0.90, we find z \u2248 1.28.</p> <p>Step 2: Convert z back to x:</p> <p>Since \\( z = \\frac{x - \\mu}{\\sigma} \\), we can solve for x: [ x = \\mu + z \\cdot \\sigma = 64.5 + (1.28)(2.5) = 64.5 + 3.2 = 67.7 \\text{ inches} ]</p> <p>Women 67.7 inches (about 5'8\") or taller are in the top 10% for height.</p>"},{"location":"chapters/05-standardization-and-normal/#the-inverse-normal-process","title":"The Inverse Normal Process","text":"<ol> <li>Identify the probability (area) given in the problem</li> <li>Determine whether the area is to the left or right</li> <li>If area is to the right, convert: area to left = 1 - area to right</li> <li>Find the corresponding z-score from the table (look in the body of the table)</li> <li>Convert z to x using: \\( x = \\mu + z \\cdot \\sigma \\)</li> </ol> <p>Common inverse problems:</p> Phrase in Problem What to Find \"Top 5%\" z with area 0.95 to left \"Bottom 10%\" z with area 0.10 to left \"Middle 90%\" z-values at 0.05 and 0.95 \"Highest 1%\" z with area 0.99 to left"},{"location":"chapters/05-standardization-and-normal/#technology-for-normal-calculations","title":"Technology for Normal Calculations","text":"<p>While normal tables are important to understand, most real-world calculations use technology. Here's how to use common tools:</p> <p>TI-83/84 Calculator:</p> <ul> <li><code>normalcdf(lower, upper, \u03bc, \u03c3)</code> \u2014 finds P(lower &lt; X &lt; upper)</li> <li><code>invNorm(area, \u03bc, \u03c3)</code> \u2014 finds x-value for given left-tail area</li> </ul> <p>For P(X &lt; 65) with \u03bc = 70, \u03c3 = 5: <code>normalcdf(-1E99, 65, 70, 5)</code> returns 0.1587</p> <p>For the value at the 90th percentile: <code>invNorm(0.90, 70, 5)</code> returns 76.41</p> <p>Online Tools and Software:</p> <p>Most statistical software (R, Python, Excel) has normal distribution functions. The concepts are identical\u2014just the syntax differs.</p> <p>\"Don't worry if tables feel clunky at first,\" Sylvia reassures. \"I still use my calculator for serious calculations. But understanding the table helps you know what the technology is actually doing. Plus, tables don't need batteries!\"</p>"},{"location":"chapters/05-standardization-and-normal/#assessing-normality","title":"Assessing Normality","text":"<p>Before using normal distribution methods, we should check whether our data is approximately normal. There are several approaches:</p>"},{"location":"chapters/05-standardization-and-normal/#visual-methods","title":"Visual Methods","text":"<p>1. Histogram: Does it look roughly symmetric and bell-shaped?</p> <p>2. Boxplot: Is the median near the center of the box? Are the whiskers roughly equal length?</p> <p>3. Normal Probability Plot: This is the most reliable visual method.</p>"},{"location":"chapters/05-standardization-and-normal/#normal-probability-plots","title":"Normal Probability Plots","text":"<p>A normal probability plot (also called a QQ plot) graphs each data value against the z-score it would have if the data were perfectly normal. If the data is normally distributed, the points will fall approximately along a straight line.</p> <p>Reading a normal probability plot:</p> <ul> <li>Points follow a straight line: Data is approximately normal</li> <li>Points curve upward at ends: Data is right-skewed (heavier right tail)</li> <li>Points curve downward at ends: Data is left-skewed (heavier left tail)</li> <li>S-shaped pattern: Data has lighter tails than normal</li> <li>Scattered points: Data may not follow any standard distribution</li> </ul>"},{"location":"chapters/05-standardization-and-normal/#diagram-normal-probability-plot-explorer","title":"Diagram: Normal Probability Plot Explorer","text":"<p>Run MicroSim Fullscreen Edit in p5.js Editor</p> Interactive Normality Assessment Tool <p>Type: MicroSim</p> <p>Learning objective: Students will assess whether data follows a normal distribution by interpreting histograms and normal probability plots (Bloom: Analyzing, Evaluating).</p> <p>Visual elements: - Left panel: Histogram of the dataset - Right panel: Normal probability plot (QQ plot) - Reference line on QQ plot showing perfect normality - Summary statistics displayed: mean, SD, skewness - \"Normality verdict\" indicator</p> <p>Interactive controls: - Dropdown to select dataset type:   - \"Approximately Normal\"   - \"Right Skewed\"   - \"Left Skewed\"   - \"Heavy Tails\"   - \"Light Tails\"   - \"Uniform\"   - \"Bimodal\" - Sample size slider (20 to 200) - \"Generate new sample\" button - Toggle: Show/hide reference line - Toggle: Show/hide ideal normal overlay on histogram</p> <p>Behavior: - Both plots update simultaneously when dataset changes - For normal data, QQ plot points cluster around the line - For skewed data, characteristic curved patterns appear - Verdict updates with explanation: \"Data appears [normal/non-normal] because...\" - Multiple samples can be generated to see sampling variation</p> <p>Canvas size: 900 x 400 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/05-standardization-and-normal/#when-is-close-enough-normal","title":"When Is \"Close Enough\" Normal?","text":"<p>Real data is never perfectly normal, so we look for \"approximately normal\" patterns:</p> <ul> <li>Small samples (n &lt; 30): Look for no extreme skewness or outliers</li> <li>Moderate samples (30 \u2264 n &lt; 100): Mild skewness is acceptable</li> <li>Large samples (n \u2265 100): Normal methods are robust even with moderate non-normality</li> </ul> <p>The Central Limit Theorem (coming in a later chapter!) explains why normal methods work even when individual observations aren't normal, as long as our samples are large enough.</p>"},{"location":"chapters/05-standardization-and-normal/#putting-it-all-together-complete-examples","title":"Putting It All Together: Complete Examples","text":""},{"location":"chapters/05-standardization-and-normal/#example-1-manufacturing-quality-control","title":"Example 1: Manufacturing Quality Control","text":"<p>A machine fills bottles with 16.0 oz of soda. The actual amounts are normally distributed with mean 16.1 oz and standard deviation 0.15 oz.</p> <p>a) What percentage of bottles contain less than 16.0 oz?</p> \\[ z = \\frac{16.0 - 16.1}{0.15} = \\frac{-0.1}{0.15} = -0.67 \\] <p>P(Z &lt; -0.67) \u2248 0.2514</p> <p>About 25.1% of bottles are underfilled.</p> <p>b) What fill amount separates the lowest 5% of bottles?</p> <p>Find z with area 0.05 to left: z \u2248 -1.645</p> \\[ x = 16.1 + (-1.645)(0.15) = 16.1 - 0.247 = 15.85 \\text{ oz} \\] <p>The lowest 5% of bottles contain less than 15.85 oz.</p>"},{"location":"chapters/05-standardization-and-normal/#example-2-comparing-standardized-test-scores","title":"Example 2: Comparing Standardized Test Scores","text":"<p>Maria scored 680 on the SAT (\u03bc = 1060, \u03c3 = 195) and 29 on the ACT (\u03bc = 21, \u03c3 = 5). Which score is relatively better?</p> <p>SAT z-score: [ z = \\frac{680 - 1060}{195} = \\frac{-380}{195} = -1.95 ]</p> <p>ACT z-score: [ z = \\frac{29 - 21}{5} = \\frac{8}{5} = +1.60 ]</p> <p>Maria's ACT score (z = +1.60) is much stronger than her SAT score (z = -1.95). Her ACT performance is 1.6 standard deviations above average, while her SAT is nearly 2 standard deviations below average.</p>"},{"location":"chapters/05-standardization-and-normal/#key-takeaways","title":"Key Takeaways","text":"<p>\"Time to squirrel away the big ideas!\"</p> <ul> <li> <p>Z-scores measure how many standard deviations a value is from the mean: \\( z = \\frac{x - \\mu}{\\sigma} \\)</p> </li> <li> <p>Standardization converts any distribution to a common scale (mean 0, SD 1), enabling meaningful comparisons</p> </li> <li> <p>Density curves are smooth mathematical models; the area under the curve represents probability</p> </li> <li> <p>Normal distributions are symmetric, bell-shaped curves defined by \u03bc and \u03c3</p> </li> <li> <p>The Empirical Rule (68-95-99.7) gives exact percentages within 1, 2, and 3 standard deviations for normal distributions</p> </li> <li> <p>The standard normal (Z ~ N(0,1)) is our reference distribution for calculations</p> </li> <li> <p>Forward problems: Given x, find probability using \\( z = \\frac{x - \\mu}{\\sigma} \\) and look up area</p> </li> <li> <p>Inverse problems: Given probability, find z from table, then calculate \\( x = \\mu + z \\cdot \\sigma \\)</p> </li> <li> <p>Normal probability plots help assess whether data follows a normal distribution\u2014look for points along a straight line</p> </li> <li> <p>Technology makes calculations faster, but understanding the underlying process is essential</p> </li> </ul>"},{"location":"chapters/05-standardization-and-normal/#practice-problems","title":"Practice Problems","text":"<ol> <li> <p>The mean score on a psychology exam is 72 with standard deviation 9. Calculate the z-score for a student who scored 63. Interpret this z-score.</p> </li> <li> <p>Adult male heights are normally distributed with \u03bc = 70 inches and \u03c3 = 3 inches.</p> </li> <li>What percentage of men are shorter than 67 inches?</li> <li>What percentage are between 67 and 76 inches?</li> <li> <p>How tall must a man be to be in the top 5%?</p> </li> <li> <p>Two students are comparing their performances. Student A scored 85 on a test with mean 78 and SD 6. Student B scored 92 on a different test with mean 85 and SD 10. Who performed better relative to their class?</p> </li> <li> <p>A normal probability plot of exam scores shows a clear curved pattern\u2014the points bend upward at the right end. What does this tell you about the distribution of scores?</p> </li> <li> <p>Use the Empirical Rule: If IQ scores are normally distributed with mean 100 and SD 15, what percentage of people have IQs between 85 and 130?</p> </li> </ol> <p>Congratulations! You've mastered one of the most important tools in all of statistics. The normal distribution and z-scores will appear again and again\u2014in sampling distributions, confidence intervals, and hypothesis testing. This foundation will serve you well!</p> <p>\"Now that's a data point worth collecting!\" Sylvia beams. \"You just learned to speak the universal language of statistics. Whether you're analyzing test scores, heights, or\u2014yes\u2014acorn counts, you've got the tools to make meaningful comparisons. Onward to new adventures!\"</p>"},{"location":"chapters/06-scatterplots-and-association/","title":"Scatterplots and Association","text":""},{"location":"chapters/06-scatterplots-and-association/#summary","title":"Summary","text":"<p>This chapter introduces scatterplots as the primary tool for visualizing relationships between two quantitative variables. Students will learn to describe the direction, form, and strength of associations, and calculate the correlation coefficient. Understanding correlation is crucial for the regression analysis that follows in the next chapter.</p>"},{"location":"chapters/06-scatterplots-and-association/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 9 concepts from the learning graph:</p> <ol> <li>Scatterplot</li> <li>Describing Scatterplots</li> <li>Form of Association</li> <li>Linear Form</li> <li>Nonlinear Form</li> <li>Correlation Coefficient</li> <li>Calculating Correlation</li> <li>Properties of Correlation</li> <li>Correlation Limitations</li> </ol>"},{"location":"chapters/06-scatterplots-and-association/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Statistics</li> <li>Chapter 2: Displaying Categorical Data</li> <li>Chapter 4: Numerical Summaries</li> </ul>"},{"location":"chapters/06-scatterplots-and-association/#introduction-when-two-variables-meet","title":"Introduction: When Two Variables Meet","text":"<p>Welcome back! So far, we've explored single variables\u2014counting categories, summarizing numerical data, and understanding distributions. But here's where things get really interesting: what happens when we want to understand how two quantitative variables relate to each other?</p> <p>Think about questions like these: Does studying more hours actually lead to better test scores? Do taller people tend to weigh more? Is there a connection between a city's average temperature and its ice cream sales? These are questions about relationships between variables, and answering them requires a new visualization tool.</p> <p>\"My tail's tingling\u2014we're onto something! When I was a young squirrel, I noticed that trees with bigger canopies tended to drop more acorns. Was that just coincidence, or was there a real pattern? That's exactly the kind of question we'll learn to investigate in this chapter!\" \u2014 Sylvia</p> <p>Let's dive into the world of scatterplots and discover how to visualize, describe, and measure relationships between variables.</p>"},{"location":"chapters/06-scatterplots-and-association/#understanding-scatterplots","title":"Understanding Scatterplots","text":"<p>A scatterplot is a graph that displays the relationship between two quantitative variables. Each point on the plot represents one observation (one individual or case), with its position determined by its values for both variables.</p> <p>Here's the setup:</p> <ul> <li>The horizontal axis (x-axis) displays one variable, typically the explanatory variable (the one we think might explain or predict changes in the other)</li> <li>The vertical axis (y-axis) displays the other variable, typically the response variable (the one we're trying to understand or predict)</li> </ul> <p>For example, if we're investigating whether hours of study affect test scores, we'd plot hours studied on the x-axis and test scores on the y-axis. Each student becomes a single dot on the plot, positioned at their specific (hours, score) coordinates.</p>"},{"location":"chapters/06-scatterplots-and-association/#creating-a-scatterplot","title":"Creating a Scatterplot","text":"<p>To create a scatterplot:</p> <ol> <li>Identify your two quantitative variables</li> <li>Decide which is the explanatory variable (x) and which is the response variable (y)</li> <li>Draw and label your axes with appropriate scales</li> <li>Plot each observation as a point at its (x, y) coordinates</li> </ol> Variable Type Placement Example Explanatory (independent) x-axis (horizontal) Hours of study Response (dependent) y-axis (vertical) Test score <p>\"Acorn for your thoughts? When plotting, I always ask myself: 'Which variable might cause or explain changes in the other?' That one goes on the x-axis. The one that might be affected goes on the y-axis. It's like asking, 'Does tree height explain acorn count?' Tree height is x, acorn count is y!\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#microsim-scatterplot-builder","title":"MicroSim: Scatterplot Builder","text":"Interactive Scatterplot Builder <p>Type: MicroSim</p> <p>Learning objective: Understand (Bloom Level 2) - Students will demonstrate understanding of scatterplot construction by placing data points and interpreting their positions.</p> <p>Visual elements:</p> <ul> <li>Coordinate plane with labeled x and y axes</li> <li>Data table showing 8-10 paired observations on the left side</li> <li>Points that appear on the scatterplot as user clicks corresponding rows</li> <li>Grid lines for easier coordinate reading</li> <li>Axis labels that can be customized (dropdown: \"Hours Studied/Test Score\", \"Height/Weight\", \"Temperature/Ice Cream Sales\")</li> </ul> <p>Interactive controls:</p> <ul> <li>Dataset selector dropdown (3 preset datasets)</li> <li>\"Add Point\" mode: click on table row to plot that point</li> <li>\"Clear\" button to reset the scatterplot</li> <li>\"Show All\" button to display all points at once</li> <li>Toggle for gridlines on/off</li> </ul> <p>Behavior:</p> <ul> <li>When user clicks a data row, the corresponding point animates onto the scatterplot</li> <li>Points highlight when hovered, showing their exact coordinates</li> <li>After all points are plotted, a message appears: \"You've built a scatterplot! What pattern do you see?\"</li> </ul> <p>Canvas size: 700 x 450, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/06-scatterplots-and-association/#describing-scatterplots","title":"Describing Scatterplots","text":"<p>Once you've created a scatterplot, the next step is to describe what you see. We use three key characteristics to describe the pattern in a scatterplot:</p> <ol> <li>Direction (positive, negative, or no association)</li> <li>Form (linear, nonlinear, or no clear form)</li> <li>Strength (strong, moderate, or weak)</li> </ol> <p>Additionally, you should always look for unusual features like outliers or clusters.</p>"},{"location":"chapters/06-scatterplots-and-association/#direction-of-association","title":"Direction of Association","text":"<p>The direction tells us how the two variables move in relation to each other:</p> <ul> <li>Positive association: As x increases, y tends to increase. The points slope upward from left to right. Think: height and weight, study time and test scores.</li> <li>Negative association: As x increases, y tends to decrease. The points slope downward from left to right. Think: price and quantity demanded, age of a car and its resale value.</li> <li>No association: There's no discernible pattern relating x and y. The points appear scattered randomly.</li> </ul>"},{"location":"chapters/06-scatterplots-and-association/#strength-of-association","title":"Strength of Association","text":"<p>The strength describes how closely the points follow the overall pattern:</p> <ul> <li>Strong: Points cluster tightly around the underlying pattern</li> <li>Moderate: Points follow the general pattern but with noticeable scatter</li> <li>Weak: Points only loosely follow the pattern with substantial scatter</li> </ul> <p>Think of it this way: if you could easily draw a line (or curve) through the data and the points would hug that line closely, the association is strong. If the points are so scattered that finding any pattern feels like wishful thinking, the association is weak.</p> <p>\"Let's crack this nut! Describing a scatterplot is like describing a cloud\u2014but with more precision. You wouldn't just say 'there's a cloud up there.' You'd describe its shape, which way it's moving, and how thick it is. Same idea with scatterplots: direction, form, strength. Write that on your forehead. Well, maybe just on your notes.\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#form-of-association","title":"Form of Association","text":"<p>The form of an association describes the overall shape of the pattern in a scatterplot. Is it a straight line? A curve? Something else entirely? Understanding form helps us choose the right tools for further analysis.</p>"},{"location":"chapters/06-scatterplots-and-association/#linear-form","title":"Linear Form","text":"<p>A relationship has a linear form when the points in a scatterplot cluster around a straight line. Linear relationships are wonderfully predictable and mathematically convenient\u2014which is why we love them in statistics!</p> <p>Characteristics of linear form:</p> <ul> <li>Points follow a straight-line pattern</li> <li>The rate of change between x and y is constant</li> <li>Can be described by the equation \\( y = mx + b \\)</li> </ul> <p>Examples of linear relationships:</p> <ul> <li>Celsius and Fahrenheit temperatures (perfectly linear!)</li> <li>Height and arm span in humans</li> <li>Number of items purchased and total cost (at a fixed price per item)</li> </ul>"},{"location":"chapters/06-scatterplots-and-association/#nonlinear-form","title":"Nonlinear Form","text":"<p>A relationship has a nonlinear form when the points follow a curved pattern rather than a straight line. Nonlinear relationships are common in the real world, even though they require more sophisticated tools to analyze.</p> <p>Common types of nonlinear patterns:</p> Pattern Description Example Curved (quadratic) Follows a parabola shape Height of a thrown ball over time Exponential Rapid increase or decrease Population growth, radioactive decay Logarithmic Rapid change then leveling off Learning curves, diminishing returns Periodic Repeating pattern Temperature over months of the year <p>The key insight is this: when you see a curved pattern, a straight line won't accurately describe the relationship. Don't try to force a linear model onto nonlinear data!</p> <p>\"Here's a nugget of wisdom: not everything in nature follows a straight line. My acorn collection grew exponentially during my best autumn ever\u2014definitely not linear! The point is to let the data show you what form it takes, rather than assuming everything is linear.\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#microsim-pattern-recognition-gallery","title":"MicroSim: Pattern Recognition Gallery","text":"Identify the Form of Association <p>Type: MicroSim</p> <p>Learning objective: Analyze (Bloom Level 4) - Students will classify scatterplots by their form (linear positive, linear negative, nonlinear, no association).</p> <p>Visual elements:</p> <ul> <li>Gallery of 6 scatterplot thumbnails displayed in a 2x3 grid</li> <li>Larger preview area showing selected scatterplot</li> <li>Classification options displayed as canvas buttons below preview</li> <li>Score tracker in corner</li> <li>Feedback area showing correct/incorrect with brief explanation</li> </ul> <p>Interactive controls:</p> <ul> <li>Click on thumbnail to select and enlarge scatterplot</li> <li>Four classification buttons: \"Linear (Positive)\", \"Linear (Negative)\", \"Nonlinear\", \"No Association\"</li> <li>\"Next Set\" button to generate new random scatterplots</li> <li>\"Hint\" button (limited uses) that highlights the general trend</li> </ul> <p>Behavior:</p> <ul> <li>Clicking a classification button checks the answer</li> <li>Correct answers: point increments, brief explanation appears, plot gets green checkmark</li> <li>Incorrect answers: explanation of correct answer appears, plot remains unmarked</li> <li>All 6 correctly classified triggers congratulatory message and option for new set</li> <li>Scatterplots generated with varying degrees of noise to match difficulty</li> </ul> <p>Canvas size: 750 x 500, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/06-scatterplots-and-association/#the-correlation-coefficient","title":"The Correlation Coefficient","text":"<p>Now let's get quantitative! While describing direction, form, and strength in words is valuable, we need a numerical measure to precisely communicate how strongly two variables are linearly related. Enter the correlation coefficient, denoted by \\( r \\).</p> <p>The correlation coefficient is a number between -1 and 1 that measures the strength and direction of the linear relationship between two quantitative variables.</p> <p>Here's what the values mean:</p> <ul> <li>\\( r = 1 \\): Perfect positive linear relationship</li> <li>\\( r = -1 \\): Perfect negative linear relationship</li> <li>\\( r = 0 \\): No linear relationship</li> <li>Values between 0 and 1 or between -1 and 0 indicate varying strengths</li> </ul>"},{"location":"chapters/06-scatterplots-and-association/#interpreting-correlation-values","title":"Interpreting Correlation Values","text":"Range of \\( r \\) Interpretation ( 0.8 \\leq r ( 0.5 \\leq r ( 0.3 \\leq r ( r <p>The sign of \\( r \\) tells you the direction:</p> <ul> <li>Positive \\( r \\): positive association (upward slope)</li> <li>Negative \\( r \\): negative association (downward slope)</li> </ul> <p>\"Time to squirrel away this knowledge! The correlation coefficient gives us a single number that captures both direction AND strength of a linear relationship. It's like a grade for how well the data follows a straight line. An \\( r \\) of 0.95? That's an A+! An \\( r \\) of 0.2? More like a D-minus for linearity.\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#microsim-guess-the-correlation","title":"MicroSim: Guess the Correlation","text":"Correlation Estimation Game <p>Type: MicroSim</p> <p>Learning objective: Evaluate (Bloom Level 5) - Students will estimate correlation values from scatterplots and develop intuition for what different r-values look like.</p> <p>Visual elements:</p> <ul> <li>Large scatterplot display area (400 x 400)</li> <li>Slider for user's correlation estimate (-1.0 to 1.0)</li> <li>Current guess displayed numerically</li> <li>\"Check Answer\" button</li> <li>Score display showing streak of close guesses</li> <li>Actual r-value revealed after guess</li> </ul> <p>Interactive controls:</p> <ul> <li>Slider to select estimated correlation value</li> <li>\"Check Answer\" button to compare guess to actual value</li> <li>\"New Plot\" button to generate fresh scatterplot</li> <li>Difficulty toggle: Easy (clear patterns, n=50), Medium (moderate scatter, n=30), Hard (subtle patterns, n=20)</li> </ul> <p>Behavior:</p> <ul> <li>User adjusts slider to estimate r-value</li> <li>Clicking \"Check\" reveals actual r with visual comparison</li> <li>If guess is within 0.1 of actual: \"Excellent!\", streak increases</li> <li>If guess is within 0.2: \"Good estimate!\", streak increases</li> <li>If guess is off by more than 0.2: \"Keep practicing!\", streak resets</li> <li>High score tracking for the session</li> <li>New scatterplots generated with random r-values and appropriate scatter</li> </ul> <p>Canvas size: 600 x 500, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/06-scatterplots-and-association/#calculating-correlation","title":"Calculating Correlation","text":"<p>How do we actually compute the correlation coefficient? The formula looks intimidating at first, but it's based on a beautiful idea: we convert both variables to z-scores, then see how their z-scores move together.</p>"},{"location":"chapters/06-scatterplots-and-association/#the-correlation-formula","title":"The Correlation Formula","text":"\\[ r = \\frac{\\sum_{i=1}^{n} z_{x_i} \\cdot z_{y_i}}{n - 1} \\] <p>Where:</p> <ul> <li>\\( z_{x_i} = \\frac{x_i - \\bar{x}}{s_x} \\) is the z-score for each x-value</li> <li>\\( z_{y_i} = \\frac{y_i - \\bar{y}}{s_y} \\) is the z-score for each y-value</li> <li>\\( n \\) is the number of data points</li> </ul> <p>Alternatively, you can write the formula using the raw values:</p> \\[ r = \\frac{1}{n-1} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{s_x} \\right) \\left( \\frac{y_i - \\bar{y}}{s_y} \\right) \\]"},{"location":"chapters/06-scatterplots-and-association/#understanding-the-formula","title":"Understanding the Formula","text":"<p>Why does this formula work? Let's break it down:</p> <ol> <li> <p>Z-scores standardize both variables: This puts x and y on the same scale (mean 0, standard deviation 1), allowing us to compare them fairly.</p> </li> <li> <p>Multiplying z-scores: When both z-scores are positive (both above their means) or both negative (both below their means), the product is positive. When they have opposite signs, the product is negative.</p> </li> <li> <p>Averaging the products: We sum up all these products and divide by \\( n-1 \\) to get the average. A large positive average means strong positive correlation; a large negative average means strong negative correlation.</p> </li> </ol>"},{"location":"chapters/06-scatterplots-and-association/#step-by-step-calculation-example","title":"Step-by-Step Calculation Example","text":"<p>Let's calculate the correlation for a small dataset of hours studied vs. test scores:</p> Student Hours (x) Score (y) A 2 65 B 4 75 C 5 85 D 3 70 E 6 90 <p>Step 1: Calculate means</p> <ul> <li>\\( \\bar{x} = \\frac{2+4+5+3+6}{5} = 4 \\)</li> <li>\\( \\bar{y} = \\frac{65+75+85+70+90}{5} = 77 \\)</li> </ul> <p>Step 2: Calculate standard deviations</p> <ul> <li>\\( s_x = \\sqrt{\\frac{(2-4)^2+(4-4)^2+(5-4)^2+(3-4)^2+(6-4)^2}{4}} = \\sqrt{\\frac{10}{4}} = 1.58 \\)</li> <li>\\( s_y = \\sqrt{\\frac{(65-77)^2+(75-77)^2+(85-77)^2+(70-77)^2+(90-77)^2}{4}} = \\sqrt{\\frac{366}{4}} = 9.57 \\)</li> </ul> <p>Step 3: Calculate z-scores and products</p> Student \\( z_x \\) \\( z_y \\) \\( z_x \\cdot z_y \\) A -1.26 -1.25 1.58 B 0 -0.21 0 C 0.63 0.84 0.53 D -0.63 -0.73 0.46 E 1.26 1.36 1.71 <p>Step 4: Calculate r</p> \\[ r = \\frac{1.58 + 0 + 0.53 + 0.46 + 1.71}{5-1} = \\frac{4.28}{4} = 1.07 \\] <p>Wait\u2014that's greater than 1! Due to rounding in our intermediate steps, we got a slightly off answer. In reality (with more precision), \\( r \\approx 0.99 \\), indicating a very strong positive linear relationship between hours studied and test scores.</p> <p>\"Don't worry\u2014every statistician drops an acorn sometimes. Rounding errors happen! When you're doing these by hand, carry extra decimal places through your calculations. Or better yet, let technology do the heavy lifting and focus on understanding what the result means!\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#microsim-correlation-calculator","title":"MicroSim: Correlation Calculator","text":"Step-by-Step Correlation Computation <p>Type: MicroSim</p> <p>Learning objective: Apply (Bloom Level 3) - Students will calculate correlation step by step and verify their understanding of the formula.</p> <p>Visual elements:</p> <ul> <li>Input table for entering (x, y) pairs (5-8 rows)</li> <li>Calculation display showing intermediate values: means, standard deviations, z-scores</li> <li>Formula displayed with current values substituted in highlighted boxes</li> <li>Scatterplot updating in real-time as data is entered</li> <li>Final r-value with interpretation</li> </ul> <p>Interactive controls:</p> <ul> <li>Editable cells for entering data values</li> <li>\"Calculate\" button to show step-by-step work</li> <li>\"Show/Hide Steps\" toggle for each calculation phase</li> <li>\"Use Sample Data\" button for preset datasets</li> <li>\"Clear All\" button to start fresh</li> <li>Slider to control animation speed of calculation steps</li> </ul> <p>Behavior:</p> <ul> <li>As user enters data, scatterplot updates in real-time</li> <li>\"Calculate\" triggers animated walkthrough of formula</li> <li>Each step highlights relevant values in the table</li> <li>Z-scores are calculated and displayed with color coding (red for negative, green for positive)</li> <li>Final r-value appears with strength/direction interpretation</li> <li>Interpretation changes if r is near 0, moderate, or strong</li> </ul> <p>Canvas size: 800 x 500, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/06-scatterplots-and-association/#properties-of-correlation","title":"Properties of Correlation","text":"<p>The correlation coefficient has several important properties that you need to understand. These properties help you use correlation correctly and avoid common mistakes.</p>"},{"location":"chapters/06-scatterplots-and-association/#key-properties-of-r","title":"Key Properties of r","text":"<ol> <li>The correlation coefficient is unitless</li> </ol> <p>Because we convert to z-scores (which have no units), the correlation between height in inches and weight in pounds is exactly the same as the correlation between height in centimeters and weight in kilograms. Units don't matter!</p> <ol> <li>Correlation is symmetric</li> </ol> <p>The correlation between x and y is exactly the same as the correlation between y and x. Mathematically, \\( r_{xy} = r_{yx} \\). It doesn't matter which variable you call x and which you call y.</p> <ol> <li>Correlation is bounded</li> </ol> <p>Always: \\( -1 \\leq r \\leq 1 \\). If you calculate a value outside this range, you've made an error!</p> <ol> <li>Correlation measures only linear relationships</li> </ol> <p>A correlation of 0 doesn't mean no relationship\u2014it means no linear relationship. Variables can have a perfect curved relationship and still have \\( r = 0 \\).</p> <ol> <li>Correlation is sensitive to outliers</li> </ol> <p>A single extreme point can dramatically change the correlation coefficient. Always examine your scatterplot visually!</p>"},{"location":"chapters/06-scatterplots-and-association/#what-correlation-does-not-tell-you","title":"What Correlation Does NOT Tell You","text":"<p>Understanding what correlation cannot tell you is just as important as understanding what it can:</p> Correlation Cannot Tell You... Why Not Which variable causes the other Correlation is not causation! Whether the relationship is practically important Even small effects can have large correlations with enough data Whether a nonlinear pattern exists It only measures linear association What will happen outside your data range Extrapolation is risky <p>\"Let's crack this nut about causation! I once noticed a near-perfect correlation between the number of birds in my tree and the number of acorns I collected that day. Did the birds bring me acorns? Of course not! More acorns attracted more birds. Same data, very different story. Never forget: correlation is not causation!\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#microsim-correlation-properties-explorer","title":"MicroSim: Correlation Properties Explorer","text":"Explore What Affects Correlation <p>Type: MicroSim</p> <p>Learning objective: Analyze (Bloom Level 4) - Students will investigate how changing data affects the correlation coefficient and develop intuition for correlation properties.</p> <p>Visual elements:</p> <ul> <li>Scatterplot with draggable points</li> <li>Real-time r-value display that updates as points move</li> <li>\"Unit toggle\" showing correlation stays same when units change</li> <li>Outlier point in different color that can be toggled on/off</li> <li>Before/after comparison panel</li> </ul> <p>Interactive controls:</p> <ul> <li>Drag individual points to new positions</li> <li>\"Add Outlier\" toggle to see impact of extreme point</li> <li>\"Swap Axes\" button demonstrating symmetry property</li> <li>\"Change Units\" dropdown (showing r stays constant)</li> <li>\"Reset Points\" button</li> <li>\"Add Random Point\" button to grow dataset</li> </ul> <p>Behavior:</p> <ul> <li>r-value updates continuously as user drags points</li> <li>Swapping axes shows same r-value (symmetry)</li> <li>Adding/removing outlier shows dramatic r-value change</li> <li>Changing units displays converted axis labels but same r</li> <li>Points near the edge of the pattern space have larger effects when moved</li> <li>Color gradient on points indicates their contribution to r</li> </ul> <p>Canvas size: 700 x 500, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/06-scatterplots-and-association/#correlation-limitations","title":"Correlation Limitations","text":"<p>Before you start using correlation for everything, let's talk about its limitations. Understanding these will make you a smarter statistician and help you avoid embarrassing mistakes.</p>"},{"location":"chapters/06-scatterplots-and-association/#correlation-is-not-causation","title":"Correlation is NOT Causation","text":"<p>This is perhaps the most important limitation. Just because two variables are correlated does not mean one causes the other. There are several reasons why non-causal variables might be correlated:</p> <ol> <li> <p>Confounding variables: A third variable influences both x and y. Ice cream sales and drowning deaths are correlated\u2014but summer weather causes both!</p> </li> <li> <p>Reverse causation: Maybe y causes x, not x causes y.</p> </li> <li> <p>Coincidence: With enough variables, some will be correlated by pure chance. (Did you know the divorce rate in Maine correlates with margarine consumption? Meaningless!)</p> </li> </ol>"},{"location":"chapters/06-scatterplots-and-association/#correlation-only-measures-linear-relationships","title":"Correlation Only Measures Linear Relationships","text":"<p>This limitation trips up many students. Consider data that follows a perfect parabola: when x is low, y is high; when x is medium, y is low; when x is high, y is high again. Despite this perfect relationship, the correlation would be near zero!</p> <p>Always plot your data first. A scatterplot will reveal nonlinear patterns that correlation will miss entirely.</p>"},{"location":"chapters/06-scatterplots-and-association/#outliers-can-distort-correlation","title":"Outliers Can Distort Correlation","text":"<p>A single outlier can:</p> <ul> <li>Inflate the correlation (making a weak relationship look strong)</li> <li>Deflate the correlation (making a strong relationship look weak)</li> <li>Even reverse the sign of the correlation!</li> </ul> <p>When you spot outliers, investigate them. Are they data entry errors? Unusual but valid observations? Your interpretation may need to account for them.</p>"},{"location":"chapters/06-scatterplots-and-association/#correlation-doesnt-work-well-for-restricted-ranges","title":"Correlation Doesn't Work Well for Restricted Ranges","text":"<p>If you only look at part of the data range, you may miss or misrepresent the true relationship. For example, the correlation between SAT scores and college GPA among students at a highly selective university will be lower than in the general population\u2014because the university already restricted the range of SAT scores!</p>"},{"location":"chapters/06-scatterplots-and-association/#other-important-limitations","title":"Other Important Limitations","text":"<ul> <li>Correlation assumes quantitative variables: Don't try to calculate r for categorical data</li> <li>Sample size matters: Correlations from small samples are less reliable</li> <li>Correlation doesn't describe the relationship: It won't tell you how y changes when x increases</li> </ul> <p>\"Here's the acorn of wisdom I want you to carry away: correlation is a powerful tool, but it's not a magic wand. It tells you about linear association\u2014nothing more. Always look at your scatterplot, think about causation carefully, and watch out for lurking variables!\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#microsim-correlation-pitfalls-demo","title":"MicroSim: Correlation Pitfalls Demo","text":"Explore Common Correlation Mistakes <p>Type: MicroSim</p> <p>Learning objective: Evaluate (Bloom Level 5) - Students will recognize situations where correlation is misleading and explain why.</p> <p>Visual elements:</p> <ul> <li>Four tabbed scenarios: \"Nonlinear Data\", \"Outlier Effect\", \"Restricted Range\", \"Confounding Variable\"</li> <li>Scatterplot in each tab showing the scenario</li> <li>Calculated r-value displayed prominently</li> <li>Explanation panel that reveals after user makes prediction</li> <li>\"What's wrong here?\" prompt for each scenario</li> </ul> <p>Interactive controls:</p> <ul> <li>Tab buttons to switch between scenarios</li> <li>\"Predict\" dropdown for each scenario (choices vary by tab)</li> <li>\"Reveal\" button to show explanation</li> <li>In \"Outlier Effect\" tab: toggle to remove outlier and see new r</li> <li>In \"Restricted Range\" tab: slider to expand/contract visible range</li> <li>\"Next Challenge\" button for additional examples within each category</li> </ul> <p>Behavior:</p> <ul> <li>Each scenario presents a scatterplot with a specific problem</li> <li>User predicts what's misleading about the correlation</li> <li>Reveal shows explanation with the correct answer</li> <li>Outlier tab: removing point shows dramatic r change</li> <li>Restricted range: expanding view shows different r</li> <li>Confounding tab: shows third variable that explains both</li> <li>Tracks correct predictions across scenarios</li> </ul> <p>Canvas size: 750 x 550, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/06-scatterplots-and-association/#bringing-it-all-together","title":"Bringing It All Together","text":"<p>Let's review the complete workflow for analyzing relationships between two quantitative variables:</p> <ol> <li> <p>Create a scatterplot with the explanatory variable on the x-axis and response on the y-axis</p> </li> <li> <p>Describe the relationship in terms of:</p> </li> <li>Direction (positive, negative, or none)</li> <li>Form (linear, nonlinear, or no pattern)</li> <li>Strength (strong, moderate, or weak)</li> <li> <p>Unusual features (outliers, clusters)</p> </li> <li> <p>Calculate correlation (if the form is linear) to quantify the strength and direction</p> </li> <li> <p>Interpret carefully:</p> </li> <li>Remember correlation is not causation</li> <li>Consider potential confounding variables</li> <li>Watch for outliers affecting your results</li> <li> <p>Don't extrapolate beyond your data</p> </li> <li> <p>Report your findings with appropriate context and caveats</p> </li> </ol> <p>\"You've come so far! From looking at single variables to understanding relationships between pairs of variables\u2014that's a huge leap. In the next chapter, we'll take this even further with regression, where we'll learn to predict one variable from another. But for now, give yourself credit for mastering scatterplots and correlation. Now that's a data point worth collecting!\" \u2014 Sylvia</p>"},{"location":"chapters/06-scatterplots-and-association/#key-takeaways","title":"Key Takeaways","text":"<p>Here are the essential concepts to squirrel away from this chapter:</p> <ol> <li> <p>Scatterplots display the relationship between two quantitative variables, with explanatory variable on the x-axis and response on the y-axis.</p> </li> <li> <p>Describe scatterplots using direction (positive/negative/none), form (linear/nonlinear/none), strength (strong/moderate/weak), and unusual features.</p> </li> <li> <p>Linear form means points cluster around a straight line; nonlinear form means points follow a curved pattern.</p> </li> <li> <p>The correlation coefficient \\( r \\) measures the strength and direction of linear relationships, ranging from -1 to +1.</p> </li> <li> <p>Correlation formula: \\( r = \\frac{1}{n-1} \\sum z_x \\cdot z_y \\) \u2014 based on products of z-scores.</p> </li> <li> <p>Properties of correlation: unitless, symmetric, bounded between -1 and 1, measures only linear relationships, sensitive to outliers.</p> </li> <li> <p>Correlation limitations: Does not imply causation, only detects linear patterns, can be distorted by outliers and restricted ranges.</p> </li> <li> <p>Always plot first, calculate second. Visual inspection reveals patterns that correlation alone cannot detect.</p> </li> <li> <p>Correlation is not causation\u2014this bears repeating! Confounding variables, reverse causation, and coincidence can all produce correlations without causal relationships.</p> </li> </ol>"},{"location":"chapters/06-scatterplots-and-association/#practice-problems","title":"Practice Problems","text":"<p>Test your understanding with these practice problems. Remember Sylvia's advice: doing statistics is where it clicks!</p>"},{"location":"chapters/06-scatterplots-and-association/#problem-1-interpreting-scatterplots","title":"Problem 1: Interpreting Scatterplots","text":"<p>A researcher collects data on the number of hours students spend on social media per day (x) and their GPA (y). The scatterplot shows points that generally go from upper left to lower right, with moderate scatter around the pattern.</p> <p>a) What is the direction of the association? b) Would you expect the correlation to be positive or negative? c) Estimate the correlation: is it closer to -0.3, -0.6, or -0.9? d) Can we conclude that social media use causes lower GPAs? Explain.</p>"},{"location":"chapters/06-scatterplots-and-association/#problem-2-calculating-correlation","title":"Problem 2: Calculating Correlation","text":"<p>Given the following data on hours of sleep (x) and alertness rating on a 1-10 scale (y):</p> Hours of Sleep 5 6 7 8 9 Alertness 4 5 7 8 9 <p>a) Create a scatterplot of this data. b) Calculate the correlation coefficient \\( r \\). c) Describe the relationship in terms of direction, form, and strength.</p>"},{"location":"chapters/06-scatterplots-and-association/#problem-3-properties-of-correlation","title":"Problem 3: Properties of Correlation","text":"<p>For each statement, determine if it is True or False and explain why:</p> <p>a) If \\( r = 0 \\), there is no relationship between x and y. b) The correlation between height in inches and weight in pounds will be different from the correlation between height in centimeters and weight in kilograms. c) If we swap x and y in our scatterplot, the correlation will remain the same. d) A correlation of \\( r = 0.95 \\) proves that changes in x cause changes in y.</p>"},{"location":"chapters/06-scatterplots-and-association/#problem-4-identifying-limitations","title":"Problem 4: Identifying Limitations","text":"<p>A study finds a correlation of \\( r = 0.78 \\) between the number of firefighters at a fire and the amount of damage caused by the fire.</p> <p>a) Does this mean that bringing more firefighters causes more damage? b) What is a more likely explanation for this correlation? c) What type of correlation limitation does this example illustrate?</p>"},{"location":"chapters/06-scatterplots-and-association/#problem-5-form-of-association","title":"Problem 5: Form of Association","text":"<p>For each scenario, predict whether the relationship would be linear or nonlinear:</p> <p>a) The height of a ball thrown upward versus time b) The cost of a phone call versus its duration (at a fixed per-minute rate) c) The population of bacteria in a petri dish versus time d) The temperature in Celsius versus temperature in Fahrenheit</p>"},{"location":"chapters/06-scatterplots-and-association/#problem-6-outlier-effects","title":"Problem 6: Outlier Effects","text":"<p>Consider a dataset with \\( n = 20 \\) points showing a strong positive linear relationship with \\( r = 0.92 \\). One additional point is added at a position far from the others.</p> <p>a) How might this outlier affect the correlation if it falls in the direction of the existing trend (far upper right)? b) How might it affect the correlation if it falls away from the trend (far lower right)? c) What should you do when you discover an outlier in your data?</p>"},{"location":"chapters/06-scatterplots-and-association/#problem-7-ap-exam-style-free-response","title":"Problem 7: AP Exam Style Free Response","text":"<p>A nutritionist studies the relationship between daily vegetable servings (x) and systolic blood pressure (y) for 50 adults. The scatterplot shows a negative linear association, and the correlation is \\( r = -0.65 \\).</p> <p>a) Describe what \\( r = -0.65 \\) tells us about this relationship. b) The nutritionist calculates \\( r^2 = 0.42 \\). Interpret this value in context. c) A health magazine reports: \"Eating more vegetables lowers blood pressure, study proves!\" Critique this claim using what you know about correlation. d) Suggest two confounding variables that might explain the observed correlation.</p> <p>Good luck with your practice! Remember: every problem you work through is another step toward mastering statistics. Let's crack these nuts!</p>"},{"location":"chapters/07-linear-regression/","title":"Linear Regression","text":""},{"location":"chapters/07-linear-regression/#summary","title":"Summary","text":"<p>This chapter covers least squares regression, the most important technique for modeling linear relationships between variables. Students will learn to interpret slope and y-intercept, make predictions, calculate and analyze residuals, understand the coefficient of determination (R\u00b2), and identify influential points and outliers in regression.</p>"},{"location":"chapters/07-linear-regression/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 16 concepts from the learning graph:</p> <ol> <li>Least Squares Regression</li> <li>Regression Line</li> <li>Regression Equation</li> <li>Slope Interpretation</li> <li>Y-Intercept Interpretation</li> <li>Making Predictions</li> <li>Extrapolation Dangers</li> <li>Residual</li> <li>Calculating Residuals</li> <li>Residual Plot</li> <li>Interpreting Residuals</li> <li>Coefficient of Determination</li> <li>R-Squared Interpretation</li> <li>Influential Point</li> <li>Leverage</li> <li>Outliers in Regression</li> </ol>"},{"location":"chapters/07-linear-regression/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 6: Scatterplots and Association</li> </ul>"},{"location":"chapters/07-linear-regression/#introduction-from-patterns-to-predictions","title":"Introduction: From Patterns to Predictions","text":"<p>Welcome back! In Chapter 6, you learned to spot linear relationships in scatterplots and measure their strength with correlation. But here's the thing\u2014knowing that height and shoe size are correlated is interesting, but wouldn't it be more useful to actually predict someone's shoe size from their height? That's exactly where regression comes in.</p> <p>Regression is one of the most powerful tools in statistics. It lets you draw a line through your data and use that line to make predictions about new observations. Doctors use it to predict health outcomes, economists use it to forecast trends, and yes, Sylvia uses it to estimate acorn yields from tree measurements.</p> <p>\ud83d\udc3f\ufe0f \"Let's crack this nut! Regression is where statistics gets really practical\u2014we're not just describing data anymore, we're predicting the future!\"</p>"},{"location":"chapters/07-linear-regression/#the-least-squares-regression-line","title":"The Least Squares Regression Line","text":"<p>When you have a scatterplot showing a linear relationship, you want to draw a line that best captures the pattern. But what makes one line \"better\" than another? The answer involves minimizing errors\u2014specifically, we want to minimize how far our data points fall from the line.</p>"},{"location":"chapters/07-linear-regression/#what-is-least-squares-regression","title":"What Is Least Squares Regression?","text":"<p>Least squares regression is a method for finding the line that minimizes the sum of the squared vertical distances from each data point to the line. These vertical distances are called residuals (more on those soon), and by squaring them before adding, we accomplish two things:</p> <ol> <li>Negative and positive distances don't cancel out</li> <li>Large errors are penalized more heavily than small ones</li> </ol> <p>The result is called the regression line or least squares regression line (LSRL)\u2014the single best-fitting straight line for your data.</p> Term Definition Least Squares Regression Method that minimizes the sum of squared residuals Regression Line The best-fit line through a scatterplot Predicted Value The y-value on the regression line for a given x"},{"location":"chapters/07-linear-regression/#the-regression-equation","title":"The Regression Equation","text":"<p>The regression equation describes the relationship between your explanatory variable \\( x \\) and your response variable \\( y \\). It takes this familiar form:</p> \\[ \\hat{y} = a + bx \\] <p>Here's what each piece means:</p> <ul> <li>\\( \\hat{y} \\) (read \"y-hat\") is the predicted value of y</li> <li>\\( a \\) is the y-intercept\u2014the predicted y-value when \\( x = 0 \\)</li> <li>\\( b \\) is the slope\u2014how much \\( \\hat{y} \\) changes for each one-unit increase in \\( x \\)</li> <li>\\( x \\) is the value of the explanatory variable</li> </ul> <p>Notice that little hat symbol over the y. It's crucial! Regular \\( y \\) represents actual observed values, while \\( \\hat{y} \\) represents predicted values from your regression line. Keeping these straight will save you many headaches on the AP exam.</p>"},{"location":"chapters/07-linear-regression/#microsim-least-squares-regression-explorer","title":"MicroSim: Least Squares Regression Explorer","text":"Interactive Least Squares Visualization <p>Type: MicroSim</p> <p>Learning objective: Understand (Bloom Level 2) how the least squares method finds the best-fit line by minimizing squared residuals</p> <p>Visual elements: - Coordinate plane with grid (400x400 pixels) - 8-12 draggable data points displayed as circles - Regression line that updates dynamically as points move - Vertical lines from each point to regression line (residuals) in light red - Squares drawn at each residual to visualize \"squared\" distances - Display of sum of squared residuals, updating in real-time</p> <p>Interactive controls: - Draggable data points (click and drag to reposition) - \"Reset Points\" button to restore default configuration - \"Random Points\" button to generate new dataset - Toggle to show/hide residual squares</p> <p>Behavior: - As user drags points, regression line recalculates instantly - Sum of squared residuals updates in real-time - Residual squares resize dynamically to show their contribution - Line always passes through the point \\( (\\bar{x}, \\bar{y}) \\)</p> <p>Canvas size: 500x450, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/07-linear-regression/#calculating-slope-and-intercept","title":"Calculating Slope and Intercept","text":"<p>While you'll typically use technology to find regression equations, understanding the formulas helps you grasp what's happening:</p> <p>The slope \\( b \\) is calculated as:</p> \\[ b = r \\cdot \\frac{s_y}{s_x} \\] <p>Where: - \\( r \\) is the correlation coefficient - \\( s_y \\) is the standard deviation of y - \\( s_x \\) is the standard deviation of x</p> <p>The y-intercept \\( a \\) is:</p> \\[ a = \\bar{y} - b\\bar{x} \\] <p>These formulas reveal something beautiful: the regression line always passes through the point \\( (\\bar{x}, \\bar{y}) \\). It's like the line is anchored at the center of your data.</p>"},{"location":"chapters/07-linear-regression/#interpreting-slope-and-y-intercept","title":"Interpreting Slope and Y-Intercept","text":"<p>Finding the regression equation is just the beginning. The real skill lies in interpreting what the slope and y-intercept tell us about the relationship between variables.</p>"},{"location":"chapters/07-linear-regression/#slope-interpretation","title":"Slope Interpretation","text":"<p>The slope tells you the rate of change\u2014specifically, how much the predicted y-value changes for each one-unit increase in x. Here's the template for interpretation:</p> <p>\"For each additional [one unit of x], the predicted [y variable] increases/decreases by [slope value] [units of y].\"</p> <p>Example: Suppose you're studying the relationship between hours of study and exam score, and you find \\( \\hat{y} = 45 + 5.2x \\).</p> <p>Interpretation: \"For each additional hour of studying, the predicted exam score increases by 5.2 points.\"</p> <p>Notice we say \"predicted\" because regression gives us estimates, not guarantees. We also say \"increases by\" because the slope (5.2) is positive. If the slope were negative, we'd say \"decreases by.\"</p> <p>\ud83d\udc3f\ufe0f \"Acorn for your thoughts? When I measured tree circumference (x) and acorn yield (y), my slope was 12.3. That means for every additional inch of circumference, I predicted 12.3 more acorns. Now THAT'S data worth collecting!\"</p>"},{"location":"chapters/07-linear-regression/#y-intercept-interpretation","title":"Y-Intercept Interpretation","text":"<p>The y-intercept is the predicted value of y when x equals zero. Here's the interpretation template:</p> <p>\"When [x variable] is zero, the predicted [y variable] is [intercept value] [units of y].\"</p> <p>Example: Using the same equation \\( \\hat{y} = 45 + 5.2x \\):</p> <p>Interpretation: \"When study time is zero hours, the predicted exam score is 45 points.\"</p> <p>Important caveat: The y-intercept often doesn't make practical sense! In our example, students who study zero hours still have some baseline knowledge, so a score of 45 might be reasonable. But if you're predicting weight from height and get a negative y-intercept, that's meaningless\u2014people can't have negative weight.</p> Situation Y-Intercept Interpretation x = 0 is within data range Interpret literally x = 0 is outside data range Often has no practical meaning x = 0 is impossible State that interpretation isn't meaningful <p>Always ask yourself: \"Does x = 0 make sense in this context?\" If not, acknowledge that the y-intercept is just the mathematical starting point of your line, not a meaningful prediction.</p>"},{"location":"chapters/07-linear-regression/#microsim-slope-and-intercept-explorer","title":"MicroSim: Slope and Intercept Explorer","text":"Interactive Slope and Intercept Manipulation <p>Type: MicroSim</p> <p>Learning objective: Analyze (Bloom Level 4) how changes to slope and y-intercept affect the regression line and predictions</p> <p>Visual elements: - Coordinate plane with labeled axes (400x400 pixels) - Regression line displayed prominently - 5-7 static data points for reference context - Current equation displayed in form \\( \\hat{y} = a + bx \\) - Predicted value marker that follows mouse x-position on line - Annotations showing rise/run for slope visualization</p> <p>Interactive controls: - Slider for slope (range -3 to 3, step 0.1) - Slider for y-intercept (range -50 to 150, step 1) - \"Show Best Fit\" toggle to display actual LSRL - Text display showing current prediction at mouse position</p> <p>Behavior: - Line updates instantly as sliders change - Prediction point moves along line following mouse x-coordinate - When \"Show Best Fit\" is on, displays comparison between user line and LSRL - Displays sum of squared residuals for current line position</p> <p>Canvas size: 550x450, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/07-linear-regression/#making-predictions","title":"Making Predictions","text":"<p>One of the primary uses of regression is making predictions. Once you have a regression equation, you can plug in any x-value to predict the corresponding y-value.</p>"},{"location":"chapters/07-linear-regression/#the-prediction-process","title":"The Prediction Process","text":"<p>Making predictions involves substituting values into your regression equation:</p> <ol> <li>Identify the x-value you want to use for prediction</li> <li>Substitute it into the equation \\( \\hat{y} = a + bx \\)</li> <li>Calculate to find \\( \\hat{y} \\)</li> </ol> <p>Example: Using \\( \\hat{y} = 45 + 5.2x \\), predict the exam score for a student who studies 6 hours.</p> \\[ \\hat{y} = 45 + 5.2(6) = 45 + 31.2 = 76.2 \\] <p>The predicted exam score is 76.2 points.</p>"},{"location":"chapters/07-linear-regression/#the-dangers-of-extrapolation","title":"The Dangers of Extrapolation","text":"<p>Here's where things get tricky. Extrapolation means making predictions outside the range of your original data\u2014and it's dangerous business.</p> <p>Why? Because you have no evidence that the linear pattern continues beyond your data. The relationship might curve, level off, or change direction entirely. Your regression line is only trustworthy within the range of x-values you actually observed.</p> <p>Example of extrapolation danger: Suppose your study time data ranged from 1 to 8 hours. Predicting for 6 hours? Perfectly fine\u2014that's interpolation (within your data range). Predicting for 20 hours? That's extrapolation, and your equation might give you a predicted score of 149 points\u2014which is impossible on a 100-point exam!</p> <p>\ud83d\udc3f\ufe0f \"Trust me, I learned this the hard way. My regression predicted that a 50-inch circumference tree would yield 600 acorns. The largest tree I'd measured was 20 inches. Turns out, massive trees have other issues\u2014squirrel traffic jams, for instance\u2014and my prediction was way off!\"</p> Term Definition Risk Level Interpolation Predicting within the x-range of data Low risk Extrapolation Predicting outside the x-range of data High risk Near extrapolation Predicting just outside the range Moderate risk"},{"location":"chapters/07-linear-regression/#understanding-residuals","title":"Understanding Residuals","text":"<p>Now let's dive into one of the most important concepts in regression analysis: residuals. Understanding residuals is key to evaluating whether your regression line is doing a good job.</p>"},{"location":"chapters/07-linear-regression/#what-is-a-residual","title":"What Is a Residual?","text":"<p>A residual is the difference between an actual observed value and the predicted value from your regression line:</p> \\[ \\text{Residual} = y - \\hat{y} = \\text{Observed} - \\text{Predicted} \\] <p>Think of residuals as prediction errors. They tell you how far off your prediction was for each data point.</p> <ul> <li>Positive residual: The actual value is above the regression line (you underestimated)</li> <li>Negative residual: The actual value is below the regression line (you overestimated)</li> <li>Residual of zero: The point falls exactly on the line (perfect prediction!)</li> </ul>"},{"location":"chapters/07-linear-regression/#calculating-residuals","title":"Calculating Residuals","text":"<p>Calculating residuals is straightforward:</p> <ol> <li>Use the regression equation to find \\( \\hat{y} \\) for each x-value</li> <li>Subtract the predicted value from the actual observed value</li> </ol> <p>Example: Given the equation \\( \\hat{y} = 45 + 5.2x \\), calculate the residual for a student who studied 4 hours and scored 68.</p> <p>Step 1: Find the predicted value</p> \\[ \\hat{y} = 45 + 5.2(4) = 45 + 20.8 = 65.8 \\] <p>Step 2: Calculate the residual</p> \\[ \\text{Residual} = 68 - 65.8 = 2.2 \\] <p>The residual is 2.2, meaning this student scored 2.2 points higher than predicted. The actual point is above the regression line.</p> <p>Here's a sample calculation table:</p> Student Hours (x) Actual Score (y) Predicted \\( \\hat{y} \\) Residual A 2 54 55.4 -1.4 B 4 68 65.8 2.2 C 6 75 76.2 -1.2 D 7 85 81.4 3.6 <p>\ud83d\udc3f\ufe0f \"Here's a fun fact: if you add up all your residuals, they'll equal zero (or really close to zero due to rounding). The least squares line is balanced\u2014the overestimates and underestimates cancel out!\"</p>"},{"location":"chapters/07-linear-regression/#microsim-residual-calculator","title":"MicroSim: Residual Calculator","text":"Interactive Residual Visualization Tool <p>Type: MicroSim</p> <p>Learning objective: Apply (Bloom Level 3) residual calculations by computing and visualizing residuals for individual data points</p> <p>Visual elements: - Scatterplot with 8-10 data points (400x400 pixels) - Regression line fitted to data - Vertical lines from each point to line showing residuals - Color-coded residuals (green for positive, red for negative) - Selected point highlighted with larger circle - Calculation display showing y, \u0177, and residual for selected point</p> <p>Interactive controls: - Click on any data point to select it - Display panel showing detailed calculation for selected point - \"Show All Residuals\" toggle - \"Add New Point\" button allowing user to click to add point</p> <p>Behavior: - Clicking a point shows detailed residual calculation - Residual lines animate when point is selected - Adding a new point recalculates regression and all residuals - Running sum of residuals displayed (showing it equals zero)</p> <p>Canvas size: 550x500, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/07-linear-regression/#residual-plots-your-diagnostic-tool","title":"Residual Plots: Your Diagnostic Tool","text":"<p>Calculating individual residuals is useful, but the real power comes from looking at all residuals together in a residual plot.</p>"},{"location":"chapters/07-linear-regression/#creating-residual-plots","title":"Creating Residual Plots","text":"<p>A residual plot displays residuals on the vertical axis versus either: - The x-values (explanatory variable), or - The predicted values \\( \\hat{y} \\)</p> <p>Both approaches work, but plotting against x-values is most common.</p>"},{"location":"chapters/07-linear-regression/#interpreting-residual-plots","title":"Interpreting Residual Plots","text":"<p>Interpreting residuals through a residual plot tells you whether your linear model is appropriate. Here's what to look for:</p> <p>Good residual plot (linear model is appropriate): - Points scattered randomly above and below the horizontal line at zero - No obvious patterns, curves, or clusters - Relatively consistent spread across all x-values</p> <p>Problematic residual plot (linear model may be inappropriate): - Curved pattern suggests a nonlinear relationship - Funnel shape (residuals fanning out) indicates changing variability - Clusters or groups suggest subpopulations in your data</p> Pattern in Residual Plot What It Suggests Random scatter Linear model is appropriate Curved pattern Relationship is nonlinear Funnel shape Variability changes with x Distinct clusters Possible subgroups in data <p>\ud83d\udc3f\ufe0f \"My tail's tingling\u2014we're onto something important here! A good residual plot should look like static on an old TV\u2014just random noise. If you see a pattern, that pattern is telling you something your line missed!\"</p>"},{"location":"chapters/07-linear-regression/#microsim-residual-plot-analyzer","title":"MicroSim: Residual Plot Analyzer","text":"Interactive Residual Plot Diagnostic Tool <p>Type: MicroSim</p> <p>Learning objective: Evaluate (Bloom Level 5) whether a linear model is appropriate by analyzing residual plot patterns</p> <p>Visual elements: - Side-by-side display: scatterplot with line (left) and residual plot (right) - Horizontal reference line at y = 0 on residual plot - Points connected between both plots (highlighting correspondence) - Pattern indicator showing diagnosis (good fit, curved, fan-shaped, etc.) - Zoom capability on residual plot</p> <p>Interactive controls: - Dataset selector dropdown (linear data, quadratic data, heteroscedastic data) - \"Generate New Data\" button for random variations - Toggle to show/hide connecting lines between plots - Pattern identification quiz mode</p> <p>Behavior: - Selecting different datasets shows corresponding residual patterns - Hovering over point in one plot highlights it in both - Quiz mode asks user to identify the pattern before revealing answer - Animated transition when switching datasets</p> <p>Canvas size: 650x400, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/07-linear-regression/#the-coefficient-of-determination-r2","title":"The Coefficient of Determination (R\u00b2)","text":"<p>You've already learned about correlation \\( r \\), which measures the strength and direction of a linear relationship. Now meet its close relative: \\( R^2 \\), the coefficient of determination.</p>"},{"location":"chapters/07-linear-regression/#what-is-r-squared","title":"What Is R-Squared?","text":"<p>The coefficient of determination, written as \\( R^2 \\), tells you how much of the variability in y is explained by the linear relationship with x. It's simply the correlation coefficient squared:</p> \\[ R^2 = r^2 \\] <p>For example, if \\( r = 0.8 \\), then \\( R^2 = 0.64 \\), meaning 64% of the variability in y is explained by the linear relationship with x.</p>"},{"location":"chapters/07-linear-regression/#interpreting-r-squared","title":"Interpreting R-Squared","text":"<p>Here's the template for R-squared interpretation:</p> <p>\"R\u00b2 = [value] means that [percentage]% of the variability in [y variable] can be explained by the linear relationship with [x variable].\"</p> <p>Example: In our study time and exam score data, suppose \\( r = 0.85 \\). Then \\( R^2 = 0.72 \\).</p> <p>Interpretation: \"72% of the variability in exam scores can be explained by the linear relationship with study time.\"</p> <p>The remaining 28%? That's variability from other factors\u2014natural ability, test anxiety, sleep quality, whether you had a good breakfast... all things not captured by study time alone.</p> R\u00b2 Value Strength Interpretation 0.90 - 1.00 Very strong x explains 90%+ of y's variability 0.70 - 0.89 Strong x explains most of y's variability 0.50 - 0.69 Moderate x explains a substantial portion 0.25 - 0.49 Weak x explains some variability 0.00 - 0.24 Very weak x explains little variability <p>Important notes about R\u00b2:</p> <ol> <li>R\u00b2 is always between 0 and 1 (or 0% and 100%)</li> <li>R\u00b2 doesn't tell you direction\u2014you lose the sign when you square r</li> <li>A high R\u00b2 doesn't mean the relationship is linear (always check residual plots!)</li> <li>R\u00b2 doesn't prove causation</li> </ol> <p>\ud83d\udc3f\ufe0f \"Time to squirrel away this knowledge: R\u00b2 is like a grade for your regression line. An R\u00b2 of 0.80 is like getting a B\u2014your line explains most of what's happening, but there's still room for improvement!\"</p>"},{"location":"chapters/07-linear-regression/#influential-points-and-outliers","title":"Influential Points and Outliers","text":"<p>Not all data points are created equal. Some points have an outsized impact on your regression line, and it's crucial to identify them.</p>"},{"location":"chapters/07-linear-regression/#influential-points","title":"Influential Points","text":"<p>An influential point is a data point that substantially changes the regression line when it's removed from the dataset. Influential points can:</p> <ul> <li>Change the slope dramatically</li> <li>Shift the y-intercept</li> <li>Alter the correlation and R\u00b2</li> </ul> <p>How do you know if a point is influential? Remove it, recalculate the regression, and see if the equation changes substantially. If it does, that point is influential.</p>"},{"location":"chapters/07-linear-regression/#leverage","title":"Leverage","text":"<p>Leverage refers to how extreme a point's x-value is compared to the other x-values in your dataset. Points with high leverage are far from \\( \\bar{x} \\) in the horizontal direction.</p> <p>Here's the key insight: points with high leverage have the potential to be influential, but they aren't automatically influential. It depends on whether they follow the pattern of the other data or deviate from it.</p> Scenario High Leverage? Influential? Point far from \\( \\bar{x} \\), follows pattern Yes Usually no Point far from \\( \\bar{x} \\), off pattern Yes Yes Point near \\( \\bar{x} \\), far from line No Usually no <p>Think of leverage like a seesaw. A person at the end of the seesaw (high leverage) can tip the balance easily, but only if they're on the wrong side of where they \"should\" be.</p>"},{"location":"chapters/07-linear-regression/#outliers-in-regression","title":"Outliers in Regression","text":"<p>An outlier in regression is a point with an unusually large residual\u2014it falls far from the regression line vertically. Outliers can be:</p> <ul> <li>Near the center (low leverage): These rarely affect the regression much because they're balanced by points on both sides</li> <li>At the extremes (high leverage): These can be highly influential because there's less data to counterbalance them</li> </ul> <p>When you find an outlier, investigate it:</p> <ol> <li>Is it a data entry error? (Fix it)</li> <li>Is it from a different population? (Consider removing it or analyzing separately)</li> <li>Is it a genuine but unusual observation? (Report results with and without it)</li> </ol> <p>\ud83d\udc3f\ufe0f \"One year, I recorded a tree that yielded 847 acorns\u2014way more than any other. Turned out it was actually TWO trees whose branches had grown together! That's an outlier worth investigating. Never just delete outliers without understanding why they're unusual.\"</p>"},{"location":"chapters/07-linear-regression/#microsim-influential-points-explorer","title":"MicroSim: Influential Points Explorer","text":"Interactive Influential Point Investigation Tool <p>Type: MicroSim</p> <p>Learning objective: Evaluate (Bloom Level 5) how individual points affect regression by manipulating high-leverage and outlier points</p> <p>Visual elements: - Scatterplot with 10-12 data points and regression line (450x400 pixels) - One special point highlighted in different color (the \"test\" point) - Secondary regression line (dashed) showing fit without the special point - Display of both equations and R\u00b2 values (with and without point) - Leverage indicator bar showing x-distance from mean</p> <p>Interactive controls: - Draggable \"test\" point that can be moved anywhere - Toggle to show/hide comparison regression line - \"Reset to Original\" button - Slider to adjust number of background points - Display showing: current residual, leverage score, influence measure</p> <p>Behavior: - As test point moves, both regression lines update - Color coding indicates influence level (green = low, yellow = moderate, red = high) - Moving point far horizontally increases leverage indicator - Moving point vertically away from pattern increases residual - Comparison statistics update in real-time</p> <p>Canvas size: 600x500, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/07-linear-regression/#putting-it-all-together-complete-regression-analysis","title":"Putting It All Together: Complete Regression Analysis","text":"<p>Now that you've learned all the components, let's walk through a complete regression analysis from start to finish.</p>"},{"location":"chapters/07-linear-regression/#the-regression-analysis-workflow","title":"The Regression Analysis Workflow","text":"<ol> <li>Examine the scatterplot - Verify the relationship appears linear</li> <li>Calculate the regression equation - Find slope and y-intercept</li> <li>Interpret the slope - In context of the problem</li> <li>Interpret the y-intercept - If meaningful</li> <li>Check R\u00b2 - How much variability is explained?</li> <li>Create and analyze the residual plot - Is the linear model appropriate?</li> <li>Look for influential points and outliers - Any concerns?</li> <li>Make predictions - For x-values within the data range</li> </ol> <p>Example: Complete Analysis</p> <p>A researcher collected data on the relationship between daily temperature (\u00b0F) and ice cream sales ($) at a beach stand over 20 summer days. Temperature ranged from 72\u00b0F to 94\u00b0F.</p> <p>Results: - Regression equation: \\( \\hat{y} = -152.3 + 4.7x \\) - \\( r = 0.92 \\), so \\( R^2 = 0.85 \\)</p> <p>Interpretation of slope: For each additional degree Fahrenheit, predicted ice cream sales increase by $4.70.</p> <p>Interpretation of y-intercept: The y-intercept of -$152.30 represents predicted sales when temperature is 0\u00b0F. This is extrapolation far outside our data range (and also, no one's buying ice cream when it's 0\u00b0F), so this value has no practical meaning.</p> <p>R\u00b2 interpretation: 85% of the variability in ice cream sales can be explained by the linear relationship with temperature.</p> <p>Prediction: What are predicted sales when the temperature is 85\u00b0F?</p> \\[ \\hat{y} = -152.3 + 4.7(85) = -152.3 + 399.5 = 247.2 \\] <p>Predicted sales are $247.20.</p>"},{"location":"chapters/07-linear-regression/#microsim-complete-regression-analysis-tool","title":"MicroSim: Complete Regression Analysis Tool","text":"Full Regression Analysis Dashboard <p>Type: MicroSim</p> <p>Learning objective: Create (Bloom Level 6) a complete regression analysis by integrating all concepts: equation, interpretation, residuals, and predictions</p> <p>Visual elements: - Main scatterplot with data and regression line (400x350 pixels) - Residual plot below scatterplot (400x200 pixels) - Statistics panel showing: equation, r, R\u00b2, mean x, mean y, slope, intercept - Prediction calculator panel - Interpretation template fills with current values</p> <p>Interactive controls: - Dataset selector (5+ pre-loaded real-world datasets) - Prediction input field with calculate button - \"Show Residual Plot\" toggle - \"Highlight Influential Points\" toggle - \"Export Analysis\" button (generates text summary)</p> <p>Behavior: - Selecting dataset updates all visualizations and statistics - Entering prediction value shows point on line and calculation - Influential points automatically identified and flagged - Warnings display for extrapolation attempts - Text interpretations auto-generate with correct context and values</p> <p>Canvas size: 500x650, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/07-linear-regression/#common-mistakes-and-misconceptions","title":"Common Mistakes and Misconceptions","text":"<p>Before we wrap up, let's address some common pitfalls:</p> <p>Mistake 1: Confusing r and R\u00b2 Remember: r ranges from -1 to 1 and includes direction; R\u00b2 ranges from 0 to 1 and doesn't indicate direction. If r = -0.7, then R\u00b2 = 0.49.</p> <p>Mistake 2: Forgetting the hat on \u0177 The hat matters! When writing predictions, always write \\( \\hat{y} \\), not y. This distinguishes predicted values from actual observed values.</p> <p>Mistake 3: Interpreting slope without context Always interpret slope in the units of your variables. \"The slope is 4.7\" means nothing. \"For each additional degree, predicted sales increase by $4.70\" tells the whole story.</p> <p>Mistake 4: Ignoring extrapolation Just because you can plug numbers into an equation doesn't mean you should. Always note the range of your original data.</p> <p>Mistake 5: High R\u00b2 means good predictions A high R\u00b2 means your line fits the data well, but it doesn't guarantee accurate predictions for new data, especially if conditions change.</p> <p>Mistake 6: Assuming causation Even a perfect R\u00b2 of 1.0 doesn't prove that x causes y. Correlation and regression describe relationships\u2014they don't establish causation.</p> <p>\ud83d\udc3f\ufe0f \"Every statistician drops an acorn sometimes. The key is learning to catch yourself before making these mistakes on the AP exam. Read each question carefully and think about what's really being asked!\"</p>"},{"location":"chapters/07-linear-regression/#key-takeaways","title":"Key Takeaways","text":"<p>Time to squirrel away the big ideas from this chapter:</p> <ol> <li> <p>Least squares regression finds the line that minimizes the sum of squared residuals, creating the best-fit line for your data.</p> </li> <li> <p>The regression equation \\( \\hat{y} = a + bx \\) allows you to predict y-values from x-values, where \\( a \\) is the y-intercept and \\( b \\) is the slope.</p> </li> <li> <p>Slope interpretation describes how much the predicted y changes for each one-unit increase in x\u2014always include units and context.</p> </li> <li> <p>Y-intercept interpretation gives the predicted y when x = 0, but this often has no practical meaning if 0 is outside your data range.</p> </li> <li> <p>Residuals measure prediction errors: Residual = Observed - Predicted. Positive means underestimation; negative means overestimation.</p> </li> <li> <p>Residual plots help diagnose model fit. Random scatter = good; patterns = the linear model may not be appropriate.</p> </li> <li> <p>R\u00b2 (coefficient of determination) tells you what percentage of y's variability is explained by the linear relationship with x.</p> </li> <li> <p>Extrapolation is dangerous\u2014only make predictions within the range of your original x-values.</p> </li> <li> <p>Influential points substantially change the regression line when removed. They often have high leverage (extreme x-values).</p> </li> <li> <p>Outliers in regression have unusually large residuals. Investigate them before deciding how to handle them.</p> </li> </ol>"},{"location":"chapters/07-linear-regression/#practice-problems","title":"Practice Problems","text":"<p>Test your understanding with these problems. Try them on your own before checking your work!</p>"},{"location":"chapters/07-linear-regression/#problem-1-basic-calculations","title":"Problem 1: Basic Calculations","text":"<p>A researcher finds the regression equation \\( \\hat{y} = 23.4 + 1.8x \\) for predicting test score (y) from hours of sleep (x).</p> <p>a) Predict the test score for someone who slept 7 hours. b) Calculate the residual if someone who slept 7 hours actually scored 38.</p>"},{"location":"chapters/07-linear-regression/#problem-2-interpretation","title":"Problem 2: Interpretation","text":"<p>The regression equation for predicting weight (in pounds) from height (in inches) is \\( \\hat{y} = -150 + 4.5x \\), with \\( r = 0.78 \\).</p> <p>a) Interpret the slope in context. b) Interpret the y-intercept. Does it make sense? c) Calculate and interpret R\u00b2.</p>"},{"location":"chapters/07-linear-regression/#problem-3-extrapolation","title":"Problem 3: Extrapolation","text":"<p>Using data from cars manufactured between 2010-2020, a regression equation predicts fuel efficiency (mpg) from engine size (liters): \\( \\hat{y} = 42.3 - 5.1x \\). Engine sizes in the dataset ranged from 1.5 to 4.0 liters.</p> <p>a) Predict fuel efficiency for a 2.5 liter engine. b) Would it be appropriate to predict for a 6.0 liter engine? Explain. c) The model predicts 42.3 mpg for a 0 liter engine. Why is this problematic?</p>"},{"location":"chapters/07-linear-regression/#problem-4-residual-analysis","title":"Problem 4: Residual Analysis","text":"<p>Given the data below and regression equation \\( \\hat{y} = 10 + 3x \\):</p> x y 2 17 4 23 6 27 8 35 <p>a) Calculate the residual for each point. b) What is the sum of the residuals? c) Which point has the largest residual?</p>"},{"location":"chapters/07-linear-regression/#problem-5-influential-points","title":"Problem 5: Influential Points","text":"<p>A dataset of 50 students shows the relationship between GPA and SAT scores. One student has a GPA of 1.2 (the lowest) but an SAT score of 1580 (near the highest).</p> <p>a) Does this point have high leverage? Explain. b) Is this point likely to be influential? Why or why not? c) What would you recommend doing about this data point?</p>"},{"location":"chapters/07-linear-regression/#problem-6-complete-analysis","title":"Problem 6: Complete Analysis","text":"<p>For a dataset examining the relationship between advertising spending (thousands of dollars) and product sales (thousands of units): - Equation: \\( \\hat{y} = 2.5 + 0.15x \\) - r = 0.73 - Advertising ranged from $10,000 to $100,000 - Residual plot shows random scatter</p> <p>a) Interpret the slope. b) Interpret R\u00b2 (you'll need to calculate it first). c) Predict sales for $50,000 in advertising spending. d) Is the linear model appropriate? How do you know? e) Would it be reasonable to predict sales for $150,000 in advertising? Explain.</p> <p>Great work completing this chapter! Linear regression is one of the most widely used statistical techniques, and you've just built a strong foundation. In the next chapter, we'll explore how to apply these concepts in more complex settings and examine the conditions required for regression inference.</p>"},{"location":"chapters/08-causation-and-study-design/","title":"Causation and Study Design","text":""},{"location":"chapters/08-causation-and-study-design/#summary","title":"Summary","text":"<p>This chapter addresses the critical distinction between correlation and causation. Students will learn about lurking and confounding variables, Simpson's Paradox, and the differences between observational studies and experiments. Understanding these concepts is essential for properly interpreting statistical findings and designing valid studies.</p>"},{"location":"chapters/08-causation-and-study-design/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 9 concepts from the learning graph:</p> <ol> <li>Lurking Variable</li> <li>Simpson's Paradox</li> <li>Causation</li> <li>Correlation vs Causation</li> <li>Observational Study</li> <li>Experiment</li> <li>Comparing Studies</li> <li>Confounding Variable</li> <li>Identifying Confounding</li> </ol>"},{"location":"chapters/08-causation-and-study-design/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 2: Displaying Categorical Data</li> <li>Chapter 6: Scatterplots and Association</li> </ul>"},{"location":"chapters/08-causation-and-study-design/#the-causation-question","title":"The Causation Question","text":"<p>Welcome back, data detectives! In the last few chapters, you've become skilled at spotting relationships between variables using scatterplots and correlation. But here's the thing: just because two variables move together doesn't mean one is causing the other. And that distinction? It's absolutely crucial.</p> <p>Let me tell you about my cousin Acorn Archie. He noticed that on days when he collected more acorns, he also spotted more birds in the trees. \"Birds must love watching me work!\" he declared proudly. But Sylvia, being the data-savvy squirrel I am, pointed out the obvious: sunny days bring out both the acorns and the birds. The weather was hiding behind the scenes, making both things happen. Archie wasn't attracting birds. He was just observing them on nice days.</p> <p>This chapter is all about avoiding Archie's mistake. We'll explore why correlation doesn't equal causation, learn about sneaky variables that hide in our data, and discover how study design determines what conclusions we can actually draw. My tail's tingling already because we're about to crack one of the biggest nuts in all of statistics!</p>"},{"location":"chapters/08-causation-and-study-design/#causation-what-does-it-really-mean","title":"Causation: What Does It Really Mean?","text":"<p>Causation means that changes in one variable directly produce changes in another variable. When we say X causes Y, we mean that if you manipulate X (and nothing else), Y will change as a result. It's a strong claim that requires strong evidence.</p> <p>Think about it this way:</p> <ul> <li>Flipping a light switch causes the light to turn on</li> <li>Dropping a ball causes it to fall to the ground</li> <li>Taking a medication causes your symptoms to improve (hopefully!)</li> </ul> <p>In each case, there's a direct mechanism connecting the action to the outcome. The switch completes an electrical circuit. Gravity pulls the ball down. The medication's active ingredients interact with your body's chemistry.</p> <p>Establishing causation in real-world situations is surprisingly difficult. Here's why: in the messy world outside laboratory conditions, many things happen simultaneously. When you observe that two variables are related, you need to rule out every other possible explanation before you can claim causation.</p> Evidence Level What It Tells Us Example Correlation Two variables are associated Ice cream sales and drowning deaths both increase in summer Temporal precedence One thing happens before another Exercise happens before improved mood Mechanism There's a plausible explanation for how X affects Y Exercise releases endorphins that improve mood Causation X actually produces changes in Y Controlled experiment shows exercise causes mood improvement"},{"location":"chapters/08-causation-and-study-design/#correlation-vs-causation-the-classic-trap","title":"Correlation vs. Causation: The Classic Trap","text":"<p>The phrase \"correlation does not imply causation\" might be the most important sentence in statistics. Correlation tells us that two variables tend to move together. When one goes up, the other goes up (positive correlation) or down (negative correlation). But this co-movement could happen for several reasons:</p> <ol> <li>X causes Y: The relationship is exactly what it seems</li> <li>Y causes X: The causation runs backward from what you assumed</li> <li>Z causes both X and Y: A third variable is the real culprit</li> <li>Coincidence: Pure chance created an apparent pattern</li> </ol> <p>Let's look at some famously silly correlations to drive this home:</p> <ul> <li>Nicholas Cage films and swimming pool drownings are correlated. (Do Cage's movies inspire reckless swimming? Obviously not!)</li> <li>Per capita cheese consumption correlates with death by bedsheet tangling. (Is cheese making people thrash in their sleep? Come on.)</li> <li>The number of pirates in the world correlates negatively with global temperature. (Are pirates cooling the planet? Unlikely, matey.)</li> </ul> <p>These examples are absurd, which makes the lesson obvious. But in real research, the relationships are often more plausible-sounding, making the trap more dangerous.</p> <p>Acorn for your thoughts?</p> <p>Sylvia says: \"Here's my favorite way to spot the correlation-causation trap: ask yourself, 'If I magically changed just one variable, would the other one have to change?' If you're not sure, you might just have correlation on your paws.\"</p>"},{"location":"chapters/08-causation-and-study-design/#diagram-correlation-vs-causation-scenarios","title":"Diagram: Correlation vs Causation Scenarios","text":"Correlation vs Causation Scenarios Interactive <p>Type: MicroSim</p> <p>Learning objective: Apply (L3) - Students will classify relationship scenarios as correlation only, possible causation, or third variable explanation.</p> <p>Visual elements: - Central area showing two variables connected by a line - Three possible relationship patterns displayed: X causes Y, Y causes X, Z causes both - Scenario cards that slide in from the side - Color-coded feedback for correct/incorrect classifications</p> <p>Interactive controls: - \"Next Scenario\" button to load a new real-world example - Three buttons to classify the relationship: \"X causes Y\", \"Y causes X\", \"Third Variable\" - Reveal button to show the correct answer with explanation - Score tracker for practice mode - Reset button to start over</p> <p>Behavior: - Each scenario presents two correlated variables (e.g., \"Coffee consumption\" and \"Heart disease\") - Student selects which relationship type best explains the correlation - Feedback explains why the answer is correct or what alternative explanation exists - Visual diagram updates to show the selected causal pathway - At least 10 different scenarios covering common misconceptions</p> <p>Canvas size: 700x450px, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/08-causation-and-study-design/#lurking-variables-the-hidden-troublemakers","title":"Lurking Variables: The Hidden Troublemakers","text":"<p>A lurking variable is a variable that is not included in your analysis but affects the relationship you're studying. It lurks in the background, influencing your results without you even measuring it. Lurking variables are one of the main reasons why correlation can masquerade as causation.</p> <p>Here's a classic example: Studies show that people who own more books tend to have higher incomes. Does buying books make you richer? Probably not. A lurking variable\u2014education level\u2014likely explains both. More educated people tend to both own more books AND earn higher incomes. Education is lurking behind the scenes, creating an apparent relationship between books and income.</p> <p>Lurking variables are sneaky because:</p> <ul> <li>You might not think to measure them</li> <li>They might be difficult or impossible to measure</li> <li>Multiple lurking variables might be at play simultaneously</li> </ul> <p>Common lurking variables to watch for:</p> Context Potential Lurking Variables Health studies Age, socioeconomic status, diet, exercise, genetics Education research Parent education, school resources, prior achievement Economics Geographic region, time period, policy changes Technology User demographics, device type, time of day <p>Lurking Variable Alert</p> <p>Whenever you see a surprising or convenient correlation, your first question should be: \"What lurking variable might explain this relationship?\" The more you practice asking this question, the better statistical thinker you'll become.</p>"},{"location":"chapters/08-causation-and-study-design/#confounding-variables-when-variables-get-tangled","title":"Confounding Variables: When Variables Get Tangled","text":"<p>A confounding variable is a specific type of lurking variable that's associated with BOTH the explanatory variable and the response variable. This creates a tangled web where you can't tell which variable is actually responsible for the effect you observe.</p> <p>Here's the formal definition: A confounding variable is related to both the explanatory variable and the response variable, making it impossible to determine whether the explanatory variable, the confounding variable, or both are affecting the response.</p> <p>Let's walk through an example. Suppose you're studying whether drinking coffee is associated with heart disease. You find that coffee drinkers have higher rates of heart disease. Should coffee lovers be worried?</p> <p>Not so fast! Consider smoking as a potential confounding variable:</p> <ul> <li>Smokers are more likely to drink coffee (smoking and coffee are associated)</li> <li>Smoking causes heart disease (smoking affects the response)</li> <li>If we don't account for smoking, we might falsely blame coffee</li> </ul> <p>In this case, the effect of coffee and the effect of smoking are confounded\u2014tangled up together in a way that makes them impossible to separate without careful study design.</p>"},{"location":"chapters/08-causation-and-study-design/#diagram-confounding-variable-visualizer","title":"Diagram: Confounding Variable Visualizer","text":"Confounding Variable Visualizer <p>Type: MicroSim</p> <p>Learning objective: Analyze (L4) - Students will analyze how confounding variables create alternative explanations for observed associations.</p> <p>Visual elements: - Three nodes representing explanatory variable (X), response variable (Y), and confounding variable (C) - Arrows showing relationships between variables - Toggle to show/hide the confounding pathway - Color coding: observed relationship in blue, confounded pathway in red</p> <p>Interactive controls: - Dropdown to select from preset scenarios (coffee/heart disease, ice cream/drowning, etc.) - Toggle to \"reveal confounding\" that shows the hidden variable - Sliders to adjust strength of each relationship (X-Y, C-X, C-Y) - Animation showing how removing confounding changes the apparent relationship - Reset button to restore defaults</p> <p>Behavior: - Initially shows only X and Y with a strong apparent relationship - Revealing confounding adds node C and shows arrows to both X and Y - Adjusting C's relationships visually shows how much of X-Y is explained by C - Text updates explaining the current confounding situation - Simulation mode: generate fake data showing confounded vs true relationship</p> <p>Canvas size: 650x400px, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/08-causation-and-study-design/#identifying-confounding-a-systematic-approach","title":"Identifying Confounding: A Systematic Approach","text":"<p>Identifying confounding requires thinking carefully about what variables might be related to both your explanatory and response variables. Here's a systematic approach:</p> <p>Step 1: List potential confounders</p> <p>For any relationship you're studying, brainstorm variables that might be associated with both the explanatory and response variables. Consider:</p> <ul> <li>Demographics (age, gender, income, education)</li> <li>Behaviors (diet, exercise, sleep)</li> <li>Environmental factors (location, season, time period)</li> <li>Pre-existing conditions or characteristics</li> </ul> <p>Step 2: Check the two requirements</p> <p>For each potential confounder, ask:</p> <ul> <li>Is it associated with the explanatory variable?</li> <li>Is it associated with the response variable?</li> </ul> <p>If the answer is yes to BOTH questions, you've identified a potential confounder.</p> <p>Step 3: Consider the direction</p> <p>A true confounder can't be on the causal pathway between your explanatory and response variables. If X causes C and C causes Y, then C is a mediator, not a confounder. Confounders are causes of both X and Y, not effects of X.</p> <p>Let's practice with an example. A study finds that students who eat breakfast have higher test scores. Is this causation?</p> <p>Potential confounders:</p> <ul> <li> <p>Socioeconomic status: Wealthier families can afford breakfast AND provide other educational advantages. SES is associated with breakfast eating. SES is associated with test scores. Possible confounder!</p> </li> <li> <p>Sleep habits: Students who sleep well are more likely to wake up with time for breakfast AND to perform well on tests. Sleep is associated with breakfast eating. Sleep is associated with test scores. Possible confounder!</p> </li> <li> <p>Parental involvement: Parents who ensure their kids eat breakfast might also ensure homework gets done. Parent involvement is associated with breakfast eating. Parent involvement is associated with test scores. Possible confounder!</p> </li> </ul> <p>See how many alternative explanations exist? Without accounting for confounders, we can't conclude that breakfast itself causes better performance.</p>"},{"location":"chapters/08-causation-and-study-design/#simpsons-paradox-when-data-plays-tricks","title":"Simpson's Paradox: When Data Plays Tricks","text":"<p>Here's where things get really interesting. Simpson's Paradox occurs when a trend that appears in several groups of data reverses or disappears when the groups are combined. It's one of the most counterintuitive phenomena in statistics.</p> <p>Let me illustrate with a famous example. Imagine two hospitals treating patients for a serious condition:</p> <p>Hospital A: - Treated 900 patients in good condition: 870 survived (97%) - Treated 100 patients in poor condition: 30 survived (30%) - Overall: 900 of 1000 survived (90%)</p> <p>Hospital B: - Treated 100 patients in good condition: 95 survived (95%) - Treated 900 patients in poor condition: 405 survived (45%) - Overall: 500 of 1000 survived (50%)</p> <p>Which hospital is better? If you look at the combined data, Hospital A looks amazing (90% vs 50% survival). But look at the subgroups:</p> <ul> <li>For good-condition patients: Hospital B is better (95% vs 97%)</li> <li>Wait, that should say Hospital A is better. Let me recalculate...</li> </ul> <p>Actually, let's use clearer numbers:</p> <p>Hospital A: - Easy cases: 90 of 100 survived (90%) - Hard cases: 10 of 100 survived (10%) - Overall: 100 of 200 survived (50%)</p> <p>Hospital B: - Easy cases: 95 of 100 survived (95%) - Hard cases: 15 of 100 survived (15%) - Overall: 110 of 200 survived (55%)</p> <p>Wait, now B looks better overall too. Simpson's Paradox needs the group sizes to be unequal. Let me give you the classic structure:</p> <p>Hospital A: - Easy cases: 900 patients, 870 survived (96.7%) - Hard cases: 100 patients, 10 survived (10%) - Overall: 880 of 1000 (88%)</p> <p>Hospital B: - Easy cases: 100 patients, 99 survived (99%) - Hard cases: 900 patients, 180 survived (20%) - Overall: 279 of 1000 (27.9%)</p> <p>Now look: Hospital A appears better overall (88% vs 28%), but Hospital B actually has HIGHER survival rates in BOTH subgroups (99% vs 96.7% for easy cases, 20% vs 10% for hard cases)!</p> <p>The paradox occurs because Hospital B takes on more hard cases. When we aggregate, the hard cases drag down Hospital B's overall rate, even though it performs better in each category.</p> <p>The lurking variable here is case severity, which affects both the hospital choice (hard cases go to B) and the outcome (hard cases die more often). It's Simpson's Paradox in action!</p>"},{"location":"chapters/08-causation-and-study-design/#diagram-simpsons-paradox-explorer","title":"Diagram: Simpson's Paradox Explorer","text":"Simpson's Paradox Explorer <p>Type: MicroSim</p> <p>Learning objective: Evaluate (L5) - Students will evaluate aggregated vs. disaggregated data to identify when Simpson's Paradox occurs and determine which analysis is more appropriate.</p> <p>Visual elements: - Bar charts showing success rates for two groups - Toggle between \"Combined\" view and \"Separated by subgroup\" view - Animated transition between views to show the reversal - Clear labels showing percentages for each bar - Indicator highlighting when paradox is present</p> <p>Interactive controls: - Preset scenario selector (hospitals, universities, treatments, etc.) - Sliders to adjust sample sizes in each subgroup - Sliders to adjust success rates in each subgroup - \"Reveal Paradox\" button that switches from combined to separated view - Text explanation that updates based on current data - Reset to classic example button</p> <p>Behavior: - Default shows a classic Simpson's Paradox example - Adjusting sliders shows when paradox appears/disappears - Color coding: green for higher rate, red for lower rate - When paradox is active, show warning indicator - Calculate and display whether the combined conclusion contradicts subgroup conclusions</p> <p>Canvas size: 700x500px, responsive design Implementation: p5.js with canvas-based controls</p> <p>Let's crack this nut!</p> <p>Sylvia says: \"Simpson's Paradox teaches us to always ask: 'What happens when I look at subgroups?' Aggregated data can hide important patterns. And hidden patterns? That's when a statistician's tail really starts to poof up!\"</p>"},{"location":"chapters/08-causation-and-study-design/#observational-studies-watching-without-interfering","title":"Observational Studies: Watching Without Interfering","text":"<p>Now that we understand the challenges of establishing causation, let's talk about how data is collected. An observational study is a study in which researchers observe and measure variables but do not attempt to influence the responses. They simply watch what happens naturally.</p> <p>In an observational study:</p> <ul> <li>Researchers collect data on existing groups</li> <li>No treatments are assigned</li> <li>People or things are measured as they naturally exist</li> <li>The goal is often to discover associations</li> </ul> <p>Examples of observational studies:</p> <ul> <li>Surveying students about their study habits and grades</li> <li>Tracking health outcomes for people who choose to exercise vs. those who don't</li> <li>Comparing accident rates for people who use hands-free devices vs. handheld phones</li> <li>Measuring pollution levels in cities with different traffic patterns</li> </ul> <p>Observational studies are valuable because:</p> <ul> <li>They're often the only ethical option (you can't force people to smoke to study cancer)</li> <li>They can study rare conditions or behaviors</li> <li>They can examine long-term outcomes</li> <li>They're often less expensive than experiments</li> </ul> <p>However, observational studies have a fundamental limitation: they cannot establish causation. Why not? Because the groups being compared might differ in ways other than the variable of interest. Those differences (confounding variables) might be the real cause of any observed effect.</p> <p>Consider studying whether drinking wine is associated with heart health. Wine drinkers might also:</p> <ul> <li>Have higher incomes</li> <li>Eat Mediterranean diets</li> <li>Have better access to healthcare</li> <li>Exercise more regularly</li> </ul> <p>Any of these factors, not the wine itself, could explain better heart health.</p>"},{"location":"chapters/08-causation-and-study-design/#experiments-taking-control","title":"Experiments: Taking Control","text":"<p>An experiment deliberately imposes a treatment on individuals to observe their responses. The defining feature of an experiment is that the researcher decides who gets what treatment.</p> <p>Key features of experiments:</p> Feature What It Means Treatment Something done to subjects (medication, teaching method, etc.) Control group Subjects who don't receive the treatment (or receive a placebo) Random assignment Subjects are randomly placed into treatment or control groups Comparison Response is measured and compared between groups <p>The power of experiments comes from random assignment. When subjects are randomly assigned to groups, all those lurking and confounding variables get distributed approximately equally across groups. Smart people end up in both groups. Healthy people end up in both groups. Morning people, night owls, coffee drinkers, vegetarians\u2014they all get randomly mixed.</p> <p>After random assignment, the only systematic difference between groups is the treatment itself. So if we observe a difference in the response, we can attribute it to the treatment. That's causation!</p> <p>Here's an example of a well-designed experiment:</p> <p>Research question: Does listening to classical music improve test performance?</p> <p>Experimental design: 1. Recruit 200 students 2. Randomly assign 100 to listen to Mozart for 10 minutes before a test 3. Assign the other 100 to sit in silence for 10 minutes 4. All students take the same test under identical conditions 5. Compare average scores between groups</p> <p>Because of random assignment, any difference in test scores can be attributed to the music (assuming the experiment was properly controlled).</p>"},{"location":"chapters/08-causation-and-study-design/#diagram-study-type-comparison-tool","title":"Diagram: Study Type Comparison Tool","text":"Study Type Comparison Tool <p>Type: MicroSim</p> <p>Learning objective: Analyze (L4) - Students will analyze study descriptions to classify them as observational studies or experiments and evaluate what conclusions can be drawn.</p> <p>Visual elements: - Side-by-side comparison of observational study and experiment - Animated flowchart showing data collection process for each type - Icons representing subjects, treatments, and measurements - \"Conclusion strength meter\" showing what each study type can claim</p> <p>Interactive controls: - Study scenario input or selection from preset examples - Classification buttons: \"Observational\" or \"Experiment\" - Checklist for identifying key features (random assignment, treatment, control) - Feedback area showing correct classification and explanation - Toggle to see same research question as both study types</p> <p>Behavior: - Present study descriptions one at a time - Student identifies whether it's observational or experimental - Feedback explains key features that determine classification - Show how conclusions differ based on study type - Side-by-side simulation showing how same question could be studied both ways</p> <p>Canvas size: 700x450px, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/08-causation-and-study-design/#comparing-studies-strengths-and-limitations","title":"Comparing Studies: Strengths and Limitations","text":"<p>Let's directly compare observational studies and experiments to understand when each is appropriate.</p> Aspect Observational Study Experiment Who decides treatment Subjects self-select Researcher assigns randomly Confounding Major concern Controlled by randomization Causation claims Cannot establish causation Can establish causation Ethics Can study harmful exposures Cannot expose subjects to harm Generalizability Often more natural settings May be artificial Cost Often less expensive Can be very costly Time Can study long-term outcomes Often shorter duration <p>When should you use each?</p> <p>Use observational studies when:</p> <ul> <li>Randomly assigning treatments would be unethical (smoking, pollution exposure)</li> <li>You want to study naturally occurring phenomena</li> <li>Long-term follow-up is needed</li> <li>Resources for experiments are unavailable</li> <li>You're exploring relationships before designing an experiment</li> </ul> <p>Use experiments when:</p> <ul> <li>You need to establish causation</li> <li>Random assignment is ethically possible</li> <li>You can control the environment</li> <li>The treatment is well-defined</li> <li>The outcome can be measured in a reasonable timeframe</li> </ul> <p>The Ethics of Experimentation</p> <p>Even if an experiment would give us cleaner data, we can't run it if it would be unethical. We can't randomly assign people to smoke to study lung cancer. We can't randomly assign children to be neglected to study child development. When experimentation is impossible, well-designed observational studies become our best option\u2014and we must interpret their results with appropriate caution.</p>"},{"location":"chapters/08-causation-and-study-design/#randomization-the-great-equalizer","title":"Randomization: The Great Equalizer","text":"<p>The secret sauce that makes experiments so powerful is random assignment. When we randomly assign subjects to treatment groups, we're letting chance decide who gets what. This might seem arbitrary, but it has a profound effect: it tends to equalize all variables\u2014both the ones we know about and the ones we don't\u2014across groups.</p> <p>Here's why this matters. Imagine you're testing a new tutoring program on 100 students. Without random assignment, you might:</p> <ul> <li>Let students choose (motivated students might choose tutoring, skewing results)</li> <li>Assign the first 50 who sign up to tutoring (early signers might be more eager)</li> <li>Put struggling students in tutoring (they'd improve less than average anyway)</li> </ul> <p>Any of these approaches creates a selection bias where the groups differ before the treatment even starts.</p> <p>With random assignment:</p> <ul> <li>Each student has an equal chance of being in either group</li> <li>Motivated and unmotivated students end up in both groups</li> <li>High and low achievers end up in both groups</li> <li>All lurking variables get balanced out, on average</li> </ul> <p>The result? Any difference we observe between groups at the end can be attributed to the treatment, not to pre-existing differences.</p> <p>Of course, random assignment doesn't guarantee perfectly balanced groups. By chance, one group might end up slightly smarter or more motivated. But with large enough samples, these random imbalances become negligible. And even with small samples, random differences are equally likely to favor either group\u2014they don't systematically bias our results in one direction.</p>"},{"location":"chapters/08-causation-and-study-design/#diagram-randomization-balance-simulator","title":"Diagram: Randomization Balance Simulator","text":"Randomization Balance Simulator <p>Type: MicroSim</p> <p>Learning objective: Apply (L3) - Students will apply random assignment to groups and observe how it balances known and unknown variables across treatment and control groups.</p> <p>Visual elements: - Population of subjects with visible characteristics (icons with varying heights, colors) - Hidden characteristic indicator (shown after randomization) - Two boxes for Treatment and Control groups - Statistics panel showing balance of characteristics in each group</p> <p>Interactive controls: - \"Randomize\" button to randomly assign subjects to groups - Sample size slider (20, 50, 100, 200 subjects) - Multiple visible characteristics toggles (age, gender, prior experience) - \"Reveal hidden variable\" toggle - Run multiple randomizations to see distribution of imbalances - Reset button</p> <p>Behavior: - Initial state shows mixed population with visible characteristics - Clicking randomize animates subjects moving to treatment/control - Statistics update showing percentage of each characteristic in each group - Multiple randomizations show that balance improves with sample size - Hidden variable demonstration shows randomization balances even unknown factors</p> <p>Canvas size: 700x450px, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/08-causation-and-study-design/#putting-it-all-together-critical-thinking-about-research","title":"Putting It All Together: Critical Thinking About Research","text":"<p>Now you have the tools to critically evaluate statistical claims. Let's practice with a systematic approach.</p> <p>When you encounter a claim that X causes Y, ask:</p> <ol> <li>How was the data collected?</li> <li>Observational study? Be skeptical of causal claims.</li> <li> <p>Experiment with random assignment? Causation is possible.</p> </li> <li> <p>What are potential confounding variables?</p> </li> <li>What else might explain this relationship?</li> <li> <p>Were these variables measured and controlled for?</p> </li> <li> <p>Is there a plausible mechanism?</p> </li> <li>Can you explain HOW X might cause Y?</li> <li> <p>Does the mechanism make scientific sense?</p> </li> <li> <p>Does the evidence support the strength of the claim?</p> </li> <li>Correlation only? Say \"is associated with.\"</li> <li> <p>Causation established? Say \"causes.\"</p> </li> <li> <p>Would looking at subgroups change the conclusion?</p> </li> <li>Could Simpson's Paradox be at play?</li> <li>Are important groups being combined?</li> </ol> <p>Here's an example of critical analysis:</p> <p>Claim: \"Studies show that people who eat organic food live longer.\"</p> <p>Analysis:</p> <ul> <li>This is likely an observational study (researchers didn't randomly assign people to eat organic)</li> <li>Confounders: People who buy organic food tend to be wealthier, more educated, more health-conscious, and may exercise more and smoke less</li> <li>Without random assignment, we can't separate the effect of organic food from these confounders</li> <li>Better claim: \"Eating organic food is associated with longer life, though this may reflect other lifestyle factors common among organic food consumers.\"</li> </ul> <p>Time to squirrel away this knowledge! Being a critical consumer of statistical claims is one of the most valuable skills you'll develop.</p>"},{"location":"chapters/08-causation-and-study-design/#real-world-applications","title":"Real-World Applications","text":"<p>Let's look at how these concepts apply in important real-world contexts.</p> <p>Medical Research</p> <p>The gold standard for testing medical treatments is the randomized controlled trial (RCT). Patients are randomly assigned to receive either the new treatment or a placebo (or standard care). This allows researchers to determine if the treatment actually works.</p> <p>The placebo control is important because of the placebo effect\u2014people often feel better just from believing they're receiving treatment. By comparing to a placebo, researchers isolate the drug's true effect from the psychological effect of taking a pill.</p> <p>Social Science</p> <p>Many social science questions can't be studied experimentally for ethical reasons. Researchers use sophisticated statistical techniques to try to control for confounders in observational data, but these methods have limitations. When you read that \"poverty causes crime\" or \"video games cause violence,\" be skeptical and ask about study design.</p> <p>Policy Decisions</p> <p>Policymakers often face decisions where experiments would be ideal but aren't feasible. Does raising the minimum wage reduce employment? Does stricter gun control reduce violence? These questions involve comparing states or countries with different policies\u2014observational comparisons where many variables differ between groups.</p> <p>Some clever approaches exist:</p> <ul> <li>Natural experiments: When a policy change or event creates something like random assignment</li> <li>Regression discontinuity: Comparing people just above and below a threshold</li> <li>Difference-in-differences: Comparing changes before and after a policy in places with and without the policy</li> </ul> <p>These methods try to approximate the power of experiments using observational data, but they require careful assumptions.</p>"},{"location":"chapters/08-causation-and-study-design/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":"<p>Before we wrap up, let's tackle some common pitfalls:</p> <p>Mistake 1: Assuming correlation implies causation Just because two variables are related doesn't mean one causes the other. Always consider alternative explanations.</p> <p>Mistake 2: Ignoring confounding variables Before accepting a causal claim, identify what other variables might explain the relationship. Were they measured and controlled?</p> <p>Mistake 3: Thinking experiments are always better Experiments establish causation, but observational studies are sometimes more ethical, practical, and generalizable. Each has its place.</p> <p>Mistake 4: Forgetting about Simpson's Paradox Combined data can tell a different story than subgroup data. When possible, look at both levels of analysis.</p> <p>Mistake 5: Assuming random assignment eliminates all problems Random assignment balances confounders on average, but experiments can still have other problems (people drop out, the setting is artificial, etc.).</p> <p>Mistake 6: Confusing statistical association with practical importance Even a causal relationship might be tiny in effect size. \"Causes\" doesn't mean \"is a major factor.\"</p>"},{"location":"chapters/08-causation-and-study-design/#key-takeaways","title":"Key Takeaways","text":"<p>Let's squirrel away the big ideas from this chapter:</p> <ol> <li> <p>Causation means that changes in one variable directly produce changes in another. It's a strong claim requiring strong evidence.</p> </li> <li> <p>Correlation does not imply causation. Associated variables might both be caused by a third variable, or the apparent relationship might be coincidental.</p> </li> <li> <p>Lurking variables affect the relationship being studied but aren't measured. They can create misleading associations.</p> </li> <li> <p>Confounding variables are associated with both the explanatory and response variables, making it impossible to separate their effects from the treatment effect.</p> </li> <li> <p>Simpson's Paradox occurs when trends in subgroups reverse when data is combined. Always consider whether aggregation might hide important patterns.</p> </li> <li> <p>Observational studies measure variables without imposing treatments. They can find associations but cannot establish causation.</p> </li> <li> <p>Experiments randomly assign subjects to treatments. Random assignment balances confounders, allowing causal conclusions.</p> </li> <li> <p>Random assignment is the key that makes experiments powerful. By letting chance decide who gets what, it equalizes groups on all variables.</p> </li> <li> <p>Critical evaluation of research requires asking about study design, potential confounders, and whether conclusions match the evidence.</p> </li> </ol>"},{"location":"chapters/08-causation-and-study-design/#practice-problems","title":"Practice Problems","text":"Problem 1: Identifying Confounders <p>A study finds that children who eat dinner with their families have higher grades than children who don't. A researcher claims that family dinners cause better academic performance.</p> <p>a) What type of study is this (observational or experiment)? b) Identify at least two potential confounding variables. c) Explain how one of these confounders could create the observed association without family dinners actually causing better grades.</p> <p>Answers: a) This is an observational study\u2014researchers observed existing behavior, they didn't randomly assign families to eat together or apart.</p> <p>b) Potential confounders include: - Parental involvement (parents who prioritize family dinners might also help with homework) - Socioeconomic status (wealthier families might have more time for dinners and resources for education) - Family stability (stable families might have more regular dinners and less stress affecting grades) - Parent work schedules (parents with flexible jobs enabling dinners might also have more time for educational support)</p> <p>c) Example: Parental involvement could be the real cause. Parents who are highly involved in their children's lives are more likely to organize family dinners AND more likely to help with homework, check on school progress, and encourage academic success. The family dinners don't cause the better grades\u2014both are effects of parental involvement.</p> Problem 2: Simpson's Paradox <p>Two tutoring companies advertise their success rates:</p> <p>Company A: 600 students total, 480 passed their exams (80%) Company B: 600 students total, 420 passed their exams (70%)</p> <p>But here's the breakdown by student type:</p> <p>Company A: - 500 well-prepared students: 450 passed (90%) - 100 struggling students: 30 passed (30%)</p> <p>Company B: - 100 well-prepared students: 95 passed (95%) - 500 struggling students: 325 passed (65%)</p> <p>a) Which company has the higher overall pass rate? b) Which company has the higher pass rate for well-prepared students? c) Which company has the higher pass rate for struggling students? d) Explain why this is Simpson's Paradox and which company is actually better.</p> <p>Answers: a) Company A has the higher overall pass rate (80% vs 70%).</p> <p>b) Company B has the higher pass rate for well-prepared students (95% vs 90%).</p> <p>c) Company B has the higher pass rate for struggling students (65% vs 30%).</p> <p>d) This is Simpson's Paradox because Company B performs better in BOTH subgroups, yet appears worse overall. The paradox occurs because Company A mostly tutors well-prepared students (who pass at high rates anyway), while Company B takes on mostly struggling students (who pass at lower rates). The aggregated data makes Company A look better only because it tutors easier cases. Company B is actually better\u2014it achieves higher success rates regardless of which type of student you consider.</p> Problem 3: Study Design <p>A researcher wants to determine whether a new energy drink improves athletic performance.</p> <p>a) Design an observational study that could investigate this question. What conclusions could you draw? b) Design an experiment that could investigate this question. What conclusions could you draw? c) Why would the experiment give stronger evidence for causation?</p> <p>Answers: a) Observational study: Survey 200 athletes about their energy drink consumption and measure their performance metrics (sprint times, strength tests, etc.). Compare performance between those who regularly use energy drinks and those who don't.</p> <p>Conclusions: Can only say energy drink use is \"associated with\" better or worse performance. Cannot claim causation because athletes who choose energy drinks might differ in training intensity, health consciousness, age, or other factors.</p> <p>b) Experiment: Recruit 100 athletes, randomly assign 50 to consume the energy drink before testing and 50 to consume a placebo drink (identical taste, no active ingredients). Measure their performance on standardized athletic tests. Compare average performance between groups.</p> <p>Conclusions: If the energy drink group performs significantly better, can conclude the drink causes improved performance. The placebo controls for the psychological effect of taking something.</p> <p>c) The experiment provides stronger evidence because random assignment ensures that, on average, the two groups are equivalent in all ways (training, motivation, genetics, experience) except for the drink they consumed. Any difference in performance can therefore be attributed to the drink. In the observational study, differences might reflect pre-existing differences between people who choose to use energy drinks.</p> Problem 4: Critical Analysis <p>A news article reports: \"New study proves that getting more sleep causes better memory. Researchers found that people who slept 8+ hours performed 20% better on memory tests than those who slept less than 6 hours.\"</p> <p>Critically analyze this claim: a) Is the word \"proves\" appropriate? Why or why not? b) What information would you need to evaluate this claim properly? c) Identify at least two potential confounding variables. d) Rewrite the headline to accurately reflect what the study likely showed.</p> <p>Answers: a) \"Proves\" is not appropriate. This appears to be an observational study (researchers observed existing sleep patterns rather than randomly assigning people to sleep amounts). Observational studies cannot prove causation\u2014they can only show association.</p> <p>b) Information needed: - Was this an experiment or observational study? - If observational, what confounders were controlled for? - How were sleep hours measured (self-report vs. objective)? - Sample size and how participants were selected - Details of the memory tests used</p> <p>c) Potential confounders: - Overall health (healthier people may both sleep better and have better memory) - Age (older people may sleep less and have worse memory) - Stress level (stressed people may sleep poorly and have impaired memory) - Lifestyle factors (exercise, diet, alcohol use) - Mental health conditions (depression affects both sleep and cognition)</p> <p>d) Better headline: \"Study finds association between longer sleep and better memory performance\" or \"People who sleep 8+ hours score higher on memory tests, study suggests\"</p> Problem 5: Identifying Study Types <p>For each scenario, identify whether it's an observational study or an experiment, and explain what conclusions can be drawn:</p> <p>a) Researchers randomly assign some classrooms to use a new math curriculum while others continue with the standard curriculum. They compare test scores at the end of the year.</p> <p>b) A hospital records which patients choose to have surgery versus medication for back pain, then follows up on their outcomes.</p> <p>c) Scientists compare cancer rates between people who live near power lines and those who don't.</p> <p>d) A tech company randomly shows half its users a new interface design and the other half the old design, then measures engagement.</p> <p>Answers: a) This is an experiment (random assignment to curricula). Conclusion: If the new curriculum group scores higher, we can conclude the curriculum caused better learning\u2014the random assignment of classrooms balances other factors.</p> <p>b) This is an observational study (patients chose their treatment). Conclusion: We can only say treatment choice is associated with outcomes. Patients who choose surgery may differ from those who choose medication in severity, overall health, or willingness to take risks. These differences, not the treatment itself, might explain different outcomes.</p> <p>c) This is an observational study (researchers observed existing locations). Conclusion: We can only find associations between location and cancer rates. People living near power lines might differ in socioeconomic status, housing quality, or other factors that affect health. We cannot conclude power lines cause cancer from this study.</p> <p>d) This is an experiment (random assignment to interface). Conclusion: If the new interface group shows higher engagement, we can conclude the new design causes better engagement. Random assignment ensures the groups are comparable, so differences must be due to the interface.</p>"},{"location":"chapters/09-probability-fundamentals/","title":"Probability Fundamentals","text":""},{"location":"chapters/09-probability-fundamentals/#summary","title":"Summary","text":"<p>This chapter introduces the foundations of probability theory. Students will learn about random phenomena, sample spaces, events, and the basic rules of probability including the addition and multiplication rules. These probability concepts provide the mathematical foundation for statistical inference covered later in the course.</p>"},{"location":"chapters/09-probability-fundamentals/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 19 concepts from the learning graph:</p> <ol> <li>Random Phenomenon</li> <li>Probability</li> <li>Probability Rules</li> <li>Sample Space</li> <li>Event</li> <li>Complement of Event</li> <li>Mutually Exclusive Events</li> <li>Disjoint Events</li> <li>Independent Events</li> <li>Dependent Events</li> <li>Addition Rule</li> <li>General Addition Rule</li> <li>Multiplication Rule</li> <li>General Multiplication Rule</li> <li>Venn Diagram</li> <li>Using Venn Diagrams</li> <li>Simulation</li> <li>Designing Simulations</li> <li>Law of Large Numbers</li> </ol>"},{"location":"chapters/09-probability-fundamentals/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Statistics</li> </ul>"},{"location":"chapters/09-probability-fundamentals/#welcome-to-the-world-of-chance","title":"Welcome to the World of Chance","text":"<p>Have you ever wondered why the weather forecast says \"70% chance of rain\" but it still ends up sunny? Or why some poker players consistently win while others always seem to lose? Or what it really means when a medical test is \"95% accurate\"?</p> <p>Welcome to probability\u2014the mathematics of uncertainty. This is where statistics gets its superpowers. Everything we've learned so far about collecting and describing data has been building toward this moment: learning to quantify the unknown.</p> <p>\"My tail's tingling\u2014we're onto something!\" Sylvia adjusts her spectacles excitedly. \"When I first learned probability, it changed how I thought about my acorn stashes. Instead of just hoping I'd have enough for winter, I started calculating the chances. Turns out, understanding uncertainty gives you more control, not less. Let's crack this nut!\"</p> <p>By the end of this chapter, you'll understand:</p> <ul> <li>What makes a phenomenon \"random\" and how to define possible outcomes</li> <li>How to calculate probabilities using fundamental rules</li> <li>When events are independent versus dependent</li> <li>How to use Venn diagrams as powerful problem-solving tools</li> <li>Why simulations can estimate probabilities we cannot calculate directly</li> <li>The remarkable Law of Large Numbers that connects probability to the real world</li> </ul>"},{"location":"chapters/09-probability-fundamentals/#random-phenomena-embracing-uncertainty","title":"Random Phenomena: Embracing Uncertainty","text":"<p>A random phenomenon is any situation where we know the possible outcomes, but we cannot predict exactly which outcome will occur on any particular trial. The key word here is uncertainty\u2014there's no way to know for certain what will happen next.</p> <p>Examples of random phenomena surround us:</p> <ul> <li>Flipping a coin (heads or tails?)</li> <li>Rolling a die (which number?)</li> <li>The weather tomorrow (rain, sun, clouds?)</li> <li>Whether a free throw goes in (swish or miss?)</li> <li>A student's score on the next exam (which grade?)</li> </ul> <p>Here's what makes these phenomena \"random\": even though we cannot predict the specific outcome of any single trial, there's a remarkable pattern when we observe many trials. Flip a fair coin 1,000 times, and you'll get close to 500 heads. Roll a die 600 times, and each number appears roughly 100 times.</p> <p>This predictable long-run behavior is the foundation of probability theory.</p> What We Know What We Don't Know All possible outcomes Which outcome will occur next The pattern over many trials The result of a single trial Long-run frequencies Short-run surprises"},{"location":"chapters/09-probability-fundamentals/#what-is-probability","title":"What Is Probability?","text":"<p>Probability is a number between 0 and 1 that describes how likely an event is to occur. It quantifies our uncertainty about random phenomena.</p> <ul> <li>Probability 0 means the event is impossible (it never happens)</li> <li>Probability 1 means the event is certain (it always happens)</li> <li>Probability 0.5 means the event is equally likely to occur or not occur</li> </ul> <p>We can express probability as a decimal, a fraction, or a percentage:</p> \\[ P(\\text{event}) = \\frac{\\text{number of favorable outcomes}}{\\text{total number of possible outcomes}} \\] <p>For a fair coin flip: [ P(\\text{heads}) = \\frac{1}{2} = 0.5 = 50\\% ]</p> <p>For rolling a 6 on a fair die: [ P(\\text{rolling a 6}) = \\frac{1}{6} \\approx 0.167 \\approx 16.7\\% ]</p> <p>There are three ways to interpret probability:</p> <p>1. Theoretical Probability: Based on mathematical reasoning about equally likely outcomes. Example: A fair die has 6 equally likely faces, so P(rolling a 3) = 1/6.</p> <p>2. Empirical Probability: Based on observed data from many trials. Example: If a basketball player made 85 out of 100 free throws, their estimated probability of making the next one is 85/100 = 0.85.</p> <p>3. Subjective Probability: Based on personal judgment or belief. Example: \"I think there's a 60% chance I'll finish my homework before dinner.\"</p> <p>For AP Statistics, we primarily work with theoretical and empirical probabilities.</p>"},{"location":"chapters/09-probability-fundamentals/#probability-rules-the-foundation","title":"Probability Rules: The Foundation","text":"<p>All probabilities must follow these fundamental probability rules:</p> <p>Rule 1: The probability of any event is between 0 and 1 (inclusive). [ 0 \\leq P(A) \\leq 1 ]</p> <p>Rule 2: The sum of probabilities of all possible outcomes equals 1. [ P(\\text{all outcomes}) = 1 ]</p> <p>Rule 3: The probability that an event does NOT occur equals 1 minus the probability it does occur. [ P(\\text{not } A) = 1 - P(A) ]</p> <p>These rules might seem simple, but they're remarkably powerful. If someone tells you an event has a probability of 1.5 or -0.3, you know immediately they've made an error. If you're trying to find the probability of something NOT happening, just subtract from 1.</p> Probability Value Interpretation 0 Impossible 0.01 Very unlikely 0.25 Unlikely 0.50 Even odds 0.75 Likely 0.99 Very likely 1 Certain <p>\"Here's something that tripped me up at first,\" Sylvia admits. \"Probability is about the long run, not individual predictions. A 90% chance of rain doesn't mean it will rain\u2014it means that when conditions are similar, it rains 9 out of 10 times. That 1-in-10 sunny day still happens!\"</p>"},{"location":"chapters/09-probability-fundamentals/#sample-space-and-events","title":"Sample Space and Events","text":"<p>To work with probability, we need precise language for describing outcomes.</p>"},{"location":"chapters/09-probability-fundamentals/#sample-space","title":"Sample Space","text":"<p>The sample space (denoted S or \u03a9) is the set of all possible outcomes of a random phenomenon. It's the complete list of everything that could happen.</p> <p>Examples:</p> <ul> <li>Coin flip: S = {Heads, Tails}</li> <li>Single die roll: S = {1, 2, 3, 4, 5, 6}</li> <li>Two coin flips: S = {HH, HT, TH, TT}</li> <li>Drawing a card: S = {all 52 cards in a standard deck}</li> </ul> <p>When we flip two coins, notice that \"HT\" and \"TH\" are different outcomes\u2014the order matters. The sample space has 4 outcomes, not 3.</p>"},{"location":"chapters/09-probability-fundamentals/#events","title":"Events","text":"<p>An event is any collection of outcomes from the sample space\u2014a subset of S. Events are what we calculate probabilities for.</p> <p>For rolling a die:</p> <ul> <li>Event A: \"Rolling an even number\" = {2, 4, 6}</li> <li>Event B: \"Rolling less than 3\" = {1, 2}</li> <li>Event C: \"Rolling a 7\" = {} (empty set\u2014impossible!)</li> </ul> <p>If all outcomes in the sample space are equally likely, then: [ P(\\text{Event}) = \\frac{\\text{Number of outcomes in the event}}{\\text{Number of outcomes in sample space}} ]</p> <p>For Event A above: [ P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2} = 0.5 ]</p>"},{"location":"chapters/09-probability-fundamentals/#diagram-sample-space-explorer","title":"Diagram: Sample Space Explorer","text":"Interactive Sample Space Visualization <p>Type: MicroSim</p> <p>Learning objective: Students will identify sample spaces and events for common random phenomena, calculating probabilities for specified events (Bloom: Understanding, Applying).</p> <p>Visual elements: - Main display showing sample space as a grid or collection of icons - Highlighted subset showing the selected event - Probability calculation displayed: P(Event) = favorable/total - Different themes: dice, cards, coins, spinners</p> <p>Interactive controls: - Dropdown to select random phenomenon:   - \"Single Die Roll\" (6 outcomes)   - \"Two Coin Flips\" (4 outcomes)   - \"Two Dice Sum\" (36 outcomes shown as grid)   - \"Drawing a Card\" (52 outcomes organized by suit) - Checkboxes or click-to-select to define events - Event description input field - \"Calculate Probability\" button - \"Reset Selection\" button</p> <p>Behavior: - Sample space displays all possible outcomes visually - Clicking outcomes adds/removes them from the event - Count updates in real-time: \"Event contains X of Y outcomes\" - Probability updates: P(Event) = X/Y = decimal = percentage - For two dice, grid shows all 36 ordered pairs</p> <p>Color scheme: - Unselected outcomes: light gray - Selected outcomes (in event): bright green - Sample space boundary: dark outline</p> <p>Canvas size: 750 x 450 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/09-probability-fundamentals/#complement-of-an-event","title":"Complement of an Event","text":"<p>The complement of an event A (written as A' or \u0100 or A^c) is the event that A does NOT occur. It consists of all outcomes in the sample space that are not in A.</p> <p>This is incredibly useful because sometimes it's easier to calculate the probability of something NOT happening.</p> \\[ P(A') = 1 - P(A) \\] <p>Example: What's the probability of rolling at least one 6 when rolling two dice?</p> <p>The sample space has 36 outcomes. Counting all the ways to get at least one 6 is tedious. Instead:</p> <ul> <li>P(no sixes) = P(first die isn't 6) \u00d7 P(second die isn't 6) = (5/6)(5/6) = 25/36</li> <li>P(at least one 6) = 1 - P(no sixes) = 1 - 25/36 = 11/36 \u2248 0.306</li> </ul> <p>The complement rule transforms hard problems into easy ones!</p> Event Complement Rain tomorrow No rain tomorrow Pass the exam Fail the exam At least one head All tails None defective At least one defective <p>\"Acorn for your thoughts?\" Sylvia asks. \"I use complements all the time. Instead of calculating the probability I'll find at least one oak tree with acorns in a grove, I calculate the probability of striking out completely and subtract from 1. Much easier!\"</p>"},{"location":"chapters/09-probability-fundamentals/#mutually-exclusive-and-disjoint-events","title":"Mutually Exclusive and Disjoint Events","text":"<p>Mutually exclusive events (also called disjoint events) are events that cannot happen at the same time. If one occurs, the other cannot.</p> <p>When rolling a single die:</p> <ul> <li>Event A: Rolling an even number {2, 4, 6}</li> <li>Event B: Rolling an odd number {1, 3, 5}</li> </ul> <p>These are mutually exclusive\u2014a roll cannot be both even AND odd.</p> <p>When rolling a single die:</p> <ul> <li>Event C: Rolling an even number {2, 4, 6}</li> <li>Event D: Rolling a number less than 4 {1, 2, 3}</li> </ul> <p>These are NOT mutually exclusive\u2014rolling a 2 satisfies both events.</p> <p>Visually, mutually exclusive events have no overlap in a Venn diagram. Their intersection is empty: [ P(A \\text{ and } B) = 0 \\quad \\text{for mutually exclusive events} ]</p> <p>This property makes probability calculations much simpler, as we'll see with the addition rule.</p>"},{"location":"chapters/09-probability-fundamentals/#independent-and-dependent-events","title":"Independent and Dependent Events","text":"<p>This distinction is crucial for calculating probabilities of combined events.</p>"},{"location":"chapters/09-probability-fundamentals/#independent-events","title":"Independent Events","text":"<p>Independent events are events where the occurrence of one does NOT affect the probability of the other. The outcome of the first event gives you no information about the second.</p> <p>Examples of independent events:</p> <ul> <li>Consecutive coin flips (getting heads first doesn't affect the second flip)</li> <li>Rolling two dice (the first die's result doesn't influence the second)</li> <li>Whether it rains today and your exam score tomorrow</li> </ul> <p>The mathematical definition: Events A and B are independent if: [ P(A \\text{ and } B) = P(A) \\times P(B) ]</p>"},{"location":"chapters/09-probability-fundamentals/#dependent-events","title":"Dependent Events","text":"<p>Dependent events are events where the occurrence of one DOES affect the probability of the other. Information about the first event changes what we know about the second.</p> <p>Examples of dependent events:</p> <ul> <li>Drawing cards without replacement (the first draw changes what's left in the deck)</li> <li>A student's grade in Calc I and their grade in Calc II (success in one suggests preparation for the other)</li> <li>Rain today and whether the ground is wet tomorrow</li> </ul> <p>For dependent events, we need to adjust the probability of the second event based on what happened first. We'll formalize this with conditional probability in the next chapter.</p> Scenario Independent or Dependent? Why? Flipping a coin twice Independent Coins have no memory Drawing 2 cards without replacement Dependent First draw changes remaining cards Weather on consecutive days Dependent Tomorrow's weather relates to today's Rolling two different dice Independent One die doesn't affect the other"},{"location":"chapters/09-probability-fundamentals/#the-addition-rule","title":"The Addition Rule","text":"<p>The addition rule helps us find the probability of \"A or B\" (meaning A occurs, or B occurs, or both occur).</p>"},{"location":"chapters/09-probability-fundamentals/#addition-rule-for-mutually-exclusive-events","title":"Addition Rule for Mutually Exclusive Events","text":"<p>When A and B are mutually exclusive (can't both happen): [ P(A \\text{ or } B) = P(A) + P(B) ]</p> <p>This works because there's no overlap to worry about.</p> <p>Example: When rolling a die, what's P(rolling a 1 or a 6)? [ P(1 \\text{ or } 6) = P(1) + P(6) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = \\frac{1}{3} ]</p>"},{"location":"chapters/09-probability-fundamentals/#general-addition-rule","title":"General Addition Rule","text":"<p>When events are NOT mutually exclusive, we need the general addition rule: [ P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B) ]</p> <p>Why subtract the intersection? Because outcomes in both A and B get counted twice (once in P(A) and once in P(B)), so we subtract once to correct.</p> <p>Example: In a standard deck, what's P(drawing a heart or a face card)?</p> <ul> <li>P(heart) = 13/52</li> <li>P(face card) = 12/52</li> <li>P(heart AND face card) = 3/52 (jack, queen, king of hearts)</li> </ul> \\[ P(\\text{heart or face}) = \\frac{13}{52} + \\frac{12}{52} - \\frac{3}{52} = \\frac{22}{52} = \\frac{11}{26} \\approx 0.423 \\]"},{"location":"chapters/09-probability-fundamentals/#diagram-addition-rule-visualizer","title":"Diagram: Addition Rule Visualizer","text":"Interactive Addition Rule Calculator <p>Type: MicroSim</p> <p>Learning objective: Students will apply both the basic and general addition rules to calculate P(A or B), understanding when to subtract the intersection (Bloom: Applying, Analyzing).</p> <p>Visual elements: - Two overlapping circles representing events A and B - Shaded regions showing P(A), P(B), and intersection - Numerical display of each region's probability - Formula shown with current values substituted - Animation highlighting why we subtract the intersection</p> <p>Interactive controls: - Slider for P(A): range 0 to 1 - Slider for P(B): range 0 to 1 - Slider for P(A and B): range 0 to min(P(A), P(B)) - Toggle: \"Mutually Exclusive\" (sets intersection to 0) - Checkbox: \"Show step-by-step calculation\" - Preset scenarios dropdown: \"Card Problems\", \"Dice Problems\", \"Survey Data\"</p> <p>Behavior: - Venn diagram circles resize based on probabilities - Overlap region visually represents P(A and B) - When adding P(A) + P(B), intersection highlights twice (flashing) - Subtracting removes the double-count (visual demonstration) - Final P(A or B) displayed with interpretation - Error message if P(A and B) exceeds logical maximum</p> <p>Canvas size: 750 x 450 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/09-probability-fundamentals/#the-multiplication-rule","title":"The Multiplication Rule","text":"<p>The multiplication rule helps us find the probability of \"A and B\" (meaning both A and B occur).</p>"},{"location":"chapters/09-probability-fundamentals/#multiplication-rule-for-independent-events","title":"Multiplication Rule for Independent Events","text":"<p>When A and B are independent: [ P(A \\text{ and } B) = P(A) \\times P(B) ]</p> <p>Example: What's the probability of flipping heads twice in a row? [ P(H \\text{ and } H) = P(H) \\times P(H) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4} ]</p> <p>Example: What's the probability of rolling a 6 on both of two dice? [ P(6 \\text{ and } 6) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36} ]</p>"},{"location":"chapters/09-probability-fundamentals/#general-multiplication-rule","title":"General Multiplication Rule","text":"<p>When events are dependent, we use the general multiplication rule: [ P(A \\text{ and } B) = P(A) \\times P(B|A) ]</p> <p>The notation P(B|A) means \"the probability of B given that A has occurred.\" This conditional probability accounts for how A's occurrence changes B's likelihood.</p> <p>Example: A bag contains 4 red and 6 blue marbles. You draw two marbles without replacement. What's the probability both are red?</p> <ul> <li>P(first red) = 4/10</li> <li>P(second red | first was red) = 3/9 (only 3 red left among 9 total)</li> </ul> \\[ P(\\text{both red}) = \\frac{4}{10} \\times \\frac{3}{9} = \\frac{12}{90} = \\frac{2}{15} \\approx 0.133 \\] <p>\"Don't worry\u2014every statistician drops an acorn sometimes,\" Sylvia reassures. \"The multiplication rule for dependent events trips up everyone at first. Just remember: when you're 'removing' things or when information flows between events, you're dealing with dependence. Slow down and adjust!\"</p>"},{"location":"chapters/09-probability-fundamentals/#venn-diagrams-visual-problem-solving","title":"Venn Diagrams: Visual Problem-Solving","text":"<p>A Venn diagram is a visual representation of events using overlapping circles. Each circle represents an event, and the overlap represents outcomes in both events.</p>"},{"location":"chapters/09-probability-fundamentals/#anatomy-of-a-venn-diagram","title":"Anatomy of a Venn Diagram","text":"<ul> <li>The rectangle represents the entire sample space (S)</li> <li>Each circle represents an event</li> <li>The overlap (intersection) represents outcomes in both events</li> <li>The region outside all circles represents outcomes in neither event</li> </ul>"},{"location":"chapters/09-probability-fundamentals/#using-venn-diagrams","title":"Using Venn Diagrams","text":"<p>Venn diagrams are incredibly useful for:</p> <ol> <li>Visualizing relationships between events</li> <li>Solving probability problems systematically</li> <li>Checking your work with the addition rule</li> <li>Understanding complement events</li> </ol> <p>Strategy for using Venn diagrams:</p> <ol> <li>Draw the rectangle (sample space) and circles (events)</li> <li>Start by filling in the intersection (middle)</li> <li>Work outward, finding each region</li> <li>Verify: all regions should sum to 1 (or the sample space size)</li> </ol> <p>Example: In a class of 30 students: - 18 take Spanish - 12 take French - 5 take both languages</p> <p>Let's find probabilities using a Venn diagram:</p> <ul> <li>Both Spanish and French: 5 students</li> <li>Spanish only: 18 - 5 = 13 students</li> <li>French only: 12 - 5 = 7 students</li> <li>Neither language: 30 - 13 - 5 - 7 = 5 students</li> </ul> Region Count Probability Spanish only 13 13/30 \u2248 0.433 French only 7 7/30 \u2248 0.233 Both 5 5/30 \u2248 0.167 Neither 5 5/30 \u2248 0.167 Total 30 1.000 <p>P(Spanish or French) = (13 + 5 + 7)/30 = 25/30 \u2248 0.833</p>"},{"location":"chapters/09-probability-fundamentals/#diagram-venn-diagram-problem-solver","title":"Diagram: Venn Diagram Problem Solver","text":"Interactive Venn Diagram Tool <p>Type: MicroSim</p> <p>Learning objective: Students will use Venn diagrams to organize information and calculate probabilities for overlapping events (Bloom: Applying, Analyzing).</p> <p>Visual elements: - Sample space rectangle with two overlapping circles - Four distinct regions: A only, B only, A\u2229B, neither - Labels showing count or probability in each region - Running total verification display - Event labels A and B (user can rename)</p> <p>Interactive controls: - Input fields for: Total in sample space, n(A), n(B), n(A and B) - Alternatively: probability inputs P(A), P(B), P(A and B) - Toggle between \"Counts\" and \"Probabilities\" mode - \"Auto-calculate regions\" button - \"Verify totals\" button (checks if regions sum correctly) - Preset scenarios: \"Language Classes\", \"Sports Teams\", \"Medical Testing\"</p> <p>Behavior: - As inputs change, regions automatically recalculate - Visual sizes of regions adjust proportionally - Impossible combinations trigger error (e.g., intersection larger than event) - Clicking a region highlights it and shows probability calculation - Formula panel shows relevant probability calculations - Quiz mode: given partial information, find missing values</p> <p>Color scheme: - Event A: blue - Event B: orange - Intersection: purple (blend) - Neither: light gray</p> <p>Canvas size: 800 x 500 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/09-probability-fundamentals/#simulation-probability-in-action","title":"Simulation: Probability in Action","text":"<p>Sometimes probability problems are too complex to solve mathematically. This is where simulation comes to the rescue.</p> <p>A simulation uses random processes to model a real situation and estimate probabilities through many repeated trials. Instead of calculating, we experiment\u2014virtually.</p> <p>Why use simulation?</p> <ul> <li>Some problems have no clean mathematical solution</li> <li>Simulations can verify your calculations</li> <li>They build intuition about probability</li> <li>Modern computers make millions of trials easy</li> </ul> <p>\"Let's crack this nut with a story,\" Sylvia begins. \"I once wondered: if I randomly choose 3 trees from a grove of 10 oaks (where 4 have excellent acorns), what's the probability at least 2 of my picks are excellent? I could calculate it... or I could simulate the selection 10,000 times and count! Both give the same answer, but simulation felt more real.\"</p>"},{"location":"chapters/09-probability-fundamentals/#designing-simulations","title":"Designing Simulations","text":"<p>Designing simulations requires careful planning:</p> <p>Step 1: Identify the random phenomenon you're modeling. What's the question you're trying to answer?</p> <p>Step 2: Design a model that accurately represents the situation. Choose a random device (random numbers, dice, coins, cards) that matches the probabilities.</p> <p>Step 3: Define what counts as a \"trial\" and what outcome you're tracking. What does one simulation run look like? What's your \"success\" condition?</p> <p>Step 4: Run many trials (typically 1,000 to 10,000). More trials = more accurate estimates.</p> <p>Step 5: Calculate the empirical probability. Proportion of trials that achieved the outcome of interest.</p>"},{"location":"chapters/09-probability-fundamentals/#simulation-example","title":"Simulation Example","text":"<p>Problem: A basketball player has a 70% free throw percentage. What's the probability they make at least 4 out of 5 free throws?</p> <p>Simulation Design:</p> <ol> <li> <p>Model: Use random digits 0-9. Let digits 0-6 represent \"make\" (7 outcomes = 70%) and digits 7-9 represent \"miss\" (3 outcomes = 30%).</p> </li> <li> <p>One trial: Generate 5 random digits and count how many are 0-6.</p> </li> <li> <p>Success: The trial is a \"success\" if 4 or 5 digits are 0-6.</p> </li> <li> <p>Run 1,000 trials and count successes.</p> </li> <li> <p>Estimate: P(at least 4 makes) \u2248 number of successes / 1000</p> </li> </ol> <p>A simulation might yield 528 successes out of 1,000 trials, estimating P(at least 4 makes) \u2248 0.528. The true theoretical probability is approximately 0.528 (calculated using the binomial formula we'll learn later).</p>"},{"location":"chapters/09-probability-fundamentals/#diagram-probability-simulation-lab","title":"Diagram: Probability Simulation Lab","text":"Interactive Simulation Tool <p>Type: MicroSim</p> <p>Learning objective: Students will design and run simulations to estimate probabilities for random phenomena, understanding how more trials leads to more accurate estimates (Bloom: Applying, Creating).</p> <p>Visual elements: - Random digit/outcome generator display - Running count of trials and successes - Live probability estimate updating - Histogram showing distribution of outcomes across trials - Confidence band narrowing as trials increase</p> <p>Interactive controls: - Scenario selector: \"Free Throws\", \"Coin Flips\", \"Dice Rolls\", \"Custom\" - For custom: input probability of success per trial - Number of trials per \"trial\" (e.g., 5 free throws) - Success condition (e.g., at least 4) - \"Run 1 trial\" button (shows details) - \"Run 100 trials\" button - \"Run 1000 trials\" button - Speed slider for animation - Reset button</p> <p>Behavior: - Single trial shows step-by-step random outcomes - Multiple trials animate quickly, updating counters - Probability estimate converges toward true value - Display shows: Estimated P = successes/trials - Compare to theoretical probability (if known) - Uncertainty decreases visually as trials increase</p> <p>Canvas size: 800 x 500 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/09-probability-fundamentals/#the-law-of-large-numbers","title":"The Law of Large Numbers","text":"<p>The Law of Large Numbers is one of the most important principles in all of probability. It states:</p> <p>As the number of trials increases, the empirical probability (observed proportion) gets closer and closer to the true theoretical probability.</p> <p>In other words, short-run randomness becomes long-run regularity.</p>"},{"location":"chapters/09-probability-fundamentals/#seeing-the-law-in-action","title":"Seeing the Law in Action","text":"<p>Flip a coin 10 times, and you might get 7 heads (70%). Flip it 100 times, and you'll probably be closer to 50%. Flip it 10,000 times, and you'll be very close to 50%.</p> <p>The Law of Large Numbers does NOT say:</p> <ul> <li>\u274c \"After getting 5 heads in a row, tails is 'due'\" (This is the Gambler's Fallacy!)</li> <li>\u274c \"The next flip will balance things out\"</li> <li>\u274c \"Results must even out in the short run\"</li> </ul> <p>The Law of Large Numbers DOES say:</p> <ul> <li>\u2705 \"Over thousands of flips, the percentage of heads approaches 50%\"</li> <li>\u2705 \"Individual deviations don't matter in the long run\"</li> <li>\u2705 \"Probability is about proportions, not counts\"</li> </ul> <p>This law is why casinos always win in the long run, why insurance companies can set premiums accurately, and why polls work (when done correctly).</p> Number of Coin Flips Possible Head Proportions 10 Could easily be 30% or 70% 100 Usually between 40% and 60% 1,000 Usually between 47% and 53% 10,000 Usually between 49% and 51% <p>\"Time to squirrel away this wisdom,\" Sylvia says sagely. \"The Law of Large Numbers is why my long-term foraging strategy works. Some days I find almost nothing; other days I hit the jackpot. But over a whole autumn, my collection consistently matches my probability-based predictions. Short-term chaos, long-term order!\"</p>"},{"location":"chapters/09-probability-fundamentals/#diagram-law-of-large-numbers-demonstrator","title":"Diagram: Law of Large Numbers Demonstrator","text":"Interactive Law of Large Numbers Visualization <p>Type: MicroSim</p> <p>Learning objective: Students will observe how empirical probability converges to theoretical probability as the number of trials increases, understanding the Law of Large Numbers (Bloom: Understanding, Analyzing).</p> <p>Visual elements: - Real-time graph showing proportion vs. number of trials - Horizontal reference line at true probability - Running proportion display that bounces around, then stabilizes - Counter showing current trial number and cumulative successes - Visual representation of trials (e.g., animated coin flips)</p> <p>Interactive controls: - Probability slider: set true P(success) from 0.1 to 0.9 - \"Flip 1\" button (adds one trial) - \"Flip 10\" button (adds 10 trials rapidly) - \"Flip 100\" button - \"Flip until stable\" button (runs until within 0.01 of true P) - Speed slider for animation - \"Reset\" button to start over</p> <p>Behavior: - After each trial, proportion updates and graph extends - Early in simulation, line jumps wildly - Later in simulation, line hugs the true probability - Display shows: \"After N trials: Observed = X/N = proportion\" - Color indicates distance from true probability (red = far, green = close) - Optional: multiple simultaneous sequences to show all converge</p> <p>Canvas size: 800 x 450 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/09-probability-fundamentals/#common-probability-mistakes","title":"Common Probability Mistakes","text":"<p>Before we practice, let's address errors that trip up even careful students:</p> <p>Mistake 1: The Gambler's Fallacy Believing that past random events affect future independent events. \"I've gotten tails 5 times in a row, so heads is due!\" Wrong\u2014the coin has no memory. Each flip is still 50/50.</p> <p>Mistake 2: Confusing Mutually Exclusive with Independent These are completely different concepts! - Mutually exclusive: Cannot happen together (P(A and B) = 0) - Independent: Occurrence of one doesn't affect the other</p> <p>In fact, if two events with non-zero probability are mutually exclusive, they CANNOT be independent!</p> <p>Mistake 3: Adding Probabilities for Non-Disjoint Events Using P(A) + P(B) when events overlap leads to double-counting. You must subtract the intersection.</p> <p>Mistake 4: Multiplying Probabilities for Dependent Events Without Adjusting Using P(A) \u00d7 P(B) when events are dependent gives wrong answers. You need P(A) \u00d7 P(B|A).</p> <p>Mistake 5: Probability Greater Than 1 If your answer exceeds 1, you've made an error. Go back and check!</p>"},{"location":"chapters/09-probability-fundamentals/#putting-it-all-together-complete-examples","title":"Putting It All Together: Complete Examples","text":""},{"location":"chapters/09-probability-fundamentals/#example-1-cards-and-probability-rules","title":"Example 1: Cards and Probability Rules","text":"<p>A card is drawn from a standard 52-card deck.</p> <p>a) What is P(Queen)? [ P(\\text{Queen}) = \\frac{4}{52} = \\frac{1}{13} \\approx 0.077 ]</p> <p>b) What is P(not a Queen)? [ P(\\text{not Queen}) = 1 - P(\\text{Queen}) = 1 - \\frac{4}{52} = \\frac{48}{52} \\approx 0.923 ]</p> <p>c) What is P(Queen or Heart)? Since some Queens are Hearts, use the general addition rule: [ P(\\text{Queen or Heart}) = \\frac{4}{52} + \\frac{13}{52} - \\frac{1}{52} = \\frac{16}{52} = \\frac{4}{13} \\approx 0.308 ]</p> <p>d) Two cards are drawn with replacement. What is P(both Hearts)? With replacement, draws are independent: [ P(\\text{both Hearts}) = \\frac{13}{52} \\times \\frac{13}{52} = \\frac{1}{4} \\times \\frac{1}{4} = \\frac{1}{16} = 0.0625 ]</p> <p>e) Two cards are drawn without replacement. What is P(both Hearts)? Without replacement, draws are dependent: [ P(\\text{both Hearts}) = \\frac{13}{52} \\times \\frac{12}{51} = \\frac{156}{2652} = \\frac{1}{17} \\approx 0.059 ]</p>"},{"location":"chapters/09-probability-fundamentals/#example-2-using-a-venn-diagram","title":"Example 2: Using a Venn Diagram","text":"<p>A survey of 100 students finds: - 62 use Instagram - 45 use TikTok - 28 use both</p> <p>Find the probability that a randomly selected student:</p> <p>Setting up the Venn diagram:</p> <ul> <li>Both: 28</li> <li>Instagram only: 62 - 28 = 34</li> <li>TikTok only: 45 - 28 = 17</li> <li>Neither: 100 - 34 - 28 - 17 = 21</li> </ul> <p>a) Uses Instagram or TikTok [ P(\\text{I or T}) = \\frac{34 + 28 + 17}{100} = \\frac{79}{100} = 0.79 ]</p> <p>b) Uses exactly one platform [ P(\\text{exactly one}) = \\frac{34 + 17}{100} = \\frac{51}{100} = 0.51 ]</p> <p>c) Uses neither platform [ P(\\text{neither}) = \\frac{21}{100} = 0.21 ]</p> <p>d) Uses at least one platform [ P(\\text{at least one}) = 1 - P(\\text{neither}) = 1 - 0.21 = 0.79 ]</p>"},{"location":"chapters/09-probability-fundamentals/#example-3-simulation-design","title":"Example 3: Simulation Design","text":"<p>Problem: In a game, you roll two dice and win if the sum is 7 or 11. Design a simulation to estimate your probability of winning.</p> <p>Simulation Design:</p> <ol> <li> <p>Model: Use a random number generator for two dice (1-6 each)</p> </li> <li> <p>One trial: Generate two random integers 1-6, find their sum</p> </li> <li> <p>Success: Sum equals 7 or 11</p> </li> <li> <p>Run 10,000 trials</p> </li> <li> <p>Estimate: P(win) = successes / 10,000</p> </li> </ol> <p>The theoretical probability is P(sum = 7) + P(sum = 11) = 6/36 + 2/36 = 8/36 \u2248 0.222. A good simulation should give a result close to this.</p>"},{"location":"chapters/09-probability-fundamentals/#key-takeaways","title":"Key Takeaways","text":"<p>\"Time to squirrel away the big ideas!\"</p> <ul> <li> <p>A random phenomenon has uncertain individual outcomes but predictable long-run patterns</p> </li> <li> <p>Probability is a number between 0 and 1 measuring how likely an event is to occur</p> </li> <li> <p>The sample space is the set of all possible outcomes; an event is any subset of the sample space</p> </li> <li> <p>The complement of event A is \"not A\"; P(A') = 1 - P(A)</p> </li> <li> <p>Mutually exclusive (disjoint) events cannot occur together; independent events don't affect each other's probabilities</p> </li> <li> <p>Addition Rule: P(A or B) = P(A) + P(B) - P(A and B). For disjoint events, the intersection term is 0</p> </li> <li> <p>Multiplication Rule: P(A and B) = P(A) \u00d7 P(B) for independent events; P(A) \u00d7 P(B|A) for dependent events</p> </li> <li> <p>Venn diagrams visually organize events and their overlaps, making probability calculations systematic</p> </li> <li> <p>Simulation estimates probabilities through repeated random trials when mathematical solutions are difficult</p> </li> <li> <p>The Law of Large Numbers states that observed proportions converge to true probabilities over many trials</p> </li> </ul>"},{"location":"chapters/09-probability-fundamentals/#practice-problems","title":"Practice Problems","text":"Check Your Understanding <p>Problem 1: A bag contains 5 red marbles, 3 blue marbles, and 2 green marbles. One marble is drawn at random.</p> <p>a) What is P(red)? b) What is P(not green)? c) What is P(red or blue)? d) Are \"red\" and \"blue\" mutually exclusive? Independent?</p> <p>Problem 2: Two dice are rolled. Let A = \"sum is even\" and B = \"sum is greater than 7.\"</p> <p>a) List the sample space for the sum (possible totals). b) Find P(A). c) Find P(B). d) Are A and B mutually exclusive? Why or why not?</p> <p>Problem 3: In a school, 40% of students play a sport, 25% are in band, and 10% do both. Draw a Venn diagram and find:</p> <p>a) P(sport only) b) P(sport or band) c) P(neither sport nor band)</p> <p>Problem 4: A coin is flipped 4 times. Design a simulation to estimate the probability of getting at least 3 heads. Describe your model, trial definition, and success condition.</p> <p>Problem 5: Explain the difference between mutually exclusive events and independent events. Give an example of each.</p> Solutions <p>Problem 1: a) P(red) = 5/10 = 1/2 = 0.5 b) P(not green) = 1 - P(green) = 1 - 2/10 = 8/10 = 0.8 c) P(red or blue) = 5/10 + 3/10 = 8/10 = 0.8 (mutually exclusive, so just add) d) Yes, mutually exclusive (a marble can't be both red and blue). Not independent\u2014if we know a marble is red, P(blue) = 0, not 3/10.</p> <p>Problem 2: a) S = {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12} b) P(even sum) = 18/36 = 1/2 (sums of 2, 4, 6, 8, 10, 12) c) P(sum &gt; 7) = 15/36 (sums of 8, 9, 10, 11, 12) d) Not mutually exclusive\u2014sums of 8, 10, and 12 are both even AND greater than 7.</p> <p>Problem 3: - Sport only: 40% - 10% = 30% - Band only: 25% - 10% = 15% - Both: 10% - Neither: 100% - 30% - 15% - 10% = 45%</p> <p>a) P(sport only) = 0.30 b) P(sport or band) = 0.30 + 0.10 + 0.15 = 0.55 c) P(neither) = 0.45</p> <p>Problem 4: - Model: Use digits 0-9, where 0-4 = heads (50%), 5-9 = tails (50%) - Trial: Generate 4 random digits - Success: 3 or 4 digits are in range 0-4 - Run 1,000+ trials and calculate proportion of successes - Expected result: approximately 0.3125 (theoretical probability using binomial)</p> <p>Problem 5: Mutually exclusive: Events that cannot occur at the same time. Example: On one die roll, \"rolling a 1\" and \"rolling a 6\" are mutually exclusive.</p> <p>Independent: Events where one occurring doesn't change the probability of the other. Example: Two separate coin flips\u2014getting heads on the first doesn't affect the second flip.</p> <p>Key difference: Mutually exclusive events with non-zero probability are always dependent!</p> <p>You've just built the foundation for all the statistical inference to come. Probability isn't just about cards and dice\u2014it's the mathematical framework for drawing conclusions from data when we can't observe everything. In the next chapter, we'll extend these ideas with conditional probability and Bayes' Theorem.</p> <p>\"Now that's a data point worth collecting!\" Sylvia beams. \"You've learned to speak the language of chance. Whether you're predicting weather, analyzing medical tests, or calculating your odds in a board game, probability is your new superpower. Let's keep going!\"</p>"},{"location":"chapters/10-conditional-probability/","title":"Conditional Probability and Independence","text":""},{"location":"chapters/10-conditional-probability/#summary","title":"Summary","text":"<p>This chapter deepens students' understanding of probability by focusing on conditional probability and independence. Students will learn to calculate conditional probabilities, use tree diagrams to solve complex probability problems, and develop intuition for Bayes' theorem. These concepts are essential for understanding statistical inference.</p>"},{"location":"chapters/10-conditional-probability/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 5 concepts from the learning graph:</p> <ol> <li>Conditional Probability</li> <li>Calculating Conditionals</li> <li>Bayes Intuition</li> <li>Tree Diagram</li> <li>Using Tree Diagrams</li> </ol>"},{"location":"chapters/10-conditional-probability/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 2: Displaying Categorical Data</li> <li>Chapter 9: Probability Fundamentals</li> </ul>"},{"location":"chapters/10-conditional-probability/#when-context-changes-everything","title":"When Context Changes Everything","text":"<p>Welcome back! I hope you've been practicing those probability fundamentals, because now we're going to take things up a notch. Today we're exploring a question that comes up constantly in real life: how does knowing something change what else we expect to happen?</p> <p>Think about it. The probability that you'll ace tomorrow's test depends on whether you studied. The chance that your package arrives today changes once you get a \"shipped\" notification. The likelihood that it will rain shifts dramatically when you look out the window and see dark clouds. In each case, new information changes the probabilities. This is the essence of conditional probability, and my tail's tingling because this concept is genuinely powerful.</p> <p>Let me share a quick story. When I was organizing my acorn stash last autumn, I noticed something interesting. The probability that an acorn was good (not rotten) was about 85% overall. But when I sorted them by which tree they came from, the probabilities changed dramatically! Acorns from the oak by the stream were good 95% of the time, while ones from the oak near the parking lot were only good 70% of the time. Knowing which tree the acorn came from changed my expectations completely. That's conditional probability in action.</p>"},{"location":"chapters/10-conditional-probability/#what-is-conditional-probability","title":"What Is Conditional Probability?","text":"<p>Conditional probability is the probability of an event occurring given that another event has already occurred. The key word here is \"given.\" We're not asking about probabilities in general; we're asking about probabilities in a specific context or condition.</p> <p>We write conditional probability using a vertical bar notation:</p> \\[ P(A \\mid B) = \\text{\"the probability of A given B\"} \\] <p>That vertical bar is read as \"given\" or \"knowing that.\" So \\(P(\\text{Rain} \\mid \\text{Cloudy})\\) means \"the probability of rain given that it's cloudy.\"</p> <p>Here are some examples to make this concrete:</p> Conditional Probability What It Means \\(P(\\text{Pass} \\mid \\text{Studied})\\) Probability of passing given that you studied \\(P(\\text{Heart} \\mid \\text{Red Card})\\) Probability of drawing a heart given it's a red card \\(P(\\text{Late} \\mid \\text{Traffic})\\) Probability of being late given there's traffic \\(P(\\text{Win} \\mid \\text{Home Game})\\) Probability of winning given it's a home game <p>The condition (the event after the bar) essentially narrows down our sample space. Instead of considering all possible outcomes, we only consider outcomes where the condition is true.</p> <p>Acorn for your thoughts?</p> <p>Sylvia says: \"Here's how I think about it. The probability that any random tree in the forest has great acorns is maybe 20%. But the probability that the old oak behind the library has great acorns, given that my grandmother collected from it for 15 years and always came back with a full stash? Much higher! Context matters.\"</p>"},{"location":"chapters/10-conditional-probability/#visualizing-conditional-probability","title":"Visualizing Conditional Probability","text":"<p>Let's use a two-way table to see how conditional probability works. Suppose we surveyed 200 students about whether they eat breakfast and whether they feel alert in their morning classes:</p> Alert Not Alert Total Ate Breakfast 72 18 90 No Breakfast 33 77 110 Total 105 95 200 <p>Now let's calculate some probabilities.</p> <p>Overall probability of being alert: [ P(\\text{Alert}) = \\frac{105}{200} = 0.525 = 52.5\\% ]</p> <p>Probability of being alert given that you ate breakfast: [ P(\\text{Alert} \\mid \\text{Ate Breakfast}) = \\frac{72}{90} = 0.80 = 80\\% ]</p> <p>Probability of being alert given no breakfast: [ P(\\text{Alert} \\mid \\text{No Breakfast}) = \\frac{33}{110} = 0.30 = 30\\% ]</p> <p>Look at that difference! The overall probability of being alert is 52.5%, but knowing whether someone ate breakfast dramatically changes our expectation. For breakfast-eaters, the probability jumps to 80%; for breakfast-skippers, it drops to 30%.</p>"},{"location":"chapters/10-conditional-probability/#diagram-conditional-probability-two-way-table-explorer","title":"Diagram: Conditional Probability Two-Way Table Explorer","text":"Conditional Probability Two-Way Table Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate</p> <p>Learning Objective: Students will calculate conditional probabilities from a two-way table by selecting conditions and observing how the relevant subset changes.</p> <p>Data Visibility Requirements: - Stage 1: Display a two-way table with counts for two categorical variables - Stage 2: User selects a condition (row or column) which highlights the relevant subset - Stage 3: User selects an outcome, and the conditional probability is calculated</p> <p>Instructional Rationale: Interactive selection from a table allows students to see how conditioning restricts the sample space. Highlighting the \"given\" row/column makes the denominator visible.</p> <p>Visual elements: - Two-way table with editable or preset values - Left side: Table with row and column headers clearly labeled - Right side: Visual representation showing the conditional probability as a fraction - Highlighted cells when condition is selected - Calculation shown step-by-step: \"Given [condition], P([outcome]) = [numerator]/[denominator]\"</p> <p>Interactive controls: - Dropdown or click to select the \"given\" condition (which row or column) - Dropdown or click to select the outcome - Toggle between different example datasets (breakfast/alert, sports/grades, etc.) - Reset button</p> <p>Default parameters: - Start with breakfast/alertness data from the text - No condition selected initially - Both rows and columns selectable as conditions</p> <p>Behavior: - When user selects a condition, highlight that entire row or column - Dim the rest of the table to show the restricted sample space - When user selects an outcome within the condition, highlight that cell - Display the calculation: P(outcome | condition) = cell count / row or column total - Show comparison to unconditional probability</p> <p>Color scheme: - Unselected cells: light gray - Condition selected: light blue background - Outcome cell: bright orange highlight - Text showing calculation in green</p> <p>Canvas size: Responsive, approximately 700x450px Implementation: p5.js with mouse click detection for cell/header selection</p>"},{"location":"chapters/10-conditional-probability/#the-conditional-probability-formula","title":"The Conditional Probability Formula","text":"<p>Now let's formalize how to calculate conditional probability. The formula connects conditional probability to the probabilities we already know:</p> \\[ P(A \\mid B) = \\frac{P(A \\text{ and } B)}{P(B)} \\] <p>In words: the probability of A given B equals the probability of both A and B happening, divided by the probability of B.</p> <p>Why does this formula work? Think about it this way. When we're given that B occurred, we're restricting our attention to only those outcomes where B happens. The denominator \\(P(B)\\) represents this restricted universe. The numerator \\(P(A \\text{ and } B)\\) captures the outcomes that satisfy both conditions.</p> <p>Let's verify with our breakfast example:</p> <ul> <li>\\(P(\\text{Ate Breakfast}) = \\frac{90}{200} = 0.45\\)</li> <li>\\(P(\\text{Alert and Ate Breakfast}) = \\frac{72}{200} = 0.36\\)</li> <li>\\(P(\\text{Alert} \\mid \\text{Ate Breakfast}) = \\frac{0.36}{0.45} = 0.80\\)</li> </ul> <p>That matches what we calculated directly from the table.</p> <p>The Multiplication Rule Revisited</p> <p>You might recognize this formula rearranged. The General Multiplication Rule states: [ P(A \\text{ and } B) = P(B) \\times P(A \\mid B) ] This tells us the probability of both events equals the probability of the first event times the conditional probability of the second given the first. We'll use this extensively with tree diagrams.</p>"},{"location":"chapters/10-conditional-probability/#calculating-conditional-probabilities","title":"Calculating Conditional Probabilities","text":"<p>Let's work through several examples to build your skills with conditional probability calculations.</p> <p>Example 1: Card Drawing</p> <p>A standard deck has 52 cards: 26 red (13 hearts, 13 diamonds) and 26 black (13 clubs, 13 spades). What is the probability of drawing a heart given that the card is red?</p> <p>Given: The card is red (26 cards) Finding: Probability it's a heart (13 of the red cards are hearts)</p> \\[ P(\\text{Heart} \\mid \\text{Red}) = \\frac{13}{26} = \\frac{1}{2} = 0.50 \\] <p>Alternatively, using the formula: [ P(\\text{Heart} \\mid \\text{Red}) = \\frac{P(\\text{Heart and Red})}{P(\\text{Red})} = \\frac{13/52}{26/52} = \\frac{13}{26} = 0.50 ]</p> <p>Example 2: Medical Testing</p> <p>In a population of 10,000 people, 200 have a certain disease. A test correctly identifies 95% of people with the disease and correctly identifies 90% of people without the disease.</p> Has Disease No Disease Total Tests Positive 190 980 1,170 Tests Negative 10 8,820 8,830 Total 200 9,800 10,000 <p>Let's calculate \\(P(\\text{Disease} \\mid \\text{Positive Test})\\):</p> \\[ P(\\text{Disease} \\mid \\text{Positive Test}) = \\frac{190}{1170} \\approx 0.162 = 16.2\\% \\] <p>Wait, only 16.2%? Even with a positive test, there's only about a 1 in 6 chance of actually having the disease! This counterintuitive result happens because the disease is rare, so even a small percentage of false positives among the healthy population outnumbers the true positives. This is a crucial insight for interpreting medical tests.</p> <p>Example 3: Weather Patterns</p> <p>Historical data shows that in Seattle, it rains on 150 days per year, and 200 days are cloudy. On 140 days, it's both cloudy and raining.</p> \\[ P(\\text{Rain} \\mid \\text{Cloudy}) = \\frac{P(\\text{Rain and Cloudy})}{P(\\text{Cloudy})} = \\frac{140/365}{200/365} = \\frac{140}{200} = 0.70 \\] <p>So if it's cloudy in Seattle, there's a 70% chance of rain. But notice:</p> \\[ P(\\text{Rain}) = \\frac{150}{365} \\approx 0.41 \\] <p>The unconditional probability of rain is only 41%, but knowing it's cloudy increases this to 70%.</p>"},{"location":"chapters/10-conditional-probability/#diagram-conditional-probability-calculator","title":"Diagram: Conditional Probability Calculator","text":"Conditional Probability Calculator <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate</p> <p>Learning Objective: Students will calculate conditional probabilities by entering counts or probabilities and seeing the formula applied step by step.</p> <p>Data Visibility Requirements: - Stage 1: Input fields for P(A), P(B), and P(A and B) - Stage 2: Show the formula with values substituted - Stage 3: Display the calculated result with explanation</p> <p>Instructional Rationale: A calculator with visible steps helps students connect the abstract formula to concrete numbers, reinforcing procedural understanding.</p> <p>Visual elements: - Three input fields for probabilities or two-way table counts - Toggle between \"probability input\" and \"count input\" modes - Step-by-step calculation display - Visual representation using a Venn diagram or area model - Result displayed prominently</p> <p>Interactive controls: - Input fields for P(A and B), P(B) [for calculating P(A|B)] - Or input fields for P(A and B), P(A) [for calculating P(B|A)] - Toggle to switch which conditional probability to calculate - Preset examples button (cards, medical test, weather) - Clear/reset button</p> <p>Default parameters: - Start with blank inputs - Example presets available - Show Venn diagram representation</p> <p>Behavior: - As user types values, update the formula display in real-time - Validate inputs (probabilities between 0 and 1, P(A and B) \u2264 min(P(A), P(B))) - Show error messages for invalid inputs - Display result with interpretation (\"Given B occurs, A has a [X]% chance of occurring\")</p> <p>Color scheme: - Input fields: white with green border - Formula: black text with colored variables - Result: large orange text - Venn diagram: blue for A, orange for B, green for intersection</p> <p>Canvas size: Responsive, approximately 650x400px Implementation: p5.js with text input handling</p>"},{"location":"chapters/10-conditional-probability/#independence-when-knowing-doesnt-help","title":"Independence: When Knowing Doesn't Help","text":"<p>Sometimes knowing that one event occurred doesn't change the probability of another event at all. When this happens, we say the events are independent.</p> <p>Formally, events A and B are independent if and only if:</p> \\[ P(A \\mid B) = P(A) \\] <p>In words: knowing B occurred doesn't change the probability of A. The condition gives you no new information.</p> <p>Equivalently, A and B are independent if:</p> \\[ P(A \\text{ and } B) = P(A) \\times P(B) \\] <p>This is the multiplication rule for independent events. The probability of both happening is just the product of their individual probabilities.</p> <p>Here are some examples of independent events:</p> <ul> <li>Flipping a coin and rolling a die (the coin doesn't affect the die)</li> <li>The weather in Tokyo and your grade on tomorrow's test</li> <li>Drawing a card, replacing it, and drawing again</li> </ul> <p>And here are dependent events (NOT independent):</p> <ul> <li>Drawing two cards without replacement (first draw changes what's left)</li> <li>Whether you study and whether you pass the test</li> <li>Being cloudy and raining</li> </ul> <p>Common Misconception</p> <p>Don't confuse independent with mutually exclusive! Mutually exclusive events CAN'T happen together (like rolling a 3 AND rolling a 5 on one die). Independent events CAN happen together, and knowing one occurred doesn't change the probability of the other. In fact, if two events are mutually exclusive and both have nonzero probability, they cannot be independent!</p> <p>Testing for Independence</p> <p>To check if events are independent, verify that \\(P(A \\mid B) = P(A)\\). Let's check with our breakfast data:</p> <ul> <li>\\(P(\\text{Alert}) = \\frac{105}{200} = 0.525\\)</li> <li>\\(P(\\text{Alert} \\mid \\text{Ate Breakfast}) = \\frac{72}{90} = 0.80\\)</li> </ul> <p>Since \\(0.80 \\neq 0.525\\), alertness and eating breakfast are NOT independent. Knowing someone ate breakfast changes (increases!) our expectation of them being alert.</p> <p>Let's crack this nut with a different example. Suppose we flip a fair coin twice. Let A = \"first flip is heads\" and B = \"second flip is heads.\"</p> <ul> <li>\\(P(A) = 0.5\\)</li> <li>\\(P(B) = 0.5\\)</li> <li>\\(P(A \\mid B) = \\) ?</li> </ul> <p>The first flip's result doesn't depend on the second flip, so \\(P(A \\mid B) = P(A) = 0.5\\). These events are independent.</p>"},{"location":"chapters/10-conditional-probability/#tree-diagrams-organizing-complex-probabilities","title":"Tree Diagrams: Organizing Complex Probabilities","text":"<p>When probability problems involve sequences of events, tree diagrams become your best friend. A tree diagram is a visual tool that shows all possible outcomes and their probabilities in a branching structure.</p> <p>Here's how to build a tree diagram:</p> <ol> <li>Start with a single point (the root)</li> <li>Draw branches for each possible outcome of the first event</li> <li>Label each branch with its probability</li> <li>From each branch, draw new branches for the next event</li> <li>Label these with conditional probabilities</li> <li>Multiply along paths to get joint probabilities</li> <li>Add probabilities of paths that lead to the same final outcome</li> </ol> <p>Let's create a tree diagram for a medical testing scenario. Suppose 2% of people have Disease D. The test is 95% accurate for people with the disease and 90% accurate for people without.</p> <pre><code>                    Disease Status        Test Result\n\n                         /--- Test+ (0.95)  \u2192 P(D and +) = 0.02 \u00d7 0.95 = 0.019\n                        /\n            D (0.02) ---\n                        \\\n                         \\--- Test- (0.05)  \u2192 P(D and -) = 0.02 \u00d7 0.05 = 0.001\nStart ---\n                         /--- Test+ (0.10)  \u2192 P(No D and +) = 0.98 \u00d7 0.10 = 0.098\n                        /\n          No D (0.98) ---\n                        \\\n                         \\--- Test- (0.90)  \u2192 P(No D and -) = 0.98 \u00d7 0.90 = 0.882\n</code></pre> <p>From this tree, we can calculate any probability we need:</p> <ul> <li>\\(P(\\text{Positive Test}) = 0.019 + 0.098 = 0.117\\)</li> <li>\\(P(\\text{Disease} \\mid \\text{Positive}) = \\frac{0.019}{0.117} \\approx 0.162\\)</li> </ul> <p>Tree diagrams make the logic visible. You can see exactly how probabilities flow through the branches and combine.</p>"},{"location":"chapters/10-conditional-probability/#diagram-interactive-tree-diagram-builder","title":"Diagram: Interactive Tree Diagram Builder","text":"Interactive Tree Diagram Builder <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: construct</p> <p>Learning Objective: Students will construct tree diagrams by specifying events and probabilities, then use the diagram to calculate joint and conditional probabilities.</p> <p>Data Visibility Requirements: - Stage 1: Show the tree structure with labeled branches - Stage 2: Display probability labels on each branch - Stage 3: Calculate and show joint probabilities at leaf nodes</p> <p>Instructional Rationale: Building tree diagrams interactively helps students understand how conditional probabilities multiply along paths and how outcomes combine.</p> <p>Visual elements: - Tree starting from left side, branching right - Nodes as circles, branches as lines - Probability labels on branches - Joint probability calculations at leaf nodes - Summary panel showing all possible outcomes and their probabilities</p> <p>Interactive controls: - Input field for number of initial branches (2-4) - Input fields for branch probabilities (must sum to 1) - Option to add second level of branches - Input fields for conditional probabilities on second level - \"Calculate\" button to show all results - Preset examples (medical test, weather forecast, defective products) - Reset button</p> <p>Default parameters: - Start with medical testing example - Two-level tree (disease status \u2192 test result) - Branch probabilities editable</p> <p>Behavior: - Tree redraws as user changes probabilities - Validate that probabilities sum to 1 at each branch point - Calculate joint probabilities by multiplying along paths - Highlight paths when user hovers over a leaf node - Show formula: P(path) = P(branch1) \u00d7 P(branch2) - Bottom panel summarizes: \"P(Disease AND Positive) = 0.019\"</p> <p>Color scheme: - First level branches: shades of blue (disease) and green (no disease) - Second level branches: shades of orange (positive) and purple (negative) - Leaf nodes: colored by final outcome - Path highlighting: bright yellow</p> <p>Canvas size: Responsive, approximately 750x500px Implementation: p5.js with interactive input fields</p>"},{"location":"chapters/10-conditional-probability/#using-tree-diagrams-to-solve-problems","title":"Using Tree Diagrams to Solve Problems","text":"<p>Tree diagrams are especially powerful for multi-step probability problems. Let's work through a complete example.</p> <p>Problem: Quality Control</p> <p>A factory has two machines. Machine A produces 60% of all items and has a 3% defect rate. Machine B produces 40% of items and has a 5% defect rate.</p> <p>(a) What's the probability that a randomly selected item is defective?</p> <p>Let's build the tree:</p> <pre><code>                Machine              Quality\n\n                     /--- Defective (0.03)   \u2192 P(A and Def) = 0.60 \u00d7 0.03 = 0.018\n                    /\n          A (0.60) ---\n                    \\\n                     \\--- Good (0.97)        \u2192 P(A and Good) = 0.60 \u00d7 0.97 = 0.582\nStart ---\n                     /--- Defective (0.05)   \u2192 P(B and Def) = 0.40 \u00d7 0.05 = 0.020\n                    /\n          B (0.40) ---\n                    \\\n                     \\--- Good (0.95)        \u2192 P(B and Good) = 0.40 \u00d7 0.95 = 0.380\n</code></pre> \\[ P(\\text{Defective}) = 0.018 + 0.020 = 0.038 = 3.8\\% \\] <p>(b) Given that an item is defective, what's the probability it came from Machine A?</p> <p>This is a conditional probability! We need:</p> \\[ P(A \\mid \\text{Defective}) = \\frac{P(A \\text{ and Defective})}{P(\\text{Defective})} = \\frac{0.018}{0.038} \\approx 0.474 = 47.4\\% \\] <p>Even though Machine A has a lower defect rate (3% vs 5%), it still produces about 47% of the defective items because it produces more items overall (60% of production).</p> <p>My tail's tingling!</p> <p>Sylvia says: \"This is exactly how I figured out which trees to avoid! I knew 70% of acorns in my area came from the big oaks and 30% from the smaller maples. Even though maples had a lower percentage of good acorns, most of my good acorns still came from oaks because there were so many of them. The tree diagram made it clear!\"</p>"},{"location":"chapters/10-conditional-probability/#bayes-theorem-reversing-the-condition","title":"Bayes' Theorem: Reversing the Condition","text":"<p>You've now seen several examples where we calculate \\(P(A \\mid B)\\) when we know \\(P(B \\mid A)\\). This \"flipping\" of the condition is formalized in Bayes' Theorem:</p> \\[ P(A \\mid B) = \\frac{P(B \\mid A) \\times P(A)}{P(B)} \\] <p>In the medical testing example: - We knew \\(P(\\text{Positive} \\mid \\text{Disease}) = 0.95\\) (the test's sensitivity) - We wanted \\(P(\\text{Disease} \\mid \\text{Positive})\\) (what a positive test means)</p> <p>Bayes' theorem lets us convert one to the other.</p> <p>The key insight is that these two conditional probabilities are often very different! \\(P(\\text{Disease} \\mid \\text{Positive})\\) was only about 16%, even though \\(P(\\text{Positive} \\mid \\text{Disease})\\) was 95%.</p> <p>Why Does This Happen?</p> <p>The difference comes from the base rate, which is how common the condition is in the first place. When disease is rare (2%), even a good test produces many false positives among the huge number of healthy people.</p> <p>Here's an intuitive way to think about it. Imagine 10,000 people:</p> <ul> <li>200 have the disease \u2192 190 test positive (true positives)</li> <li>9,800 don't have disease \u2192 980 test positive (false positives)</li> </ul> <p>Total positives: 190 + 980 = 1,170</p> <p>Proportion who actually have disease: 190/1170 \u2248 16%</p> <p>The false positives swamp the true positives because there are so many more healthy people.</p>"},{"location":"chapters/10-conditional-probability/#diagram-bayes-theorem-visualizer","title":"Diagram: Bayes' Theorem Visualizer","text":"Bayes' Theorem Visualizer <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: analyze</p> <p>Learning Objective: Students will analyze how prior probability (base rate), sensitivity, and specificity affect the posterior probability using Bayes' theorem.</p> <p>Data Visibility Requirements: - Stage 1: Show population split by disease status (prior probability) - Stage 2: Show test results within each group - Stage 3: Calculate and display the posterior probability with visual representation</p> <p>Instructional Rationale: An interactive visualization showing populations and test results helps students build intuition for why base rates matter so much in Bayesian reasoning.</p> <p>Visual elements: - Icon array or area diagram showing population of 1000 people - Color coding: disease (red icons) vs healthy (blue icons) - Second layer showing test results: positive (highlighted) vs negative (dimmed) - Calculation panel showing Bayes' theorem with current values - Sliders clearly connected to the visualization</p> <p>Interactive controls: - Slider for prior probability P(Disease): 1% to 50% - Slider for sensitivity P(Positive|Disease): 70% to 99% - Slider for specificity P(Negative|No Disease): 70% to 99% - Toggle between icon array and tree diagram view - Reset to default values button</p> <p>Default parameters: - Prior: 2% (disease prevalence) - Sensitivity: 95% - Specificity: 90% - Show 1000-person population</p> <p>Behavior: - As sliders change, population visualization updates in real-time - Count and percentage of each category displayed - Final calculation shows P(Disease|Positive) prominently - Animation showing which positive tests are true vs false positives - Comparison statement: \"X% of positive tests are actually true positives\"</p> <p>Color scheme: - Disease: red/salmon - Healthy: blue/teal - Positive test: bright border - Negative test: faded/dimmed - True positive: gold star - False positive: orange warning</p> <p>Canvas size: Responsive, approximately 750x500px Implementation: p5.js with slider controls</p>"},{"location":"chapters/10-conditional-probability/#common-patterns-and-pitfalls","title":"Common Patterns and Pitfalls","text":"<p>As you work with conditional probability, watch out for these common issues:</p> <p>The Prosecutor's Fallacy</p> <p>Don't confuse \\(P(\\text{Evidence} \\mid \\text{Innocent})\\) with \\(P(\\text{Innocent} \\mid \\text{Evidence})\\). A rare match (like DNA) might have \\(P(\\text{Match} \\mid \\text{Innocent}) = 0.0001\\), but \\(P(\\text{Innocent} \\mid \\text{Match})\\) depends on how many people could be suspects!</p> <p>Base Rate Neglect</p> <p>People often ignore how common or rare the underlying condition is. Even a very accurate test produces unreliable results when testing for something rare. Always consider the base rate.</p> <p>Confusing Independence with Unrelated</p> <p>Independence is a precise mathematical property. Two events might seem \"unrelated\" but still not be independent. Always check the numbers.</p> <p>Forgetting to Update</p> <p>When you condition on new information, you must use that information. The sample space shrinks. Old probabilities may no longer apply.</p>"},{"location":"chapters/10-conditional-probability/#putting-it-all-together","title":"Putting It All Together","text":"<p>Let's work through a comprehensive example that uses all our tools.</p> <p>Problem: Weather and Commuting</p> <p>Data from a commuter's log:</p> On Time Late Total Rain 15 45 60 No Rain 180 60 240 Total 195 105 300 <p>(a) Are being late and rain independent?</p> <p>Check if \\(P(\\text{Late} \\mid \\text{Rain}) = P(\\text{Late})\\):</p> <ul> <li>\\(P(\\text{Late}) = \\frac{105}{300} = 0.35\\)</li> <li>\\(P(\\text{Late} \\mid \\text{Rain}) = \\frac{45}{60} = 0.75\\)</li> </ul> <p>Since \\(0.75 \\neq 0.35\\), these events are NOT independent. Rain more than doubles the probability of being late!</p> <p>(b) Given that the commuter was late, what's the probability it was raining?</p> \\[ P(\\text{Rain} \\mid \\text{Late}) = \\frac{45}{105} \\approx 0.429 = 42.9\\% \\] <p>(c) Draw a tree diagram for this situation.</p> <pre><code>                    Weather             Arrival\n\n                         /--- On Time (0.25)  \u2192 P(Rain, On Time) = 0.20 \u00d7 0.25 = 0.05\n                        /\n         Rain (0.20) ---\n                        \\\n                         \\--- Late (0.75)     \u2192 P(Rain, Late) = 0.20 \u00d7 0.75 = 0.15\nStart ---\n                         /--- On Time (0.75)  \u2192 P(No Rain, On Time) = 0.80 \u00d7 0.75 = 0.60\n                        /\n       No Rain (0.80) ---\n                        \\\n                         \\--- Late (0.25)     \u2192 P(No Rain, Late) = 0.80 \u00d7 0.25 = 0.20\n</code></pre> <p>Notice how the conditional probabilities for \"Late\" change depending on the weather: 75% when raining versus only 25% when not raining.</p>"},{"location":"chapters/10-conditional-probability/#key-takeaways","title":"Key Takeaways","text":"<p>Let's squirrel away the big ideas from this chapter:</p> <ol> <li> <p>Conditional probability \\(P(A \\mid B)\\) is the probability of A occurring given that B has occurred. The condition restricts our sample space.</p> </li> <li> <p>The conditional probability formula is: [ P(A \\mid B) = \\frac{P(A \\text{ and } B)}{P(B)} ]</p> </li> <li> <p>Events are independent if knowing one doesn't change the probability of the other: \\(P(A \\mid B) = P(A)\\). For independent events, \\(P(A \\text{ and } B) = P(A) \\times P(B)\\).</p> </li> <li> <p>Tree diagrams organize sequential probabilities. Multiply along branches to get joint probabilities; add probabilities of paths leading to the same outcome.</p> </li> <li> <p>Bayes' theorem lets us reverse conditional probabilities: [ P(A \\mid B) = \\frac{P(B \\mid A) \\times P(A)}{P(B)} ]</p> </li> <li> <p>Base rate matters enormously! Even accurate tests can give misleading results when the condition being tested for is rare.</p> </li> </ol>"},{"location":"chapters/10-conditional-probability/#practice-problems","title":"Practice Problems","text":"Problem 1: Cards <p>Two cards are drawn from a standard deck without replacement.</p> <p>(a) What is the probability the second card is a king given that the first card was a king?</p> <p>(b) What is the probability both cards are kings?</p> <p>Solutions:</p> <p>(a) After drawing one king, 51 cards remain with 3 kings among them: [P(\\text{2nd King} \\mid \\text{1st King}) = \\frac{3}{51} = \\frac{1}{17} \\approx 0.059]</p> <p>(b) Using the multiplication rule: [P(\\text{Both Kings}) = P(\\text{1st King}) \\times P(\\text{2nd King} \\mid \\text{1st King}) = \\frac{4}{52} \\times \\frac{3}{51} = \\frac{12}{2652} = \\frac{1}{221} \\approx 0.0045]</p> Problem 2: Student Activities <p>At a high school, 40% of students play sports, 30% are in band, and 15% do both.</p> <p>(a) What is the probability a student is in band given they play sports?</p> <p>(b) Are playing sports and being in band independent?</p> <p>Solutions:</p> <p>(a) [P(\\text{Band} \\mid \\text{Sports}) = \\frac{P(\\text{Band and Sports})}{P(\\text{Sports})} = \\frac{0.15}{0.40} = 0.375 = 37.5\\%]</p> <p>(b) Check if \\(P(\\text{Band} \\mid \\text{Sports}) = P(\\text{Band})\\): - \\(P(\\text{Band}) = 0.30\\) - \\(P(\\text{Band} \\mid \\text{Sports}) = 0.375\\)</p> <p>Since \\(0.375 \\neq 0.30\\), these events are NOT independent. Being an athlete makes it more likely a student is also in band.</p> Problem 3: Disease Screening <p>A disease affects 1% of a population. A screening test has 90% sensitivity (correctly identifies those with disease) and 95% specificity (correctly identifies those without disease).</p> <p>(a) Draw a tree diagram for this situation.</p> <p>(b) What is the probability of a positive test result?</p> <p>(c) If someone tests positive, what is the probability they have the disease?</p> <p>Solutions:</p> <p>(a) Tree diagram: <pre><code>                  /--- Positive (0.90)  \u2192 0.01 \u00d7 0.90 = 0.009\n     Disease (0.01)\n                  \\--- Negative (0.10)  \u2192 0.01 \u00d7 0.10 = 0.001\nStart\n                  /--- Positive (0.05)  \u2192 0.99 \u00d7 0.05 = 0.0495\n   No Disease (0.99)\n                  \\--- Negative (0.95)  \u2192 0.99 \u00d7 0.95 = 0.9405\n</code></pre></p> <p>(b) \\(P(\\text{Positive}) = 0.009 + 0.0495 = 0.0585 = 5.85\\%\\)</p> <p>(c) [P(\\text{Disease} \\mid \\text{Positive}) = \\frac{0.009}{0.0585} \\approx 0.154 = 15.4\\%]</p> <p>Even with a positive test, there's only about a 15% chance of actually having the disease because the disease is rare.</p> Problem 4: Manufacturing <p>Factory A produces 55% of a company's widgets and 3% of Factory A's widgets are defective. Factory B produces the rest and 4% of Factory B's widgets are defective.</p> <p>(a) What percentage of all widgets are defective?</p> <p>(b) A widget is found to be defective. What is the probability it came from Factory A?</p> <p>Solutions:</p> <p>(a) Factory B produces 45% of widgets. [P(\\text{Defective}) = 0.55 \\times 0.03 + 0.45 \\times 0.04 = 0.0165 + 0.0180 = 0.0345 = 3.45\\%]</p> <p>(b) [P(\\text{Factory A} \\mid \\text{Defective}) = \\frac{0.0165}{0.0345} \\approx 0.478 = 47.8\\%]</p> <p>Even though Factory A has a lower defect rate, it still produces about 48% of defective items because it produces more widgets overall.</p> <p>Now that's a data point worth collecting! You've learned how new information changes probabilities, how to use tree diagrams to organize complex problems, and why base rates matter so much in Bayesian reasoning. These tools are essential for the statistical inference we'll explore in upcoming chapters.</p>"},{"location":"chapters/11-sampling-and-bias/","title":"Sampling and Bias","text":"<p>\"Alright, friends, here's the deal: in statistics, the way you gather your data matters just as much as what you do with it afterward. Get this step wrong, and everything downstream goes wonky. But don't worry\u2014by the end of this chapter, you'll be a sampling superstar. Let's crack this nut!\" \u2014 Sylvia</p>"},{"location":"chapters/11-sampling-and-bias/#introduction-why-sampling-matters","title":"Introduction: Why Sampling Matters","text":"<p>Imagine you want to know what percentage of students at your school prefer pizza over tacos for lunch. You could ask every single student\u2014but that would take forever! Instead, you might ask a smaller group and use their answers to estimate what the whole school thinks. This process of selecting a subset to represent the whole is called sampling, and it's one of the most powerful tools in statistics.</p> <p>The catch? If you choose your sample poorly, your conclusions could be completely wrong. Ask only the students in the pizza club, and you'll get a very different answer than if you surveyed the whole school fairly. The errors that creep in when samples don't represent populations well are called bias, and learning to avoid bias is what this chapter is all about.</p> <p>Good sampling is like building a foundation for a house. Get it right, and everything you build on top\u2014your confidence intervals, your hypothesis tests, your predictions\u2014will be solid. Get it wrong, and the whole structure wobbles.</p>"},{"location":"chapters/11-sampling-and-bias/#census-vs-sample-the-big-picture","title":"Census vs. Sample: The Big Picture","text":"<p>Before we dive into sampling methods, let's clarify two fundamental approaches to gathering data:</p> Approach Definition Advantages Disadvantages Census Collect data from every member of the population Complete accuracy; no sampling error Expensive, time-consuming, often impractical Sample Collect data from a subset of the population Faster, cheaper, feasible for large populations May not perfectly represent the population <p>A census is the gold standard\u2014if you could magically survey every person, you'd know exactly what the population looks like. The U.S. Census attempts this every ten years, but even with massive resources, achieving a true census is difficult. People move, refuse to respond, or get missed.</p> <p>In most real-world situations, we use samples instead. The key question becomes: how do we select a sample that accurately represents the population?</p> <p>\"Think of it this way,\" Sylvia explains, \"a census is like counting every single acorn in the forest. A sample is like carefully picking a handful from different spots and using that to estimate the total. Both have their place, but samples are way more practical when your forest has millions of trees!\"</p>"},{"location":"chapters/11-sampling-and-bias/#the-problem-of-bias","title":"The Problem of Bias","text":"<p>Bias occurs when the sampling method systematically favors certain outcomes over others. A biased sample doesn't represent the population fairly\u2014it's tilted in one direction.</p> <p>Here's the crucial distinction:</p> <ul> <li>Unbiased Estimator: A sampling method where, on average, the sample statistic equals the population parameter. If you repeated the sampling process many times, the results would center on the true value.</li> <li>Biased Estimator: A sampling method that consistently overestimates or underestimates the population parameter. No matter how many samples you take, your results systematically miss the mark.</li> </ul> Show/Hide <p>The target diagram helps visualize this concept:</p> <ul> <li>Low bias, low variability: Your shots cluster tightly around the bullseye. This is the ideal.</li> <li>Low bias, high variability: Your shots are centered on the bullseye but scattered widely. You're not systematically missing, just inconsistent.</li> <li>High bias, low variability: Your shots cluster tightly, but they're consistently off to one side. You're reliably missing in the same direction.</li> <li>High bias, high variability: Your shots are scattered AND off-center. This is the worst scenario.</li> </ul> <p>\"My tail's tingling\u2014we're onto something important here!\" Sylvia says. \"Bias is sneaky because it doesn't average out. Take more samples with a biased method, and you just get more confidently wrong!\"</p>"},{"location":"chapters/11-sampling-and-bias/#diagram-bias-vs-variability-target-visualization","title":"Diagram: Bias vs. Variability Target Visualization","text":"<p>Create an interactive MicroSim showing the classic \"target\" diagram illustrating bias and variability.</p> <p>Learning Objective: Students will understand the difference between bias (systematic error) and variability (random error) through a visual target metaphor.</p> <p>Inputs:</p> <ul> <li>Dropdown selector: \"Low Bias/Low Variability\", \"Low Bias/High Variability\", \"High Bias/Low Variability\", \"High Bias/High Variability\"</li> <li>Button to generate new random sample points</li> </ul> <p>Outputs:</p> <ul> <li>Target with bullseye representing the true population parameter</li> <li>Dots representing sample estimates scattered according to the selected bias/variability combination</li> <li>Visual explanation text updating based on selection</li> </ul> <p>Behavior:</p> <ul> <li>Low Bias/Low Variability: Dots cluster tightly around the bullseye center</li> <li>Low Bias/High Variability: Dots spread widely but centered on bullseye</li> <li>High Bias/Low Variability: Dots cluster tightly but away from center</li> <li>High Bias/High Variability: Dots spread widely and off-center</li> </ul> <p>Size: 600 x 450 pixels</p>"},{"location":"chapters/11-sampling-and-bias/#probability-sampling-methods","title":"Probability Sampling Methods","text":"<p>To avoid bias, statisticians use probability sampling methods, where every member of the population has a known, non-zero chance of being selected. Let's explore the four main types.</p>"},{"location":"chapters/11-sampling-and-bias/#simple-random-sample-srs","title":"Simple Random Sample (SRS)","text":"<p>A simple random sample gives every possible sample of size \\( n \\) an equal chance of being selected. Equivalently, every individual has an equal probability of being chosen.</p> <p>How it works:</p> <ol> <li>List all members of the population (create a sampling frame)</li> <li>Assign each member a unique number</li> <li>Use a random process to select \\( n \\) numbers</li> <li>Include those individuals in your sample</li> </ol> <p>The random selection process is crucial. You can use:</p> <ul> <li>Random Number Generator: A computer algorithm that produces unpredictable numbers. Most calculators and spreadsheets have built-in RNG functions.</li> <li>Random Digit Table: A printed table of random digits (0-9) arranged in groups. You read through the table to select numbers that correspond to individuals in your population.</li> </ul> <p>Example using a Random Digit Table:</p> <p>Suppose you have 50 students numbered 01-50, and you want to select 5 for your sample. Starting at a random position in the table, you read two-digit numbers:</p> Digits Read Action 29 Select student 29 07 Select student 07 53 Skip (out of range) 98 Skip (out of range) 41 Select student 41 12 Select student 12 29 Skip (already selected) 33 Select student 33 <p>Your sample: Students 07, 12, 29, 33, 41</p> Show/Hide <p>Advantages of SRS:</p> <ul> <li>Simple to understand and implement</li> <li>Eliminates selection bias</li> <li>Statistical theory is well-developed</li> </ul> <p>Disadvantages of SRS:</p> <ul> <li>Requires a complete list of the population</li> <li>May miss important subgroups by chance</li> <li>Can be expensive for geographically spread populations</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#diagram-random-digit-table-simulator","title":"Diagram: Random Digit Table Simulator","text":"<p>Create an interactive MicroSim demonstrating how to use a random digit table for sampling.</p> <p>Learning Objective: Students will practice using a random digit table to select a simple random sample.</p> <p>Inputs:</p> <ul> <li>Population size input (1-999)</li> <li>Sample size input (1-50)</li> <li>Starting row and column position in the table</li> <li>\"Generate New Table\" button</li> <li>\"Step Through Selection\" button</li> </ul> <p>Outputs:</p> <ul> <li>Displayed random digit table (10 rows x 20 digits)</li> <li>Highlighted digits as user steps through</li> <li>Running list of selected sample members</li> <li>Explanation of why each number was accepted/rejected</li> </ul> <p>Behavior:</p> <ul> <li>Determines how many digits to read based on population size</li> <li>Highlights current position in table</li> <li>Shows skip reasons (out of range, already selected)</li> <li>Counts until sample is complete</li> </ul> <p>Size: 700 x 500 pixels</p>"},{"location":"chapters/11-sampling-and-bias/#stratified-random-sample","title":"Stratified Random Sample","text":"<p>A stratified random sample divides the population into non-overlapping groups called strata (singular: stratum), then takes a simple random sample from each stratum.</p> <p>When to Stratify:</p> <ul> <li>When the population contains distinct subgroups that may differ in the characteristic you're measuring</li> <li>When you want to ensure representation of small subgroups</li> <li>When you want to compare subgroups</li> <li>When you have prior knowledge about variability within strata</li> </ul> <p>Example: Surveying student opinions about the new cafeteria menu.</p> Stratum Population Size Sample Size Freshmen 400 40 Sophomores 350 35 Juniors 300 30 Seniors 250 25 Total 1,300 130 <p>By stratifying, you guarantee that all grade levels are represented proportionally\u2014something an SRS might miss by chance.</p> <p>\"Acorn for your thoughts?\" Sylvia muses. \"If I wanted to estimate acorn production across different tree species in my forest, I wouldn't just randomly sample trees. I'd make sure to include oaks, maples, and pines separately. That's stratifying!\"</p> <p>Why stratification works: The key insight is that variability within strata is usually less than variability across the whole population. By sampling each stratum separately, you reduce overall sampling error.</p>"},{"location":"chapters/11-sampling-and-bias/#cluster-sample","title":"Cluster Sample","text":"<p>A cluster sample divides the population into groups called clusters, randomly selects some clusters, and then surveys everyone (or a random sample) within the selected clusters.</p> <p>Key difference from stratified sampling:</p> Stratified Cluster Use ALL strata Use SOME clusters Sample FROM each stratum Sample everyone IN selected clusters Strata should be internally homogeneous Clusters should be internally heterogeneous Goal: Reduce variability Goal: Reduce cost <p>Example: To survey U.S. high school students, you might:</p> <ol> <li>Randomly select 100 high schools from the list of all U.S. high schools</li> <li>Survey all students at those 100 schools</li> </ol> <p>This is much cheaper than creating a list of all U.S. high school students and sampling from it directly.</p> Show/Hide <p>When to use cluster sampling:</p> <ul> <li>When a complete list of individuals is unavailable, but a list of clusters exists</li> <li>When clusters are geographically convenient</li> <li>When the cost of sampling is high</li> </ul> <p>Drawback: If clusters are internally similar to each other (low within-cluster variability), cluster sampling can be less precise than SRS.</p>"},{"location":"chapters/11-sampling-and-bias/#diagram-stratified-vs-cluster-sampling-comparison","title":"Diagram: Stratified vs. Cluster Sampling Comparison","text":"<p>Create an interactive MicroSim comparing stratified and cluster sampling visually.</p> <p>Learning Objective: Students will distinguish between stratified and cluster sampling approaches.</p> <p>Inputs:</p> <ul> <li>Toggle between \"Stratified\" and \"Cluster\" sampling mode</li> <li>Population displayed as a grid of colored dots (colors represent strata/clusters)</li> <li>\"Select Sample\" button</li> </ul> <p>Outputs:</p> <ul> <li>Visual highlighting of selected individuals</li> <li>Count of individuals selected from each group</li> <li>Text explanation of the sampling process used</li> </ul> <p>Behavior:</p> <ul> <li>Stratified mode: Shows population divided into horizontal strata; randomly selects from EACH stratum</li> <li>Cluster mode: Shows population divided into vertical clusters; selects entire clusters randomly</li> <li>Clear visual distinction between the two approaches</li> </ul> <p>Size: 650 x 500 pixels</p>"},{"location":"chapters/11-sampling-and-bias/#systematic-sample","title":"Systematic Sample","text":"<p>A systematic sample selects individuals at regular intervals from an ordered list. You randomly select a starting point, then pick every \\( k \\)th individual.</p> <p>How it works:</p> <ol> <li>Order the population (the order shouldn't be related to what you're measuring)</li> <li>Calculate \\( k = \\frac{\\text{Population size}}{\\text{Sample size}} \\)</li> <li>Randomly select a starting point between 1 and \\( k \\)</li> <li>Select every \\( k \\)th individual after that</li> </ol> <p>Example: To select 50 students from 1,000:</p> <ul> <li>\\( k = 1000/50 = 20 \\)</li> <li>Random start: 7</li> <li>Sample: Students 7, 27, 47, 67, 87, ... , 987</li> </ul> <p>Advantages: Easy to implement, spreads sample evenly across the population.</p> <p>Caution: If the list has a periodic pattern that matches your sampling interval, systematic sampling can introduce bias. For example, if every 10th house on a street is a corner house, and \\( k = 10 \\), your sample would include only corner houses.</p>"},{"location":"chapters/11-sampling-and-bias/#non-probability-sampling-methods-and-why-theyre-problematic","title":"Non-Probability Sampling Methods (and Why They're Problematic)","text":"<p>Not all sampling methods involve random selection. While sometimes convenient, these methods often produce biased results.</p>"},{"location":"chapters/11-sampling-and-bias/#convenience-sample","title":"Convenience Sample","text":"<p>A convenience sample selects individuals who are easiest to reach. The researcher simply gathers data from whoever is available.</p> <p>Examples:</p> <ul> <li>Surveying friends about their music preferences</li> <li>Interviewing people at a mall on a Tuesday afternoon</li> <li>Asking your Instagram followers for opinions</li> </ul> <p>\"Don't worry\u2014every statistician drops an acorn sometimes,\" Sylvia admits, \"and I'll confess: when I was young, I used to estimate forest conditions based only on trees near my nest. Major convenience sample mistake! Turns out, my neighborhood wasn't representative at all.\"</p> <p>Why it's biased: The people who are easy to reach often differ systematically from the population. Mall shoppers on weekday afternoons might be retirees or shift workers\u2014not representative of all consumers.</p>"},{"location":"chapters/11-sampling-and-bias/#voluntary-response-sample","title":"Voluntary Response Sample","text":"<p>A voluntary response sample allows individuals to self-select into the sample. The researcher puts out a request, and people who feel strongly about the topic choose to respond.</p> <p>Examples:</p> <ul> <li>Online polls (\"Click here to vote!\")</li> <li>Call-in radio shows</li> <li>Product reviews</li> <li>Letters to the editor</li> </ul> <p>Why it's biased: People with extreme opinions (very positive or very negative) are more likely to respond. The results typically overrepresent strong feelings and underrepresent moderate views.</p> Sampling Method Random? Equal Probability? Likely Biased? Simple Random Sample Yes Yes No Stratified Random Sample Yes Can vary by stratum No Cluster Sample Yes Depends on cluster selection No Systematic Sample Partially Approximately Usually no Convenience Sample No No Yes Voluntary Response Sample No No Yes"},{"location":"chapters/11-sampling-and-bias/#sources-of-bias","title":"Sources of Bias","text":"<p>Even with good sampling methods, bias can sneak in through other doors. Let's examine the main sources.</p>"},{"location":"chapters/11-sampling-and-bias/#undercoverage","title":"Undercoverage","text":"<p>Undercoverage occurs when some members of the population are less likely to be included in the sample than others\u2014or are excluded entirely from the sampling frame.</p> <p>Examples:</p> <ul> <li>Phone surveys miss people without phones</li> <li>Online surveys miss people without internet access</li> <li>Household surveys miss homeless individuals</li> <li>School surveys miss students who are absent frequently</li> </ul> <p>Historical example: The 1936 Literary Digest poll predicted Alf Landon would defeat Franklin Roosevelt in a landslide. They surveyed people from phone directories and automobile registrations\u2014but during the Great Depression, many Roosevelt supporters couldn't afford phones or cars. The poll suffered from severe undercoverage of lower-income voters.</p> Show/Hide"},{"location":"chapters/11-sampling-and-bias/#diagram-undercoverage-visualization","title":"Diagram: Undercoverage Visualization","text":"<p>Create an interactive MicroSim demonstrating how undercoverage affects sample estimates.</p> <p>Learning Objective: Students will understand how incomplete sampling frames lead to biased estimates.</p> <p>Inputs:</p> <ul> <li>Population with two groups: \"covered\" and \"undercovered\"</li> <li>Slider: percentage of population undercovered (0-50%)</li> <li>Slider: difference in response between covered/undercovered groups</li> <li>\"Take Sample\" button</li> </ul> <p>Outputs:</p> <ul> <li>Visual representation of population and sample</li> <li>True population proportion</li> <li>Sample estimate</li> <li>Bias = (sample estimate) - (true proportion)</li> <li>Explanation of how undercoverage affected the result</li> </ul> <p>Behavior:</p> <ul> <li>Shows grayed-out undercovered individuals who cannot be sampled</li> <li>Sample taken only from covered portion</li> <li>Demonstrates how different values in the undercovered group lead to biased estimates</li> </ul> <p>Size: 600 x 450 pixels</p>"},{"location":"chapters/11-sampling-and-bias/#nonresponse-bias","title":"Nonresponse Bias","text":"<p>Nonresponse bias occurs when individuals selected for the sample do not respond, and those who don't respond differ systematically from those who do.</p> <p>Key insight: It's not the nonresponse itself that causes bias\u2014it's whether nonresponders differ from responders on the variable being measured.</p> <p>Examples:</p> <ul> <li>Wealthy people may be less likely to respond to income surveys (underestimating average income... or overestimating, depending on the context!)</li> <li>Busy parents may skip lengthy surveys about parenting practices</li> <li>People with negative experiences may be more likely to complete complaint surveys</li> </ul> <p>Response rates matter: A survey with a 10% response rate is more susceptible to nonresponse bias than one with an 80% response rate\u2014though even high response rates don't guarantee the absence of bias.</p>"},{"location":"chapters/11-sampling-and-bias/#response-bias","title":"Response Bias","text":"<p>Response bias occurs when responses are systematically inaccurate. The problem isn't who's answering; it's that the answers themselves are distorted.</p> <p>Causes of response bias:</p> Type Description Example Social desirability People give answers they think are more acceptable Overreporting exercise, underreporting alcohol consumption Interviewer effect Responses influenced by who's asking People may respond differently to interviewers of different demographics Recall issues Memory failures or distortions \"How many times did you eat vegetables last month?\" Prestige bias Exaggerating positive attributes Overreporting income or education level"},{"location":"chapters/11-sampling-and-bias/#wording-of-questions","title":"Wording of Questions","text":"<p>The wording of questions can dramatically influence responses. Even small changes in phrasing can shift results significantly.</p> <p>Problematic question types:</p> <ol> <li>Leading questions: Suggest a particular answer</li> <li>Bad: \"Don't you agree that the new policy is beneficial?\"</li> <li> <p>Better: \"What is your opinion of the new policy?\"</p> </li> <li> <p>Loaded questions: Contain emotionally charged words</p> </li> <li>Bad: \"Should taxpayers be forced to fund this wasteful program?\"</li> <li> <p>Better: \"Should government funding continue for this program?\"</p> </li> <li> <p>Double-barreled questions: Ask two things at once</p> </li> <li>Bad: \"Do you support increasing teacher salaries and reducing class sizes?\"</li> <li> <p>Better: Ask these as two separate questions</p> </li> <li> <p>Confusing questions: Use jargon or complex phrasing</p> </li> <li>Bad: \"To what extent do you concur with the proposition that pedagogical methodologies should be reformed?\"</li> <li>Better: \"Should teaching methods be changed?\"</li> </ol> <p>\"Let's crack this nut with an example,\" Sylvia offers. \"Watch how question wording changes responses about the same issue:\"</p> Question Version Likely Response Pattern \"Should the government prohibit hate speech?\" Higher support \"Should the government restrict free speech?\" Lower support \"Should the government regulate harmful rhetoric online?\" Moderate support <p>All three ask about limits on speech, but the framing dramatically affects answers.</p> Show/Hide"},{"location":"chapters/11-sampling-and-bias/#diagram-question-wording-effects-simulator","title":"Diagram: Question Wording Effects Simulator","text":"<p>Create an interactive MicroSim demonstrating how question wording affects survey responses.</p> <p>Learning Objective: Students will recognize how subtle changes in question wording can produce different response patterns.</p> <p>Inputs:</p> <ul> <li>Topic selector (e.g., environmental policy, school rules, technology use)</li> <li>Three versions of a question on the same topic with different wording (neutral, positively framed, negatively framed)</li> <li>Radio button to select which version to \"send\"</li> </ul> <p>Outputs:</p> <ul> <li>Simulated response distribution for each question version</li> <li>Bar chart comparing support levels across different wordings</li> <li>Highlighted words that create the framing effect</li> </ul> <p>Behavior:</p> <ul> <li>Shows how the same underlying topic yields different apparent \"public opinion\" based on wording</li> <li>Identifies specific word choices that trigger bias</li> <li>Explains the psychological mechanism behind each bias</li> </ul> <p>Size: 650 x 500 pixels</p>"},{"location":"chapters/11-sampling-and-bias/#designing-surveys-putting-it-all-together","title":"Designing Surveys: Putting It All Together","text":"<p>Good survey design requires attention to every stage of the process. Here's a checklist for designing valid surveys:</p>"},{"location":"chapters/11-sampling-and-bias/#1-define-your-target-population-clearly","title":"1. Define Your Target Population Clearly","text":"<ul> <li>Who exactly do you want to learn about?</li> <li>Be specific: \"U.S. adults aged 18-65\" vs. \"people\"</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#2-develop-a-complete-sampling-frame","title":"2. Develop a Complete Sampling Frame","text":"<ul> <li>List all members of your target population</li> <li>Identify and address potential gaps that could cause undercoverage</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#3-choose-an-appropriate-sampling-method","title":"3. Choose an Appropriate Sampling Method","text":"<ul> <li>For most situations, probability sampling (SRS, stratified, cluster, or systematic) is essential</li> <li>Match the method to your resources and population structure</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#4-minimize-nonresponse","title":"4. Minimize Nonresponse","text":"<p>Strategies include:</p> <ul> <li>Keep surveys short and engaging</li> <li>Offer incentives (with caution\u2014they can introduce other biases)</li> <li>Use multiple contact attempts</li> <li>Make participation easy (online options, flexible times)</li> <li>Explain the importance of the research</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#5-write-clear-unbiased-questions","title":"5. Write Clear, Unbiased Questions","text":"<p>Question design checklist:</p> <ul> <li>[ ] Is the question clear and unambiguous?</li> <li>[ ] Does it avoid leading language?</li> <li>[ ] Does it ask about only one thing?</li> <li>[ ] Are response options exhaustive and mutually exclusive?</li> <li>[ ] Is the question free of jargon?</li> <li>[ ] Have you tested the question with a pilot group?</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#6-order-questions-thoughtfully","title":"6. Order Questions Thoughtfully","text":"<ul> <li>Start with easy, non-threatening questions</li> <li>Group related questions together</li> <li>Place sensitive questions later (after rapport is established)</li> <li>Consider how earlier questions might influence later answers</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#7-pilot-test-your-survey","title":"7. Pilot Test Your Survey","text":"<p>Before full deployment:</p> <ul> <li>Test with a small group similar to your target population</li> <li>Identify confusing questions</li> <li>Check how long the survey takes</li> <li>Revise based on feedback</li> </ul> Show/Hide <p>\"Time to squirrel away this knowledge!\" Sylvia summarizes. \"Good surveys don't just happen\u2014they're carefully designed. Every choice you make, from who you sample to how you phrase questions, affects the quality of your data.\"</p>"},{"location":"chapters/11-sampling-and-bias/#diagram-survey-design-checklist-interactive","title":"Diagram: Survey Design Checklist Interactive","text":"<p>Create an interactive MicroSim that walks students through evaluating survey quality.</p> <p>Learning Objective: Students will apply survey design principles to evaluate and improve sample surveys.</p> <p>Inputs:</p> <ul> <li>Display a sample survey scenario with potential problems</li> <li>Checklist of survey quality criteria</li> <li>Text field for student suggestions</li> </ul> <p>Outputs:</p> <ul> <li>Highlighted problems in the survey</li> <li>Score based on criteria met</li> <li>Suggested improvements</li> <li>\"Before and After\" comparison when fixes are applied</li> </ul> <p>Behavior:</p> <ul> <li>Present 3-4 different survey scenarios with various flaws</li> <li>Allow students to identify problems using the checklist</li> <li>Show improved version when student correctly identifies issues</li> <li>Track which types of problems are hardest to spot</li> </ul> <p>Size: 700 x 550 pixels</p>"},{"location":"chapters/11-sampling-and-bias/#common-scenarios-identifying-sampling-issues","title":"Common Scenarios: Identifying Sampling Issues","text":"<p>Let's practice identifying bias in real-world scenarios:</p> <p>Scenario 1: A magazine wants to know readers' opinions about its new format. They include a survey card in the magazine asking readers to mail it back.</p> <ul> <li>Problem: Voluntary response bias. Only readers with strong opinions (love it or hate it) will bother returning the card.</li> </ul> <p>Scenario 2: A researcher studies teen social media use by surveying students at an elite private school.</p> <ul> <li>Problem: Convenience sample and undercoverage. Students at this school may not represent all teens.</li> </ul> <p>Scenario 3: A political poll asks, \"Do you support the reckless spending bill proposed by Senator Smith?\"</p> <ul> <li>Problem: Leading/loaded question. \"Reckless\" biases respondents toward a negative answer.</li> </ul> <p>Scenario 4: A health survey administered only in English in a multilingual community.</p> <ul> <li>Problem: Undercoverage of non-English speakers.</li> </ul> <p>Scenario 5: A phone survey conducted only on landlines.</p> <ul> <li>Problem: Undercoverage of people who only have cell phones (often younger adults).</li> </ul>"},{"location":"chapters/11-sampling-and-bias/#key-takeaways","title":"Key Takeaways","text":"<p>Let's squirrel away the essential concepts from this chapter:</p> <ol> <li> <p>Sampling vs. Census: A sample examines a subset of the population; a census examines everyone. Samples are usually more practical but must be carefully designed.</p> </li> <li> <p>Bias: Systematic error that causes sample statistics to consistently miss the population parameter in one direction. Unlike random variability, bias doesn't average out with larger samples.</p> </li> <li> <p>Probability Sampling Methods:</p> </li> <li>Simple Random Sample (SRS): Every possible sample of size n has equal probability</li> <li>Stratified: Divide into strata, SRS from each</li> <li>Cluster: Randomly select clusters, sample everyone in chosen clusters</li> <li> <p>Systematic: Select every kth individual from a random start</p> </li> <li> <p>Non-Probability Methods (avoid when possible):</p> </li> <li>Convenience: Select whoever is easy to reach</li> <li> <p>Voluntary Response: Let people self-select</p> </li> <li> <p>Sources of Bias:</p> </li> <li>Undercoverage: Sampling frame misses part of the population</li> <li>Nonresponse: Selected individuals don't respond (and differ from responders)</li> <li> <p>Response Bias: Answers are systematically inaccurate</p> </li> <li> <p>Question Wording: Avoid leading, loaded, double-barreled, and confusing questions.</p> </li> <li> <p>Survey Design: Requires careful attention to population definition, sampling frame, sampling method, question design, and pilot testing.</p> </li> <li> <p>Unbiased vs. Biased Estimators: An unbiased estimator centers on the true parameter value across many samples; a biased estimator systematically misses.</p> </li> </ol> <p>\"And that, my friends, is how you collect data that's actually worth analyzing!\" Sylvia beams. \"Remember: garbage in, garbage out. But good data in? That's where the statistical magic happens!\"</p>"},{"location":"chapters/11-sampling-and-bias/#practice-problems","title":"Practice Problems","text":"<p>Test your understanding with these problems:</p> <p>Problem 1: A university wants to survey student satisfaction. They email a survey to all 25,000 students and receive 2,500 responses.</p> <p>a) What type of sampling method is this? b) What type of bias is most likely to affect the results? c) Suggest an improvement to the study design.</p> Show Solution <p>a) Voluntary response sample \u2014 students choose whether to respond.</p> <p>b) Nonresponse bias is most likely. Only 10% responded, and those who felt strongly (positively or negatively) about their experience are more likely to complete the survey. Voluntary response bias is also present since students self-selected.</p> <p>c) Improvement: Select a simple random sample of 500 students and use multiple follow-up contacts to maximize response rate. Consider offering an incentive for completion.</p> <p>Problem 2: To estimate the average number of hours students spend on homework, a researcher stands outside the library and surveys students as they exit.</p> <p>a) Identify the sampling method. b) Explain why this sample is likely biased. c) What direction would you expect the bias to be?</p> Show Solution <p>a) Convenience sample \u2014 surveying whoever is easy to reach.</p> <p>b) Students at the library are likely to be those who spend more time on homework than the typical student. Students who rarely use the library for studying are systematically excluded.</p> <p>c) The bias is likely upward \u2014 the sample will probably overestimate the average homework hours because library users tend to be more studious.</p> <p>Problem 3: A polling organization wants to estimate support for a new city park. They divide the city into 50 neighborhoods, randomly select 5 neighborhoods, and survey every household in those neighborhoods.</p> <p>a) What sampling method is this? b) Under what conditions might this method produce a biased estimate?</p> Show Solution <p>a) Cluster sample \u2014 randomly selecting some clusters (neighborhoods) and surveying everyone within them.</p> <p>b) This method could produce biased estimates if: - The selected neighborhoods are systematically different from the city as a whole - Neighborhoods are internally similar but different from each other (e.g., wealthy neighborhoods vs. lower-income neighborhoods might have different views on how to spend city resources) - Five neighborhoods may be too few to adequately represent the city's diversity</p> <p>Problem 4: Classify each question as leading, loaded, double-barreled, or well-designed:</p> <p>a) \"Do you agree that the brilliant new superintendent has improved schools?\" b) \"How satisfied are you with school lunches and after-school programs?\" c) \"On a scale of 1-5, how would you rate the quality of your education?\" d) \"Should wasteful government programs be eliminated?\"</p> Show Solution <p>a) Leading \u2014 \"brilliant\" suggests how the respondent should answer</p> <p>b) Double-barreled \u2014 asks about two different things (lunches AND after-school programs)</p> <p>c) Well-designed \u2014 neutral wording, clear scale, asks about one thing</p> <p>d) Loaded \u2014 \"wasteful\" is emotionally charged and assumes the programs are wasteful</p> <p>Problem 5: A random digit table shows these digits: 15028 39247 10583 72641</p> <p>Use this table to select a simple random sample of 3 students from a class of 30 students (numbered 01-30). Start at the beginning and read two-digit numbers from left to right.</p> Show Solution <p>Reading two-digit numbers from left to right: - 15: Select student 15 - 02: Select student 02 - 83: Skip (greater than 30) - 92: Skip (greater than 30) - 47: Skip (greater than 30) - 10: Select student 10</p> <p>Sample: Students 02, 10, and 15</p> <p>Problem 6: A researcher wants to compare the study habits of athletes and non-athletes at a school of 800 students (200 athletes, 600 non-athletes). She wants a sample of 80 students.</p> <p>a) If she uses a simple random sample, what might go wrong? b) Suggest a better sampling approach and explain why it's superior. c) How many students should she select from each group?</p> Show Solution <p>a) With SRS, she might get very few athletes by chance. With only 200/800 = 25% athletes in the population, a random sample might have anywhere from 10-30 athletes, making athlete/non-athlete comparisons difficult.</p> <p>b) Stratified random sample \u2014 divide into athletes and non-athletes, then SRS from each stratum. This guarantees sufficient representation of both groups and allows for meaningful comparisons.</p> <p>c) Proportional allocation: 25% athletes, 75% non-athletes - Athletes: \\( 80 \\times 0.25 = 20 \\) students - Non-athletes: \\( 80 \\times 0.75 = 60 \\) students</p> <p>(Alternatively, she might oversample athletes if comparison is the primary goal, selecting 40 from each group.)</p> <p>Problem 7: A survey asks: \"How many times per week do you exercise for at least 30 minutes?\"</p> <p>Identify two types of response bias that might affect answers to this question.</p> Show Solution <ol> <li> <p>Social desirability bias: Respondents may overreport exercise because physical fitness is viewed positively. They might exaggerate to appear healthier than they are.</p> </li> <li> <p>Recall bias: Respondents may not accurately remember their exercise frequency, especially for activities that weren't scheduled or recorded. They might include activities that didn't actually reach 30 minutes or forget workouts from earlier in the week.</p> </li> </ol> <p>\"Now THAT'S a data point worth collecting!\" Sylvia cheers. \"You've learned how to gather data that actually means something. The foundation is set\u2014now you're ready to build some serious statistical knowledge on top of it!\"</p>"},{"location":"chapters/11-sampling-and-bias/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 19 concepts from the learning graph:</p> <ol> <li>Bias</li> <li>Sources of Bias</li> <li>Census</li> <li>Simple Random Sample</li> <li>Random Number Generator</li> <li>Stratified Random Sample</li> <li>When to Stratify</li> <li>Cluster Sample</li> <li>Systematic Sample</li> <li>Convenience Sample</li> <li>Voluntary Response Sample</li> <li>Undercoverage</li> <li>Nonresponse Bias</li> <li>Response Bias</li> <li>Wording of Questions</li> <li>Designing Surveys</li> <li>Random Digit Table</li> <li>Unbiased Estimator</li> <li>Biased Estimator</li> </ol>"},{"location":"chapters/11-sampling-and-bias/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Statistics</li> <li>Chapter 8: Causation and Study Design</li> <li>Chapter 9: Probability Fundamentals</li> </ul>"},{"location":"chapters/12-experimental-design/","title":"Experimental Design","text":""},{"location":"chapters/12-experimental-design/#summary","title":"Summary","text":"<p>This chapter covers the principles of designing experiments to establish causal relationships. Students will learn about experimental units, treatments, factors, and levels. Key principles include control, randomization, replication, and blinding. Understanding good experimental design enables students to critically evaluate scientific claims.</p>"},{"location":"chapters/12-experimental-design/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 19 concepts from the learning graph:</p> <ol> <li>Experimental Units</li> <li>Subjects</li> <li>Treatment</li> <li>Factor</li> <li>Levels of a Factor</li> <li>Placebo</li> <li>Placebo Effect</li> <li>Control Group</li> <li>Comparison in Experiments</li> <li>Blinding</li> <li>Single-Blind Experiment</li> <li>Double-Blind Experiment</li> <li>Random Assignment</li> <li>Why Randomize</li> <li>Randomized Block Design</li> <li>Matched Pairs Design</li> <li>Completely Randomized Design</li> <li>Replication</li> </ol>"},{"location":"chapters/12-experimental-design/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 8: Causation and Study Design</li> <li>Chapter 11: Sampling and Bias</li> </ul>"},{"location":"chapters/12-experimental-design/#introduction-from-observation-to-experimentation","title":"Introduction: From Observation to Experimentation","text":"<p>Welcome back! In earlier chapters, you learned the difference between observational studies and experiments. You discovered that while observational studies can reveal fascinating associations in data, they can't tell us that one thing causes another. That's where experiments come in.</p> <p>\"Alright, here's where things get really exciting,\" Sylvia says, adjusting her glasses. \"Experiments are how we actually prove cause and effect. It's like being a detective, but with data instead of magnifying glasses. Well, okay, sometimes we use magnifying glasses too.\"</p> <p>Think about it this way: if you notice that students who eat breakfast tend to get better grades, you might wonder whether eating breakfast causes better academic performance. But wait, maybe students who eat breakfast also come from families that emphasize education, or maybe they go to bed earlier, or maybe they're just morning people. These are all confounding variables that could explain the relationship without breakfast being the actual cause.</p> <p>The only way to truly establish that breakfast causes better grades is to run an experiment. And in this chapter, you're going to learn exactly how to do that.</p>"},{"location":"chapters/12-experimental-design/#the-language-of-experiments","title":"The Language of Experiments","text":"<p>Before we dive into experimental design, we need to establish some vocabulary. Every field has its own special terms, and experimental design is no exception. Don't worry though; these terms are pretty intuitive once you see them in action.</p>"},{"location":"chapters/12-experimental-design/#experimental-units-and-subjects","title":"Experimental Units and Subjects","text":"<p>An experimental unit is the smallest entity to which a treatment is applied. Think of it as the \"thing\" you're experimenting on. When we're studying people, we typically call experimental units subjects or participants. But experimental units don't have to be people.</p> <p>Here are some examples of experimental units:</p> Study Focus Experimental Unit Drug effectiveness Individual patients Fertilizer impact Plots of land Teaching method Classroom sections Battery life Individual batteries Website design Website visitors <p>\"I once ran an experiment on acorn storage methods,\" Sylvia notes. \"Each storage container was an experimental unit. Not a single acorn was harmed in the making of that study. Well, maybe one got eaten during a data collection break.\"</p>"},{"location":"chapters/12-experimental-design/#treatments-factors-and-levels","title":"Treatments, Factors, and Levels","text":"<p>A treatment is the specific experimental condition applied to an experimental unit. It's what we're testing. But here's where it gets interesting: treatments are made up of factors and levels.</p> <p>A factor is an explanatory variable whose effect on the response we want to study. The specific values or categories of a factor are called levels. When you combine different levels of different factors, you create treatments.</p> <p>Let's make this concrete with an example. Suppose you're studying how different study techniques and study durations affect test performance.</p> <ul> <li>Factor 1: Study technique (levels: flashcards, practice problems, reading notes)</li> <li>Factor 2: Study duration (levels: 30 minutes, 60 minutes)</li> </ul> <p>Each combination of levels creates a different treatment:</p> Treatment Study Technique Duration 1 Flashcards 30 min 2 Flashcards 60 min 3 Practice problems 30 min 4 Practice problems 60 min 5 Reading notes 30 min 6 Reading notes 60 min <p>That's 3 levels times 2 levels = 6 treatments total!</p>"},{"location":"chapters/12-experimental-design/#diagram-factors-and-levels-tree","title":"Diagram: Factors and Levels Tree","text":"Factors and Levels Tree Diagram <p>Type: diagram</p> <p>Purpose: Visualize how factors and levels combine to create treatments in a 2-factor experiment</p> <p>Bloom Level: Understand (L2) Bloom Verb: classify, explain</p> <p>Learning Objective: Students will be able to explain how factors and levels combine to create distinct treatments in a multi-factor experiment.</p> <p>Components to show: - Root node: \"Experiment: Study Methods\" - First branch level: Factor 1 (Study Technique) with 3 levels as child nodes - Second branch level: Factor 2 (Duration) with 2 levels branching from each technique - Leaf nodes: The 6 resulting treatments, each showing the combination</p> <p>Visual Layout: - Hierarchical tree structure flowing left to right or top to bottom - Factor labels on connecting lines - Level labels in oval nodes - Treatment boxes at the bottom with treatment number and description</p> <p>Interactive features: - Hover over any treatment box to highlight the path (factors and levels) that created it - Click a treatment to see a description of what that experimental condition involves</p> <p>Color scheme: - Root node: Sylvia green (#2E7D32) - Factor 1 nodes: Light blue - Factor 2 nodes: Light orange - Treatment boxes: Sylvia auburn (#B5651D)</p> <p>Implementation: p5.js with interactive hover states Canvas size: Responsive, approximately 700x400px</p>"},{"location":"chapters/12-experimental-design/#the-placebo-effect-why-we-need-controls","title":"The Placebo Effect: Why We Need Controls","text":"<p>Here's a fascinating quirk of human psychology: sometimes people get better just because they believe they're receiving treatment, even when they're not receiving anything at all. This is called the placebo effect.</p> <p>A placebo is an inactive treatment that looks exactly like the real treatment. In drug studies, it might be a sugar pill that looks identical to the medication being tested. In other contexts, it might be a fake procedure or a dummy intervention.</p> <p>\"The placebo effect is wild,\" Sylvia admits. \"Imagine if I told you this acorn was a magic energy acorn and you actually felt more energetic. Your brain is incredibly powerful, for better or worse.\"</p> <p>The placebo effect is so powerful that it can produce real, measurable changes in people. Studies have shown that placebo treatments can reduce pain, improve mood, and even affect blood pressure. This is why simply giving people a treatment and watching them improve doesn't prove the treatment works; they might have improved just because they expected to.</p>"},{"location":"chapters/12-experimental-design/#control-groups-the-foundation-of-comparison","title":"Control Groups: The Foundation of Comparison","text":"<p>This is why experiments need a control group. A control group is a group of experimental units that either receives no treatment, a placebo, or the standard existing treatment. The control group provides a baseline for comparison in experiments.</p> <p>Without a control group, you can't tell whether:</p> <ul> <li>The treatment actually caused the improvement</li> <li>The improvement was due to the placebo effect</li> <li>The improvement would have happened naturally over time</li> <li>Some other factor caused the change</li> </ul> <p>Consider this example: A company claims their new energy drink improves athletic performance because runners who drank it ran faster than before. But wait! Did they run faster because of the drink, or because:</p> <ul> <li>They had been training and were getting better anyway?</li> <li>They were more motivated because they thought the drink would help?</li> <li>Weather conditions were better on the second test day?</li> </ul> <p>A proper experiment would randomly assign runners to either receive the energy drink (treatment group) or a similar-looking drink without the active ingredients (control group). Then we could compare the two groups fairly.</p>"},{"location":"chapters/12-experimental-design/#diagram-treatment-vs-control-comparison","title":"Diagram: Treatment vs Control Comparison","text":"Treatment vs Control Group Comparison <p>Type: microsim</p> <p>Purpose: Demonstrate why control groups are necessary by showing the difference between comparing before/after within a group versus comparing treatment to control</p> <p>Bloom Level: Understand (L2) Bloom Verb: explain, compare</p> <p>Learning Objective: Students will be able to explain why comparing treatment and control groups is more reliable than comparing before and after measurements within a single group.</p> <p>Data Visibility Requirements:   Stage 1: Show a single group's before scores (e.g., test scores around 70)   Stage 2: Show the same group's after scores (improved to around 78)   Stage 3: Reveal a parallel control group that also improved (from 70 to 76)   Stage 4: Show the true treatment effect is only 2 points (78-76), not 8 points</p> <p>Visual Elements: - Two parallel timelines (Treatment Group and Control Group) - Bar charts showing scores at each time point - Animated reveal of control group results - Calculation showing: True Effect = Treatment Improvement - Control Improvement</p> <p>Interactive Controls: - Button: \"Step Through\" to progress through stages - Button: \"Reset\" to start over - Toggle: \"Show/Hide Confounds\" to reveal factors like natural improvement, practice effects</p> <p>Instructional Rationale: Step-through with concrete data is appropriate because the Understand/explain objective requires learners to trace the logic of why control groups matter. Showing the reveal progressively helps students experience the \"aha\" moment.</p> <p>Implementation: p5.js with step-through controls Canvas size: Responsive, approximately 650x350px</p>"},{"location":"chapters/12-experimental-design/#the-three-principles-of-good-experimental-design","title":"The Three Principles of Good Experimental Design","text":"<p>Now we arrive at the heart of experimental design. There are three fundamental principles that make experiments valid and trustworthy: control, randomization, and replication. Think of them as the three legs of a stool; remove any one, and your experiment falls over.</p>"},{"location":"chapters/12-experimental-design/#principle-1-control","title":"Principle 1: Control","text":"<p>Control means holding constant any extraneous variables that might affect the response. When we control for variables, we eliminate them as possible explanations for any differences we observe between treatment groups.</p> <p>For example, if you're testing whether a new teaching method improves math scores:</p> <ul> <li>Give both groups the same amount of instruction time</li> <li>Use the same classroom and testing conditions</li> <li>Administer tests at the same time of day</li> <li>Use the same instructor (or carefully match instructors)</li> </ul> <p>The only thing that should differ between groups is the treatment itself.</p>"},{"location":"chapters/12-experimental-design/#principle-2-random-assignment","title":"Principle 2: Random Assignment","text":"<p>Random assignment means using a chance mechanism to decide which experimental units receive which treatment. This is different from random sampling (which we covered in Chapter 11). Random sampling determines who is in your study; random assignment determines what treatment each participant receives.</p> <p>\"Don't mix these up!\" Sylvia warns, her tail twitching. \"Random sampling helps you generalize to a population. Random assignment helps you establish causation. They're both important, but they do different jobs.\"</p> <p>Here's a quick comparison:</p> Concept Purpose Example Random Sampling Select representative participants Randomly choosing 200 students from all students in the district Random Assignment Distribute participants to treatment groups Randomly assigning those 200 students to treatment or control"},{"location":"chapters/12-experimental-design/#why-randomize","title":"Why Randomize?","text":"<p>So why randomize? Random assignment is powerful because it tends to balance out all variables across treatment groups, including ones you haven't even thought of! When you randomly assign, any differences between groups are due to chance rather than some systematic bias.</p> <p>Consider what could go wrong without random assignment. If you let students choose whether they want the new teaching method or the traditional one:</p> <ul> <li>More motivated students might choose the new method</li> <li>Students who struggle might avoid change</li> <li>Students with involved parents might be encouraged toward the \"better\" option</li> </ul> <p>Any of these factors could create systematic differences between groups that confound your results.</p> <p>Sylvia's Pro Tip</p> <p>Random assignment doesn't guarantee that groups are identical; it guarantees that any differences are due to chance. With large enough groups, these chance differences become very small. That's why replication (having many subjects) matters too!</p>"},{"location":"chapters/12-experimental-design/#principle-3-replication","title":"Principle 3: Replication","text":"<p>Replication means having enough experimental units in each treatment group to detect real effects and to reduce the impact of individual variation. One data point proves nothing. Even two or three might be coincidence. But when you see the same pattern across dozens or hundreds of experimental units, you can be confident it's real.</p> <p>Replication reduces the impact of individual variability. Imagine testing a new fertilizer on just one plant. If that plant grows better, was it the fertilizer, or was that particular plant just healthier to begin with? But if you test 50 plants with fertilizer and 50 without, and the fertilized plants consistently grow better, the pattern is much more convincing.</p> <p>The more experimental units you have, the more likely you are to detect a true treatment effect if one exists. We'll learn more about this concept, called statistical power, in later chapters on hypothesis testing.</p>"},{"location":"chapters/12-experimental-design/#diagram-three-principles-of-experimental-design","title":"Diagram: Three Principles of Experimental Design","text":"Three Principles of Experimental Design Interactive <p>Type: infographic</p> <p>Purpose: Create an interactive visualization showing how control, randomization, and replication work together in experimental design</p> <p>Bloom Level: Understand (L2) Bloom Verb: explain, summarize</p> <p>Learning Objective: Students will be able to summarize the three principles of good experimental design and explain the purpose of each.</p> <p>Visual Layout: - Three large circular or card-based sections arranged horizontally - Each section represents one principle: Control, Randomization, Replication - Center area shows a mini experimental setup that changes based on which principle is selected</p> <p>Content for each principle: 1. Control section:    - Icon: Lock or equal sign    - Definition: \"Hold variables constant\"    - Visual: Side-by-side groups with identical conditions except treatment    - Hover reveals: List of variables to control (time, location, instructions, etc.)</p> <ol> <li>Randomization section:</li> <li>Icon: Dice or shuffle symbol</li> <li>Definition: \"Use chance to assign treatments\"</li> <li>Visual: Animation of shuffling/random assignment</li> <li> <p>Hover reveals: \"Balances known AND unknown variables\"</p> </li> <li> <p>Replication section:</p> </li> <li>Icon: Multiple figures or stacked symbols</li> <li>Definition: \"Use enough experimental units\"</li> <li>Visual: Single unit vs. many units comparison</li> <li>Hover reveals: \"Reduces impact of individual variation\"</li> </ol> <p>Interactive Features: - Click each principle card to see it demonstrated in the central experiment visualization - Hover over elements for detailed explanations - Toggle showing \"What goes wrong without this principle?\"</p> <p>Color Scheme: - Control: Blue - Randomization: Sylvia green (#2E7D32) - Replication: Sylvia auburn (#B5651D) - Background: Sylvia cream (#FFF8E1)</p> <p>Implementation: HTML/CSS/JavaScript with SVG icons and p5.js for animations Canvas size: Responsive, approximately 800x450px</p>"},{"location":"chapters/12-experimental-design/#blinding-protecting-against-bias","title":"Blinding: Protecting Against Bias","text":"<p>Even with control groups and random assignment, experiments can be compromised by a subtle form of bias: the expectations of participants and researchers. This is where blinding comes in.</p>"},{"location":"chapters/12-experimental-design/#single-blind-experiments","title":"Single-Blind Experiments","text":"<p>In a single-blind experiment, the experimental units (subjects) don't know which treatment they're receiving, but the researchers do know. This prevents subjects from behaving differently based on their expectations.</p> <p>For example, in a drug trial, patients don't know whether they're taking the real medication or a placebo. They can't unconsciously (or consciously!) behave in ways that might affect the outcome based on knowing which group they're in.</p>"},{"location":"chapters/12-experimental-design/#double-blind-experiments","title":"Double-Blind Experiments","text":"<p>A double-blind experiment goes further: neither the subjects nor the researchers who interact with them know which treatment is being administered. This is even better because it prevents researchers from unconsciously treating participants differently or interpreting results based on their expectations.</p> <p>\"Think about it,\" Sylvia says. \"If a researcher knows a patient is getting the real drug, they might be more attentive, more encouraging, or more likely to notice positive changes. Even tiny differences in how researchers act can influence results!\"</p> <p>In a double-blind drug trial:</p> <ul> <li>Patients don't know if they have the real drug or placebo</li> <li>Doctors administering treatments and evaluating patients don't know either</li> <li>Only a separate group of researchers who don't interact with patients knows the assignment</li> </ul> <p>Here's a comparison of blinding approaches:</p> Type Who is \"blind\"? What it prevents No blinding No one Nothing (most prone to bias) Single-blind Subjects only Subject expectation effects Double-blind Subjects AND researchers Subject expectations AND researcher bias <p>When Blinding Isn't Possible</p> <p>Sometimes blinding is impossible due to the nature of the treatment. For example, you can't hide whether someone is exercising or not, or whether a classroom is using laptops or textbooks. In these cases, researchers should acknowledge this limitation and interpret results carefully.</p>"},{"location":"chapters/12-experimental-design/#diagram-blinding-comparison-flowchart","title":"Diagram: Blinding Comparison Flowchart","text":"Blinding Types Flowchart <p>Type: workflow</p> <p>Purpose: Show decision process for determining appropriate level of blinding and illustrate information flow in different blinding scenarios</p> <p>Bloom Level: Analyze (L4) Bloom Verb: differentiate, compare</p> <p>Learning Objective: Students will be able to differentiate between single-blind and double-blind experiments and identify which type of blinding is appropriate for different research scenarios.</p> <p>Visual Layout: Split view showing three parallel experimental setups - Left: No blinding (everyone knows everything) - Center: Single-blind (subjects don't know, researchers do) - Right: Double-blind (neither knows)</p> <p>Elements in each setup: - Subject figures (labeled) - Researcher figures (labeled) - Treatment assignment arrow (visible/hidden based on blinding) - \"Knowledge bubbles\" showing what each party knows - Bias risk indicators (high/medium/low)</p> <p>Interactive Features: - Hover over each setup to see advantages and disadvantages - Click \"Show Information Flow\" to animate what each party knows - Toggle examples for each scenario (drug trial, exercise study, therapy study)</p> <p>Color coding: - \"Knows assignment\": Red/Orange - \"Doesn't know\": Green - Arrows: Sylvia auburn for visible information, gray dotted for hidden</p> <p>Implementation: p5.js with hover and toggle interactions Canvas size: Responsive, approximately 750x380px</p>"},{"location":"chapters/12-experimental-design/#types-of-experimental-designs","title":"Types of Experimental Designs","text":"<p>Now that you understand the principles, let's explore different ways to structure experiments. The design you choose depends on your research question, available resources, and the nature of your experimental units.</p>"},{"location":"chapters/12-experimental-design/#completely-randomized-design","title":"Completely Randomized Design","text":"<p>A completely randomized design is the simplest and most straightforward experimental structure. You take all your experimental units and randomly assign each one to a treatment group. That's it!</p> <p>For example, to test three different fertilizers on plant growth:</p> <ol> <li>Get 60 identical seedlings</li> <li>Use a random number generator to assign 20 plants to Fertilizer A, 20 to Fertilizer B, and 20 to Fertilizer C</li> <li>Apply treatments identically</li> <li>Measure growth after a set period</li> <li>Compare results</li> </ol> <p>The completely randomized design works well when your experimental units are relatively homogeneous (similar to each other). But what if there's substantial variation among your units?</p>"},{"location":"chapters/12-experimental-design/#randomized-block-design","title":"Randomized Block Design","text":"<p>A randomized block design groups experimental units into blocks based on a characteristic that might affect the response, then randomly assigns treatments within each block.</p> <p>\"Here's an analogy,\" Sylvia offers. \"Imagine you're testing acorn storage methods, but your acorns come from different tree species. Oak acorns and chestnut acorns might respond differently to storage conditions. So you'd create blocks by species, then randomly assign storage methods within each block.\"</p> <p>Why block? Because it allows you to control for a known source of variability. By ensuring each treatment appears equally in each block, you can separate the effect of the blocking variable from the treatment effect.</p> <p>Example: Testing study techniques (flashcards vs. practice problems) on test scores, blocking by prior math ability:</p> Block (Prior Ability) Treatment 1 (Flashcards) Treatment 2 (Practice Problems) High ability 10 students randomly assigned 10 students randomly assigned Medium ability 10 students randomly assigned 10 students randomly assigned Low ability 10 students randomly assigned 10 students randomly assigned <p>Now any differences in outcomes can't be attributed to prior ability, because each treatment group has equal representation from all ability levels.</p>"},{"location":"chapters/12-experimental-design/#matched-pairs-design","title":"Matched Pairs Design","text":"<p>A matched pairs design is a special type of randomized block design where each block contains exactly two experimental units that are matched based on relevant characteristics. Then one unit in each pair is randomly assigned to each treatment.</p> <p>Matched pairs are especially useful when:</p> <ul> <li>You have only two treatments to compare</li> <li>There's substantial individual variation</li> <li>You can find meaningful ways to match units</li> </ul> <p>Common matched pairs approaches:</p> <ol> <li>Same person, different times: Each subject experiences both treatments (with time gap and random order)</li> <li>Matched individuals: Pair similar individuals and assign one to each treatment</li> <li>Twins or siblings: Natural matching based on genetics</li> <li>Before/after with crossover: Subjects switch treatments partway through</li> </ol> <p>The most common matched pairs design uses each subject as their own control. If you're testing whether caffeine affects reaction time, you might:</p> <ol> <li>Measure each person's reaction time without caffeine</li> <li>Measure the same person's reaction time with caffeine</li> <li>Compare the difference for each person</li> </ol> <p>This eliminates individual differences entirely because each person serves as their own baseline.</p> <p>Order Effects in Matched Pairs</p> <p>When the same subject receives both treatments, you must worry about order effects. Maybe people perform better the second time regardless of treatment because they've had practice. Always randomize the order of treatments!</p>"},{"location":"chapters/12-experimental-design/#diagram-experimental-design-types-comparison","title":"Diagram: Experimental Design Types Comparison","text":"Experimental Design Types Comparison MicroSim <p>Type: microsim</p> <p>Purpose: Allow students to explore and compare the three main experimental designs (completely randomized, randomized block, matched pairs) through interactive visualization</p> <p>Bloom Level: Analyze (L4) Bloom Verb: compare, differentiate, organize</p> <p>Learning Objective: Students will be able to compare the three main experimental designs and analyze which design is most appropriate for different research scenarios.</p> <p>Visual Elements: - Top section: Design selector (three buttons/tabs) - Main area: Visual representation of the selected design   - Completely Randomized: Pool of units randomly divided into treatment groups   - Randomized Block: Units grouped into blocks, then randomly assigned within blocks   - Matched Pairs: Units paired and one from each pair assigned to each treatment - Bottom section: Key characteristics and \"Best for...\" summary</p> <p>Data Visibility Requirements: - Show the actual units (represented as circles or figures) - Color-code treatment assignment - For block design, show blocking variable - For matched pairs, show pairing connections</p> <p>Interactive Controls: - Design selector: Completely Randomized | Randomized Block | Matched Pairs - \"Animate Assignment\" button: Shows the random assignment process - \"Show Advantages\" toggle: Reveals when each design is preferred - Scenario dropdown: \"Drug trial\", \"Agricultural study\", \"Educational intervention\" to see how design changes</p> <p>Default view: Completely Randomized Design</p> <p>Color Scheme: - Treatment A: Sylvia green (#2E7D32) - Treatment B: Sylvia auburn (#B5651D) - Block boundaries: Gray dashed lines - Matched pair connections: Blue lines - Unassigned units: Light gray</p> <p>Instructional Rationale: Interactive comparison allows students to directly observe the structural differences between designs and reason about when each is appropriate.</p> <p>Implementation: p5.js with tabbed interface and animations Canvas size: Responsive, approximately 750x500px</p>"},{"location":"chapters/12-experimental-design/#putting-it-all-together-designing-an-experiment","title":"Putting It All Together: Designing an Experiment","text":"<p>Let's walk through how to design a complete experiment from scratch. This will help you synthesize all the concepts we've covered.</p> <p>Research Question: Does listening to classical music while studying improve test performance compared to silence?</p>"},{"location":"chapters/12-experimental-design/#step-1-identify-the-components","title":"Step 1: Identify the Components","text":"<ul> <li>Experimental units: Students (subjects)</li> <li>Factor: Study environment (music vs. silence)</li> <li>Levels: Classical music, No music (control)</li> <li>Treatments: Studying with classical music, Studying in silence</li> <li>Response variable: Test score</li> </ul>"},{"location":"chapters/12-experimental-design/#step-2-choose-a-design","title":"Step 2: Choose a Design","text":"<p>We need to decide between:</p> <ul> <li>Completely randomized: If students are fairly similar</li> <li>Randomized block: If there's a known variable (like prior GPA) that affects test performance</li> <li>Matched pairs: If we can have each student study both ways (with time gap) or if we can pair students by ability</li> </ul> <p>Let's say we choose a randomized block design, blocking by prior academic performance (high, medium, low GPA).</p>"},{"location":"chapters/12-experimental-design/#step-3-apply-the-three-principles","title":"Step 3: Apply the Three Principles","text":"<p>Control:</p> <ul> <li>Same study material for all participants</li> <li>Same amount of study time (30 minutes)</li> <li>Same testing environment and test</li> <li>Same time of day for all sessions</li> <li>If using music, same playlist and volume</li> </ul> <p>Randomization:</p> <ul> <li>Within each GPA block, randomly assign half to music and half to silence</li> <li>Use a random number generator, not personal choice</li> </ul> <p>Replication:</p> <ul> <li>Include at least 20 students per treatment per block</li> <li>Total: 120 students minimum (20 x 2 treatments x 3 blocks)</li> </ul>"},{"location":"chapters/12-experimental-design/#step-4-consider-blinding","title":"Step 4: Consider Blinding","text":"<ul> <li>Students can't be blind to whether music is playing (impossible to hide)</li> <li>BUT: we can blind the person grading the tests</li> <li>We can also avoid telling students the specific hypothesis</li> </ul>"},{"location":"chapters/12-experimental-design/#step-5-collect-data-and-analyze","title":"Step 5: Collect Data and Analyze","text":"<p>After running the experiment, compare test scores between groups, accounting for the blocking variable.</p> <p>Here's a summary of our experimental design:</p> Component Decision Design type Randomized Block Blocking variable Prior GPA (High, Medium, Low) Treatments Classical music, Silence Sample size 120 students (20 per cell) Blinding Single-blind (grader doesn't know group) Controls Study time, material, testing conditions Random assignment Random within each block"},{"location":"chapters/12-experimental-design/#diagram-complete-experiment-planning-flowchart","title":"Diagram: Complete Experiment Planning Flowchart","text":"Experiment Planning Decision Flowchart <p>Type: workflow</p> <p>Purpose: Guide students through the decision-making process when designing an experiment, from research question to final design</p> <p>Bloom Level: Create (L6) Bloom Verb: design, formulate</p> <p>Learning Objective: Students will be able to design a complete experiment by following a structured decision-making process.</p> <p>Visual Layout: Flowchart with decision points and process boxes</p> <p>Flow Structure: 1. Start: \"Define Research Question\"    - Output: Identify response variable, factors, levels</p> <ol> <li>Decision: \"Is there significant unit variability?\"</li> <li>No \u2192 Completely Randomized Design</li> <li> <p>Yes \u2192 Continue</p> </li> <li> <p>Decision: \"Can you measure the source of variability?\"</p> </li> <li>No \u2192 Consider increasing sample size</li> <li> <p>Yes \u2192 Continue</p> </li> <li> <p>Decision: \"Comparing exactly 2 treatments?\"</p> </li> <li>Yes \u2192 Consider Matched Pairs</li> <li> <p>No \u2192 Randomized Block Design</p> </li> <li> <p>Process: \"Apply Three Principles\"</p> </li> <li>Control: List variables to hold constant</li> <li>Randomization: Method for random assignment</li> <li> <p>Replication: Calculate needed sample size</p> </li> <li> <p>Decision: \"Is blinding possible?\"</p> </li> <li>Yes \u2192 Determine single or double blind</li> <li> <p>No \u2192 Document limitation</p> </li> <li> <p>End: \"Final Design Summary\"</p> </li> </ol> <p>Interactive Features: - Click each node to see detailed explanation and examples - Hover for quick tips at each decision point - Input your own scenario and follow the flowchart to see recommended design - \"Show Example\" button that walks through the classical music study</p> <p>Color Scheme: - Decision diamonds: Sylvia auburn (#B5651D) - Process rectangles: Sylvia green (#2E7D32) - Start/End: Sylvia hazel (#8B7355) - Arrows: Dark gray</p> <p>Implementation: p5.js or vis-network with interactive node exploration Canvas size: Responsive, approximately 700x480px</p>"},{"location":"chapters/12-experimental-design/#common-pitfalls-in-experimental-design","title":"Common Pitfalls in Experimental Design","text":"<p>Even well-intentioned researchers can make mistakes. Here are some common pitfalls to avoid:</p>"},{"location":"chapters/12-experimental-design/#pitfall-1-confusing-random-sampling-and-random-assignment","title":"Pitfall 1: Confusing Random Sampling and Random Assignment","text":"<p>Remember: random sampling helps you generalize to a population. Random assignment helps you establish causation. Many studies have one but not the other.</p> Study Characteristic Generalization? Causation? Random sample + Random assignment Yes Yes Random sample + No random assignment Yes No Non-random sample + Random assignment Limited Yes Neither random Very limited No"},{"location":"chapters/12-experimental-design/#pitfall-2-inadequate-control-group","title":"Pitfall 2: Inadequate Control Group","text":"<p>Sometimes researchers use a \"no treatment\" control when a placebo control would be more appropriate. If subjects know they're getting nothing, the comparison isn't fair due to placebo effects.</p>"},{"location":"chapters/12-experimental-design/#pitfall-3-insufficient-sample-size","title":"Pitfall 3: Insufficient Sample Size","text":"<p>Running an experiment with too few subjects means you might miss real effects. It's like trying to hear a whisper in a noisy room. You need enough observations to detect the signal above the noise.</p>"},{"location":"chapters/12-experimental-design/#pitfall-4-ignoring-confounding-variables","title":"Pitfall 4: Ignoring Confounding Variables","text":"<p>Even with random assignment, things can go wrong if the experiment isn't run carefully. If one treatment group is always tested in the morning and another in the afternoon, time of day becomes confounded with treatment.</p>"},{"location":"chapters/12-experimental-design/#pitfall-5-demand-characteristics","title":"Pitfall 5: Demand Characteristics","text":"<p>When subjects figure out what the experimenter wants, they might unconsciously (or consciously) behave accordingly. Good blinding and careful experimental protocols help prevent this.</p> <p>\"My biggest mistake?\" Sylvia reflects. \"Once I didn't randomize which trees I collected acorns from first. Turns out, I was always more thorough in the morning when I had more energy. My data on acorn distribution was totally biased! Lesson learned.\"</p>"},{"location":"chapters/12-experimental-design/#reading-research-critically","title":"Reading Research Critically","text":"<p>One of the most valuable skills you'll gain from this chapter is the ability to critically evaluate research claims. When you read about a study in the news or encounter research in your future studies, ask yourself:</p> <p>Key Questions for Evaluating Experiments:</p> <ol> <li>Was there a control group? What kind?</li> <li>Were subjects randomly assigned to treatments?</li> <li>Was blinding used? Single or double?</li> <li>How large were the sample sizes?</li> <li>What variables were controlled?</li> <li>What potential confounds might remain?</li> <li>Was the study replicated?</li> </ol> <p>Here's a quick checklist format:</p> <ul> <li>[ ] Control group present and appropriate</li> <li>[ ] Random assignment to treatments</li> <li>[ ] Adequate blinding (if possible)</li> <li>[ ] Sufficient sample size</li> <li>[ ] Major confounds addressed</li> <li>[ ] Key variables controlled</li> <li>[ ] Results replicated or replicable</li> </ul>"},{"location":"chapters/12-experimental-design/#ap-exam-focus-describing-experimental-designs","title":"AP Exam Focus: Describing Experimental Designs","text":"<p>On the AP Statistics exam, you'll often need to describe how to design an experiment. Here's a template that will serve you well:</p> <p>Sylvia's Four-Step Experiment Description</p> <ol> <li>Identify experimental units and treatments - State what you're experimenting on and what treatments you're comparing</li> <li>Describe random assignment - Explain HOW you'll randomly assign units to treatments (be specific about the mechanism)</li> <li>Explain what's being compared - State the response variable and how you'll compare groups</li> <li>Mention controls and blinding - Describe what variables you're holding constant and whether blinding is used</li> </ol> <p>Example Response:</p> <p>\"To test whether caffeine improves test scores, randomly assign the 40 student volunteers to two groups of 20 using a random number generator. Group 1 receives a caffeinated beverage; Group 2 receives an identical-looking decaffeinated beverage (placebo). Neither students nor the proctor administering the test know who received caffeine (double-blind). Control for study time, test difficulty, time of day, and testing environment by keeping these constant for all participants. After students study for 30 minutes and take the test, compare the mean test scores between the two groups.\"</p>"},{"location":"chapters/12-experimental-design/#diagram-random-assignment-simulator","title":"Diagram: Random Assignment Simulator","text":"Random Assignment Simulator MicroSim <p>Type: microsim</p> <p>Purpose: Allow students to practice random assignment by simulating the process of assigning experimental units to treatment groups</p> <p>Bloom Level: Apply (L3) Bloom Verb: use, execute, implement</p> <p>Learning Objective: Students will be able to execute random assignment using a chance mechanism and verify that the assignment process is truly random.</p> <p>Visual Elements: - Left panel: Pool of experimental units (represented as numbered circles) - Right panel: Treatment group containers (Treatment A, Treatment B, Control) - Center: Random number generator display - Bottom: Statistics showing current distribution</p> <p>Interactive Controls: - Number input: \"Number of units\" (default: 20) - Number input: \"Number of groups\" (default: 2) - Button: \"Assign One Unit\" (step through one at a time) - Button: \"Assign All\" (animate full assignment) - Button: \"Reset\" - Toggle: \"Show assignment method\" (random numbers, coin flip simulation, etc.)</p> <p>Behavior: - When \"Assign One Unit\" clicked:   1. Highlight next unassigned unit   2. Show random number generation   3. Animate unit moving to assigned group   4. Update group counts</p> <ul> <li>When \"Assign All\" clicked:</li> <li> <p>Rapidly animate all assignments with brief pauses</p> </li> <li> <p>Statistics displayed:</p> </li> <li>Count in each group</li> <li>Percentage in each group</li> <li>Whether groups are balanced (within acceptable range)</li> </ul> <p>Visual Style: - Units: Circles with numbers - Treatment A: Sylvia green (#2E7D32) - Treatment B: Sylvia auburn (#B5651D) - Control (if 3 groups): Blue - Unassigned: Gray</p> <p>Instructional Rationale: Hands-on practice with random assignment helps students understand both the procedure and why it tends to create balanced groups.</p> <p>Implementation: p5.js with canvas-based controls Canvas size: Responsive, approximately 700x400px</p>"},{"location":"chapters/12-experimental-design/#summary-key-takeaways","title":"Summary: Key Takeaways","text":"<p>\"Time to squirrel away this knowledge!\" Sylvia says with a satisfied swish of her tail.</p> <p>Let's recap the essential concepts from this chapter:</p> <p>Experimental Vocabulary:</p> <ul> <li>Experimental units are the entities receiving treatment (subjects when human)</li> <li>Treatments are the experimental conditions we apply</li> <li>Factors are the explanatory variables; levels are their specific values</li> <li>Placebo is an inactive treatment; the placebo effect is improvement from belief alone</li> <li>Control groups provide a baseline for comparison</li> </ul> <p>Three Principles of Experimental Design:</p> <ul> <li>Control: Hold extraneous variables constant</li> <li>Randomization: Use chance to assign treatments</li> <li>Replication: Use enough experimental units</li> </ul> <p>Blinding:</p> <ul> <li>Single-blind: Subjects don't know their treatment</li> <li>Double-blind: Neither subjects nor researchers know</li> </ul> <p>Experimental Designs:</p> <ul> <li>Completely randomized: Randomly assign all units to treatments</li> <li>Randomized block: Group by a variable, randomize within blocks</li> <li>Matched pairs: Pair similar units, randomize within pairs</li> </ul> <p>\"You've got this,\" Sylvia encourages. \"Every time you see a claim that 'X causes Y,' you now have the tools to ask the right questions. Does the study have a control group? Was there random assignment? That's a superpower right there!\"</p> Practice Question: Identify the Design <p>A researcher wants to test whether a new algebra tutoring method improves test scores. She recruits 60 students and pairs them by their current math grades, creating 30 pairs. Within each pair, she flips a coin to determine which student gets the new method and which gets traditional tutoring. After 8 weeks, she compares test scores.</p> <p>What type of experimental design is this?</p> <p>Answer: This is a matched pairs design. Students are paired based on a relevant characteristic (current math grade), and random assignment occurs within each pair. This design controls for prior math ability.</p> Practice Question: Design Critique <p>A coffee company claims their new blend increases energy levels because 50 volunteers who drank their coffee reported feeling more energetic than before drinking it.</p> <p>What are at least two problems with this study design?</p> <p>Answer: 1. No control group: Without a control group (or placebo group drinking decaf that looks identical), we can't distinguish between the coffee's effect and the placebo effect. 2. No random assignment: This appears to be an observational before/after study, not a true experiment. 3. Self-reported outcomes: \"Feeling energetic\" is subjective and susceptible to expectation bias. 4. Volunteers only: Self-selected participants may differ from the general population.</p>"},{"location":"chapters/12-experimental-design/#looking-ahead","title":"Looking Ahead","text":"<p>In the next chapter, we'll dive into the world of random variables and probability distributions. You'll learn how to mathematically model random processes, which is essential for understanding the inferential statistics that come later in the course.</p> <p>\"The beautiful thing about experiments?\" Sylvia muses. \"They're how we move from 'I wonder if...' to 'Now I know.' And that's pretty amazing, if you ask me. See you in the next chapter!\"</p>"},{"location":"chapters/13-random-variables/","title":"Random Variables","text":""},{"location":"chapters/13-random-variables/#summary","title":"Summary","text":"<p>This chapter introduces random variables and probability distributions. Students will learn about discrete random variables, expected value, variance, and standard deviation. The binomial and geometric distributions are covered in depth as key examples of discrete probability models used throughout statistics.</p>"},{"location":"chapters/13-random-variables/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 23 concepts from the learning graph:</p> <ol> <li>Random Variable</li> <li>Discrete Random Variable</li> <li>Probability Distribution</li> <li>Valid Distribution</li> <li>Expected Value</li> <li>Calculating Expected Value</li> <li>Variance of Random Variable</li> <li>Standard Deviation of RV</li> <li>Linear Transformation</li> <li>Combining Random Variables</li> <li>Sum of Random Variables</li> <li>Difference of RVs</li> <li>Binomial Setting</li> <li>Binomial Conditions</li> <li>Binomial Distribution</li> <li>Binomial Probability</li> <li>Binomial Formula</li> <li>Binomial Mean</li> <li>Binomial Standard Dev</li> <li>Geometric Setting</li> <li>Geometric Distribution</li> <li>Geometric Probability</li> <li>Geometric Mean</li> </ol>"},{"location":"chapters/13-random-variables/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 4: Numerical Summaries</li> <li>Chapter 9: Probability Fundamentals</li> </ul>"},{"location":"chapters/13-random-variables/#introduction-putting-numbers-on-chance","title":"Introduction: Putting Numbers on Chance","text":"<p>Welcome back! Sylvia here, and I have to tell you, this is one of my favorite chapters. Why? Because we're about to take everything you've learned about probability and supercharge it with some seriously powerful mathematical tools.</p> <p>Think about it: probability tells us that something is \"likely\" or \"unlikely,\" but what if we could be more precise? What if we could calculate the average outcome of a random process, or measure how much variability to expect? That's exactly what random variables let us do.</p> <p>Here's a real-world example. Imagine you're running a carnival game where players pay $2 to spin a wheel. Sometimes they win $5, sometimes $1, sometimes nothing. How do you know if your game will make money over hundreds of spins? Random variables give you the answer.</p> <p>Sylvia Says</p> <p>Random variables are like translating the unpredictable language of chance into the precise language of numbers. Once you've made that translation, a whole world of calculations opens up!</p>"},{"location":"chapters/13-random-variables/#what-is-a-random-variable","title":"What Is a Random Variable?","text":"<p>A random variable is a variable whose value is determined by the outcome of a random process. It's like a rule that assigns a number to every possible outcome of an experiment.</p> <p>Let's make this concrete. When you flip two coins, the possible outcomes are:</p> <ul> <li>HH (both heads)</li> <li>HT (head, then tail)</li> <li>TH (tail, then head)</li> <li>TT (both tails)</li> </ul> <p>If we let X = \"the number of heads,\" then X is a random variable that assigns these values:</p> Outcome Value of X HH 2 HT 1 TH 1 TT 0 <p>Notice what we've done: we've converted word descriptions of outcomes into numbers. That's the magic of random variables.</p>"},{"location":"chapters/13-random-variables/#discrete-vs-continuous-random-variables","title":"Discrete vs. Continuous Random Variables","text":"<p>Random variables come in two flavors:</p> <ul> <li>Discrete random variables take on a countable number of values (like counting things: 0, 1, 2, 3...)</li> <li>Continuous random variables take on any value in an interval (like measuring: 5.2, 5.21, 5.217...)</li> </ul> <p>In this chapter, we focus on discrete random variables. You'll meet continuous random variables when we explore normal distributions more deeply.</p> <p>Here are some examples to help you distinguish between them:</p> Variable Type Reason Number of texts you send today Discrete You count texts (0, 1, 2, ...) Time spent studying Continuous Could be 45.3 minutes, 45.37 minutes, etc. Number of heads in 10 coin flips Discrete You count heads (0, 1, 2, ..., 10) Height of a randomly selected student Continuous Measured values can be infinitely precise Number of cars in a parking lot Discrete You count cars"},{"location":"chapters/13-random-variables/#probability-distributions","title":"Probability Distributions","text":"<p>A probability distribution tells you all possible values of a random variable and how likely each value is. Think of it as a complete picture of what might happen and the chances of each possibility.</p> <p>For a discrete random variable, we can display the probability distribution as a table, a graph, or a formula.</p>"},{"location":"chapters/13-random-variables/#example-rolling-a-die","title":"Example: Rolling a Die","text":"<p>Let X = the number showing when you roll a fair six-sided die.</p> Value of X 1 2 3 4 5 6 P(X = x) 1/6 1/6 1/6 1/6 1/6 1/6 <p>Each outcome has equal probability, so this is a uniform distribution.</p>"},{"location":"chapters/13-random-variables/#diagram-probability-distribution-bar-chart","title":"Diagram: Probability Distribution Bar Chart","text":"Probability Distribution Bar Chart <p>Type: chart</p> <p>Purpose: Visualize the probability distribution for rolling a die, showing equal probabilities for each outcome</p> <p>Bloom Level: Understand (L2) Bloom Verb: Interpret</p> <p>Learning Objective: Students will interpret a probability distribution by examining a bar chart where each bar's height represents the probability of that outcome.</p> <p>Chart Type: Bar chart with interactive elements</p> <p>Visual Elements: - X-axis: Values 1, 2, 3, 4, 5, 6 - Y-axis: Probability from 0 to 0.3 (or fraction scale showing 1/6) - Six equal-height bars at height 1/6 (approximately 0.167) - Each bar labeled with its probability value - Grid lines for easy reading</p> <p>Interactive Features: - Hover over any bar to see exact probability value - Display shows P(X = value) = 1/6 on hover - Option to toggle between fraction (1/6) and decimal (0.167) display</p> <p>Color Scheme: Use Sylvia's green (--sylvia-green: #2E7D32) for bars</p> <p>Canvas Size: Responsive, approximately 600x400px</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/13-random-variables/#what-makes-a-valid-distribution","title":"What Makes a Valid Distribution?","text":"<p>Not every table of numbers is a valid probability distribution. A distribution is valid if and only if:</p> <ol> <li>Every probability is between 0 and 1: For all values, \\( 0 \\leq P(X = x) \\leq 1 \\)</li> <li>The probabilities sum to 1: \\( \\sum P(X = x) = 1 \\)</li> </ol> <p>These rules make sense. A probability can't be negative (that would mean something is \"less than impossible\"), and it can't be greater than 1 (that would mean something is \"more than certain\"). And since something has to happen, the total probability must equal 1.</p> <p>Check Your Work</p> <p>Always verify that your probabilities sum to 1. If they don't, you've made an error somewhere. This is a common mistake on the AP exam!</p>"},{"location":"chapters/13-random-variables/#practice-valid-or-invalid","title":"Practice: Valid or Invalid?","text":"<p>Consider this distribution for X:</p> x 1 2 3 4 P(X = x) 0.3 0.3 0.2 0.2 <p>Is this valid? Let's check:</p> <ul> <li>All probabilities are between 0 and 1: 0.3, 0.3, 0.2, 0.2 all pass</li> <li>Sum: 0.3 + 0.3 + 0.2 + 0.2 = 1.0</li> </ul> <p>Yes, this is a valid probability distribution.</p>"},{"location":"chapters/13-random-variables/#expected-value-the-long-run-average","title":"Expected Value: The Long-Run Average","text":"<p>Here's where things get really useful. The expected value of a random variable is what you'd expect the average outcome to be if you repeated the random process many, many times.</p> <p>The notation is \\( E(X) \\) or \\( \\mu_X \\) (read as \"mu sub X\").</p>"},{"location":"chapters/13-random-variables/#the-formula-for-expected-value","title":"The Formula for Expected Value","text":"<p>For a discrete random variable X with possible values \\( x_1, x_2, ..., x_n \\), the expected value is:</p> \\[ E(X) = \\mu_X = \\sum x_i \\cdot P(X = x_i) \\] <p>In words: multiply each value by its probability, then add them all up.</p>"},{"location":"chapters/13-random-variables/#example-expected-value-of-a-die-roll","title":"Example: Expected Value of a Die Roll","text":"<p>For rolling a fair die:</p> \\[ E(X) = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6} \\] \\[ E(X) = \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} = \\frac{21}{6} = 3.5 \\] <p>Wait, 3.5? But you can't roll a 3.5! That's exactly right. The expected value doesn't have to be a possible outcome. It's the long-run average. If you rolled a die 1,000 times and averaged all your rolls, you'd get something very close to 3.5.</p> <p>Acorn for Your Thoughts</p> <p>I once tried to figure out how many acorns I'd collect on average each day. Some days were great (12 acorns!), some were terrible (just 2). By calculating the expected value, I knew my long-run average was about 7 acorns per day. That helped me plan my winter storage perfectly!</p>"},{"location":"chapters/13-random-variables/#example-insurance-premiums","title":"Example: Insurance Premiums","text":"<p>Insurance companies use expected value constantly. Suppose a company sells a $100,000 life insurance policy to a 30-year-old for $250/year. Based on mortality tables, there's a 0.001 probability this person dies during the year.</p> <p>Let X = the company's profit from this policy.</p> Outcome X (Profit) Probability Person lives $250 0.999 Person dies $250 - \\(100,000 = -\\)99,750 0.001 \\[ E(X) = 250(0.999) + (-99,750)(0.001) \\] \\[ E(X) = 249.75 - 99.75 = \\$150 \\] <p>On average, the company profits $150 per policy. With thousands of policies, this adds up significantly!</p>"},{"location":"chapters/13-random-variables/#diagram-expected-value-calculator","title":"Diagram: Expected Value Calculator","text":"Expected Value Calculator MicroSim <p>Type: microsim</p> <p>Purpose: Allow students to create custom probability distributions and calculate expected value interactively</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate</p> <p>Learning Objective: Students will calculate expected value by entering values and probabilities, observing how the weighted average is computed step-by-step.</p> <p>Instructional Rationale: An interactive calculator supports the Apply level by letting students practice the expected value formula with immediate feedback. Students can experiment with different distributions and see how changing probabilities affects the expected value.</p> <p>Canvas Layout: - Main area: Input table for values and probabilities - Side panel: Running calculation display - Bottom: Expected value result with visual bar</p> <p>Visual Elements: - Editable table with columns: Value (x), Probability P(X=x), Contribution (x * P) - Start with 4 rows, button to add more (up to 8) - Running total of probabilities shown (must equal 1.0) - Visual indicator (green checkmark or red X) showing if distribution is valid - Bar chart showing the distribution updates in real-time - Final expected value displayed prominently</p> <p>Interactive Controls: - Text inputs for values (numbers) - Text inputs for probabilities (0-1) - \"Add Row\" button - \"Clear All\" button - \"Calculate E(X)\" button - Toggle between fraction and decimal input</p> <p>Default Parameters: - Pre-loaded with die roll example: values 1-6, each with probability 1/6</p> <p>Behavior: - As user enters probabilities, probability sum updates - If sum exceeds 1 or any probability is negative, show error - Contribution column auto-calculates as user types - Expected value shown with calculation breakdown</p> <p>Data Visibility: - Stage 1: Show input values and probabilities - Stage 2: Show each x * P(X=x) contribution - Stage 3: Show sum of contributions = E(X)</p> <p>Color Scheme: Sylvia's green for valid states, auburn for errors</p> <p>Implementation: p5.js with canvas-based input controls</p>"},{"location":"chapters/13-random-variables/#variance-and-standard-deviation-of-random-variables","title":"Variance and Standard Deviation of Random Variables","text":"<p>Expected value tells us the center, but we also need to know about spread. How much variability should we expect?</p>"},{"location":"chapters/13-random-variables/#variance-of-a-random-variable","title":"Variance of a Random Variable","text":"<p>The variance of X measures the average squared distance from the mean:</p> \\[ Var(X) = \\sigma_X^2 = \\sum (x_i - \\mu_X)^2 \\cdot P(X = x_i) \\] <p>There's also a computational formula that's often easier to use:</p> \\[ Var(X) = E(X^2) - [E(X)]^2 \\] <p>In words: the variance equals \"the expected value of X squared\" minus \"the expected value of X, quantity squared.\"</p>"},{"location":"chapters/13-random-variables/#standard-deviation-of-a-random-variable","title":"Standard Deviation of a Random Variable","text":"<p>The standard deviation is simply the square root of variance:</p> \\[ \\sigma_X = \\sqrt{Var(X)} \\] <p>Standard deviation is in the same units as X, which makes it easier to interpret.</p>"},{"location":"chapters/13-random-variables/#example-calculating-variance-for-a-die-roll","title":"Example: Calculating Variance for a Die Roll","text":"<p>We already know \\( E(X) = 3.5 \\). Now let's find \\( E(X^2) \\):</p> \\[ E(X^2) = 1^2 \\cdot \\frac{1}{6} + 2^2 \\cdot \\frac{1}{6} + 3^2 \\cdot \\frac{1}{6} + 4^2 \\cdot \\frac{1}{6} + 5^2 \\cdot \\frac{1}{6} + 6^2 \\cdot \\frac{1}{6} \\] \\[ E(X^2) = \\frac{1 + 4 + 9 + 16 + 25 + 36}{6} = \\frac{91}{6} \\approx 15.17 \\] \\[ Var(X) = E(X^2) - [E(X)]^2 = 15.17 - (3.5)^2 = 15.17 - 12.25 = 2.92 \\] \\[ \\sigma_X = \\sqrt{2.92} \\approx 1.71 \\] <p>This means die rolls typically deviate from the mean of 3.5 by about 1.71 points.</p>"},{"location":"chapters/13-random-variables/#transforming-random-variables","title":"Transforming Random Variables","text":"<p>What happens when we add a constant to a random variable, or multiply it by something? Understanding these linear transformations is crucial.</p>"},{"location":"chapters/13-random-variables/#adding-a-constant","title":"Adding a Constant","text":"<p>If we define \\( Y = X + a \\) (add a constant a to every value):</p> <ul> <li>\\( E(Y) = E(X) + a \\) (the mean shifts by a)</li> <li>\\( Var(Y) = Var(X) \\) (the spread stays the same)</li> <li>\\( \\sigma_Y = \\sigma_X \\) (standard deviation unchanged)</li> </ul> <p>Think about it: if everyone in a class gets 5 bonus points on a test, the class average goes up by 5, but the spread of scores doesn't change.</p>"},{"location":"chapters/13-random-variables/#multiplying-by-a-constant","title":"Multiplying by a Constant","text":"<p>If we define \\( Y = bX \\) (multiply every value by constant b):</p> <ul> <li>\\( E(Y) = b \\cdot E(X) \\) (the mean is multiplied by b)</li> <li>\\( Var(Y) = b^2 \\cdot Var(X) \\) (variance is multiplied by b squared)</li> <li>\\( \\sigma_Y = |b| \\cdot \\sigma_X \\) (standard deviation is multiplied by |b|)</li> </ul>"},{"location":"chapters/13-random-variables/#general-linear-transformation","title":"General Linear Transformation","text":"<p>For \\( Y = a + bX \\):</p> \\[ E(Y) = a + b \\cdot E(X) \\] \\[ \\sigma_Y = |b| \\cdot \\sigma_X \\] Operation Effect on Mean Effect on SD Add constant a Mean + a No change Multiply by b Mean \u00d7 b SD \u00d7 |b| Y = a + bX a + b(Mean) |b| \u00d7 SD <p>Currency Conversion</p> <p>If X is the price in dollars with \\( E(X) = \\$50 \\) and \\( \\sigma_X = \\$10 \\), and you convert to euros where Y = 0.85X:</p> <ul> <li>\\( E(Y) = 0.85 \\times 50 = 42.50 \\) euros</li> <li>\\( \\sigma_Y = 0.85 \\times 10 = 8.50 \\) euros</li> </ul>"},{"location":"chapters/13-random-variables/#combining-random-variables","title":"Combining Random Variables","text":"<p>Often we need to work with sums or differences of random variables. This is where things get really interesting!</p>"},{"location":"chapters/13-random-variables/#sum-of-random-variables","title":"Sum of Random Variables","text":"<p>For \\( T = X + Y \\):</p> \\[ E(X + Y) = E(X) + E(Y) \\] <p>The expected value of a sum is always the sum of expected values. This works no matter what!</p> <p>But for variance, we need to be careful:</p> \\[ Var(X + Y) = Var(X) + Var(Y) \\quad \\text{(only if X and Y are independent)} \\] <p>If X and Y are independent (knowing one tells you nothing about the other), variances add. If they're dependent, we need more information.</p>"},{"location":"chapters/13-random-variables/#difference-of-random-variables","title":"Difference of Random Variables","text":"<p>For \\( D = X - Y \\):</p> \\[ E(X - Y) = E(X) - E(Y) \\] <p>And here's the surprise for many students:</p> \\[ Var(X - Y) = Var(X) + Var(Y) \\quad \\text{(if X and Y are independent)} \\] <p>Wait, variances still ADD even when we're subtracting? Yes! Variability comes from both sources, regardless of whether we're adding or subtracting.</p> <p>Common Mistake Alert</p> <p>Students often think Var(X - Y) = Var(X) - Var(Y). But that's wrong! Variability doesn't cancel out when you subtract. Variance always adds for independent variables.</p>"},{"location":"chapters/13-random-variables/#standard-deviation-rules","title":"Standard Deviation Rules","text":"<p>Since \\( \\sigma = \\sqrt{Var} \\), and we add variances for independent variables:</p> \\[ \\sigma_{X+Y} = \\sqrt{\\sigma_X^2 + \\sigma_Y^2} \\] \\[ \\sigma_{X-Y} = \\sqrt{\\sigma_X^2 + \\sigma_Y^2} \\] <p>Notice these are the same! Standard deviations don't add directly, they add \"Pythagorean style\" under a square root.</p>"},{"location":"chapters/13-random-variables/#example-combining-test-scores","title":"Example: Combining Test Scores","text":"<p>Suppose scores on Quiz 1 have \\( \\mu = 75 \\), \\( \\sigma = 10 \\), and Quiz 2 has \\( \\mu = 80 \\), \\( \\sigma = 12 \\). If the quizzes are independent:</p> <p>Total score T = Quiz1 + Quiz2:</p> <ul> <li>\\( E(T) = 75 + 80 = 155 \\)</li> <li>\\( Var(T) = 10^2 + 12^2 = 100 + 144 = 244 \\)</li> <li>\\( \\sigma_T = \\sqrt{244} \\approx 15.6 \\)</li> </ul> <p>Difference D = Quiz2 - Quiz1:</p> <ul> <li>\\( E(D) = 80 - 75 = 5 \\)</li> <li>\\( Var(D) = 10^2 + 12^2 = 244 \\) (same as for sum!)</li> <li>\\( \\sigma_D = \\sqrt{244} \\approx 15.6 \\)</li> </ul>"},{"location":"chapters/13-random-variables/#diagram-combining-random-variables-visualizer","title":"Diagram: Combining Random Variables Visualizer","text":"Combining Random Variables Visualizer <p>Type: microsim</p> <p>Purpose: Demonstrate how means and variances combine when adding or subtracting independent random variables</p> <p>Bloom Level: Understand (L2) Bloom Verb: Explain</p> <p>Learning Objective: Students will explain why variances add for both sums and differences of independent random variables, and why standard deviations don't simply add.</p> <p>Instructional Rationale: Visual representation with concrete examples helps students overcome the common misconception that Var(X-Y) = Var(X) - Var(Y). The step-by-step display shows exactly how the formulas work.</p> <p>Data Visibility Requirements: - Stage 1: Display X distribution with mean and SD - Stage 2: Display Y distribution with mean and SD - Stage 3: Show calculation for E(X+Y) and E(X-Y) - Stage 4: Show Var(X) + Var(Y) calculation - Stage 5: Show final SD calculation with square root</p> <p>Visual Elements: - Two normal curve representations for X and Y - Sliders to adjust mean and SD of each - Toggle switch: \"Sum (X+Y)\" vs \"Difference (X-Y)\" - Result display showing combined distribution - Step-by-step calculation panel</p> <p>Interactive Controls: - Slider for E(X): range 0-100, default 50 - Slider for SD(X): range 1-20, default 10 - Slider for E(Y): range 0-100, default 50 - Slider for SD(Y): range 1-20, default 10 - Toggle: Sum / Difference - Button: \"Show Calculation Steps\"</p> <p>Behavior: - As sliders move, combined distribution updates - Calculation shows E(X+Y) = E(X) + E(Y) - Variance calculation explicitly shows addition - SD calculation shows square root of sum of squared SDs - Visual emphasis that SD(X+Y) &lt; SD(X) + SD(Y)</p> <p>Color Scheme: - X distribution: Sylvia's green - Y distribution: Sylvia's auburn - Combined: Sylvia's hazel</p> <p>Implementation: p5.js with canvas-based sliders and toggle</p>"},{"location":"chapters/13-random-variables/#the-binomial-distribution","title":"The Binomial Distribution","text":"<p>Now we're ready for one of the most important distributions in statistics: the binomial distribution. You'll use this constantly in AP Statistics and beyond.</p>"},{"location":"chapters/13-random-variables/#the-binomial-setting","title":"The Binomial Setting","text":"<p>A binomial setting has four conditions (remember BINS):</p> <ol> <li>Binary outcomes: Each trial has exactly two outcomes (success/failure)</li> <li>Independent trials: The outcome of one trial doesn't affect others</li> <li>Number of trials is fixed: We know n ahead of time</li> <li>Same probability: The probability of success p is constant</li> </ol> Condition What It Means Example That Fits Example That Doesn't Binary Only 2 outcomes Coin flip (H/T) Die roll (1,2,3,4,5,6) Independent Trials don't affect each other Multiple coin flips Drawing without replacement Fixed n Know total trials Flip exactly 10 coins Flip until you get heads Same p Constant probability Fair coin (p=0.5) Getting harder as you go"},{"location":"chapters/13-random-variables/#examples-of-binomial-settings","title":"Examples of Binomial Settings","text":"<p>These ARE binomial:</p> <ul> <li>Flip a coin 20 times, count heads</li> <li>Survey 100 people, count those who approve (if population is large)</li> <li>Answer 15 multiple-choice questions by guessing, count correct</li> </ul> <p>These are NOT binomial:</p> <ul> <li>Draw 5 cards without replacement, count aces (not independent)</li> <li>Flip until you get 3 heads (n not fixed)</li> <li>Shoot free throws until you miss (n not fixed, and maybe p changes as you tire)</li> </ul> <p>Sylvia's BINS Check</p> <p>Before using binomial formulas, always verify all four conditions. I write \"BINS\" in the margin and check each one. It's saved my bushy tail on many exams!</p>"},{"location":"chapters/13-random-variables/#the-binomial-distribution_1","title":"The Binomial Distribution","text":"<p>If X counts the number of successes in n independent trials with success probability p, then X has a binomial distribution:</p> \\[ X \\sim \\text{Binomial}(n, p) \\] <p>The possible values are X = 0, 1, 2, ..., n.</p>"},{"location":"chapters/13-random-variables/#the-binomial-probability-formula","title":"The Binomial Probability Formula","text":"<p>The probability of getting exactly k successes in n trials is:</p> \\[ P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k} \\] <p>Where:</p> <ul> <li>\\( \\binom{n}{k} = \\frac{n!}{k!(n-k)!} \\) is the binomial coefficient (\"n choose k\")</li> <li>\\( p^k \\) is the probability of k successes</li> <li>\\( (1-p)^{n-k} \\) is the probability of (n-k) failures</li> </ul> <p>Let's break this down:</p> <ul> <li>\\( \\binom{n}{k} \\): How many ways can k successes occur among n trials?</li> <li>\\( p^k \\): Probability of success happening k times</li> <li>\\( (1-p)^{n-k} \\): Probability of failure happening (n-k) times</li> </ul>"},{"location":"chapters/13-random-variables/#example-coin-flips","title":"Example: Coin Flips","text":"<p>What's the probability of getting exactly 3 heads in 5 coin flips?</p> <p>Here \\( n = 5 \\), \\( k = 3 \\), and \\( p = 0.5 \\).</p> \\[ P(X = 3) = \\binom{5}{3} (0.5)^3 (0.5)^2 \\] \\[ = 10 \\cdot 0.125 \\cdot 0.25 = 10 \\cdot 0.03125 = 0.3125 \\] <p>There's a 31.25% chance of getting exactly 3 heads.</p>"},{"location":"chapters/13-random-variables/#diagram-binomial-probability-explorer","title":"Diagram: Binomial Probability Explorer","text":"Binomial Probability Explorer MicroSim <p>Type: microsim</p> <p>Purpose: Allow students to explore how n and p affect the shape of the binomial distribution</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Examine</p> <p>Learning Objective: Students will analyze how changing the number of trials (n) and probability of success (p) affects the shape, center, and spread of the binomial distribution.</p> <p>Instructional Rationale: Parameter exploration supports the Analyze level by helping students discover patterns and relationships. Students can observe that larger n makes the distribution more symmetric and that p determines skewness.</p> <p>Canvas Layout: - Main area (70%): Bar chart showing P(X = k) for all k from 0 to n - Control panel (30%): Sliders and displays</p> <p>Visual Elements: - Probability histogram with bars for each k value - Highlighted bar showing P(X = selected k) - Overlay showing mean (vertical line) - Display of calculated probabilities P(X = k), P(X &lt;= k), P(X &gt;= k)</p> <p>Interactive Controls: - Slider for n: range 1-50, default 10 - Slider for p: range 0-1, step 0.05, default 0.5 - Slider for k: range 0-n, default 5 - Checkboxes: Show mean line, Show cumulative region - Button: \"Calculate P(X = k)\"</p> <p>Default Parameters: - n = 10 - p = 0.5 - k = 5</p> <p>Behavior: - Distribution updates in real-time as n or p changes - Mean marker \u03bc = np moves with parameters - For k selection, show step-by-step formula calculation - Display P(X = k) with full formula breakdown - Color region for P(X &lt;= k) or P(X &gt;= k) based on toggle</p> <p>Key Insights to Highlight: - When p = 0.5, distribution is symmetric - When p &lt; 0.5, distribution is right-skewed - When p &gt; 0.5, distribution is left-skewed - Larger n \u2192 more bell-shaped</p> <p>Color Scheme: - Bars: Sylvia's green with auburn highlight for selected k - Mean line: Sylvia's hazel - Cumulative region: Light green fill</p> <p>Implementation: p5.js with canvas-based sliders, include binomial coefficient calculation display</p> <p>Canvas Size: Responsive, minimum 700x500px</p>"},{"location":"chapters/13-random-variables/#binomial-mean-and-standard-deviation","title":"Binomial Mean and Standard Deviation","text":"<p>For a binomial distribution with parameters n and p:</p> \\[ \\mu_X = np \\] \\[ \\sigma_X = \\sqrt{np(1-p)} \\] <p>These formulas are wonderfully simple and very useful!</p> <p>Example: For n = 100 coin flips with p = 0.5:</p> <ul> <li>\\( \\mu = 100 \\times 0.5 = 50 \\) heads expected</li> <li>\\( \\sigma = \\sqrt{100 \\times 0.5 \\times 0.5} = \\sqrt{25} = 5 \\)</li> </ul> <p>So in 100 flips, we expect about 50 heads, give or take about 5.</p>"},{"location":"chapters/13-random-variables/#using-technology-for-binomial-probabilities","title":"Using Technology for Binomial Probabilities","text":"<p>Calculating binomial probabilities by hand is tedious for large n. Use your calculator!</p> <p>TI-83/84:</p> <ul> <li>binompdf(n, p, k): Calculates P(X = k)</li> <li>binomcdf(n, p, k): Calculates P(X \u2264 k)</li> </ul> <p>Examples with n = 10, p = 0.3:</p> <ul> <li>P(X = 4): binompdf(10, 0.3, 4) = 0.200</li> <li>P(X \u2264 4): binomcdf(10, 0.3, 4) = 0.850</li> <li>P(X \u2265 5): 1 - binomcdf(10, 0.3, 4) = 0.150</li> </ul>"},{"location":"chapters/13-random-variables/#the-geometric-distribution","title":"The Geometric Distribution","text":"<p>The geometric distribution answers a different question: \"How many trials until the first success?\"</p>"},{"location":"chapters/13-random-variables/#the-geometric-setting","title":"The Geometric Setting","text":"<p>Like the binomial, but with one key difference:</p> <ol> <li>Binary outcomes: Each trial has two outcomes (success/failure)</li> <li>Independent trials: Trials don't affect each other</li> <li>Trials continue until first success: We keep going until we succeed</li> <li>Same probability: The probability p is constant</li> </ol> <p>Notice we don't have a fixed n because we stop when we get our first success.</p>"},{"location":"chapters/13-random-variables/#geometric-distribution","title":"Geometric Distribution","text":"<p>If X = number of trials until first success, then X has a geometric distribution:</p> \\[ X \\sim \\text{Geometric}(p) \\] <p>The possible values are X = 1, 2, 3, ... (infinitely many, but probabilities get tiny)</p>"},{"location":"chapters/13-random-variables/#geometric-probability-formula","title":"Geometric Probability Formula","text":"\\[ P(X = k) = (1-p)^{k-1} \\cdot p \\] <p>This makes sense:</p> <ul> <li>\\( (1-p)^{k-1} \\): Fail (k-1) times</li> <li>\\( p \\): Then succeed on trial k</li> </ul>"},{"location":"chapters/13-random-variables/#example-first-head","title":"Example: First Head","text":"<p>You flip a coin until you get heads. What's P(X = 4), the probability that the first head is on the 4th flip?</p> <p>You need: TTTH</p> \\[ P(X = 4) = (0.5)^3 \\cdot (0.5) = 0.125 \\cdot 0.5 = 0.0625 \\] <p>There's a 6.25% chance the first head appears on flip 4.</p>"},{"location":"chapters/13-random-variables/#geometric-mean","title":"Geometric Mean","text":"<p>The expected number of trials until first success is:</p> \\[ \\mu_X = \\frac{1}{p} \\] <p>This formula is beautifully intuitive. If p = 0.5 (coin flip), you expect 1/0.5 = 2 flips to get your first head. If p = 0.1 (rare event), you expect 1/0.1 = 10 trials.</p> Probability of Success (p) Expected Trials Until Success (1/p) 0.5 2 0.25 4 0.1 10 0.05 20 0.01 100 <p>Sylvia's Acorn Hunt</p> <p>When I'm searching for the perfect acorn, I might have a 1 in 5 chance (p = 0.2) of finding one under any given tree. On average, I expect to check 1/0.2 = 5 trees before finding my perfect acorn. Some days I get lucky on tree 1; other days it takes 10 or more!</p>"},{"location":"chapters/13-random-variables/#diagram-geometric-distribution-simulator","title":"Diagram: Geometric Distribution Simulator","text":"Geometric Distribution Simulator <p>Type: microsim</p> <p>Purpose: Simulate trials until first success and build up the geometric distribution empirically</p> <p>Bloom Level: Apply (L3) Bloom Verb: Demonstrate</p> <p>Learning Objective: Students will demonstrate understanding of the geometric distribution by running simulations and comparing empirical results to theoretical probabilities.</p> <p>Instructional Rationale: Simulation supports the Apply level by letting students practice concepts through experimentation. Seeing many trials accumulate into the theoretical distribution reinforces the connection between individual trials and probability.</p> <p>Canvas Layout: - Top: Trial animation area showing sequence of successes/failures - Middle: Building histogram of \"trials until success\" - Bottom: Controls and statistics</p> <p>Visual Elements: - Animated sequence showing S/F outcomes - Growing bar chart of trial counts - Display of running average vs theoretical mean (1/p) - Comparison of empirical vs theoretical P(X = k)</p> <p>Interactive Controls: - Slider for p: range 0.05-0.95, step 0.05, default 0.3 - \"Run 1 Trial\" button - \"Run 10 Trials\" button - \"Run 100 Trials\" button - \"Reset\" button - Speed slider for animation</p> <p>Default Parameters: - p = 0.3 - Animation speed: Medium</p> <p>Behavior: - Each trial shows sequence: F, F, F, ..., S (animation) - Record number of trials until S - Add to histogram - Update running average - Show theoretical mean line - After many trials, empirical distribution matches geometric</p> <p>Statistics Display: - Total experiments run - Empirical mean - Theoretical mean (1/p) - Empirical P(X = 1), P(X = 2), etc.</p> <p>Color Scheme: - Success (S): Sylvia's green - Failure (F): Sylvia's auburn - Bars: Green with intensity based on frequency - Theoretical line: Hazel</p> <p>Implementation: p5.js with canvas-based buttons and animation</p> <p>Canvas Size: Responsive, minimum 650x450px</p>"},{"location":"chapters/13-random-variables/#comparing-binomial-and-geometric","title":"Comparing Binomial and Geometric","text":"Feature Binomial Geometric Question How many successes in n trials? How many trials until first success? Fixed? n is fixed n is random Random variable Number of successes Number of trials Possible values 0, 1, 2, ..., n 1, 2, 3, ... (infinite) Mean formula \u03bc = np \u03bc = 1/p When to use \"Out of n trials, how many...\" \"How long until...\""},{"location":"chapters/13-random-variables/#putting-it-all-together","title":"Putting It All Together","text":"<p>Random variables are the bridge between probability and the statistical inference you'll learn soon. Let's recap the key formulas:</p>"},{"location":"chapters/13-random-variables/#summary-of-formulas","title":"Summary of Formulas","text":"<p>Expected Value: [ E(X) = \\sum x_i \\cdot P(X = x_i) ]</p> <p>Variance: [ Var(X) = \\sum (x_i - \\mu)^2 \\cdot P(X = x_i) = E(X^2) - [E(X)]^2 ]</p> <p>Linear Transformation (Y = a + bX): [ E(Y) = a + b \\cdot E(X), \\quad \\sigma_Y = |b| \\cdot \\sigma_X ]</p> <p>Combining Independent Variables: [ E(X \\pm Y) = E(X) \\pm E(Y) ] [ Var(X \\pm Y) = Var(X) + Var(Y) \\text{ (both add!)} ]</p> <p>Binomial Distribution (X ~ Binomial(n, p)): [ P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k} ] [ \\mu = np, \\quad \\sigma = \\sqrt{np(1-p)} ]</p> <p>Geometric Distribution (X ~ Geometric(p)): [ P(X = k) = (1-p)^{k-1} p ] [ \\mu = \\frac{1}{p} ]</p>"},{"location":"chapters/13-random-variables/#decision-guide-which-distribution","title":"Decision Guide: Which Distribution?","text":"<p>Use this flowchart thinking:</p> <ol> <li>Are you counting successes in fixed trials? \u2192 Binomial</li> <li>Are you counting trials until first success? \u2192 Geometric</li> <li>Is it neither of these special cases? \u2192 General discrete distribution (use table)</li> </ol>"},{"location":"chapters/13-random-variables/#diagram-random-variable-concept-map","title":"Diagram: Random Variable Concept Map","text":"Random Variable Concept Map <p>Type: infographic</p> <p>Purpose: Show the relationships between all random variable concepts covered in this chapter</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Organize</p> <p>Learning Objective: Students will organize their understanding of random variable concepts by exploring an interactive concept map showing how definitions, formulas, and distributions connect.</p> <p>Visual Layout: Network/mind map with \"Random Variable\" at center</p> <p>Main Nodes: - Center: Random Variable - Level 1: Discrete RV, Probability Distribution, Expected Value, Variance - Level 2: Valid Distribution, Calculating E(X), SD of RV, Linear Transformation - Level 3: Combining RVs, Binomial Distribution, Geometric Distribution</p> <p>Connections with Labels: - Random Variable \u2192 \"has a\" \u2192 Probability Distribution - Probability Distribution \u2192 \"must be\" \u2192 Valid Distribution - Random Variable \u2192 \"is summarized by\" \u2192 Expected Value - Random Variable \u2192 \"has spread\" \u2192 Variance - Variance \u2192 \"square root gives\" \u2192 Standard Deviation - Expected Value \u2192 \"changes by\" \u2192 Linear Transformation - Combining RVs \u2192 \"uses\" \u2192 Sum/Difference formulas - Binomial \u2192 \"special case of\" \u2192 Discrete RV - Geometric \u2192 \"special case of\" \u2192 Discrete RV</p> <p>Interactive Features: - Hover over any node to see definition/formula - Click node to expand details panel - Highlight all connected concepts on click - Zoom in/out capability - Different colors for concept types (definitions, formulas, distributions)</p> <p>Color Scheme: - Core concepts: Sylvia's green - Formulas/calculations: Sylvia's auburn - Special distributions: Sylvia's hazel - Connections: Light gray with labels</p> <p>Implementation: vis-network or p5.js with force-directed layout</p> <p>Canvas Size: Responsive, minimum 700x500px</p>"},{"location":"chapters/13-random-variables/#chapter-review","title":"Chapter Review","text":"<p>Let's squirrel away the key ideas from this chapter!</p>"},{"location":"chapters/13-random-variables/#key-takeaways","title":"Key Takeaways","text":"<ol> <li> <p>Random variables translate random outcomes into numbers, enabling mathematical analysis.</p> </li> <li> <p>Probability distributions show all possible values and their probabilities. Valid distributions have probabilities between 0 and 1 that sum to 1.</p> </li> <li> <p>Expected value is the long-run average outcome: \\( E(X) = \\sum x \\cdot P(X = x) \\)</p> </li> <li> <p>Variance measures spread around the mean. Standard deviation is its square root.</p> </li> <li> <p>Linear transformations: Adding shifts the mean; multiplying scales both mean and SD.</p> </li> <li> <p>Combining independent random variables: Means add/subtract as expected, but variances ALWAYS add.</p> </li> <li> <p>Binomial distribution (BINS): Count successes in n trials. Mean = np, SD = \u221anp(1-p).</p> </li> <li> <p>Geometric distribution: Count trials until first success. Mean = 1/p.</p> </li> </ol>"},{"location":"chapters/13-random-variables/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":"<ul> <li>Thinking expected value must be a possible outcome</li> <li>Subtracting variances when combining random variables</li> <li>Forgetting to check BINS conditions before using binomial formulas</li> <li>Adding standard deviations directly instead of using the square root formula</li> <li>Confusing P(X = k) with P(X \u2264 k)</li> </ul> <p>You've Got This!</p> <p>Random variables might seem abstract at first, but they're the foundation for everything coming next: sampling distributions, confidence intervals, and hypothesis tests. You've just learned the language that makes all of that possible. My tail's tingling with excitement for what's ahead!</p> Practice Problem: Test Your Understanding <p>A basketball player makes 70% of her free throws. She shoots 10 free throws in a game.</p> <p>(a) What distribution describes the number of free throws she makes?</p> <p>(b) What is the expected number of made free throws?</p> <p>(c) What is the probability she makes exactly 8?</p> <p>(d) What is the probability she makes at least 8?</p> <p>Click to reveal answers:</p> <p>(a) Binomial(n=10, p=0.7) - because BINS conditions are met: Binary (make/miss), Independent shots, n=10 fixed, Same probability p=0.7</p> <p>(b) E(X) = np = 10(0.7) = 7 made free throws</p> <p>(c) P(X = 8) = C(10,8)(0.7)^8(0.3)^2 = 45(0.0576)(0.09) = 0.233 or about 23.3%</p> <p>(d) P(X \u2265 8) = P(X=8) + P(X=9) + P(X=10) = 0.233 + 0.121 + 0.028 = 0.382 or about 38.2%</p>"},{"location":"chapters/14-sampling-distributions/","title":"Sampling Distributions","text":""},{"location":"chapters/14-sampling-distributions/#summary","title":"Summary","text":"<p>This chapter introduces the concept of sampling distributions, which form the theoretical foundation for statistical inference. Students will learn about sampling variability, the sampling distribution of sample proportions and sample means, and the Central Limit Theorem. Understanding these concepts is essential for constructing confidence intervals and performing hypothesis tests.</p>"},{"location":"chapters/14-sampling-distributions/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 17 concepts from the learning graph:</p> <ol> <li>Sampling Variability</li> <li>Sampling Distribution</li> <li>Sample Proportion</li> <li>Sampling Dist of Proportion</li> <li>Mean of Sample Proportion</li> <li>SD of Sample Proportion</li> <li>Conditions for Proportion SD</li> <li>Sample Mean</li> <li>Sampling Dist of Mean</li> <li>Mean of Sample Mean</li> <li>SD of Sample Mean</li> <li>Central Limit Theorem</li> <li>CLT Conditions</li> <li>Normal Approximation</li> <li>Statistical Inference</li> <li>Sample Size for CI</li> </ol>"},{"location":"chapters/14-sampling-distributions/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 5: Standardization and Normal Distributions</li> <li>Chapter 11: Sampling and Bias</li> <li>Chapter 13: Random Variables</li> </ul>"},{"location":"chapters/14-sampling-distributions/#introduction-from-sample-to-population","title":"Introduction: From Sample to Population","text":"<p>Welcome back! Sylvia here, and I have to tell you\u2014this chapter contains some of the most beautiful ideas in all of statistics. I know, I know, you might think I say that about every chapter. But sampling distributions? These are the mathematical bridge that lets us make claims about millions of people based on just a few hundred responses. That's pretty amazing when you think about it!</p> <p>Here's the big question we're tackling: If you take a sample from a population and calculate a statistic (like a mean or proportion), how confident can you be that your sample statistic is close to the true population parameter? After all, different samples give different results\u2014that's just the nature of randomness.</p> <p>Think about it this way: I've spent years tracking acorn production in Oak Valley. Every autumn, I can't possibly count every acorn on every tree (trust me, I've tried\u2014it made me a little nutty). Instead, I sample a few trees and use those results to estimate the whole forest's production. But here's what kept me up at night: how much can my estimate vary from sample to sample? And can I trust my estimate?</p> <p>That's exactly what sampling distributions help us understand. They're the key to unlocking statistical inference\u2014the process of using sample data to draw conclusions about populations.</p>"},{"location":"chapters/14-sampling-distributions/#sampling-variability-why-samples-differ","title":"Sampling Variability: Why Samples Differ","text":"<p>Let's start with a fundamental truth that every statistician must embrace: sampling variability is unavoidable. Different random samples from the same population will yield different statistics.</p> <p>Imagine we want to know the proportion of students at your school who prefer online learning over in-person classes. If you randomly surveyed 50 students, you might find that 62% prefer online learning. But if your friend surveyed a different random sample of 50 students, they might find 58%. A third sample might give 65%.</p> <p>None of these samples are \"wrong\"\u2014they're just different. This natural fluctuation in sample statistics from one sample to another is called sampling variability.</p> Sample Number Surveyed Proportion Preferring Online Sample 1 50 0.62 Sample 2 50 0.58 Sample 3 50 0.65 Sample 4 50 0.60 Sample 5 50 0.56 <p>Sylvia Says</p> <p>Don't worry\u2014every statistician drops an acorn sometimes. Sampling variability isn't a problem to fix; it's a reality to understand and quantify. Once we know how much our estimates typically vary, we can account for that uncertainty in our conclusions.</p> <p>The key insight is that while individual samples vary, the pattern of this variation is predictable. If we could take thousands of samples and calculate a statistic from each one, the distribution of those statistics would follow a recognizable pattern. This pattern is called a sampling distribution.</p>"},{"location":"chapters/14-sampling-distributions/#what-is-a-sampling-distribution","title":"What Is a Sampling Distribution?","text":"<p>A sampling distribution is the distribution of a statistic (like the sample mean or sample proportion) calculated from all possible samples of the same size from a population.</p> <p>Here's how to think about it conceptually:</p> <ol> <li>Imagine taking every possible random sample of size \\( n \\) from a population</li> <li>Calculate your statistic (mean, proportion, etc.) for each sample</li> <li>Create a distribution of all those statistics</li> </ol> <p>The resulting distribution shows us:</p> <ul> <li>The center: What value does the statistic typically cluster around?</li> <li>The spread: How much do sample statistics vary?</li> <li>The shape: Is the distribution normal, skewed, or something else?</li> </ul> <p>Now, in reality, we only take one sample. But understanding the theoretical sampling distribution helps us know how reliable our single sample is likely to be.</p>"},{"location":"chapters/14-sampling-distributions/#diagram-sampling-distribution-concept-visualization","title":"Diagram: Sampling Distribution Concept Visualization","text":"Sampling Distribution Concept Visualization <p>Type: microsim</p> <p>Learning Objective: Understand (L2) how individual samples combine to form a sampling distribution; explain how the distribution of sample statistics differs from the distribution of individual data points</p> <p>Bloom Taxonomy Level: Understand (L2) Bloom Taxonomy Verb: explain, demonstrate</p> <p>Purpose: Demonstrate visually how taking many samples and calculating a statistic from each creates a predictable sampling distribution, even when individual samples vary</p> <p>Canvas layout: - Drawing area (full width): Population visualization at top, samples in middle, sampling distribution histogram at bottom</p> <p>Visual elements: - Top section: A large population represented as colored dots (blue and orange for a proportion, or a distribution for means) - Middle section: Animation showing samples being drawn, with sample statistic calculated - Bottom section: Histogram building as each sample statistic is added - Counter showing number of samples taken - Display of current sample statistic</p> <p>Interactive controls: - Button: \"Take 1 Sample\" - draws one sample and adds statistic to histogram - Button: \"Take 10 Samples\" - rapidly draws 10 samples - Button: \"Take 100 Samples\" - rapidly draws 100 samples - Button: \"Reset\" - clears the histogram and starts over - Slider: Sample size n (10, 25, 50, 100) - Display: Mean and standard deviation of the sampling distribution</p> <p>Default parameters: - Population proportion: 0.6 (or mean = 100, SD = 15 for means) - Sample size: 25 - Animation speed: moderate</p> <p>Behavior: - When sample is taken, show dots being selected from population - Calculate sample statistic and briefly display it - Add statistic to histogram with animation - Update running mean and SD of sampling distribution - As more samples accumulate, show histogram becoming smoother and more normal-shaped</p> <p>Instructional Rationale: Step-through demonstration is appropriate because students need to see the process of sampling and statistic calculation repeatedly to understand that the sampling distribution emerges from aggregating many sample statistics. The ability to control pace (1, 10, or 100 samples) lets students observe both individual variation and the overall pattern.</p> <p>Implementation: p5.js with responsive canvas sizing</p>"},{"location":"chapters/14-sampling-distributions/#sample-proportion-and-its-sampling-distribution","title":"Sample Proportion and Its Sampling Distribution","text":"<p>When we're dealing with categorical data, we often want to estimate the proportion of a population that has a certain characteristic. The sample proportion, denoted \\( \\hat{p} \\) (read as \"p-hat\"), is calculated as:</p> \\[ \\hat{p} = \\frac{\\text{number of successes}}{n} \\] <p>where \\( n \\) is the sample size and \"success\" refers to the outcome we're counting.</p> <p>For example, if you survey 200 students and 124 say they prefer morning classes, then:</p> \\[ \\hat{p} = \\frac{124}{200} = 0.62 \\]"},{"location":"chapters/14-sampling-distributions/#the-sampling-distribution-of-the-sample-proportion","title":"The Sampling Distribution of the Sample Proportion","text":"<p>Now here's where it gets exciting! If we could take many, many samples of size \\( n \\) from a population with true proportion \\( p \\), the sampling distribution of \\( \\hat{p} \\) has these remarkable properties:</p> <p>Center (Mean of \\( \\hat{p} \\)):</p> \\[ \\mu_{\\hat{p}} = p \\] <p>The mean of the sampling distribution equals the population proportion! This tells us that \\( \\hat{p} \\) is an unbiased estimator of \\( p \\)\u2014on average, our sample proportion hits the target.</p> <p>Spread (Standard Deviation of \\( \\hat{p} \\)):</p> \\[ \\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}} \\] <p>This formula reveals something profound: larger samples have smaller standard deviations, meaning less variability in our estimates. This is why pollsters survey 1,000 people instead of 100!</p> Sample Size \\( n \\) Standard Deviation (when \\( p = 0.5 \\)) 25 0.100 100 0.050 400 0.025 1,600 0.0125 <p>Notice the pattern: to cut the standard deviation in half, you need to quadruple the sample size. This is because of the square root in the formula.</p>"},{"location":"chapters/14-sampling-distributions/#conditions-for-using-the-proportion-formula","title":"Conditions for Using the Proportion Formula","text":"<p>The standard deviation formula works when these conditions are met:</p> <ol> <li> <p>Independence Condition: Individual observations must be independent. This is satisfied when sampling is random and, if sampling without replacement, the sample size is less than 10% of the population (the \"10% condition\").</p> </li> <li> <p>Large Counts Condition: Both \\( np \\geq 10 \\) and \\( n(1-p) \\geq 10 \\). This ensures enough successes and failures for the normal approximation to work.</p> </li> </ol> <p>Why the 10% Rule?</p> <p>When we sample without replacement, each selection affects the probability of subsequent selections. However, when the sample is less than 10% of the population, this effect is negligible, and we can treat selections as approximately independent.</p>"},{"location":"chapters/14-sampling-distributions/#sample-mean-and-its-sampling-distribution","title":"Sample Mean and Its Sampling Distribution","text":"<p>When working with quantitative data, we often focus on the sample mean, denoted \\( \\bar{x} \\) (read as \"x-bar\"):</p> \\[ \\bar{x} = \\frac{\\sum x_i}{n} \\] <p>Just like the sample proportion, the sample mean has a sampling distribution with predictable properties.</p>"},{"location":"chapters/14-sampling-distributions/#properties-of-the-sampling-distribution-of-the-sample-mean","title":"Properties of the Sampling Distribution of the Sample Mean","text":"<p>Center (Mean of \\( \\bar{x} \\)):</p> \\[ \\mu_{\\bar{x}} = \\mu \\] <p>The mean of the sampling distribution equals the population mean. Like \\( \\hat{p} \\), the sample mean \\( \\bar{x} \\) is an unbiased estimator.</p> <p>Spread (Standard Deviation of \\( \\bar{x} \\)):</p> \\[ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} \\] <p>This quantity is sometimes called the standard error of the mean. Again, we see that larger samples lead to less variability\u2014the square root of \\( n \\) appears in the denominator.</p> <p>Let me give you a concrete example. Suppose SAT math scores have a population mean \\( \\mu = 500 \\) and standard deviation \\( \\sigma = 100 \\).</p> Sample Size Standard Deviation of \\( \\bar{x} \\) 1 100 25 20 100 10 400 5 <p>With one person, your \"sample mean\" is just their score\u2014wildly variable. But with 400 people, your sample mean will typically be within about 10 points (two standard errors) of the true mean.</p>"},{"location":"chapters/14-sampling-distributions/#diagram-standard-error-and-sample-size-explorer","title":"Diagram: Standard Error and Sample Size Explorer","text":"Standard Error and Sample Size Explorer <p>Type: microsim</p> <p>Learning Objective: Apply (L3) the relationship between sample size and standard error; demonstrate how increasing sample size reduces the variability of the sampling distribution</p> <p>Bloom Taxonomy Level: Apply (L3) Bloom Taxonomy Verb: demonstrate, calculate, apply</p> <p>Purpose: Allow students to interactively explore how sample size affects the spread of sampling distributions for both proportions and means</p> <p>Canvas layout: - Left side (60%): Graph showing sampling distribution curve - Right side (40%): Control panel and calculations</p> <p>Visual elements: - Normal curve representing the sampling distribution - Shaded region showing one standard error on each side of the mean - Numerical display of standard error calculation - Formula display with current values substituted</p> <p>Interactive controls: - Radio buttons: Choose \"Proportion\" or \"Mean\" - Slider: Sample size n (10 to 500) - For Proportion mode: Slider for p (0.1 to 0.9) - For Mean mode: Input for population standard deviation sigma (1 to 100) - Display: Current standard error with calculation breakdown</p> <p>Default parameters: - Mode: Proportion - p = 0.5 - n = 50 - sigma = 15 (for mean mode)</p> <p>Behavior: - As sample size increases, curve becomes narrower (less spread) - Standard error calculation updates in real-time - Show the formula with actual numbers substituted - Highlight that quadrupling n halves the standard error</p> <p>Instructional Rationale: This apply-level simulation lets students manipulate parameters and immediately see the effect on the sampling distribution. The focus on the formula with substituted values helps connect the abstract formula to concrete calculations.</p> <p>Implementation: p5.js with responsive canvas sizing</p>"},{"location":"chapters/14-sampling-distributions/#the-central-limit-theorem-the-crown-jewel-of-statistics","title":"The Central Limit Theorem: The Crown Jewel of Statistics","text":"<p>And now, my tail is absolutely tingling because we've arrived at the most important theorem in statistics: the Central Limit Theorem (CLT).</p> <p>Here's the amazing claim:</p> <p>The Central Limit Theorem</p> <p>For a random sample of size \\( n \\) from any population with mean \\( \\mu \\) and standard deviation \\( \\sigma \\), the sampling distribution of the sample mean \\( \\bar{x} \\) becomes approximately normal as \\( n \\) gets larger, regardless of the shape of the population distribution.</p> <p>Let that sink in. The population could be skewed, bimodal, uniform, or any shape whatsoever. It doesn't matter! If you take large enough samples, the distribution of sample means will be approximately normal.</p> <p>This is genuinely remarkable. It's like saying, \"No matter how chaotic the ingredients, the cake always comes out the same shape.\"</p>"},{"location":"chapters/14-sampling-distributions/#why-the-clt-matters","title":"Why the CLT Matters","text":"<p>The Central Limit Theorem is why we can:</p> <ul> <li>Use normal probability calculations for inference</li> <li>Construct confidence intervals</li> <li>Perform hypothesis tests</li> <li>Make predictions about sample statistics</li> </ul> <p>Without the CLT, we'd need to know the exact shape of every population we study\u2014an impossible task!</p>"},{"location":"chapters/14-sampling-distributions/#clt-conditions-when-does-it-apply","title":"CLT Conditions: When Does It Apply?","text":"<p>The Central Limit Theorem works when:</p> <ol> <li>Random sampling: Data must come from a random sample or randomized experiment</li> <li>Independence: Observations must be independent (10% condition for sampling without replacement)</li> <li>Sample size: \\( n \\) must be \"large enough\"</li> </ol> <p>What counts as \"large enough\"? Here's a practical guide:</p> Population Shape Minimum Sample Size Already normal Any size works Slightly skewed \\( n \\geq 15 \\) Moderately skewed \\( n \\geq 25 \\) Heavily skewed \\( n \\geq 40 \\) Extremely skewed or outliers May need \\( n \\geq 100 \\) <p>The more skewed or unusual the population, the larger the sample you need for the sampling distribution to become approximately normal.</p>"},{"location":"chapters/14-sampling-distributions/#diagram-central-limit-theorem-demonstration","title":"Diagram: Central Limit Theorem Demonstration","text":"Central Limit Theorem Demonstration <p>Type: microsim</p> <p>Learning Objective: Analyze (L4) how the Central Limit Theorem transforms non-normal population distributions into normal sampling distributions as sample size increases; compare sampling distributions across different population shapes</p> <p>Bloom Taxonomy Level: Analyze (L4) Bloom Taxonomy Verb: compare, examine, differentiate</p> <p>Purpose: Provide visual, interactive proof of the Central Limit Theorem by showing how sampling distributions become normal regardless of the population shape</p> <p>Canvas layout: - Top section (30%): Population distribution display - Middle section (50%): Sampling distribution histogram that builds dynamically - Bottom section (20%): Controls and statistics</p> <p>Visual elements: - Population distribution shown as histogram or smooth curve - Building histogram of sample means - Overlaid normal curve on sampling distribution for comparison - Statistics panel showing mean and SD of sampling distribution - Comparison of theoretical vs observed values</p> <p>Interactive controls: - Dropdown: Population shape (Uniform, Skewed Right, Skewed Left, Bimodal, Normal, U-shaped) - Slider: Sample size n (1, 2, 5, 10, 25, 50, 100) - Button: \"Take 1 Sample\" - Button: \"Take 100 Samples\" - Button: \"Take 1000 Samples\" - Button: \"Reset\" - Toggle: Show/hide normal overlay curve</p> <p>Default parameters: - Population: Skewed Right - Sample size: n = 1 - Show normal overlay: On</p> <p>Behavior: - When n = 1, sampling distribution matches population shape - As n increases, sampling distribution becomes more bell-shaped - Normal overlay helps students see how close to normal the distribution is - Display theoretical mean and SD alongside observed values - Color coding: population in one color, sampling distribution in another</p> <p>Data Visibility Requirements: - Stage 1: Show population distribution clearly labeled - Stage 2: Show individual sample being drawn (highlight selected values) - Stage 3: Show calculation of sample mean for that sample - Stage 4: Show sample mean being added to histogram - Stage 5: As samples accumulate, show histogram converging to normal</p> <p>Instructional Rationale: The power of this simulation is letting students see the CLT in action. Starting with n=1 (where sampling distribution matches population) and gradually increasing n shows the transformation process. The analyze-level objective is supported by comparing different population shapes and sample sizes.</p> <p>Implementation: p5.js with responsive canvas sizing; pre-defined population distributions</p>"},{"location":"chapters/14-sampling-distributions/#the-clt-for-proportions","title":"The CLT for Proportions","text":"<p>The Central Limit Theorem also applies to sample proportions! When the conditions are met, the sampling distribution of \\( \\hat{p} \\) is approximately normal with:</p> <ul> <li>Mean: \\( \\mu_{\\hat{p}} = p \\)</li> <li>Standard deviation: \\( \\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}} \\)</li> </ul> <p>The conditions for the normal approximation for proportions are:</p> <ol> <li>Random sample</li> <li>Independence (10% condition)</li> <li>Large counts: \\( np \\geq 10 \\) and \\( n(1-p) \\geq 10 \\)</li> </ol> <p>The large counts condition ensures we have enough \"successes\" and \"failures\" for the normal approximation to work well.</p>"},{"location":"chapters/14-sampling-distributions/#normal-approximation-in-practice","title":"Normal Approximation in Practice","text":"<p>Once we know a sampling distribution is approximately normal, we can use z-scores to find probabilities! This is called the normal approximation.</p>"},{"location":"chapters/14-sampling-distributions/#for-sample-proportions","title":"For Sample Proportions","text":"<p>If the conditions are met, we can calculate:</p> \\[ z = \\frac{\\hat{p} - p}{\\sqrt{\\frac{p(1-p)}{n}}} \\] <p>This z-score tells us how many standard errors our sample proportion is from the population proportion.</p>"},{"location":"chapters/14-sampling-distributions/#for-sample-means","title":"For Sample Means","text":"<p>Similarly, for sample means:</p> \\[ z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\]"},{"location":"chapters/14-sampling-distributions/#worked-example-polling-for-an-election","title":"Worked Example: Polling for an Election","text":"<p>Let's work through a realistic example. Suppose 52% of voters in a large city support a ballot measure. A polling organization surveys a random sample of 400 voters.</p> <p>Question: What's the probability that the sample proportion supporting the measure is less than 50%?</p> <p>Step 1: Check conditions</p> <ul> <li>Random sample: Given</li> <li>Independence: 400 is less than 10% of the city's voters</li> <li>Large counts: \\( np = 400(0.52) = 208 \\geq 10 \\) and \\( n(1-p) = 400(0.48) = 192 \\geq 10 \\)</li> </ul> <p>Step 2: Find mean and standard deviation of sampling distribution</p> \\[ \\mu_{\\hat{p}} = 0.52 \\] \\[ \\sigma_{\\hat{p}} = \\sqrt{\\frac{0.52(0.48)}{400}} = \\sqrt{\\frac{0.2496}{400}} = 0.025 \\] <p>Step 3: Calculate z-score</p> \\[ z = \\frac{0.50 - 0.52}{0.025} = \\frac{-0.02}{0.025} = -0.80 \\] <p>Step 4: Find probability using normal distribution</p> <p>Using a z-table or calculator: \\( P(Z &lt; -0.80) \\approx 0.212 \\)</p> <p>Interpretation: Even though the true proportion is 52%, there's about a 21% chance that a random sample of 400 voters will show less than 50% support. This illustrates why close elections are so hard to predict!</p> <p>Sylvia Says</p> <p>Acorn for your thoughts? This example shows why sample size matters. If the pollster surveyed 1,600 voters instead of 400, the standard error would be half as large (0.0125 instead of 0.025), making it much less likely to get a misleading result.</p>"},{"location":"chapters/14-sampling-distributions/#statistical-inference-connecting-samples-to-populations","title":"Statistical Inference: Connecting Samples to Populations","text":"<p>Everything we've learned in this chapter builds toward statistical inference\u2014the process of using sample data to make conclusions about population parameters.</p> <p>There are two main types of statistical inference:</p> <ol> <li>Confidence Intervals: Estimating a parameter with a range of plausible values</li> <li>Hypothesis Testing: Evaluating claims about a parameter</li> </ol> <p>Both rely critically on understanding sampling distributions! Here's why:</p> <ul> <li>When we construct a confidence interval, we need to know how much sample statistics typically vary (the standard error)</li> <li>When we perform a hypothesis test, we need to know how likely our observed result would be if the null hypothesis were true (requires knowing the sampling distribution)</li> </ul> <p>The sampling distribution is the bridge between our single sample and the population we're trying to understand.</p>"},{"location":"chapters/14-sampling-distributions/#diagram-statistical-inference-workflow","title":"Diagram: Statistical Inference Workflow","text":"Statistical Inference Workflow <p>Type: infographic</p> <p>Learning Objective: Understand (L2) how sampling distributions enable statistical inference; explain the connection between sample statistics, sampling distributions, and population parameters</p> <p>Bloom Taxonomy Level: Understand (L2) Bloom Taxonomy Verb: explain, summarize</p> <p>Purpose: Provide a visual roadmap showing how sample data, sampling distributions, and population parameters connect in the inference process</p> <p>Layout: Flowchart style with three main stages arranged vertically or horizontally</p> <p>Components: 1. Population box (top or left):    - Label: \"Population\"    - Contains parameter symbols (p or mu)    - Text: \"Unknown - what we want to learn about\"    - Color: Green (Sylvia's cardigan color)</p> <ol> <li>Sample box (middle):</li> <li>Label: \"Sample (n)\"</li> <li>Shows data collection arrow from population</li> <li>Contains statistic symbols (p-hat or x-bar)</li> <li>Text: \"Observed - what we can measure\"</li> <li> <p>Color: Auburn (Sylvia's fur color)</p> </li> <li> <p>Sampling Distribution box (central, larger):</p> </li> <li>Shows normal curve</li> <li>Labels for mean and standard error</li> <li>Text: \"Theoretical - describes how statistics vary\"</li> <li>Connects sample to population via CLT</li> <li> <p>Color: Light green background</p> </li> <li> <p>Inference arrows:</p> </li> <li>Confidence Interval arrow: points from sample toward population</li> <li>Hypothesis Test arrow: compares sample to claimed population value</li> </ol> <p>Interactive elements: - Hover over each component to reveal detailed explanation - Click on \"Confidence Interval\" to highlight that path - Click on \"Hypothesis Test\" to highlight that path - Tooltips explain each concept</p> <p>Color scheme: Use Sylvia color palette (green, auburn, cream)</p> <p>Implementation: HTML/CSS/JavaScript with SVG elements and interactive hover/click events</p>"},{"location":"chapters/14-sampling-distributions/#sample-size-determination-for-confidence-intervals","title":"Sample Size Determination for Confidence Intervals","text":"<p>Looking ahead to confidence intervals (coming up in the next chapter!), the sample size directly affects how precise our estimates can be. The margin of error in a confidence interval depends on:</p> \\[ \\text{Margin of Error} = z^* \\times \\text{Standard Error} \\] <p>Since the standard error decreases as \\( n \\) increases, larger samples give smaller margins of error and more precise estimates.</p>"},{"location":"chapters/14-sampling-distributions/#sample-size-formula-for-proportions","title":"Sample Size Formula for Proportions","text":"<p>If you want a specific margin of error \\( E \\) for a proportion at a given confidence level, you can solve for the required sample size:</p> \\[ n = \\left( \\frac{z^*}{E} \\right)^2 \\times p(1-p) \\] <p>If you don't know \\( p \\) in advance, use \\( p = 0.5 \\) (which maximizes the sample size, giving a conservative estimate).</p> <p>Example: How many people should you survey to estimate a proportion within 3 percentage points (E = 0.03) with 95% confidence?</p> <p>Using \\( z^* = 1.96 \\) for 95% confidence and \\( p = 0.5 \\):</p> \\[ n = \\left( \\frac{1.96}{0.03} \\right)^2 \\times 0.5(0.5) = (65.33)^2 \\times 0.25 = 4268.4(0.25) \\approx 1067 \\] <p>You'd need about 1,067 people to achieve that precision.</p> Desired Margin of Error Sample Size Needed (95% confidence) 5% (0.05) 385 4% (0.04) 601 3% (0.03) 1,068 2% (0.02) 2,401 1% (0.01) 9,604 <p>This table explains why national polls typically survey around 1,000-1,500 people\u2014that's enough for a margin of error around 3%, which is acceptable for most purposes.</p> <p>Cost-Benefit of Larger Samples</p> <p>Notice the diminishing returns: going from 3% to 2% margin of error requires more than doubling your sample size (from ~1,000 to ~2,400). At some point, the extra precision isn't worth the extra cost!</p>"},{"location":"chapters/14-sampling-distributions/#putting-it-all-together-a-complete-example","title":"Putting It All Together: A Complete Example","text":"<p>Let's work through a comprehensive example that uses everything from this chapter.</p> <p>Scenario: A factory produces light bulbs with a mean lifetime of 1,200 hours and standard deviation of 100 hours. Quality control randomly selects 64 bulbs to test.</p> <p>Question 1: What are the mean and standard deviation of the sampling distribution of the sample mean lifetime?</p> \\[ \\mu_{\\bar{x}} = \\mu = 1200 \\text{ hours} \\] \\[ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{100}{\\sqrt{64}} = \\frac{100}{8} = 12.5 \\text{ hours} \\] <p>Question 2: Can we assume the sampling distribution is approximately normal? Why?</p> <p>Yes! By the Central Limit Theorem, with \\( n = 64 \\), the sampling distribution of \\( \\bar{x} \\) will be approximately normal regardless of the population shape. Even if individual bulb lifetimes aren't normally distributed, the mean of 64 bulbs will be.</p> <p>Question 3: What's the probability that the sample mean is between 1,190 and 1,210 hours?</p> <p>First, calculate z-scores:</p> \\[ z_1 = \\frac{1190 - 1200}{12.5} = \\frac{-10}{12.5} = -0.80 \\] \\[ z_2 = \\frac{1210 - 1200}{12.5} = \\frac{10}{12.5} = 0.80 \\] <p>Using normal probability:</p> \\[ P(-0.80 &lt; Z &lt; 0.80) = P(Z &lt; 0.80) - P(Z &lt; -0.80) \\approx 0.788 - 0.212 = 0.576 \\] <p>There's about a 58% chance the sample mean falls within 10 hours of the true mean.</p> <p>Question 4: What's the probability that the sample mean is less than 1,175 hours?</p> \\[ z = \\frac{1175 - 1200}{12.5} = \\frac{-25}{12.5} = -2.00 \\] \\[ P(Z &lt; -2.00) \\approx 0.023 \\] <p>Only about a 2.3% chance! If the sample mean actually came out this low, quality control might suspect a problem with the production process.</p>"},{"location":"chapters/14-sampling-distributions/#diagram-light-bulb-sampling-distribution-calculator","title":"Diagram: Light Bulb Sampling Distribution Calculator","text":"Sampling Distribution Calculator <p>Type: microsim</p> <p>Learning Objective: Apply (L3) sampling distribution concepts to calculate probabilities; practice using z-scores with sampling distributions</p> <p>Bloom Taxonomy Level: Apply (L3) Bloom Taxonomy Verb: calculate, solve, apply</p> <p>Purpose: Interactive calculator for finding probabilities involving sample means or proportions, with visual feedback</p> <p>Canvas layout: - Top section (30%): Input parameters - Middle section (50%): Normal curve with shaded region - Bottom section (20%): Results and calculations</p> <p>Visual elements: - Normal distribution curve representing the sampling distribution - Shaded region showing the probability being calculated - Labels for mean and standard error on the curve - Step-by-step calculation display</p> <p>Interactive controls: - Radio buttons: \"Sample Mean\" or \"Sample Proportion\" - For Mean: Inputs for population mean (mu), population SD (sigma), sample size (n) - For Proportion: Inputs for population proportion (p), sample size (n) - Dropdown: Probability type (less than, greater than, between) - Input fields: Cutoff value(s) - Button: \"Calculate\"</p> <p>Default parameters: - Mode: Sample Mean - mu = 1200 - sigma = 100 - n = 64 - Probability: less than 1175</p> <p>Behavior: - Display calculation steps: \"Step 1: Find standard error\", \"Step 2: Calculate z-score\", \"Step 3: Find probability\" - Show the formula with values substituted - Animate the shaded region on the curve - Display final probability prominently</p> <p>Instructional Rationale: This apply-level tool provides scaffolded practice for probability calculations. Showing each step explicitly helps students learn the process while getting immediate feedback on their understanding.</p> <p>Implementation: p5.js with responsive canvas sizing</p>"},{"location":"chapters/14-sampling-distributions/#common-misconceptions-to-avoid","title":"Common Misconceptions to Avoid","text":"<p>Before we wrap up, let's address some common mistakes students make with sampling distributions. Even experienced squirrels slip up sometimes!</p> <p>Misconception 1: \"A larger sample means a larger standard deviation.\"</p> <p>Reality: It's the opposite! Larger samples give smaller standard errors because there's less variability in the sampling distribution.</p> <p>Misconception 2: \"The Central Limit Theorem says the population becomes normal.\"</p> <p>Reality: The CLT says the sampling distribution of the mean becomes normal. The population's shape doesn't change at all.</p> <p>Misconception 3: \"We need the population to be normal for inference to work.\"</p> <p>Reality: Thanks to the CLT, we only need a large enough sample. The population can be any shape.</p> <p>Misconception 4: \"The standard deviation and standard error are the same thing.\"</p> <p>Reality: The standard deviation measures spread of individual values. The standard error measures spread of sample statistics. They're related but different:</p> \\[ \\text{Standard Error} = \\frac{\\text{Standard Deviation}}{\\sqrt{n}} \\] <p>Misconception 5: \"A sample proportion of 0.60 means the population proportion is 0.60.\"</p> <p>Reality: The sample proportion is an estimate of the population proportion. Due to sampling variability, it may not equal the true value exactly.</p>"},{"location":"chapters/14-sampling-distributions/#summary-time-to-squirrel-away-this-knowledge","title":"Summary: Time to Squirrel Away This Knowledge!","text":"<p>Congratulations! You've just learned some of the most foundational concepts in statistical inference. Let's recap the big ideas:</p> <p>Key Concepts:</p> <ul> <li>Sampling variability is the natural variation in statistics from sample to sample</li> <li>A sampling distribution shows the pattern of how a statistic varies across all possible samples</li> <li>The sample proportion \\( \\hat{p} \\) and sample mean \\( \\bar{x} \\) are unbiased estimators of their population parameters</li> <li>The standard error measures variability in the sampling distribution and decreases as sample size increases</li> <li>The Central Limit Theorem states that sampling distributions of means become approximately normal for large samples, regardless of population shape</li> <li>For proportions, the normal approximation requires the large counts condition (\\( np \\geq 10 \\) and \\( n(1-p) \\geq 10 \\))</li> <li>Sampling distributions are the foundation for statistical inference\u2014confidence intervals and hypothesis tests</li> </ul> <p>Key Formulas:</p> Statistic Mean of Sampling Distribution Standard Error \\( \\hat{p} \\) \\( \\mu_{\\hat{p}} = p \\) \\( \\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}} \\) \\( \\bar{x} \\) \\( \\mu_{\\bar{x}} = \\mu \\) \\( \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} \\) <p>The Big Picture:</p> <p>Sampling distributions connect what we observe (sample statistics) to what we want to know (population parameters). The CLT guarantees that with large enough samples, we can use normal probability calculations to quantify our uncertainty and make inferences about populations.</p> <p>You've Got This!</p> <p>Look at you go! You just learned something that took statisticians centuries to figure out. The Central Limit Theorem is one of the most beautiful results in mathematics, and now you understand why it's so powerful. My tail's puffing up with pride!</p>"},{"location":"chapters/14-sampling-distributions/#practice-problems","title":"Practice Problems","text":"Problem 1: Checking Conditions <p>A researcher wants to estimate the proportion of households in a city that have solar panels. She plans to survey 150 randomly selected households.</p> <p>a) If the true proportion is 0.08, can she use the normal approximation for the sampling distribution of \\( \\hat{p} \\)?</p> <p>b) What if the true proportion were 0.15?</p> <p>Click to reveal answer</p> <p>a) Check: \\( np = 150(0.08) = 12 \\geq 10 \\) \u2713, but \\( n(1-p) = 150(0.92) = 138 \\geq 10 \\) \u2713. Yes, conditions are met!</p> <p>b) \\( np = 150(0.15) = 22.5 \\geq 10 \\) \u2713 and \\( n(1-p) = 150(0.85) = 127.5 \\geq 10 \\) \u2713. Yes, conditions are also met.</p> Problem 2: Sample Mean Probabilities <p>The weights of apples from an orchard have a mean of 150 grams and standard deviation of 25 grams. A sample of 100 apples is selected.</p> <p>a) What are the mean and standard error of the sampling distribution of \\( \\bar{x} \\)?</p> <p>b) What is the probability that the sample mean weight is greater than 155 grams?</p> <p>Click to reveal answer</p> <p>a) Mean: \\( \\mu_{\\bar{x}} = 150 \\) grams; Standard error: \\( \\sigma_{\\bar{x}} = \\frac{25}{\\sqrt{100}} = 2.5 \\) grams</p> <p>b) \\( z = \\frac{155 - 150}{2.5} = 2.0 \\); \\( P(Z &gt; 2.0) = 1 - 0.977 = 0.023 \\), or about 2.3%</p> Problem 3: Sample Size Calculation <p>A political campaign wants to estimate support for their candidate within 2 percentage points (margin of error) with 95% confidence. How many voters should they survey? (Use \\( p = 0.5 \\) for planning.)</p> <p>Click to reveal answer</p> <p>Using the formula: \\( n = \\left(\\frac{1.96}{0.02}\\right)^2 \\times 0.5(0.5) = (98)^2 \\times 0.25 = 9604 \\times 0.25 = 2401 \\)</p> <p>They need to survey about 2,401 voters.</p> Problem 4: Understanding the CLT <p>Explain why a marketing researcher can use normal probability calculations to find the probability that the sample mean income of 50 randomly selected customers exceeds $60,000, even though income distributions are typically right-skewed.</p> <p>Click to reveal answer</p> <p>By the Central Limit Theorem, the sampling distribution of the sample mean becomes approximately normal for sufficiently large samples (typically n \u2265 30 for moderately skewed populations), regardless of the shape of the population distribution. Since n = 50, the sampling distribution of the sample mean income will be approximately normal, even though individual incomes are right-skewed. This allows us to use z-scores and the normal distribution to calculate probabilities.</p>"},{"location":"chapters/14-sampling-distributions/#looking-ahead","title":"Looking Ahead","text":"<p>In the next chapter, we'll put sampling distributions to work! We'll learn how to construct confidence intervals\u2014ranges of plausible values for population parameters based on sample data. Everything we learned about standard errors and the normal approximation will be essential.</p> <p>Until then, keep collecting those data points, and remember\u2014every sample tells a story about the population it came from!</p>"},{"location":"chapters/15-confidence-intervals/","title":"Confidence Intervals","text":""},{"location":"chapters/15-confidence-intervals/#summary","title":"Summary","text":"<p>This chapter introduces confidence intervals as a method of estimation in statistical inference. Students will learn to construct and interpret confidence intervals for proportions, understand margin of error and confidence level, and determine appropriate sample sizes. Confidence intervals quantify the uncertainty inherent in using sample data to estimate population parameters.</p>"},{"location":"chapters/15-confidence-intervals/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 17 concepts from the learning graph:</p> <ol> <li>Point Estimate</li> <li>Interval Estimate</li> <li>Confidence Interval</li> <li>Margin of Error</li> <li>Confidence Level</li> <li>Interpreting Confidence</li> <li>Critical Value</li> <li>Z Critical Values</li> <li>Standard Error</li> <li>CI for One Proportion</li> <li>Conditions for CI Proportion</li> <li>Interpreting CI</li> <li>CI Width Factors</li> <li>CI for Difference in Props</li> <li>Pooled Proportion</li> <li>Factors Affecting Power</li> </ol>"},{"location":"chapters/15-confidence-intervals/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 5: Standardization and Normal Distributions</li> <li>Chapter 14: Sampling Distributions</li> </ul>"},{"location":"chapters/15-confidence-intervals/#introduction-from-sample-to-population","title":"Introduction: From Sample to Population","text":"<p>Welcome back, statistics explorers! In the last chapter, we discovered something remarkable: when you take many random samples from a population, the sample proportions form a beautiful, predictable pattern called a sampling distribution. Now we're going to use that knowledge for something incredibly practical: making educated guesses about an entire population based on just one sample.</p> <p>Think about it this way. Imagine you're trying to figure out what percentage of students at your school prefer online learning. You can't ask all 2,000 students (that would take forever!), so you survey 100 randomly selected students and find that 62% prefer online learning. But here's the million-dollar question: Is the true proportion for the whole school exactly 62%? Probably not exactly, right? So what is it?</p> <p>This is where confidence intervals come to the rescue. Instead of claiming a single number, we'll learn to say something like: \"We're 95% confident that between 52% and 72% of all students prefer online learning.\" That interval captures the uncertainty in our estimate while still giving us useful information.</p> <p>Sylvia Says</p> <p>\"Let's crack this nut! Confidence intervals are one of the most powerful tools in statistics. They help us be honest about what we don't know while still making meaningful claims about what we've learned. My tail's tingling - we're onto something big here!\"</p>"},{"location":"chapters/15-confidence-intervals/#point-estimates-your-best-single-guess","title":"Point Estimates: Your Best Single Guess","text":"<p>When we use sample data to estimate a population parameter, we call that estimate a point estimate. It's a single value that represents our best guess about the true population value.</p> <p>For proportions, the point estimate is simply the sample proportion, denoted \\(\\hat{p}\\) (read as \"p-hat\"). If 62 out of 100 surveyed students prefer online learning, then:</p> \\[ \\hat{p} = \\frac{62}{100} = 0.62 \\] <p>The sample proportion \\(\\hat{p}\\) is our best single guess for the true population proportion \\(p\\).</p> <p>Here are common point estimates you'll encounter:</p> Population Parameter Point Estimate Symbol Population proportion Sample proportion \\(\\hat{p}\\) Population mean Sample mean \\(\\bar{x}\\) Population standard deviation Sample standard deviation \\(s\\) <p>Point estimates are useful, but they have a significant limitation: they give us no information about how accurate they might be. That 62% could be spot-on, or it could be quite far from the truth. We need something more.</p>"},{"location":"chapters/15-confidence-intervals/#interval-estimates-embracing-uncertainty","title":"Interval Estimates: Embracing Uncertainty","text":"<p>An interval estimate provides a range of plausible values for the population parameter. Instead of a single number, we give a lower bound and an upper bound that we believe captures the true parameter value.</p> <p>The key insight here is that interval estimates acknowledge the reality of sampling variability. Every random sample gives slightly different results, so rather than pretending we know the exact truth, we embrace uncertainty by providing a range.</p> <p>Think of it like estimating your arrival time for a road trip. You could say \"I'll arrive at 3:47 PM\" (a point estimate), but it's more realistic to say \"I'll arrive between 3:30 and 4:00 PM\" (an interval estimate). The interval acknowledges that traffic, weather, and other factors create uncertainty.</p>"},{"location":"chapters/15-confidence-intervals/#diagram-point-estimate-vs-interval-estimate","title":"Diagram: Point Estimate vs Interval Estimate","text":"Point Estimate vs Interval Estimate Visualization <p>Type: microsim</p> <p>Bloom Level: Understand (L2) Bloom Verb: Compare, contrast</p> <p>Learning Objective: Help students visualize the difference between a point estimate (single value) and an interval estimate (range of values) for a population parameter.</p> <p>Visual Elements: - A horizontal number line representing possible values of a population proportion (0 to 1) - A vertical line marking the \"true\" population parameter (hidden initially, revealed on toggle) - A single dot representing the point estimate (sample proportion) - A horizontal bar/bracket representing the interval estimate (confidence interval) - Multiple sample scenarios to cycle through</p> <p>Interactive Controls: - \"New Sample\" button: generates a new random sample, showing new point estimate and interval - Toggle: \"Show True Parameter\" to reveal where the true value actually is - Counter showing: \"X out of Y intervals captured the true parameter\"</p> <p>Default Parameters: - True population proportion: 0.65 (hidden initially) - Sample size: n = 100 - Confidence level: 95%</p> <p>Behavior: - Each \"New Sample\" generates a new sample proportion and corresponding interval - Point estimate appears as a single colored dot - Interval appears as a horizontal bracket extending from the point estimate - When true parameter is shown, intervals that capture it turn green, those that miss turn red - Running count tracks the capture rate</p> <p>Instructional Rationale: Visual comparison helps students understand why intervals provide more useful information than point estimates alone. The reveal feature demonstrates that intervals usually (but not always) capture the true value.</p> <p>Implementation: p5.js with canvas-based controls Canvas size: 600 x 400 (responsive)</p>"},{"location":"chapters/15-confidence-intervals/#confidence-intervals-the-complete-package","title":"Confidence Intervals: The Complete Package","text":"<p>A confidence interval is a specific type of interval estimate that comes with a stated confidence level (usually 90%, 95%, or 99%). The confidence level tells us how confident we are that our interval-building method will capture the true parameter.</p> <p>The general formula for a confidence interval is:</p> \\[ \\text{Point Estimate} \\pm \\text{Margin of Error} \\] <p>Or equivalently:</p> \\[ (\\text{Point Estimate} - \\text{Margin of Error}, \\text{Point Estimate} + \\text{Margin of Error}) \\] <p>For a population proportion, this becomes:</p> \\[ \\hat{p} \\pm z^* \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\] <p>Let's break down each piece of this formula:</p> <ul> <li>\\(\\hat{p}\\) is the sample proportion (our point estimate)</li> <li>\\(z^*\\) is the critical value (we'll discuss this soon)</li> <li>\\(\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) is the standard error of the sample proportion</li> <li>\\(z^* \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) is the margin of error</li> </ul> <p>Sylvia's Study Tip</p> <p>\"I like to think of confidence intervals as putting a 'safety net' around my point estimate. The margin of error is the width of that net - wider nets catch more fish (or in our case, are more likely to catch the true parameter), but they're also less precise!\"</p>"},{"location":"chapters/15-confidence-intervals/#understanding-margin-of-error","title":"Understanding Margin of Error","text":"<p>The margin of error quantifies the maximum expected difference between the point estimate and the true population parameter. It represents the \"plus or minus\" part of our confidence interval.</p> <p>Margin of error depends on three factors:</p> <ol> <li>Confidence level: Higher confidence = larger margin of error</li> <li>Sample size: Larger sample = smaller margin of error</li> <li>Variability in the data: More variability = larger margin of error</li> </ol> <p>For a proportion, the margin of error formula is:</p> \\[ \\text{ME} = z^* \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\] <p>When you hear poll results like \"The candidate has 48% support with a margin of error of 3 percentage points,\" that means the confidence interval is 48% +/- 3%, or roughly 45% to 51%.</p>"},{"location":"chapters/15-confidence-intervals/#diagram-margin-of-error-components","title":"Diagram: Margin of Error Components","text":"Margin of Error Explorer MicroSim <p>Type: microsim</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Examine, differentiate</p> <p>Learning Objective: Students will analyze how changes in confidence level, sample size, and sample proportion affect the margin of error and resulting confidence interval width.</p> <p>Visual Elements: - Central display showing a confidence interval on a number line (0 to 1) - Point estimate marked as a dot - Margin of error shown as brackets extending from the point estimate - Real-time calculation display showing the formula with current values highlighted - Visual indicators of what's changing (pulsing effect on modified components)</p> <p>Interactive Controls (canvas-based): - Slider: Confidence Level (80% to 99%, default 95%) - Slider: Sample Size n (20 to 500, default 100) - Slider: Sample Proportion (0.1 to 0.9, default 0.50) - Display panel showing:   - Current ME value   - Current CI bounds   - z* value for selected confidence level</p> <p>Default Parameters: - Confidence level: 95% (z* = 1.96) - Sample size: n = 100 - Sample proportion: 0.50</p> <p>Behavior: - As confidence level increases, z* increases, ME increases, interval widens - As sample size increases, standard error decreases, ME decreases, interval narrows - As sample proportion moves toward 0.5, standard error increases (maximum variability) - As sample proportion moves toward 0 or 1, standard error decreases - Formula display updates in real-time with current values</p> <p>Data Visibility Requirements: - Stage 1: Show current parameter values - Stage 2: Show z* value and how it relates to confidence level - Stage 3: Show standard error calculation with current values - Stage 4: Show margin of error calculation - Stage 5: Show final confidence interval bounds</p> <p>Instructional Rationale: Interactive sliders allow students to develop intuition about the relationships between components through experimentation rather than memorization.</p> <p>Implementation: p5.js with canvas-based sliders and displays Canvas size: 650 x 450 (responsive)</p>"},{"location":"chapters/15-confidence-intervals/#confidence-level-what-does-95-really-mean","title":"Confidence Level: What Does 95% Really Mean?","text":"<p>The confidence level is one of the most misunderstood concepts in statistics. Let's make sure you understand it correctly.</p> <p>When we say we have a \"95% confidence interval,\" we do NOT mean:</p> <ul> <li>There's a 95% chance the true parameter is in this specific interval</li> <li>95% of the data falls within this interval</li> <li>We're 95% sure we're right</li> </ul> <p>What we DO mean:</p> <p>If we were to repeat our sampling process many, many times and construct a confidence interval each time, approximately 95% of those intervals would contain the true population parameter.</p> <p>It's about the reliability of the METHOD, not the probability for any single interval.</p> <p>Here's an analogy: Imagine a basketball player who makes 95% of their free throws. Before they shoot any particular free throw, we're confident in their ability (the method), but we can't say there's a 95% chance THIS specific shot goes in - it either will or it won't. Similarly, our confidence interval either contains the true parameter or it doesn't. The 95% describes how often the method works in the long run.</p> Confidence Level Meaning 90% 90 out of 100 intervals would capture the true parameter 95% 95 out of 100 intervals would capture the true parameter 99% 99 out of 100 intervals would capture the true parameter"},{"location":"chapters/15-confidence-intervals/#diagram-confidence-level-demonstration","title":"Diagram: Confidence Level Demonstration","text":"Confidence Level Simulator MicroSim <p>Type: microsim</p> <p>Bloom Level: Understand (L2) Bloom Verb: Interpret, explain</p> <p>Learning Objective: Students will understand the true meaning of confidence level by observing that approximately X% of confidence intervals capture the true parameter when many samples are taken.</p> <p>Visual Elements: - A vertical line on the left representing the true population parameter (p = 0.60) - Multiple horizontal confidence intervals stacked vertically (up to 100) - Green intervals: those that capture the true parameter - Red intervals: those that miss the true parameter - Running counter: \"X of Y intervals contain the true parameter (Z%)\" - Distribution of sample proportions shown at bottom (optional toggle)</p> <p>Interactive Controls (canvas-based): - \"Generate 1 Sample\" button: adds one confidence interval - \"Generate 10 Samples\" button: adds 10 confidence intervals - \"Generate 100 Samples\" button: shows all 100 intervals - \"Reset\" button: clears all intervals - Slider: Confidence Level (90%, 95%, 99%) - Display showing current capture rate vs expected rate</p> <p>Default Parameters: - True population proportion: p = 0.60 - Sample size: n = 50 - Confidence level: 95% - Starting intervals: 0</p> <p>Behavior: - Each new sample generates a random sample from the population - Calculate sample proportion and confidence interval - Display interval horizontally, green if it contains 0.60, red if not - Update running counter - After many samples, capture rate should approach the confidence level</p> <p>Instructional Rationale: Simulation makes the abstract concept of \"long-run frequency\" concrete. Students see that individual intervals either hit or miss, but the proportion of hits matches the confidence level.</p> <p>Implementation: p5.js with canvas-based controls Canvas size: 700 x 500 (responsive)</p> <p>Sylvia Says</p> <p>\"Acorn for your thoughts? Here's the key insight: once you've calculated a specific confidence interval, the true parameter is either in there or it isn't - we just don't know which! The confidence level tells us about the reliability of our interval-building process, not the probability for any single interval. Every statistician drops an acorn sometimes, and about 5% of 95% confidence intervals miss the mark!\"</p>"},{"location":"chapters/15-confidence-intervals/#critical-values-the-z-factor","title":"Critical Values: The z* Factor","text":"<p>The critical value (often written as \\(z^*\\)) is the number of standard errors we extend from our point estimate to create the desired confidence level. It comes from the standard normal distribution.</p> <p>For common confidence levels, the critical values are:</p> Confidence Level Critical Value \\(z^*\\) Interpretation 90% 1.645 Extend 1.645 standard errors each direction 95% 1.960 Extend 1.960 standard errors each direction 99% 2.576 Extend 2.576 standard errors each direction <p>Where do these numbers come from? They're the z-scores that capture the middle portion of the standard normal distribution:</p> <ul> <li>For 95% confidence, we want the middle 95% of the normal curve</li> <li>This leaves 2.5% in each tail</li> <li>The z-score that has 2.5% above it is 1.96</li> </ul> <p>You can find critical values using a z-table (looking for the z-score with the appropriate tail area) or using technology.</p>"},{"location":"chapters/15-confidence-intervals/#diagram-critical-values-on-the-normal-curve","title":"Diagram: Critical Values on the Normal Curve","text":"Critical Value Visualizer MicroSim <p>Type: microsim</p> <p>Bloom Level: Remember (L1) Bloom Verb: Identify, locate</p> <p>Learning Objective: Students will identify how critical values correspond to areas under the standard normal curve for different confidence levels.</p> <p>Visual Elements: - Standard normal distribution curve (bell curve) - Shaded middle region representing the confidence level - Unshaded tail regions - Vertical lines at -z and +z marking the critical values - Labels showing:   - z* values on x-axis   - Confidence level percentage in middle region   - Tail area percentages (alpha/2) in each tail - Area calculations displayed</p> <p>Interactive Controls (canvas-based): - Dropdown or buttons: Select confidence level (90%, 95%, 99%, or custom) - Slider for custom confidence level (80% to 99.9%) - Toggle: Show/hide exact area values</p> <p>Default Parameters: - Confidence level: 95% - z* = 1.96 - Middle area = 0.95, each tail = 0.025</p> <p>Behavior: - When confidence level changes:   - Critical values move inward (lower confidence) or outward (higher confidence)   - Shaded region expands or contracts   - Tail areas update   - z* value display updates - Animation shows smooth transition between confidence levels</p> <p>Instructional Rationale: Visual connection between the abstract critical value number and the actual area under the normal curve helps students remember and understand why we use these specific values.</p> <p>Implementation: p5.js with canvas-based controls Canvas size: 650 x 420 (responsive)</p>"},{"location":"chapters/15-confidence-intervals/#standard-error-measuring-sampling-variability","title":"Standard Error: Measuring Sampling Variability","text":"<p>The standard error is the standard deviation of the sampling distribution. It measures how much we expect sample statistics to vary from sample to sample.</p> <p>For a sample proportion, the standard error is:</p> \\[ SE_{\\hat{p}} = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\] <p>Notice that we use \\(\\hat{p}\\) (the sample proportion) in this formula because we typically don't know the true population proportion \\(p\\). This is slightly different from the standard deviation of the sampling distribution formula you learned in Chapter 14, which used \\(p\\).</p> <p>The standard error decreases as sample size increases, which makes intuitive sense: larger samples give us more information about the population and thus more reliable estimates.</p> <p>Here's how sample size affects standard error (assuming \\(\\hat{p} = 0.5\\)):</p> Sample Size (n) Standard Error 25 0.100 100 0.050 400 0.025 1600 0.0125 <p>Notice that to cut the standard error in half, you need to quadruple the sample size. This is because of the square root in the formula.</p> <p>Quick Tip</p> <p>The standard error is largest when \\(\\hat{p} = 0.5\\) and decreases as \\(\\hat{p}\\) moves toward 0 or 1. This is because variability is maximized when outcomes are evenly split.</p>"},{"location":"chapters/15-confidence-intervals/#constructing-a-confidence-interval-for-one-proportion","title":"Constructing a Confidence Interval for One Proportion","text":"<p>Now let's put it all together! To construct a confidence interval for a population proportion, follow these steps:</p> <p>Step 1: Check the conditions (we'll cover these in detail next)</p> <p>Step 2: Calculate the point estimate [ \\hat{p} = \\frac{x}{n} ] where \\(x\\) is the number of successes and \\(n\\) is the sample size.</p> <p>Step 3: Find the critical value \\(z^*\\) based on your confidence level</p> <p>Step 4: Calculate the standard error [ SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} ]</p> <p>Step 5: Calculate the margin of error [ ME = z^* \\cdot SE ]</p> <p>Step 6: Construct the interval [ (\\hat{p} - ME, \\hat{p} + ME) ]</p> <p>Example: A random sample of 200 registered voters found that 124 support a new tax proposal. Construct a 95% confidence interval for the true proportion of all registered voters who support the proposal.</p> <p>Solution:</p> <ul> <li>\\(\\hat{p} = \\frac{124}{200} = 0.62\\)</li> <li>For 95% confidence, \\(z^* = 1.96\\)</li> <li>\\(SE = \\sqrt{\\frac{0.62(1-0.62)}{200}} = \\sqrt{\\frac{0.62(0.38)}{200}} = \\sqrt{0.001178} \\approx 0.0343\\)</li> <li>\\(ME = 1.96 \\times 0.0343 \\approx 0.0672\\)</li> <li>CI: \\((0.62 - 0.0672, 0.62 + 0.0672) = (0.553, 0.687)\\)</li> </ul> <p>We are 95% confident that between 55.3% and 68.7% of all registered voters support the new tax proposal.</p>"},{"location":"chapters/15-confidence-intervals/#diagram-ci-construction-step-by-step","title":"Diagram: CI Construction Step-by-Step","text":"Confidence Interval Construction Walkthrough MicroSim <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate, execute</p> <p>Learning Objective: Students will practice constructing confidence intervals by working through each step of the calculation process with guided feedback.</p> <p>Visual Elements: - Step-by-step display panel showing all 6 steps - Input fields for sample data (x = successes, n = sample size) - Dropdown for confidence level selection - Calculation workspace showing formulas and values - Final confidence interval displayed on a number line - Progress indicator showing current step</p> <p>Interactive Controls (canvas-based): - Input: Number of successes (x) - Input: Sample size (n) - Dropdown: Confidence level (90%, 95%, 99%) - \"Calculate Step\" button to advance through each calculation - \"Show All Steps\" button to see complete solution - \"New Problem\" button to generate practice problems - Toggle: \"Check My Work\" mode for practice</p> <p>Default Parameters: - x = 124, n = 200 - Confidence level: 95% - Start at Step 1</p> <p>Behavior: - Step 1: Verify conditions (display success/failure counts) - Step 2: Calculate and display p-hat - Step 3: Look up and display z* - Step 4: Calculate and display SE with formula filled in - Step 5: Calculate and display ME - Step 6: Calculate and display final interval with number line visualization</p> <p>Data Visibility Requirements: - Each step shows the formula, substituted values, and result - Previous steps remain visible as new steps are revealed - Final summary shows all values together</p> <p>Instructional Rationale: Step-by-step scaffolding helps students learn the process before attempting calculations independently.</p> <p>Implementation: p5.js with canvas-based inputs and displays Canvas size: 700 x 520 (responsive)</p>"},{"location":"chapters/15-confidence-intervals/#conditions-for-constructing-a-ci-for-proportions","title":"Conditions for Constructing a CI for Proportions","text":"<p>Before constructing a confidence interval for a proportion, we must verify that certain conditions are met. These conditions ensure that the sampling distribution of \\(\\hat{p}\\) is approximately normal, which is necessary for our interval to be valid.</p> <p>The Three Conditions:</p> <ol> <li> <p>Random Sample: The data must come from a random sample or randomized experiment. This ensures the sample is representative of the population.</p> </li> <li> <p>Independence (10% Condition): When sampling without replacement, the sample size should be no more than 10% of the population size. This ensures that selecting one individual doesn't noticeably affect the probability of selecting another.    [    n \\leq 0.10N    ]    where \\(n\\) is sample size and \\(N\\) is population size.</p> </li> <li> <p>Large Counts (Success/Failure Condition): Both the number of successes and failures in the sample must be at least 10:    [    n\\hat{p} \\geq 10 \\quad \\text{and} \\quad n(1-\\hat{p}) \\geq 10    ]</p> </li> </ol> <p>The large counts condition ensures the sampling distribution is approximately normal. If this condition fails, the normal approximation doesn't work well, and our confidence interval won't be reliable.</p> <p>Example Check: For our voter example with \\(n = 200\\) and \\(\\hat{p} = 0.62\\):</p> <ul> <li>Random sample? Assume yes (stated in problem)</li> <li>Independence? If there are at least 2,000 registered voters, then 200 is at most 10% of the population. Check!</li> <li>Large counts?</li> <li>Successes: \\(200 \\times 0.62 = 124 \\geq 10\\) Check!</li> <li>Failures: \\(200 \\times 0.38 = 76 \\geq 10\\) Check!</li> </ul> <p>All conditions are satisfied.</p> <p>Condition Check Required</p> <p>On the AP exam, you must always verify conditions before constructing a confidence interval. Simply stating \"conditions met\" without showing the checks will cost you points!</p>"},{"location":"chapters/15-confidence-intervals/#interpreting-confidence-intervals-correctly","title":"Interpreting Confidence Intervals Correctly","text":"<p>How you interpret a confidence interval matters - a lot! Let's look at correct and incorrect interpretations.</p> <p>Correct Interpretation Template: \"We are [confidence level]% confident that the true [parameter in context] is between [lower bound] and [upper bound].\"</p> <p>For our voter example: \"We are 95% confident that the true proportion of all registered voters who support the new tax proposal is between 0.553 and 0.687 (or 55.3% and 68.7%).\"</p> <p>Common Mistakes to Avoid:</p> Incorrect Statement Why It's Wrong \"There is a 95% probability that the true proportion is in this interval\" The true proportion is fixed; it's either in the interval or not. Probability doesn't apply. \"95% of voters support the proposal between 55.3% and 68.7%\" This describes individual voters, not the parameter. \"95% of all samples will give proportions in this interval\" The interval is about the parameter, not future sample statistics. \"We are 95% confident the sample proportion is between...\" The sample proportion is known exactly - it's 0.62! The interval estimates the population proportion. <p>The key is to always mention:</p> <ul> <li>The confidence level</li> <li>That you're estimating the population parameter (not the sample statistic)</li> <li>The context (what the proportion represents)</li> <li>The actual interval bounds</li> </ul> <p>Sylvia Says</p> <p>\"Time to squirrel away this knowledge! Remember: confidence intervals are about the POPULATION parameter, not the sample statistic. I've seen many students mix these up. The sample proportion is 0.62 - we know that for certain! What we're uncertain about is the population proportion, which is why we need the interval.\"</p>"},{"location":"chapters/15-confidence-intervals/#factors-that-affect-confidence-interval-width","title":"Factors That Affect Confidence Interval Width","text":"<p>The width of a confidence interval tells us how precise our estimate is. Narrower intervals are more useful because they give a tighter range of plausible values.</p> <p>The width of a confidence interval is:</p> \\[ \\text{Width} = 2 \\times \\text{Margin of Error} = 2 \\times z^* \\times SE \\] <p>Three factors affect CI width:</p> <p>1. Confidence Level</p> <p>Higher confidence level = Larger \\(z^*\\) = Wider interval</p> <p>This is the trade-off between confidence and precision. If you want to be more confident, you pay for it with a wider interval.</p> Confidence Level z* Relative Width 90% 1.645 Narrowest 95% 1.960 Medium 99% 2.576 Widest <p>2. Sample Size</p> <p>Larger sample size = Smaller standard error = Narrower interval</p> <p>This is because \\(SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\), and \\(n\\) is in the denominator under the square root.</p> <p>Important: To cut the margin of error in half, you must quadruple the sample size!</p> <p>3. Sample Proportion</p> <p>The standard error is maximized when \\(\\hat{p} = 0.5\\) and decreases as \\(\\hat{p}\\) approaches 0 or 1.</p> Sample Proportion SE (assuming n=100) Relative Width 0.5 0.050 Widest 0.7 or 0.3 0.046 Medium 0.9 or 0.1 0.030 Narrower <p>This makes sense: when opinions are evenly split, there's more variability (and uncertainty) than when they're lopsided.</p>"},{"location":"chapters/15-confidence-intervals/#determining-sample-size","title":"Determining Sample Size","text":"<p>Sometimes you need to plan a study and want to achieve a specific margin of error. You can work backward from the margin of error formula to determine the required sample size.</p> <p>Starting with: [ ME = z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} ]</p> <p>Solving for \\(n\\): [ n = \\left(\\frac{z^*}{ME}\\right)^2 \\hat{p}(1-\\hat{p}) ]</p> <p>The Problem: Before collecting data, we don't know \\(\\hat{p}\\)!</p> <p>Two Solutions:</p> <ol> <li>Use a prior estimate if you have one from previous research or a pilot study</li> <li>Use \\(\\hat{p} = 0.5\\) for a conservative estimate (this maximizes the required sample size)</li> </ol> <p>Example: A pollster wants to estimate the proportion of adults who support a policy with a margin of error of 3 percentage points at 95% confidence. How many people should be surveyed?</p> <p>Using \\(\\hat{p} = 0.5\\) for the conservative approach: [ n = \\left(\\frac{1.96}{0.03}\\right)^2 (0.5)(0.5) = (65.33)^2 (0.25) = 4268.44 (0.25) \\approx 1067 ]</p> <p>The pollster should survey at least 1,067 people.</p> <p>Always round UP when determining sample size to ensure the margin of error is at most the desired amount.</p>"},{"location":"chapters/15-confidence-intervals/#diagram-sample-size-calculator","title":"Diagram: Sample Size Calculator","text":"Sample Size Calculator MicroSim <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate, solve</p> <p>Learning Objective: Students will determine the required sample size to achieve a desired margin of error for a given confidence level.</p> <p>Visual Elements: - Input panel for desired margin of error and confidence level - Option to use p = 0.5 (conservative) or enter an estimated proportion - Step-by-step calculation display showing formula and substitution - Result display with the required sample size (rounded up) - Visual comparison showing how different ME goals require different sample sizes - Cost/effort indicator (informal visual showing \"more effort\" for larger samples)</p> <p>Interactive Controls (canvas-based): - Slider or input: Desired margin of error (1% to 10%, default 3%) - Dropdown: Confidence level (90%, 95%, 99%) - Toggle: Use conservative p = 0.5 vs. enter estimate - Input: Prior estimate of p (if not using conservative) - \"Calculate\" button</p> <p>Default Parameters: - Desired ME: 3% (0.03) - Confidence level: 95% - Use conservative p = 0.5</p> <p>Behavior: - Shows formula and calculation steps - Displays intermediate values (z*, p(1-p), etc.) - Shows final n, always rounded UP - If using estimated p, shows both the result and what conservative would give - Displays note about why we round up</p> <p>Instructional Rationale: Interactive calculator reinforces the process while handling the arithmetic, allowing students to focus on understanding the relationships.</p> <p>Implementation: p5.js with canvas-based inputs Canvas size: 600 x 400 (responsive)</p>"},{"location":"chapters/15-confidence-intervals/#confidence-interval-for-the-difference-in-two-proportions","title":"Confidence Interval for the Difference in Two Proportions","text":"<p>Sometimes we want to compare two populations. For example: Is there a difference in the proportion of teens vs. adults who use social media daily?</p> <p>When comparing two proportions from independent samples, we construct a confidence interval for \\(p_1 - p_2\\), the difference between the two population proportions.</p> <p>The formula is:</p> \\[ (\\hat{p}_1 - \\hat{p}_2) \\pm z^* \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}} \\] <p>The standard error for the difference combines the variability from both samples:</p> \\[ SE_{\\hat{p}_1 - \\hat{p}_2} = \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}} \\] <p>Conditions for Two-Proportion CI:</p> <ol> <li>Random samples: Both samples must be random (or from randomized experiments)</li> <li>Independence:</li> <li>The two samples are independent of each other</li> <li>Each sample is no more than 10% of its population</li> <li>Large counts: All four counts must be at least 10:</li> <li>\\(n_1\\hat{p}_1 \\geq 10\\) and \\(n_1(1-\\hat{p}_1) \\geq 10\\)</li> <li>\\(n_2\\hat{p}_2 \\geq 10\\) and \\(n_2(1-\\hat{p}_2) \\geq 10\\)</li> </ol> <p>Interpretation: If the interval contains 0, there's no statistically significant difference between the two proportions. If the entire interval is positive, \\(p_1 &gt; p_2\\). If the entire interval is negative, \\(p_1 &lt; p_2\\).</p> <p>Example: In a survey, 156 of 200 teens use social media daily, compared to 98 of 180 adults.</p> <ul> <li>\\(\\hat{p}_1 = 156/200 = 0.78\\) (teens)</li> <li>\\(\\hat{p}_2 = 98/180 = 0.544\\) (adults)</li> <li>\\(\\hat{p}_1 - \\hat{p}_2 = 0.78 - 0.544 = 0.236\\)</li> </ul> <p>For 95% confidence: [ SE = \\sqrt{\\frac{0.78(0.22)}{200} + \\frac{0.544(0.456)}{180}} = \\sqrt{0.000858 + 0.001378} = \\sqrt{0.002236} \\approx 0.0473 ]</p> \\[ ME = 1.96 \\times 0.0473 \\approx 0.0927 \\] \\[ CI: (0.236 - 0.093, 0.236 + 0.093) = (0.143, 0.329) \\] <p>We are 95% confident that the true difference in proportions (teens minus adults) who use social media daily is between 0.143 and 0.329. Since the entire interval is positive, we can conclude that a higher proportion of teens use social media daily compared to adults.</p>"},{"location":"chapters/15-confidence-intervals/#understanding-pooled-proportion","title":"Understanding Pooled Proportion","text":"<p>The pooled proportion is used in hypothesis testing (which we'll cover in the next chapter) when we assume two populations have the same proportion. It combines data from both samples to get a single estimate.</p> \\[ \\hat{p}_{\\text{pooled}} = \\frac{x_1 + x_2}{n_1 + n_2} \\] <p>where \\(x_1\\) and \\(x_2\\) are the number of successes in each sample.</p> <p>Important: We do NOT use the pooled proportion when constructing confidence intervals for the difference in proportions. The pooled proportion is only used in hypothesis testing when we assume \\(H_0: p_1 = p_2\\).</p> <p>For confidence intervals, we use the individual sample proportions \\(\\hat{p}_1\\) and \\(\\hat{p}_2\\) because we're not assuming the proportions are equal - we're trying to estimate their difference!</p> Situation Use Reason CI for difference Individual \\(\\hat{p}_1\\) and \\(\\hat{p}_2\\) Not assuming equality Hypothesis test with \\(H_0: p_1 = p_2\\) Pooled \\(\\hat{p}_{\\text{pooled}}\\) Assuming equality under null"},{"location":"chapters/15-confidence-intervals/#factors-affecting-statistical-power-preview","title":"Factors Affecting Statistical Power (Preview)","text":"<p>While we'll study hypothesis testing in detail next chapter, it's worth previewing how confidence intervals connect to power - the ability to detect a real difference or effect when one exists.</p> <p>Statistical power is the probability of correctly rejecting a false null hypothesis. In the context of confidence intervals, higher power means narrower intervals that are more likely to exclude false values.</p> <p>Factors that increase power (and narrow confidence intervals):</p> <ol> <li>Larger sample size: More data = more precision = more power</li> <li>Larger effect size: Bigger differences are easier to detect</li> <li>Lower confidence level: 90% CI is narrower than 99% CI (but less confident)</li> <li>Lower variability: Less noise in the data makes patterns clearer</li> </ol> <p>The relationship between sample size and power is particularly important when designing studies. If you need to detect small differences with high confidence, you'll need a large sample size.</p> Change Effect on CI Width Effect on Power Increase sample size Decreases (narrows) Increases Increase confidence level Increases (widens) Decreases Increase effect size No direct effect Increases Decrease variability Decreases (narrows) Increases"},{"location":"chapters/15-confidence-intervals/#common-mistakes-and-how-to-avoid-them","title":"Common Mistakes and How to Avoid Them","text":"<p>Let's wrap up by reviewing the most common errors students make with confidence intervals.</p> <p>Mistake 1: Incorrect interpretation of confidence level</p> <ul> <li>Wrong: \"There's a 95% probability the true proportion is in this interval\"</li> <li>Right: \"If we repeated this process many times, 95% of the intervals would contain the true proportion\"</li> </ul> <p>Mistake 2: Forgetting to check conditions</p> <p>Always verify:</p> <ul> <li>Random sample</li> <li>Independence (10% condition)</li> <li>Large counts (at least 10 successes and 10 failures)</li> </ul> <p>Mistake 3: Using the wrong formula</p> <ul> <li>For one proportion: \\(\\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\)</li> <li>For difference in proportions: \\((\\hat{p}_1 - \\hat{p}_2) \\pm z^* \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}\\)</li> </ul> <p>Mistake 4: Confusing standard error and standard deviation</p> <ul> <li>Standard deviation describes spread within a sample</li> <li>Standard error describes variability of sample statistics across samples</li> </ul> <p>Mistake 5: Not interpreting in context</p> <p>Always mention what the proportion represents! Don't just say \"between 0.55 and 0.69\" - say \"between 55% and 69% of registered voters.\"</p> <p>Mistake 6: Using pooled proportion for confidence intervals</p> <p>Pooled proportion is for hypothesis tests only, not for CIs for the difference in proportions.</p>"},{"location":"chapters/15-confidence-intervals/#chapter-summary","title":"Chapter Summary","text":"<p>Congratulations! You've learned one of the most powerful tools in statistics. Let's review the key concepts.</p> <p>Key Takeaways:</p> <ul> <li>A point estimate is a single value used to estimate a parameter (\\(\\hat{p}\\) estimates \\(p\\))</li> <li>An interval estimate provides a range of plausible values</li> <li>A confidence interval = point estimate \\(\\pm\\) margin of error</li> <li>Margin of error = \\(z^* \\times SE\\)</li> <li>Confidence level describes the long-run capture rate of the interval-building method</li> <li>Critical values (\\(z^*\\)) come from the normal distribution: 1.645 (90%), 1.96 (95%), 2.576 (99%)</li> <li>Standard error measures sampling variability: \\(SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\)</li> </ul> <p>Conditions for CI for proportions:</p> <ol> <li>Random sample</li> <li>Independence (10% condition)</li> <li>Large counts (at least 10 successes and failures)</li> </ol> <p>Factors affecting CI width:</p> <ul> <li>Confidence level (higher = wider)</li> <li>Sample size (larger = narrower)</li> <li>Sample proportion (closer to 0.5 = wider)</li> </ul> <p>Correct interpretation template: \"We are [C]% confident that the true [parameter in context] is between [lower] and [upper].\"</p> <p>Sylvia's Final Thought</p> <p>\"Look at you go! You just learned how to quantify uncertainty - something that took statisticians centuries to figure out. Confidence intervals let us be honest about what we don't know while still making meaningful claims. That's a superpower right there. Now that's a data point worth collecting! In the next chapter, we'll use these same ideas to test hypotheses. Time to squirrel away this knowledge!\"</p>"},{"location":"chapters/15-confidence-intervals/#practice-problems","title":"Practice Problems","text":"Problem 1: Constructing a CI <p>A random sample of 150 college students found that 87 use streaming services as their primary source of entertainment. Construct a 95% confidence interval for the proportion of all college students who use streaming as their primary entertainment source.</p> <p>Solution:</p> <p>First, check conditions: - Random sample: Given - Independence: Assume the college has at least 1,500 students - Large counts: 87 successes and 63 failures, both &gt; 10</p> <p>Calculate: - \\(\\hat{p} = 87/150 = 0.58\\) - \\(z^* = 1.96\\) - \\(SE = \\sqrt{0.58(0.42)/150} = \\sqrt{0.001624} = 0.0403\\) - \\(ME = 1.96 \\times 0.0403 = 0.079\\) - CI: (0.58 - 0.079, 0.58 + 0.079) = (0.501, 0.659)</p> <p>We are 95% confident that between 50.1% and 65.9% of all college students use streaming services as their primary entertainment source.</p> Problem 2: Interpreting a CI <p>A 99% confidence interval for the proportion of adults who exercise regularly is (0.35, 0.45). Which of the following is a correct interpretation?</p> <p>A) 99% of adults exercise between 35% and 45% of the time B) There is a 99% probability that the true proportion is between 0.35 and 0.45 C) We are 99% confident that between 35% and 45% of all adults exercise regularly D) 99% of samples will have proportions between 0.35 and 0.45</p> <p>Solution: C is correct. The confidence interval estimates the population proportion, and the confidence level describes the reliability of the method, not the probability for this specific interval.</p> Problem 3: Sample Size Determination <p>A researcher wants to estimate the proportion of high school students who have part-time jobs with a margin of error of 4 percentage points at 90% confidence. What sample size is needed?</p> <p>Solution:</p> <p>Using the conservative approach (\\(\\hat{p} = 0.5\\)): - \\(z^* = 1.645\\) for 90% confidence - \\(ME = 0.04\\)</p> \\[ n = \\left(\\frac{1.645}{0.04}\\right)^2 (0.5)(0.5) = (41.125)^2 (0.25) = 1691.27 (0.25) = 422.8 \\] <p>Round up: The researcher needs at least 423 students.</p>"},{"location":"chapters/15-confidence-intervals/#key-formulas-reference","title":"Key Formulas Reference","text":"Formula Purpose \\(\\hat{p} = \\frac{x}{n}\\) Sample proportion (point estimate) \\(SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) Standard error of proportion \\(ME = z^* \\cdot SE\\) Margin of error \\(\\hat{p} \\pm ME\\) Confidence interval for one proportion \\(n = \\left(\\frac{z^*}{ME}\\right)^2 \\hat{p}(1-\\hat{p})\\) Sample size for desired ME \\(SE_{\\hat{p}_1-\\hat{p}_2} = \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}\\) SE for difference in proportions \\(\\hat{p}_{\\text{pooled}} = \\frac{x_1 + x_2}{n_1 + n_2}\\) Pooled proportion (for hypothesis testing only)"},{"location":"chapters/16-hypothesis-testing/","title":"Hypothesis Testing","text":""},{"location":"chapters/16-hypothesis-testing/#summary","title":"Summary","text":"<p>This chapter introduces hypothesis testing, the other main branch of statistical inference. Students will learn to formulate null and alternative hypotheses, calculate and interpret p-values, understand Type I and Type II errors, and make conclusions based on statistical evidence. These skills enable students to test claims about population parameters using sample data.</p>"},{"location":"chapters/16-hypothesis-testing/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 22 concepts from the learning graph:</p> <ol> <li>Hypothesis Test</li> <li>Null Hypothesis</li> <li>Alternative Hypothesis</li> <li>Writing Hypotheses</li> <li>One-Sided Test</li> <li>Two-Sided Test</li> <li>Test Statistic</li> <li>P-Value</li> <li>Calculating P-Values</li> <li>Interpreting P-Values</li> <li>Significance Level</li> <li>Choosing Alpha</li> <li>Statistical Significance</li> <li>Making Conclusions</li> <li>Type I Error</li> <li>Type II Error</li> <li>Error Tradeoffs</li> <li>Power of a Test</li> <li>Test for One Proportion</li> <li>Conditions for Z-Test</li> <li>Test for Two Proportions</li> <li>Practical Significance</li> </ol>"},{"location":"chapters/16-hypothesis-testing/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 14: Sampling Distributions</li> <li>Chapter 15: Confidence Intervals</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#the-art-of-statistical-detective-work","title":"The Art of Statistical Detective Work","text":"<p>Have you ever heard someone claim that a new medication works better than an old one? Or that a coin might be unfair? Or that more than half of teenagers prefer a certain brand? How do we know if these claims are actually true, or just coincidence?</p> <p>Welcome to hypothesis testing\u2014the scientific method of statistics. This is where we become data detectives, using evidence to evaluate claims about the world. Rather than just accepting assertions at face value, we'll learn to put them on trial and let the data be the judge.</p> <p>\"Let's crack this nut!\" Sylvia adjusts her spectacles with enthusiasm. \"When I first started tracking which trees produced the best acorns, I had a hunch that oaks on the south side of the forest were more productive. But hunches aren't evidence! I needed a systematic way to test my theory. That's exactly what hypothesis testing does\u2014it turns our hunches into rigorous questions that data can answer.\"</p> <p>By the end of this chapter, you'll be able to:</p> <ul> <li>Formulate statistical hypotheses that can be tested with data</li> <li>Calculate and interpret p-values correctly</li> <li>Make appropriate conclusions using significance levels</li> <li>Understand the consequences of Type I and Type II errors</li> <li>Conduct hypothesis tests for proportions</li> <li>Distinguish between statistical and practical significance</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#what-is-a-hypothesis-test","title":"What Is a Hypothesis Test?","text":"<p>A hypothesis test is a formal procedure for using sample data to evaluate a claim about a population parameter. Think of it as a trial where the claim is \"innocent until proven guilty\"\u2014we start by assuming the claim is false and then look for evidence strong enough to convince us otherwise.</p> <p>The general framework involves four key steps:</p> <ol> <li>State the hypotheses (the claim we're testing and its alternative)</li> <li>Collect data and calculate a test statistic (measuring how far the data is from what we'd expect)</li> <li>Find the p-value (the probability of getting data this extreme if the claim is false)</li> <li>Make a conclusion (reject or fail to reject based on the evidence)</li> </ol> <p>This structured approach ensures we're not fooled by random variation. Just because 53% of people in a sample prefer chocolate doesn't mean more than half the population does\u2014that 53% might just be sampling variability. Hypothesis testing helps us determine when the evidence is compelling enough to draw conclusions.</p> Everyday Situation Statistical Question \"This coin seems biased\" Is P(heads) different from 0.5? \"The new drug is better\" Is the cure rate higher than before? \"More people prefer A over B\" Is the proportion choosing A greater than 0.5? \"The machines produce different results\" Is there a difference in proportions?"},{"location":"chapters/16-hypothesis-testing/#the-null-and-alternative-hypotheses","title":"The Null and Alternative Hypotheses","text":"<p>Every hypothesis test begins with two competing statements about the population parameter.</p>"},{"location":"chapters/16-hypothesis-testing/#the-null-hypothesis","title":"The Null Hypothesis","text":"<p>The null hypothesis (denoted \\( H_0 \\), pronounced \"H-naught\" or \"H-zero\") represents the status quo\u2014the claim that nothing special is happening. It's always a statement of equality or \"no effect.\"</p> <p>The null hypothesis is what we assume to be true until we have enough evidence to reject it. Think of it as the default position\u2014the boring, expected outcome.</p> <p>Examples of null hypotheses:</p> <ul> <li>\\( H_0: p = 0.5 \\) (the coin is fair)</li> <li>\\( H_0: p = 0.20 \\) (the success rate is 20%, as claimed)</li> <li>\\( H_0: p_1 - p_2 = 0 \\) (there's no difference between groups)</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#the-alternative-hypothesis","title":"The Alternative Hypothesis","text":"<p>The alternative hypothesis (denoted \\( H_a \\) or \\( H_1 \\)) represents what we're trying to find evidence for\u2014the claim that something interesting IS happening. It's the research hypothesis, the thing we suspect might be true.</p> <p>Examples of alternative hypotheses:</p> <ul> <li>\\( H_a: p \\neq 0.5 \\) (the coin is NOT fair)</li> <li>\\( H_a: p &gt; 0.20 \\) (the success rate is HIGHER than 20%)</li> <li>\\( H_a: p_1 - p_2 \\neq 0 \\) (there IS a difference between groups)</li> </ul> <p>\"Here's something that tripped me up at first,\" Sylvia admits. \"The null hypothesis isn't necessarily what you believe\u2014it's what you're trying to disprove! I suspected the south-side oaks were better, so my null hypothesis was 'there's no difference.' My alternative was 'south-side oaks produce more.' We assume the boring answer is true, then look for evidence against it.\"</p>"},{"location":"chapters/16-hypothesis-testing/#the-logic-of-hypothesis-testing","title":"The Logic of Hypothesis Testing","text":"<p>Why do we structure things this way? Because we can never prove something is definitely true\u2014we can only accumulate evidence against the alternative. This is similar to the legal principle of \"innocent until proven guilty\":</p> Court Trial Hypothesis Test Defendant is presumed innocent Null hypothesis is assumed true Prosecution presents evidence We collect sample data Jury weighs the evidence We calculate the p-value \"Guilty\" if evidence is overwhelming \"Reject \\( H_0 \\)\" if p-value is small \"Not guilty\" if evidence is insufficient \"Fail to reject \\( H_0 \\)\" if p-value is large <p>Note: \"Not guilty\" doesn't mean \"innocent\"\u2014it just means there wasn't enough evidence to convict. Similarly, \"fail to reject \\( H_0 \\)\" doesn't mean \\( H_0 \\) is true\u2014it just means we don't have enough evidence to reject it.</p>"},{"location":"chapters/16-hypothesis-testing/#writing-hypotheses","title":"Writing Hypotheses","text":"<p>Writing hypotheses correctly is crucial\u2014a poorly stated hypothesis leads to a confused analysis. Here are the rules:</p>"},{"location":"chapters/16-hypothesis-testing/#rule-1-hypotheses-are-about-population-parameters-not-sample-statistics","title":"Rule 1: Hypotheses are about population parameters, not sample statistics","text":"<ul> <li>Correct: \\( H_0: p = 0.5 \\) (where p is the population proportion)</li> <li>Incorrect: \\( H_0: \\hat{p} = 0.5 \\) (that's a sample statistic)</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#rule-2-the-null-hypothesis-always-contains-equality","title":"Rule 2: The null hypothesis always contains equality","text":"<ul> <li>Correct: \\( H_0: p = 0.30 \\)</li> <li>Incorrect: \\( H_0: p &gt; 0.30 \\)</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#rule-3-the-alternative-hypothesis-determines-the-test-direction","title":"Rule 3: The alternative hypothesis determines the test direction","text":"<p>The form of \\( H_a \\) tells us what kind of evidence would lead us to reject \\( H_0 \\):</p> If \\( H_a \\) contains We call it We reject \\( H_0 \\) if sample proportion is \\( \\neq \\) Two-sided test Far from \\( p_0 \\) in either direction \\( &gt; \\) One-sided (right) Much larger than \\( p_0 \\) \\( &lt; \\) One-sided (left) Much smaller than \\( p_0 \\)"},{"location":"chapters/16-hypothesis-testing/#writing-hypotheses-complete-example","title":"Writing Hypotheses: Complete Example","text":"<p>Scenario: A company claims that 40% of customers prefer their product. You survey 200 customers and want to test if the true proportion differs from the claim.</p> <p>Step 1: Identify the parameter: p = the true proportion of all customers who prefer the product</p> <p>Step 2: Write the null hypothesis (the claim, assuming equality): [ H_0: p = 0.40 ]</p> <p>Step 3: Write the alternative hypothesis (what you're looking for evidence of): [ H_a: p \\neq 0.40 ]</p> <p>This is a two-sided test because we're interested in whether the proportion differs in either direction\u2014higher OR lower than 40%.</p>"},{"location":"chapters/16-hypothesis-testing/#one-sided-vs-two-sided-tests","title":"One-Sided vs. Two-Sided Tests","text":"<p>The choice between a one-sided test and a two-sided test depends on your research question.</p>"},{"location":"chapters/16-hypothesis-testing/#two-sided-tests","title":"Two-Sided Tests","text":"<p>A two-sided test (also called two-tailed) looks for evidence that the parameter differs from the null value in either direction. Use this when:</p> <ul> <li>You want to detect any difference, regardless of direction</li> <li>You don't have a strong prior reason to expect only one direction</li> <li>You're being conservative and open to any surprise</li> </ul> <p>Alternative hypothesis form: \\( H_a: p \\neq p_0 \\)</p> <p>Example: Testing whether a coin is fair (it could be biased toward heads OR tails).</p>"},{"location":"chapters/16-hypothesis-testing/#one-sided-tests","title":"One-Sided Tests","text":"<p>A one-sided test (also called one-tailed) looks for evidence in only one direction. Use this when:</p> <ul> <li>You only care about differences in a specific direction</li> <li>Scientific theory strongly predicts the direction</li> <li>Practical considerations make only one direction meaningful</li> </ul> <p>Alternative hypothesis forms: \\( H_a: p &gt; p_0 \\) or \\( H_a: p &lt; p_0 \\)</p> <p>Example: Testing whether a new medication improves cure rates (we only care if it's BETTER, not worse).</p> <p>Choose Your Test Before Seeing the Data</p> <p>You must decide whether to use a one-sided or two-sided test BEFORE collecting or analyzing data. Choosing after you see the results is cheating\u2014it's called \"p-hacking\" and leads to false conclusions.</p> Scenario Appropriate Test Does the proportion differ from 50%? Two-sided Is the proportion greater than 50%? One-sided (right) Is the proportion less than 50%? One-sided (left) Has the medication changed outcomes? Two-sided Has the medication improved outcomes? One-sided (right)"},{"location":"chapters/16-hypothesis-testing/#the-test-statistic","title":"The Test Statistic","text":"<p>A test statistic measures how far our sample result is from what we'd expect if the null hypothesis were true. It standardizes the difference, allowing us to determine how unusual our sample is.</p> <p>For a test about one proportion, the test statistic is:</p> \\[ z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] <p>Where: - \\( \\hat{p} \\) = sample proportion (what we observed) - \\( p_0 \\) = hypothesized population proportion (from \\( H_0 \\)) - \\( n \\) = sample size - The denominator is the standard error under the null hypothesis</p> <p>This z-score tells us how many standard errors the sample proportion is from the hypothesized value. A z-score of 0 means the sample matched expectations perfectly. A z-score of 2 or -2 means the sample was unusually far from what we expected.</p>"},{"location":"chapters/16-hypothesis-testing/#calculating-a-test-statistic-example","title":"Calculating a Test Statistic: Example","text":"<p>Scenario: A company claims 60% of customers are satisfied. In a sample of 250 customers, 135 (54%) reported satisfaction. Test whether satisfaction differs from the claim.</p> <p>Given information: - \\( \\hat{p} = 135/250 = 0.54 \\) - \\( p_0 = 0.60 \\) (from the claim) - \\( n = 250 \\)</p> <p>Calculate the test statistic: [ z = \\frac{0.54 - 0.60}{\\sqrt{\\frac{0.60(1-0.60)}{250}}} = \\frac{-0.06}{\\sqrt{\\frac{0.24}{250}}} = \\frac{-0.06}{0.031} \\approx -1.94 ]</p> <p>The sample proportion is about 1.94 standard errors below the claimed value. Is this unusual enough to reject the claim? We need the p-value to decide.</p>"},{"location":"chapters/16-hypothesis-testing/#diagram-test-statistic-calculator","title":"Diagram: Test Statistic Calculator","text":"Interactive Test Statistic Calculator <p>Type: MicroSim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Taxonomy Verb: Calculate</p> <p>Learning objective: Students will calculate z-test statistics for one-proportion hypothesis tests by inputting sample data and hypothesized values, understanding how the test statistic measures deviation from the null hypothesis.</p> <p>Visual elements: - Input fields for sample size (n), number of successes (x), and hypothesized proportion (p\u2080) - Automatic calculation of sample proportion (p-hat = x/n) - Visual display of the z-formula with current values substituted - Number line showing the z-score position relative to 0 - Standard normal curve with the z-score marked - Color-coded output: green for small z (close to expected), yellow for moderate z, red for extreme z</p> <p>Interactive controls: - Number input for sample size n (range: 10 to 1000) - Number input for number of successes x (range: 0 to n) - Slider or input for hypothesized proportion p\u2080 (range: 0.01 to 0.99) - \"Calculate\" button to compute test statistic - \"Clear\" button to reset all fields - Toggle to show/hide calculation steps</p> <p>Behavior: - As inputs change, live updates show intermediate calculations - Standard error calculation displayed step-by-step - Test statistic updates automatically - Visual position on normal curve updates in real-time - Warning message if conditions not met (np\u2080 &lt; 10 or n(1-p\u2080) &lt; 10) - Display interpretation: \"The sample proportion is ___ standard errors [above/below] the hypothesized value\"</p> <p>Canvas size: 800 x 500 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/16-hypothesis-testing/#understanding-the-p-value","title":"Understanding the P-Value","text":"<p>The p-value is the probability of obtaining sample results at least as extreme as those observed, assuming the null hypothesis is true.</p> <p>This is a mouthful, so let's break it down:</p> <ol> <li>Assume \\( H_0 \\) is true (we're working in a hypothetical world where the null is correct)</li> <li>Consider all possible samples we could draw in this world</li> <li>Find the probability of getting a sample as unusual as ours (or more unusual)</li> </ol> <p>A small p-value means: \"If \\( H_0 \\) were true, results like ours would be very rare. Either we witnessed something unlikely, or \\( H_0 \\) isn't true.\"</p> <p>A large p-value means: \"If \\( H_0 \\) were true, results like ours would be fairly common. There's no reason to doubt \\( H_0 \\).\"</p>"},{"location":"chapters/16-hypothesis-testing/#p-value-interpretation","title":"P-Value Interpretation","text":"P-Value Verbal Interpretation 0.50 \"Results like this happen half the time if \\( H_0 \\) is true\" 0.25 \"Results like this are fairly common under \\( H_0 \\)\" 0.10 \"Results like this are somewhat unusual under \\( H_0 \\)\" 0.05 \"Results like this are unusual under \\( H_0 \\)\" 0.01 \"Results like this are quite rare under \\( H_0 \\)\" 0.001 \"Results like this are very rare under \\( H_0 \\)\" <p>\"Acorn for your thoughts?\" Sylvia asks. \"The p-value confused me at first. It's NOT the probability that \\( H_0 \\) is true! It's the probability of seeing our data (or more extreme) IF \\( H_0 \\) were true. Big difference! Think of it as measuring how surprised we should be if the null hypothesis is actually correct.\"</p>"},{"location":"chapters/16-hypothesis-testing/#calculating-p-values","title":"Calculating P-Values","text":"<p>Calculating p-values depends on whether your test is one-sided or two-sided.</p>"},{"location":"chapters/16-hypothesis-testing/#for-a-two-sided-test","title":"For a Two-Sided Test","text":"<p>When \\( H_a: p \\neq p_0 \\), evidence against \\( H_0 \\) could come from either tail. The p-value is:</p> \\[ \\text{p-value} = 2 \\times P(Z &gt; |z|) \\] <p>We double the one-tail probability because extreme values in either direction count as evidence.</p>"},{"location":"chapters/16-hypothesis-testing/#for-a-one-sided-test-right","title":"For a One-Sided Test (Right)","text":"<p>When \\( H_a: p &gt; p_0 \\), only large positive z-values count as evidence:</p> \\[ \\text{p-value} = P(Z &gt; z) \\]"},{"location":"chapters/16-hypothesis-testing/#for-a-one-sided-test-left","title":"For a One-Sided Test (Left)","text":"<p>When \\( H_a: p &lt; p_0 \\), only large negative z-values count as evidence:</p> \\[ \\text{p-value} = P(Z &lt; z) \\]"},{"location":"chapters/16-hypothesis-testing/#p-value-calculation-example","title":"P-Value Calculation Example","text":"<p>Continuing our satisfaction example where z = -1.94:</p> <p>For a two-sided test (\\( H_a: p \\neq 0.60 \\)): [ \\text{p-value} = 2 \\times P(Z &lt; -1.94) = 2 \\times 0.0262 = 0.0524 ]</p> <p>For a one-sided test (\\( H_a: p &lt; 0.60 \\)): [ \\text{p-value} = P(Z &lt; -1.94) = 0.0262 ]</p> <p>The p-value tells us that if the true satisfaction rate were really 60%, we'd see a sample proportion as extreme as 54% (or more extreme) about 5.2% of the time with a two-sided test.</p>"},{"location":"chapters/16-hypothesis-testing/#diagram-p-value-visualizer","title":"Diagram: P-Value Visualizer","text":"Interactive P-Value Visualization <p>Type: MicroSim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Taxonomy Verb: Interpret</p> <p>Learning objective: Students will interpret p-values by visualizing the area under the normal curve corresponding to the probability of obtaining results as extreme as the test statistic, distinguishing between one-sided and two-sided tests.</p> <p>Data Visibility Requirements: - Stage 1: Show the standard normal curve with test statistic marked - Stage 2: Highlight the tail area(s) corresponding to the p-value - Stage 3: Display the calculated probability as a decimal and percentage - Stage 4: Show interpretation sentence explaining what the p-value means</p> <p>Visual elements: - Standard normal distribution curve (bell curve) - Vertical line at z = 0 (center) - Movable marker showing test statistic position - Shaded region(s) representing the p-value - Numerical display of z-value and corresponding p-value - Toggle between one-sided (left/right) and two-sided views</p> <p>Interactive controls: - Slider for z-statistic (range: -4 to +4) - Radio buttons: \"Two-sided\", \"One-sided (left)\", \"One-sided (right)\" - \"Show/Hide\" toggle for each tail region - Display mode: \"Show area\" or \"Show probability\" - Input field to enter a specific z-value - Reset button</p> <p>Behavior: - As z-slider moves, shaded region updates in real-time - P-value display updates continuously - For two-sided test, both tails shade symmetrically - For one-sided test, only relevant tail shades - When p-value &lt; 0.05, region turns red; otherwise blue - Interpretation text updates: \"If H\u2080 is true, results this extreme occur ___% of the time\"</p> <p>Instructional Rationale: Step-through visualization with explicit data visibility is appropriate because the Understanding/interpret objective requires learners to connect the visual area representation to the numerical probability, building intuition about what p-values mean.</p> <p>Canvas size: 800 x 450 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/16-hypothesis-testing/#interpreting-p-values","title":"Interpreting P-Values","text":"<p>Interpreting p-values correctly is essential\u2014and widely misunderstood, even by scientists!</p>"},{"location":"chapters/16-hypothesis-testing/#what-the-p-value-is","title":"What the P-Value IS","text":"<p>The p-value is the probability of obtaining sample results at least as extreme as those observed, assuming the null hypothesis is true.</p> <p>Correct interpretation: \"If the true proportion were [null value], there is a [p-value] probability of observing a sample proportion at least as extreme as [observed value].\"</p> <p>Example: \"If the true satisfaction rate were 60%, there is a 5.24% probability of observing a sample proportion at least as far from 60% as our observed 54%.\"</p>"},{"location":"chapters/16-hypothesis-testing/#what-the-p-value-is-not","title":"What the P-Value is NOT","text":"<ul> <li>NOT the probability that \\( H_0 \\) is true</li> <li>NOT the probability that \\( H_a \\) is false</li> <li>NOT the probability that you made an error</li> <li>NOT the magnitude or importance of the effect</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#common-misinterpretations","title":"Common Misinterpretations","text":"Incorrect Statement Why It's Wrong \"There's a 5% chance \\( H_0 \\) is true\" P-value doesn't give probability of hypotheses \"The results are 95% likely to be real\" P-value is about data, not reality \"If p = 0.03, there's a 97% chance the treatment works\" P-value isn't about effectiveness \"A small p-value means a large effect\" P-value says nothing about effect size <p>\"Don't worry\u2014every statistician drops an acorn sometimes,\" Sylvia reassures. \"P-value interpretation trips up even experts! The key is remembering we're calculating a probability about DATA, not about whether our hypothesis is true. We're asking 'how surprising is this data?' not 'what's the truth?'\"</p>"},{"location":"chapters/16-hypothesis-testing/#the-significance-level","title":"The Significance Level","text":"<p>The significance level (denoted \\( \\alpha \\), the Greek letter alpha) is the threshold we set BEFORE the test to decide how small the p-value must be to reject \\( H_0 \\).</p> <p>Think of \\( \\alpha \\) as our \"surprise threshold\"\u2014how rare must the data be before we're convinced something unusual is happening?</p>"},{"location":"chapters/16-hypothesis-testing/#common-significance-levels","title":"Common Significance Levels","text":"\\( \\alpha \\) Interpretation 0.10 Reject if p-value &lt; 0.10 (lenient) 0.05 Reject if p-value &lt; 0.05 (most common) 0.01 Reject if p-value &lt; 0.01 (strict) 0.001 Reject if p-value &lt; 0.001 (very strict) <p>The most common choice is \\( \\alpha = 0.05 \\), meaning we reject \\( H_0 \\) if there's less than a 5% chance of seeing data this extreme under \\( H_0 \\).</p>"},{"location":"chapters/16-hypothesis-testing/#choosing-alpha","title":"Choosing Alpha","text":"<p>Choosing alpha involves balancing competing concerns:</p> <p>Lower \\( \\alpha \\) (like 0.01): - Harder to reject \\( H_0 \\)\u2014requires stronger evidence - Fewer false positives (wrongly rejecting a true \\( H_0 \\)) - More false negatives (failing to detect real effects) - Appropriate when false positives are costly (e.g., medical treatments)</p> <p>Higher \\( \\alpha \\) (like 0.10): - Easier to reject \\( H_0 \\)\u2014requires less evidence - More false positives - Fewer false negatives (better at detecting real effects) - Appropriate in exploratory research or when missing effects is costly</p> Field Typical \\( \\alpha \\) Reasoning Clinical trials 0.01 or lower False positives could harm patients Psychology/social science 0.05 Balance of concerns Exploratory research 0.10 Don't want to miss interesting leads Particle physics 0.0000003 (5 sigma) Extraordinary claims require extraordinary evidence"},{"location":"chapters/16-hypothesis-testing/#statistical-significance","title":"Statistical Significance","text":"<p>We say a result is statistically significant when the p-value falls below our chosen significance level \\( \\alpha \\).</p> \\[ \\text{Statistically significant} \\Leftrightarrow \\text{p-value} &lt; \\alpha \\] <p>Example: With \\( \\alpha = 0.05 \\): - p-value = 0.03 \u2192 statistically significant (reject \\( H_0 \\)) - p-value = 0.08 \u2192 not statistically significant (fail to reject \\( H_0 \\))</p>"},{"location":"chapters/16-hypothesis-testing/#the-meaning-of-statistical-significance","title":"The Meaning of Statistical Significance","text":"<p>When results are statistically significant, we're saying: \"The observed difference is too large to reasonably attribute to random sampling variation alone.\"</p> <p>When results are not statistically significant, we're saying: \"The observed difference could plausibly be due to random sampling variation.\"</p> <p>What Statistical Significance Does NOT Mean</p> <ul> <li>It does NOT mean the results are important or meaningful</li> <li>It does NOT prove \\( H_0 \\) is false</li> <li>It does NOT mean the effect is large</li> <li>It does NOT mean the finding will replicate</li> </ul> <p>Statistical significance is about the strength of evidence against \\( H_0 \\), not about practical importance. A tiny, meaningless difference can be statistically significant with a large enough sample.</p>"},{"location":"chapters/16-hypothesis-testing/#making-conclusions","title":"Making Conclusions","text":"<p>Making conclusions in hypothesis testing requires careful language. There are only two possible outcomes:</p>"},{"location":"chapters/16-hypothesis-testing/#outcome-1-reject-h_0","title":"Outcome 1: Reject \\( H_0 \\)","text":"<p>When p-value &lt; \\( \\alpha \\): - We have sufficient evidence to reject the null hypothesis - We conclude there IS evidence supporting the alternative - The result is statistically significant</p> <p>Template: \"At the \\( \\alpha = \\_\\_\\_ \\) significance level, we reject \\( H_0 \\). There is statistically significant evidence that [alternative hypothesis in context].\"</p> <p>Example: \"At the \\( \\alpha = 0.05 \\) significance level, we reject \\( H_0 \\). There is statistically significant evidence that the true customer satisfaction rate differs from 60%.\"</p>"},{"location":"chapters/16-hypothesis-testing/#outcome-2-fail-to-reject-h_0","title":"Outcome 2: Fail to Reject \\( H_0 \\)","text":"<p>When p-value \\( \\geq \\alpha \\): - We do NOT have sufficient evidence to reject the null hypothesis - We CANNOT conclude the alternative is true - The result is not statistically significant</p> <p>Template: \"At the \\( \\alpha = \\_\\_\\_ \\) significance level, we fail to reject \\( H_0 \\). There is not sufficient evidence that [alternative hypothesis in context].\"</p> <p>Example: \"At the \\( \\alpha = 0.05 \\) significance level, we fail to reject \\( H_0 \\). There is not sufficient evidence that the true customer satisfaction rate differs from 60%.\"</p>"},{"location":"chapters/16-hypothesis-testing/#critical-language-points","title":"Critical Language Points","text":"Correct Phrasing NEVER Say \"Fail to reject \\( H_0 \\)\" \"Accept \\( H_0 \\)\" \"Not sufficient evidence to conclude...\" \"We prove \\( H_0 \\) is true\" \"Evidence suggests...\" \"We prove \\( H_a \\) is true\" \"At the \\( \\alpha \\) level\" (omitting the significance level) <p>\"Time to squirrel away this crucial point!\" Sylvia emphasizes. \"We NEVER 'accept' the null hypothesis\u2014we only fail to reject it. Just like a jury doesn't declare someone 'innocent'\u2014they find them 'not guilty.' Absence of evidence isn't evidence of absence!\"</p>"},{"location":"chapters/16-hypothesis-testing/#diagram-hypothesis-testing-decision-flowchart","title":"Diagram: Hypothesis Testing Decision Flowchart","text":"Hypothesis Testing Decision Guide <p>Type: workflow</p> <p>Bloom Taxonomy: Apply (L3) Bloom Taxonomy Verb: Implement</p> <p>Learning objective: Students will follow the complete hypothesis testing procedure, making correct conclusions based on p-values and significance levels.</p> <p>Visual elements: - Flowchart with decision diamonds and process boxes - Color-coded paths for different outcomes - Summary boxes for each type of conclusion - Examples embedded at each decision point</p> <p>Steps in workflow: 1. Start: \"State hypotheses (H\u2080 and H\u2090)\"    Hover text: \"H\u2080 contains =, H\u2090 contains \u2260, &lt;, or &gt;\"</p> <ol> <li> <p>Process: \"Check conditions\"    Hover text: \"Verify np\u2080 \u2265 10 and n(1-p\u2080) \u2265 10 for z-test\"</p> </li> <li> <p>Decision: \"Conditions met?\"    Hover text: \"If not, cannot proceed with z-test\"</p> </li> <li> <p>Process: \"Calculate test statistic z\"    Hover text: \"z = (p\u0302 - p\u2080) / \u221a(p\u2080(1-p\u2080)/n)\"</p> </li> <li> <p>Process: \"Find p-value\"    Hover text: \"One-sided or two-sided based on H\u2090\"</p> </li> <li> <p>Decision: \"p-value &lt; \u03b1?\"    Hover text: \"Compare to chosen significance level\"</p> </li> </ol> <p>7a. (If Yes) Result: \"Reject H\u2080\"     Hover text: \"Statistically significant evidence for H\u2090\"     Color: Green</p> <p>7b. (If No) Result: \"Fail to Reject H\u2080\"     Hover text: \"Insufficient evidence for H\u2090\"     Color: Orange</p> <ol> <li>End: \"State conclusion in context\"    Hover text: \"Always relate back to the original question\"</li> </ol> <p>Visual style: Modern flowchart with rounded rectangles Color coding: - Blue: Process steps - Yellow: Decision points - Green: Reject H\u2080 path - Orange: Fail to reject path</p> <p>Canvas size: 800 x 600 pixels, responsive design Implementation: p5.js with canvas-based hover interactions</p>"},{"location":"chapters/16-hypothesis-testing/#type-i-and-type-ii-errors","title":"Type I and Type II Errors","text":"<p>In hypothesis testing, we make decisions based on incomplete information (sample data), so we can make mistakes. There are exactly two types of errors possible.</p>"},{"location":"chapters/16-hypothesis-testing/#type-i-error-false-positive","title":"Type I Error: False Positive","text":"<p>A Type I error occurs when we reject \\( H_0 \\) when it's actually true. We concluded something is happening when it's actually not\u2014a false alarm.</p> <p>Consequences of Type I Error: - Claiming a treatment works when it doesn't - Concluding a coin is unfair when it's actually fair - Believing there's a difference when there isn't one</p> <p>Probability of Type I Error: \\( P(\\text{Type I Error}) = \\alpha \\)</p> <p>This is why \\( \\alpha \\) is sometimes called the \"Type I error rate.\" When we set \\( \\alpha = 0.05 \\), we're accepting a 5% chance of a false positive.</p>"},{"location":"chapters/16-hypothesis-testing/#type-ii-error-false-negative","title":"Type II Error: False Negative","text":"<p>A Type II error occurs when we fail to reject \\( H_0 \\) when it's actually false. We missed something real\u2014we failed to detect a true effect.</p> <p>Consequences of Type II Error: - Missing an effective treatment - Declaring a biased coin \"fair\" - Concluding no difference when one exists</p> <p>Probability of Type II Error: \\( P(\\text{Type II Error}) = \\beta \\)</p> <p>The probability \\( \\beta \\) depends on sample size, the true parameter value, and how different reality is from \\( H_0 \\).</p>"},{"location":"chapters/16-hypothesis-testing/#the-four-possible-outcomes","title":"The Four Possible Outcomes","text":"\\( H_0 \\) is True \\( H_0 \\) is False Reject \\( H_0 \\) Type I Error (\\( \\alpha \\)) Correct Decision! Fail to Reject \\( H_0 \\) Correct Decision! Type II Error (\\( \\beta \\))"},{"location":"chapters/16-hypothesis-testing/#real-world-analogy","title":"Real-World Analogy","text":"Scenario Type I Error Type II Error Medical test Healthy patient diagnosed with disease Sick patient given clean bill of health Fire alarm Alarm sounds with no fire No alarm during actual fire Court trial Convicting an innocent person Acquitting a guilty person Spam filter Legitimate email marked as spam Spam gets through to inbox <p>\"Acorn for your thoughts on this?\" Sylvia asks. \"In my acorn quality testing, a Type I error means I reject perfectly good acorns thinking they're bad. A Type II error means I keep bad acorns thinking they're good. Both are problems, but depending on the situation, one might be worse than the other!\"</p>"},{"location":"chapters/16-hypothesis-testing/#diagram-type-i-and-type-ii-error-visualizer","title":"Diagram: Type I and Type II Error Visualizer","text":"Interactive Error Type Demonstration <p>Type: MicroSim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Taxonomy Verb: Distinguish</p> <p>Learning objective: Students will distinguish between Type I and Type II errors by exploring scenarios where the null hypothesis is either true or false, observing how different sample outcomes lead to correct decisions or errors.</p> <p>Data Visibility Requirements: - Stage 1: Show the true state of reality (H\u2080 true or false) - Stage 2: Show the sample data collected - Stage 3: Show the test statistic and p-value calculated - Stage 4: Show the decision made (reject or fail to reject) - Stage 5: Show the outcome (correct decision, Type I error, or Type II error)</p> <p>Visual elements: - Two parallel tracks: \"Reality\" track and \"Our Decision\" track - Reality track shows true population parameter (controlled by user) - Decision track shows sample, test statistic, p-value, and conclusion - Outcome box shows whether we made correct decision or error type - Color coding: green for correct, red for Type I, orange for Type II - Counter tracking cumulative error rates over many trials</p> <p>Interactive controls: - Toggle: \"H\u2080 is actually true\" vs \"H\u2080 is actually false\" - Slider for true population proportion (when H\u2080 is false) - Slider for sample size n - Input for significance level \u03b1 - \"Draw One Sample\" button - \"Run 100 Samples\" button to see error rates accumulate - Reset button</p> <p>Behavior: - When H\u2080 is true and we reject \u2192 Type I Error (red highlight) - When H\u2080 is true and we fail to reject \u2192 Correct (green) - When H\u2080 is false and we reject \u2192 Correct (green) - When H\u2080 is false and we fail to reject \u2192 Type II Error (orange) - Running counters show: \"Type I Errors: X/Y trials when H\u2080 true\" - Running counters show: \"Type II Errors: X/Y trials when H\u2080 false\" - Demonstrates that Type I rate \u2248 \u03b1 when H\u2080 is true</p> <p>Instructional Rationale: Interactive exploration with explicit state visibility is appropriate because the Analyze/distinguish objective requires learners to compare outcomes across different scenarios, building understanding of when each error type occurs.</p> <p>Canvas size: 850 x 550 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/16-hypothesis-testing/#error-tradeoffs","title":"Error Tradeoffs","text":"<p>There's an inherent tension between Type I and Type II errors\u2014reducing one tends to increase the other.</p>"},{"location":"chapters/16-hypothesis-testing/#the-tradeoff","title":"The Tradeoff","text":"<p>If we lower \\( \\alpha \\) (more strict): - Harder to reject \\( H_0 \\) - Fewer Type I errors (fewer false positives) - MORE Type II errors (more missed true effects)</p> <p>If we raise \\( \\alpha \\) (more lenient): - Easier to reject \\( H_0 \\) - More Type I errors - FEWER Type II errors (better detection)</p>"},{"location":"chapters/16-hypothesis-testing/#balancing-the-errors","title":"Balancing the Errors","text":"<p>The appropriate balance depends on consequences:</p> If Type I Error is Worse If Type II Error is Worse Use lower \\( \\alpha \\) (0.01) Use higher \\( \\alpha \\) (0.10) Convicting innocent people Letting guilty people go free Approving harmful drugs Missing effective treatments False alarms waste resources Missing real threats is dangerous"},{"location":"chapters/16-hypothesis-testing/#the-only-free-lunch-increase-sample-size","title":"The Only Free Lunch: Increase Sample Size","text":"<p>Want to reduce BOTH error types simultaneously? Increase your sample size. Larger samples provide more information, making it easier to:</p> <ul> <li>Detect real effects (reducing Type II errors)</li> <li>Have enough precision to avoid false alarms (reducing Type I errors)</li> </ul> <p>This is why well-funded studies use large samples\u2014they can afford to gather more data and make more accurate decisions.</p>"},{"location":"chapters/16-hypothesis-testing/#power-of-a-test","title":"Power of a Test","text":"<p>The power of a test is the probability of correctly rejecting \\( H_0 \\) when it's false\u2014the probability of detecting a real effect when one exists.</p> \\[ \\text{Power} = 1 - \\beta = P(\\text{Reject } H_0 | H_0 \\text{ is false}) \\] <p>Higher power is always better. A powerful test rarely misses real effects.</p>"},{"location":"chapters/16-hypothesis-testing/#factors-affecting-power","title":"Factors Affecting Power","text":"Factor Effect on Power Larger sample size Increases power Larger significance level (\\( \\alpha \\)) Increases power Larger true effect Increases power (easier to detect big differences) Less variability in data Increases power One-sided vs two-sided test One-sided has more power (if direction is correct)"},{"location":"chapters/16-hypothesis-testing/#practical-power-guidelines","title":"Practical Power Guidelines","text":"<ul> <li>Minimum acceptable power: 0.80 (80% chance of detecting a real effect)</li> <li>Desirable power: 0.90 or higher</li> <li>Power below 0.50: The test is essentially useless</li> </ul> <p>Power analysis is often done BEFORE data collection to determine the needed sample size. If we want 80% power to detect a specific effect size at \\( \\alpha = 0.05 \\), we can calculate how many observations we need.</p> <p>\"My tail's tingling\u2014we're onto something important!\" Sylvia exclaims. \"Power is like having good eyesight for data. A high-powered test can see small effects; a low-powered test might miss even obvious ones. Before starting a study, I always ask: 'Do I have enough acorns\u2014I mean, observations\u2014to actually detect what I'm looking for?'\"</p>"},{"location":"chapters/16-hypothesis-testing/#test-for-one-proportion","title":"Test for One Proportion","text":"<p>A test for one proportion determines whether a population proportion equals a specific value. This is the most common type of proportion test.</p>"},{"location":"chapters/16-hypothesis-testing/#the-setup","title":"The Setup","text":"<ul> <li>Parameter: p = true population proportion</li> <li>Hypotheses:</li> <li>\\( H_0: p = p_0 \\) (null value)</li> <li>\\( H_a: p \\neq p_0 \\) or \\( p &gt; p_0 \\) or \\( p &lt; p_0 \\)</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#the-test-statistic_1","title":"The Test Statistic","text":"\\[ z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] <p>Note: We use \\( p_0 \\) (not \\( \\hat{p} \\)) in the standard error because we calculate the probability assuming \\( H_0 \\) is true.</p>"},{"location":"chapters/16-hypothesis-testing/#complete-example-testing-a-claim","title":"Complete Example: Testing a Claim","text":"<p>Scenario: A coin is flipped 200 times and lands on heads 114 times. Test whether the coin is fair at \\( \\alpha = 0.05 \\).</p> <p>Step 1: State Hypotheses - \\( H_0: p = 0.5 \\) (coin is fair) - \\( H_a: p \\neq 0.5 \\) (coin is not fair)</p> <p>Step 2: Check Conditions - \\( np_0 = 200(0.5) = 100 \\geq 10 \\) \u2713 - \\( n(1-p_0) = 200(0.5) = 100 \\geq 10 \\) \u2713</p> <p>Step 3: Calculate Test Statistic [ \\hat{p} = \\frac{114}{200} = 0.57 ] [ z = \\frac{0.57 - 0.50}{\\sqrt{\\frac{0.50(0.50)}{200}}} = \\frac{0.07}{0.0354} = 1.98 ]</p> <p>Step 4: Find P-Value Two-sided test: \\( \\text{p-value} = 2 \\times P(Z &gt; 1.98) = 2 \\times 0.0239 = 0.0478 \\)</p> <p>Step 5: Make Conclusion Since p-value (0.0478) &lt; \\( \\alpha \\) (0.05), we reject \\( H_0 \\).</p> <p>\"At the 0.05 significance level, there is statistically significant evidence that the coin is not fair. The sample data suggests the probability of heads differs from 0.5.\"</p>"},{"location":"chapters/16-hypothesis-testing/#conditions-for-z-test","title":"Conditions for Z-Test","text":"<p>The conditions for z-test must be verified before conducting the test. If conditions aren't met, the p-value calculations may be inaccurate.</p>"},{"location":"chapters/16-hypothesis-testing/#the-three-conditions","title":"The Three Conditions","text":"<p>1. Random Sample The data must come from a random sample or randomized experiment. This ensures the sample is representative of the population.</p> <p>2. Independence (10% Rule) Sample observations must be independent. When sampling without replacement, the sample size should be less than 10% of the population. [ n &lt; 0.10N ]</p> <p>3. Large Counts (Normality) The sampling distribution of \\( \\hat{p} \\) must be approximately normal. This requires: [ np_0 \\geq 10 \\quad \\text{and} \\quad n(1-p_0) \\geq 10 ]</p> <p>Note: For hypothesis tests, we check using \\( p_0 \\) (the hypothesized proportion), not \\( \\hat{p} \\).</p>"},{"location":"chapters/16-hypothesis-testing/#what-if-conditions-arent-met","title":"What If Conditions Aren't Met?","text":"Condition Violated Problem Solution Not random Results may be biased Use proper random sampling Not independent Standard error is wrong Sample less than 10% of population Small counts Normal approximation fails Use exact binomial test or collect more data <p>Always Check Conditions First</p> <p>Before calculating test statistics and p-values, verify all three conditions. Many students lose points on AP Statistics by skipping this step!</p>"},{"location":"chapters/16-hypothesis-testing/#test-for-two-proportions","title":"Test for Two Proportions","text":"<p>A test for two proportions compares proportions between two independent groups. This is useful when asking: \"Is the proportion different between Group A and Group B?\"</p>"},{"location":"chapters/16-hypothesis-testing/#the-setup_1","title":"The Setup","text":"<ul> <li>Parameters: \\( p_1 \\) = proportion in population 1, \\( p_2 \\) = proportion in population 2</li> <li>Hypotheses:</li> <li>\\( H_0: p_1 - p_2 = 0 \\) (or equivalently, \\( p_1 = p_2 \\))</li> <li>\\( H_a: p_1 - p_2 \\neq 0 \\) or \\( &gt; 0 \\) or \\( &lt; 0 \\)</li> </ul>"},{"location":"chapters/16-hypothesis-testing/#pooled-proportion","title":"Pooled Proportion","text":"<p>Since \\( H_0 \\) assumes the proportions are equal, we combine the samples to get a pooled proportion:</p> \\[ \\hat{p}_{pool} = \\frac{x_1 + x_2}{n_1 + n_2} = \\frac{\\text{total successes}}{\\text{total sample size}} \\]"},{"location":"chapters/16-hypothesis-testing/#the-test-statistic_2","title":"The Test Statistic","text":"\\[ z = \\frac{(\\hat{p}_1 - \\hat{p}_2) - 0}{\\sqrt{\\hat{p}_{pool}(1-\\hat{p}_{pool})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}} \\]"},{"location":"chapters/16-hypothesis-testing/#conditions-for-two-proportion-z-test","title":"Conditions for Two-Proportion Z-Test","text":"<ol> <li>Random: Both samples are random samples or from randomized experiments</li> <li>Independent: Samples are independent of each other, and within each sample, observations are independent</li> <li>Large Counts: For each group: \\( n_i \\hat{p}_{pool} \\geq 10 \\) and \\( n_i(1-\\hat{p}_{pool}) \\geq 10 \\)</li> </ol>"},{"location":"chapters/16-hypothesis-testing/#complete-example-comparing-two-groups","title":"Complete Example: Comparing Two Groups","text":"<p>Scenario: In a study of a new teaching method: - Control group (traditional): 45 of 120 passed (\\( \\hat{p}_1 = 0.375 \\)) - Treatment group (new method): 68 of 130 passed (\\( \\hat{p}_2 = 0.523 \\))</p> <p>Test whether the new method produces different pass rates at \\( \\alpha = 0.05 \\).</p> <p>Step 1: State Hypotheses - \\( H_0: p_1 - p_2 = 0 \\) (no difference) - \\( H_a: p_1 - p_2 \\neq 0 \\) (there is a difference)</p> <p>Step 2: Calculate Pooled Proportion [ \\hat{p}_{pool} = \\frac{45 + 68}{120 + 130} = \\frac{113}{250} = 0.452 ]</p> <p>Step 3: Check Conditions - \\( 120(0.452) = 54.2 \\geq 10 \\) \u2713 - \\( 120(0.548) = 65.8 \\geq 10 \\) \u2713 - \\( 130(0.452) = 58.8 \\geq 10 \\) \u2713 - \\( 130(0.548) = 71.2 \\geq 10 \\) \u2713</p> <p>Step 4: Calculate Test Statistic [ z = \\frac{(0.375 - 0.523) - 0}{\\sqrt{0.452(0.548)\\left(\\frac{1}{120} + \\frac{1}{130}\\right)}} = \\frac{-0.148}{\\sqrt{0.2477(0.0077 + 0.0077)}} = \\frac{-0.148}{0.0632} = -2.34 ]</p> <p>Step 5: Find P-Value Two-sided: \\( \\text{p-value} = 2 \\times P(Z &lt; -2.34) = 2 \\times 0.0096 = 0.0192 \\)</p> <p>Step 6: Conclusion Since p-value (0.0192) &lt; \\( \\alpha \\) (0.05), we reject \\( H_0 \\).</p> <p>\"At the 0.05 significance level, there is statistically significant evidence of a difference in pass rates between the traditional and new teaching methods.\"</p>"},{"location":"chapters/16-hypothesis-testing/#diagram-two-proportion-test-comparison","title":"Diagram: Two-Proportion Test Comparison","text":"Interactive Two-Proportion Test Calculator <p>Type: MicroSim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Taxonomy Verb: Execute</p> <p>Learning objective: Students will conduct a complete two-proportion z-test by entering data from two groups, calculating the pooled proportion and test statistic, and interpreting the results.</p> <p>Visual elements: - Two side-by-side input panels for each group's data - Visual comparison bar chart showing the two sample proportions - Pooled proportion calculation display - Test statistic formula with substituted values - Normal curve with z-score marked and p-value shaded - Conclusion statement generator</p> <p>Interactive controls: - Group 1: Input fields for n\u2081 (sample size) and x\u2081 (successes) - Group 2: Input fields for n\u2082 (sample size) and x\u2082 (successes) - Radio buttons for test type: two-sided, p\u2081 &gt; p\u2082, p\u2081 &lt; p\u2082 - Slider for significance level \u03b1 (0.01, 0.05, 0.10) - \"Calculate\" button - \"Check Conditions\" button (highlights which conditions pass/fail) - \"Show Steps\" toggle for detailed calculation breakdown</p> <p>Behavior: - Automatically calculates p\u0302\u2081, p\u0302\u2082, pooled p\u0302 - Displays step-by-step calculation of standard error and z-statistic - Shows p-value with visual representation on normal curve - Compares p-value to \u03b1 and states conclusion - Generates properly worded conclusion statement - Warning messages for condition violations</p> <p>Canvas size: 900 x 600 pixels, responsive design Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/16-hypothesis-testing/#practical-significance","title":"Practical Significance","text":"<p>Practical significance asks whether a statistically significant result actually matters in the real world. Just because we can detect a difference doesn't mean the difference is important.</p>"},{"location":"chapters/16-hypothesis-testing/#the-problem-with-large-samples","title":"The Problem with Large Samples","text":"<p>With a large enough sample, even tiny differences become statistically significant. This happens because:</p> <ul> <li>The standard error shrinks as n increases</li> <li>Small differences produce large z-scores</li> <li>P-values become very small</li> </ul> <p>Example: If a medication improves outcomes from 80.0% to 80.5%, that's a 0.5% improvement. With n = 10,000 in each group, this tiny difference might have p-value &lt; 0.001. Statistically significant? Yes. Practically important? Probably not.</p>"},{"location":"chapters/16-hypothesis-testing/#statistical-vs-practical-significance","title":"Statistical vs. Practical Significance","text":"Aspect Statistical Significance Practical Significance Question answered \"Is there any difference?\" \"Is the difference big enough to matter?\" Measured by P-value Effect size, context Affected by Sample size Real-world implications Can exist without Large sample needed Can't have practical without some effect"},{"location":"chapters/16-hypothesis-testing/#assessing-practical-significance","title":"Assessing Practical Significance","text":"<p>When evaluating practical significance, consider:</p> <ol> <li>The size of the effect: How big is the difference in practical terms?</li> <li>The context: What would this difference mean in the real world?</li> <li>The cost-benefit analysis: Is the difference worth acting on?</li> <li>Comparison to meaningful benchmarks: How does the effect compare to what's considered meaningful in this field?</li> </ol> <p>Example Evaluation: - A diet produces statistically significant weight loss of 0.5 pounds - Context: Is losing half a pound meaningful for health? - Cost: What are the burdens of this diet? - Benchmark: Doctors consider 5% body weight loss clinically meaningful</p> <p>Conclusion: Statistically significant but not practically significant.</p> <p>\"Here's wisdom from my acorn research,\" Sylvia shares. \"I once found a statistically significant difference in acorn weight between north and south sides of a tree\u2014about 0.01 grams. My p-value was tiny! But would I change my foraging strategy over one hundredth of a gram? Of course not. The effect was real but meaningless for my purposes.\"</p>"},{"location":"chapters/16-hypothesis-testing/#complete-hypothesis-testing-examples","title":"Complete Hypothesis Testing Examples","text":"<p>Let's work through complete examples that bring all the concepts together.</p>"},{"location":"chapters/16-hypothesis-testing/#example-1-one-proportion-test","title":"Example 1: One-Proportion Test","text":"<p>Scenario: A school claims that 75% of their graduates go to college. A sample of 180 graduates finds that 125 went to college. Test whether the true proportion differs from the claim at \\( \\alpha = 0.05 \\).</p> <p>Solution:</p> <p>Step 1: State Hypotheses - \\( H_0: p = 0.75 \\) - \\( H_a: p \\neq 0.75 \\)</p> <p>Step 2: Check Conditions - Random: Assuming this is a random sample of graduates \u2713 - Independence: 180 is less than 10% of all graduates (assuming large alumni base) \u2713 - Large counts: \\( 180(0.75) = 135 \\geq 10 \\) \u2713 and \\( 180(0.25) = 45 \\geq 10 \\) \u2713</p> <p>Step 3: Calculate Test Statistic [ \\hat{p} = \\frac{125}{180} = 0.694 ] [ z = \\frac{0.694 - 0.75}{\\sqrt{\\frac{0.75(0.25)}{180}}} = \\frac{-0.056}{0.0323} = -1.73 ]</p> <p>Step 4: Find P-Value [ \\text{p-value} = 2 \\times P(Z &lt; -1.73) = 2 \\times 0.0418 = 0.0836 ]</p> <p>Step 5: Conclusion Since p-value (0.0836) &gt; \\( \\alpha \\) (0.05), we fail to reject \\( H_0 \\).</p> <p>At the 0.05 significance level, there is not sufficient evidence to conclude that the true proportion of graduates going to college differs from 75%.</p>"},{"location":"chapters/16-hypothesis-testing/#example-2-one-sided-test","title":"Example 2: One-Sided Test","text":"<p>Scenario: A company's old website had a 12% conversion rate. After a redesign, 156 of 1000 visitors made a purchase. Test whether the new design improved conversions at \\( \\alpha = 0.01 \\).</p> <p>Solution:</p> <p>Step 1: State Hypotheses - \\( H_0: p = 0.12 \\) - \\( H_a: p &gt; 0.12 \\) (one-sided, testing for improvement)</p> <p>Step 2: Check Conditions - \\( 1000(0.12) = 120 \\geq 10 \\) \u2713 - \\( 1000(0.88) = 880 \\geq 10 \\) \u2713</p> <p>Step 3: Calculate Test Statistic [ \\hat{p} = \\frac{156}{1000} = 0.156 ] [ z = \\frac{0.156 - 0.12}{\\sqrt{\\frac{0.12(0.88)}{1000}}} = \\frac{0.036}{0.0103} = 3.50 ]</p> <p>Step 4: Find P-Value One-sided (right): \\( \\text{p-value} = P(Z &gt; 3.50) = 0.0002 \\)</p> <p>Step 5: Conclusion Since p-value (0.0002) &lt; \\( \\alpha \\) (0.01), we reject \\( H_0 \\).</p> <p>At the 0.01 significance level, there is statistically significant evidence that the new website design has a higher conversion rate than the old design's 12%.</p>"},{"location":"chapters/16-hypothesis-testing/#common-mistakes-in-hypothesis-testing","title":"Common Mistakes in Hypothesis Testing","text":"<p>Before we conclude, let's address errors that trip up even careful students:</p> <p>Mistake 1: Wrong Hypothesis Structure - Using \\( \\hat{p} \\) instead of p in hypotheses (hypotheses are about parameters, not statistics) - Putting inequality in \\( H_0 \\) instead of \\( H_a \\)</p> <p>Mistake 2: Using Wrong Standard Error - For hypothesis tests, use \\( p_0 \\) (the null value) in the standard error - For confidence intervals, use \\( \\hat{p} \\) (the sample value)</p> <p>Mistake 3: Confusing P-Value Interpretation - The p-value is NOT the probability that \\( H_0 \\) is true - It's the probability of getting data this extreme IF \\( H_0 \\) were true</p> <p>Mistake 4: Saying \"Accept \\( H_0 \\)\" - We never \"accept\" the null hypothesis - We either \"reject\" or \"fail to reject\"</p> <p>Mistake 5: Ignoring Practical Significance - Statistical significance doesn't imply practical importance - Always consider context and effect size</p> <p>Mistake 6: Choosing Test Direction After Seeing Data - One-sided vs. two-sided must be decided before analysis - Choosing after seeing results is \"p-hacking\"</p> <p>Mistake 7: Forgetting to Check Conditions - Always verify random sample, independence, and large counts - Invalid conditions mean unreliable p-values</p>"},{"location":"chapters/16-hypothesis-testing/#key-takeaways","title":"Key Takeaways","text":"<p>\"Time to squirrel away the big ideas!\"</p> <ul> <li> <p>A hypothesis test uses sample data to evaluate a claim about a population parameter</p> </li> <li> <p>The null hypothesis (\\( H_0 \\)) represents \"no effect\" and contains equality; the alternative hypothesis (\\( H_a \\)) is what we seek evidence for</p> </li> <li> <p>One-sided tests look for evidence in one direction; two-sided tests look for evidence in either direction</p> </li> <li> <p>The test statistic measures how far the sample result is from what's expected under \\( H_0 \\)</p> </li> <li> <p>The p-value is the probability of getting results as extreme as observed, assuming \\( H_0 \\) is true</p> </li> <li> <p>The significance level (\\( \\alpha \\)) is the threshold for rejecting \\( H_0 \\); common choice is 0.05</p> </li> <li> <p>Statistical significance means p-value &lt; \\( \\alpha \\); we reject \\( H_0 \\) and have evidence for \\( H_a \\)</p> </li> <li> <p>Type I error: Rejecting a true \\( H_0 \\) (false positive); probability = \\( \\alpha \\)</p> </li> <li> <p>Type II error: Failing to reject a false \\( H_0 \\) (false negative); probability = \\( \\beta \\)</p> </li> <li> <p>Power = 1 - \\( \\beta \\) = probability of correctly rejecting a false \\( H_0 \\)</p> </li> <li> <p>For one-proportion z-test: \\( z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\)</p> </li> <li> <p>For two-proportion z-test: Use the pooled proportion when calculating the standard error</p> </li> <li> <p>Practical significance considers whether a statistically significant difference actually matters in context</p> </li> </ul>"},{"location":"chapters/16-hypothesis-testing/#practice-problems","title":"Practice Problems","text":"Check Your Understanding <p>Problem 1: A company claims that 90% of orders are delivered on time. In a random sample of 400 orders, 348 were on time.</p> <p>a) State the null and alternative hypotheses to test if the proportion differs from the claim. b) Calculate the test statistic. c) Find the p-value. d) At \u03b1 = 0.05, what is your conclusion?</p> <p>Problem 2: A researcher wants to test if more than 60% of adults support a new policy. In a random sample of 500 adults, 325 support the policy.</p> <p>a) State the appropriate hypotheses. b) Is this a one-sided or two-sided test? Why? c) Conduct the complete hypothesis test at \u03b1 = 0.05.</p> <p>Problem 3: Explain the difference between a Type I error and a Type II error in the context of testing whether a new drug is effective.</p> <p>Problem 4: Two factories produce the same product. Factory A had 24 defects in 600 items. Factory B had 42 defects in 700 items. Test whether there's a difference in defect rates at \u03b1 = 0.05.</p> <p>Problem 5: A study finds that a diet pill produces statistically significant weight loss (p &lt; 0.001) with an average loss of 0.3 pounds. Discuss statistical versus practical significance.</p> Solutions <p>Problem 1:</p> <p>a) \\( H_0: p = 0.90 \\), \\( H_a: p \\neq 0.90 \\)</p> <p>b) \\( \\hat{p} = 348/400 = 0.87 \\) \\( z = \\frac{0.87 - 0.90}{\\sqrt{0.90(0.10)/400}} = \\frac{-0.03}{0.015} = -2.0 \\)</p> <p>c) p-value = 2 \u00d7 P(Z &lt; -2.0) = 2 \u00d7 0.0228 = 0.0456</p> <p>d) Since 0.0456 &lt; 0.05, reject \\( H_0 \\). At the 0.05 significance level, there is statistically significant evidence that the on-time delivery rate differs from 90%.</p> <p>Problem 2:</p> <p>a) \\( H_0: p = 0.60 \\), \\( H_a: p &gt; 0.60 \\)</p> <p>b) One-sided (right-tailed) because we're specifically testing if more than 60% support the policy.</p> <p>c) \\( \\hat{p} = 325/500 = 0.65 \\) \\( z = \\frac{0.65 - 0.60}{\\sqrt{0.60(0.40)/500}} = \\frac{0.05}{0.0219} = 2.28 \\) p-value = P(Z &gt; 2.28) = 0.0113 Since 0.0113 &lt; 0.05, reject \\( H_0 \\). There is statistically significant evidence that more than 60% of adults support the policy.</p> <p>Problem 3: Type I error: Concluding the drug is effective when it actually isn't (approving an ineffective drug). This could lead to patients receiving useless treatment.</p> <p>Type II error: Concluding the drug is not effective when it actually is (rejecting an effective drug). This could deny patients a beneficial treatment.</p> <p>In drug testing, Type I errors are often considered more dangerous because approving an ineffective drug wastes resources and may have side effects with no benefit.</p> <p>Problem 4: \\( \\hat{p}_A = 24/600 = 0.04 \\), \\( \\hat{p}_B = 42/700 = 0.06 \\) \\( \\hat{p}_{pool} = (24+42)/(600+700) = 66/1300 = 0.0508 \\) \\( z = \\frac{0.04 - 0.06}{\\sqrt{0.0508(0.9492)(1/600 + 1/700)}} = \\frac{-0.02}{0.0123} = -1.63 \\) p-value = 2 \u00d7 P(Z &lt; -1.63) = 2 \u00d7 0.0516 = 0.1032 Since 0.1032 &gt; 0.05, fail to reject \\( H_0 \\). There is not sufficient evidence of a difference in defect rates between the factories.</p> <p>Problem 5: The result is statistically significant (p &lt; 0.001), meaning if the pill had no effect, observing 0.3 pounds average weight loss would be extremely rare.</p> <p>However, the practical significance is questionable. Losing 0.3 pounds is barely noticeable and unlikely to have health benefits. The very small p-value likely results from a large sample size rather than a meaningful effect. Clinically meaningful weight loss is typically considered 5% of body weight. This pill might \"work\" statistically but isn't practically useful.</p> <p>You've now mastered the core concepts of hypothesis testing\u2014one of the most important tools in statistical inference. This framework for making decisions based on data applies everywhere: in medicine, business, science, and everyday life.</p> <p>\"Now that's a data point worth collecting!\" Sylvia beams. \"You've learned to be a data detective, testing claims with evidence rather than just accepting them. Whether you're evaluating a new product, a medical treatment, or even whether a coin is fair, you now have the tools to let the data speak. That's a superpower worth having!\"</p> <p>In the upcoming chapters, we'll extend these ideas to tests involving means and apply hypothesis testing to more complex scenarios. The logic remains the same\u2014only the formulas change.</p>"},{"location":"chapters/17-inference-for-means/","title":"Inference for Means","text":""},{"location":"chapters/17-inference-for-means/#summary","title":"Summary","text":"<p>This chapter extends inference procedures to population means using t-distributions. Students will learn about the t-distribution and its properties, construct confidence intervals and perform hypothesis tests for one-sample and two-sample means, and understand when to use paired t-procedures. The robustness of t-procedures and their conditions are emphasized.</p>"},{"location":"chapters/17-inference-for-means/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 18 concepts from the learning graph:</p> <ol> <li>T-Distribution</li> <li>T vs Z Distribution</li> <li>Degrees of Freedom</li> <li>T Critical Values</li> <li>One-Sample T-Interval</li> <li>Conditions for T-Procedures</li> <li>One-Sample T-Test</li> <li>Two-Sample T-Interval</li> <li>Two-Sample T-Test</li> <li>Pooled vs Unpooled</li> <li>Paired T-Test</li> <li>Paired Data</li> <li>When to Pair</li> <li>Robustness</li> <li>Regression Model</li> <li>Slope Parameter</li> <li>Standard Error of Slope</li> </ol>"},{"location":"chapters/17-inference-for-means/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 15: Confidence Intervals</li> <li>Chapter 16: Hypothesis Testing</li> </ul>"},{"location":"chapters/17-inference-for-means/#from-proportions-to-means-a-new-challenge","title":"From Proportions to Means: A New Challenge","text":"<p>So far, you've mastered inference for proportions\u2014estimating and testing claims about what fraction of a population has some characteristic. But what about quantitative data? What if we want to estimate the average height of students, compare mean test scores between two groups, or test whether a new teaching method improves learning?</p> <p>Welcome to inference for means! This chapter opens up a whole new world of statistical analysis, one that handles measurements, amounts, and continuous data. The good news? The logical framework you learned for proportions still applies\u2014we'll still construct confidence intervals and perform hypothesis tests. The twist? We need a new distribution to work with.</p> <p>\"Acorn for your thoughts?\" Sylvia tilts her head thoughtfully. \"When I wanted to know if south-side oaks produced more acorns, I wasn't just counting successes and failures\u2014I was measuring actual quantities! How many acorns per tree? What's the average weight? That's quantitative data, and it needs special treatment. Don't worry\u2014we've got just the tool for the job!\"</p> <p>By the end of this chapter, you'll be able to:</p> <ul> <li>Understand why we need the t-distribution for inference about means</li> <li>Calculate degrees of freedom and find t critical values</li> <li>Construct and interpret confidence intervals for one mean and the difference of two means</li> <li>Perform hypothesis tests for means using one-sample and two-sample t-tests</li> <li>Recognize when paired data requires special treatment</li> <li>Evaluate the robustness of t-procedures when conditions aren't perfectly met</li> </ul>"},{"location":"chapters/17-inference-for-means/#why-not-use-the-z-distribution","title":"Why Not Use the Z-Distribution?","text":"<p>When we did inference for proportions, we used the normal (Z) distribution. This worked because the sampling distribution of \\( \\hat{p} \\) is approximately normal for large samples, and we knew (or could estimate) the population proportion to calculate the standard error.</p> <p>But here's the problem with means: to calculate the standard error of \\( \\bar{x} \\), we'd need to know the population standard deviation \\( \\sigma \\). And we almost never know \\( \\sigma \\)!</p> <p>The standard error formula for sample means is:</p> \\[ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} \\] <p>Since we don't know \\( \\sigma \\), we substitute the sample standard deviation \\( s \\):</p> \\[ SE_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\] <p>This substitution introduces extra uncertainty\u2014\\( s \\) is itself a random variable that varies from sample to sample. The normal distribution doesn't account for this extra variability, especially in smaller samples. Enter the t-distribution!</p> When Doing Inference About... We Know... We Use... Proportions Can estimate \\( p \\) from \\( \\hat{p} \\) Z-distribution Means (known \\( \\sigma \\)) Population SD Z-distribution Means (unknown \\( \\sigma \\)) Only sample SD \\( s \\) t-distribution"},{"location":"chapters/17-inference-for-means/#the-t-distribution","title":"The T-Distribution","text":"<p>The t-distribution (also called Student's t-distribution) was developed by William Sealy Gosset in 1908 while working at the Guinness Brewery in Dublin. He published under the pseudonym \"Student\" because Guinness didn't allow employees to publish under their own names\u2014hence \"Student's t.\"</p> <p>The t-distribution looks similar to the normal distribution but accounts for the extra uncertainty when we estimate \\( \\sigma \\) with \\( s \\).</p>"},{"location":"chapters/17-inference-for-means/#properties-of-the-t-distribution","title":"Properties of the T-Distribution","text":"<p>The t-distribution has several key properties:</p> <ul> <li>Symmetric and bell-shaped: Just like the normal distribution</li> <li>Centered at zero: The mean is 0 (when sampling from a normal population)</li> <li>Heavier tails: More probability in the tails than the normal distribution</li> <li>Depends on sample size: Gets closer to normal as \\( n \\) increases</li> <li>Defined by degrees of freedom: The shape is determined by a parameter called degrees of freedom</li> </ul> <p>\"Here's something that really helped the concept click for me,\" Sylvia shares. \"The t-distribution is basically saying 'Hey, we're less certain about things because we had to estimate the spread from our sample.' Those heavier tails mean extreme values are more likely than with the normal distribution. It's the distribution being honest about our uncertainty!\"</p>"},{"location":"chapters/17-inference-for-means/#visual-comparison-t-vs-normal","title":"Visual Comparison: T vs. Normal","text":"<p>The t-distribution's heavier tails have real consequences for inference. Because more probability is in the tails, critical values for the t-distribution are larger than for the normal distribution. This means:</p> <ul> <li>Confidence intervals are wider when using t</li> <li>It's harder to get statistically significant results with small samples</li> </ul> <p>As the sample size increases, the t-distribution approaches the normal distribution. With 30+ observations, they're quite similar. With 100+ observations, they're nearly identical.</p> Degrees of Freedom Critical Value for 95% CI 5 2.571 10 2.228 20 2.086 30 2.042 50 2.009 100 1.984 \u221e (Normal) 1.960 <p>Notice how the critical values decrease as degrees of freedom increase, approaching 1.96 (the z* value for 95% confidence).</p>"},{"location":"chapters/17-inference-for-means/#diagram-t-distribution-vs-normal-distribution-comparison","title":"Diagram: T-Distribution vs Normal Distribution Comparison","text":"T-Distribution vs Normal Distribution Comparison <p>Type: microsim</p> <p>Bloom Level: Understand (L2) Bloom Verb: Compare, contrast</p> <p>Learning Objective: Students will compare the shapes of t-distributions with different degrees of freedom to the standard normal distribution, understanding how heavier tails affect inference.</p> <p>Data Visibility Requirements: - Stage 1: Show standard normal distribution (Z) as baseline curve in blue - Stage 2: Overlay t-distribution with user-selected df in orange/red - Stage 3: Show critical values for both distributions at 95% confidence level - Stage 4: Display area in tails for both distributions</p> <p>Visual Elements: - Two overlapping distribution curves on same axes - Standard normal curve (blue, solid line) - T-distribution curve (orange, dashed line initially) - Shaded tail areas showing 2.5% in each tail - Vertical lines marking critical values - Legend showing which curve is which</p> <p>Interactive Controls: - Slider: Degrees of freedom (df) from 1 to 100 - Radio buttons: Show 90%, 95%, or 99% confidence level - Checkbox: Show/hide shaded tail areas - Checkbox: Show/hide critical value lines</p> <p>Display Panel (right side): - Current df value - t critical value for selected confidence level - z critical value for comparison - Difference between t and z</p> <p>Default Parameters: - df = 5 - Confidence level = 95% - Tail areas shown - Critical values shown</p> <p>Behavior: - As df slider moves, t-distribution curve smoothly transitions - Critical value lines and tail areas update in real-time - At high df (100+), curves should nearly overlap - At low df (1-5), t-distribution should have noticeably heavier tails</p> <p>Instructional Rationale: Slider exploration is appropriate because the Apply/compare objective requires learners to see how the parameter (df) affects the distribution shape. Real-time visual feedback helps build intuition about why small samples produce wider intervals.</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/17-inference-for-means/#degrees-of-freedom","title":"Degrees of Freedom","text":"<p>Degrees of freedom (df) is a parameter that determines the exact shape of the t-distribution. For the procedures in this chapter:</p> <ul> <li>One-sample t-procedures: df = n - 1</li> <li>Two-sample t-procedures: df is calculated from a complex formula (or conservatively estimated)</li> <li>Paired t-procedures: df = n - 1 (where n is the number of pairs)</li> </ul> <p>But what ARE degrees of freedom? Conceptually, they represent the number of independent pieces of information available to estimate a parameter.</p> <p>Here's an analogy: Imagine you have 5 numbers that must add up to 50. You can choose the first 4 numbers freely, but once you've chosen them, the 5th number is determined\u2014it's whatever value makes the sum equal 50. You had 4 \"degrees of freedom\" in your choices.</p> <p>Similarly, when calculating the sample standard deviation \\( s \\), we use the sample mean \\( \\bar{x} \\) in our calculations. Since we've already used the data to calculate \\( \\bar{x} \\), we've \"used up\" one degree of freedom. That's why df = n - 1.</p>"},{"location":"chapters/17-inference-for-means/#why-degrees-of-freedom-matter","title":"Why Degrees of Freedom Matter","text":"<p>Degrees of freedom affect:</p> <ul> <li>Shape of the t-distribution: Lower df means heavier tails</li> <li>Critical values: Lower df means larger critical values</li> <li>Width of confidence intervals: Lower df means wider intervals</li> <li>Difficulty of rejecting H\u2080: Lower df means we need more extreme evidence</li> </ul> <p>\"I love thinking about this one!\" Sylvia's tail twitches with excitement. \"Degrees of freedom are like how many independent choices you have left. If you're filling 5 bags with exactly 100 acorns total, you can put whatever you want in the first 4 bags. But that last bag? No choice\u2014it gets whatever makes the total 100. Four degrees of freedom!\"</p>"},{"location":"chapters/17-inference-for-means/#t-critical-values","title":"T Critical Values","text":"<p>T critical values (denoted \\( t^* \\)) are the values that mark off specified areas in the tails of the t-distribution. To find a t critical value, you need:</p> <ol> <li>The confidence level (or significance level)</li> <li>The degrees of freedom</li> </ol>"},{"location":"chapters/17-inference-for-means/#finding-t-critical-values","title":"Finding T Critical Values","text":"<p>Most statistics courses use t-tables, calculators, or statistical software to find t critical values.</p> <p>For a confidence interval at confidence level C: - Find the value \\( t^* \\) such that C% of the t-distribution is between -\\( t^* \\) and +\\( t^* \\) - This leaves (1-C)/2 in each tail</p> <p>For a hypothesis test at significance level \u03b1: - For a two-sided test: find \\( t^* \\) with \u03b1/2 in each tail - For a one-sided test: find \\( t^* \\) with \u03b1 in the relevant tail</p> Confidence Level Area in Each Tail Example t* (df=20) 90% 0.05 1.725 95% 0.025 2.086 99% 0.005 2.845"},{"location":"chapters/17-inference-for-means/#diagram-interactive-t-critical-value-finder","title":"Diagram: Interactive T Critical Value Finder","text":"Interactive T Critical Value Finder <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate, use</p> <p>Learning Objective: Students will find t critical values for different degrees of freedom and confidence levels, connecting the visual representation to the numerical values used in formulas.</p> <p>Visual Elements: - T-distribution curve centered on canvas - Shaded regions showing tail areas or central area - Vertical lines at critical values - Labels showing t* values on the axis</p> <p>Interactive Controls: - Slider: Degrees of freedom (1 to 100) - Dropdown: Select test type (Two-sided, Right-tailed, Left-tailed) - Dropdown: Select confidence/significance level (90%, 95%, 99%) - Toggle: Show confidence interval view vs. hypothesis test view</p> <p>Display Panel: - Current df - t critical value(s) - Shaded area percentage - Comparison to z (when df &gt; 30)</p> <p>Behavior: - Curve shape updates smoothly with df changes - Shaded areas and critical value lines update in real-time - For two-sided: shade both tails - For one-sided: shade appropriate tail - Display exact t* value rounded to 3 decimal places</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/17-inference-for-means/#conditions-for-t-procedures","title":"Conditions for T-Procedures","text":"<p>Before using any t-procedure, we must check that certain conditions for t-procedures are met. The validity of our inference depends on these conditions.</p>"},{"location":"chapters/17-inference-for-means/#the-three-conditions","title":"The Three Conditions","text":"<p>1. Random: The data must come from a random sample or randomized experiment.</p> <ul> <li>This ensures our sample is representative</li> <li>Without randomness, we cannot make inferences about the population</li> <li>Check: Was there a random selection or random assignment process?</li> </ul> <p>2. Normal/Large Sample: The sampling distribution of \\( \\bar{x} \\) must be approximately normal.</p> <p>This condition is satisfied if EITHER: - The population distribution is approximately normal, OR - The sample size is large (n \u2265 30) due to the Central Limit Theorem</p> <p>For smaller samples (n &lt; 30): - Look at a dotplot, histogram, or Normal probability plot of the data - Check for severe skewness or outliers - The more symmetric and outlier-free the data, the smaller the sample can be</p> <p>3. Independence: Individual observations must be independent.</p> <ul> <li>For sampling without replacement: The population should be at least 10 times the sample size (10% condition)</li> <li>For experiments: Random assignment helps ensure independence</li> </ul>"},{"location":"chapters/17-inference-for-means/#checking-normality","title":"Checking Normality","text":"<p>The t-procedures are fairly robust to violations of the normality condition\u2014they work reasonably well even when the population isn't perfectly normal. However:</p> <ul> <li>With small samples (n &lt; 15), the data should be close to normal with no outliers</li> <li>With moderate samples (15 \u2264 n &lt; 30), the procedures can handle slight skewness</li> <li>With large samples (n \u2265 30), the CLT kicks in, and normality matters less</li> </ul> <p>Sylvia's Normality Check Tip</p> <p>\"Here's my rule of thumb: Graph the data first! If it looks roughly symmetric and has no extreme outliers, you're probably fine. If it looks like a ski slope (heavily skewed) or has values way out in the tails, be cautious\u2014especially with small samples.\"</p> Sample Size Acceptable Data Shape n &lt; 15 Must be close to normal, no outliers 15 \u2264 n &lt; 30 Can handle moderate skewness, no extreme outliers n \u2265 30 CLT applies; any reasonable distribution works n \u2265 40 Even skewed distributions are usually fine"},{"location":"chapters/17-inference-for-means/#one-sample-t-interval","title":"One-Sample T-Interval","text":"<p>A one-sample t-interval is a confidence interval for a single population mean \u03bc when \u03c3 is unknown (which is almost always).</p>"},{"location":"chapters/17-inference-for-means/#the-formula","title":"The Formula","text":"\\[ \\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}} \\] <p>Where: - \\( \\bar{x} \\) = sample mean - \\( t^* \\) = t critical value for the desired confidence level with df = n - 1 - \\( s \\) = sample standard deviation - \\( n \\) = sample size - \\( \\frac{s}{\\sqrt{n}} \\) = standard error of the mean</p>"},{"location":"chapters/17-inference-for-means/#interpretation","title":"Interpretation","text":"<p>We interpret the interval the same way as before: \"We are C% confident that the true population mean \u03bc lies between [lower bound] and [upper bound].\"</p> <p>Remember: The confidence level refers to the method, not to any particular interval. If we repeatedly took samples and built 95% confidence intervals, about 95% of those intervals would contain the true \u03bc.</p>"},{"location":"chapters/17-inference-for-means/#complete-example-study-time","title":"Complete Example: Study Time","text":"<p>Scenario: A researcher wants to estimate the average amount of time high school students spend on homework per week. A random sample of 25 students reported their weekly homework hours.</p> <p>Data summary: - Sample size: n = 25 - Sample mean: \\( \\bar{x} = 8.2 \\) hours - Sample standard deviation: s = 3.1 hours - Desired confidence level: 95%</p> <p>Step 1: Check conditions - Random? Assume the sample was randomly selected \u2713 - Normal? With n = 25, we need to check the data. Assume a histogram showed roughly symmetric distribution with no extreme outliers \u2713 - Independent? The population of high school students is much larger than 10(25) = 250 \u2713</p> <p>Step 2: Find the critical value - df = 25 - 1 = 24 - For 95% confidence, t* = 2.064 (from t-table or calculator)</p> <p>Step 3: Calculate the confidence interval</p> \\[ 8.2 \\pm 2.064 \\cdot \\frac{3.1}{\\sqrt{25}} = 8.2 \\pm 2.064 \\cdot 0.62 = 8.2 \\pm 1.28 \\] <p>95% CI: (6.92, 9.48) hours</p> <p>Step 4: Interpret We are 95% confident that the true mean weekly homework time for all high school students is between 6.92 and 9.48 hours.</p>"},{"location":"chapters/17-inference-for-means/#diagram-one-sample-t-interval-calculator","title":"Diagram: One-Sample T-Interval Calculator","text":"One-Sample T-Interval Calculator <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate, demonstrate</p> <p>Learning Objective: Students will construct and interpret one-sample t-intervals for a population mean by entering sample statistics and seeing the step-by-step calculation process.</p> <p>Data Visibility Requirements: - Stage 1: Show input values (x\u0304, s, n, confidence level) - Stage 2: Show df calculation (n - 1) - Stage 3: Show t lookup with visual on distribution - Stage 4: Show SE calculation (s / \u221an) - Stage 5: Show margin of error (t \u00d7 SE) - Stage 6: Show final interval (x\u0304 \u00b1 ME)</p> <p>Visual Elements: - Input form for sample statistics - Step-by-step calculation display - T-distribution curve with shaded confidence region - Number line showing the confidence interval - Written interpretation in proper statistical language</p> <p>Interactive Controls: - Number input: Sample mean (x\u0304) - Number input: Sample standard deviation (s) - Number input: Sample size (n) - Dropdown: Confidence level (90%, 95%, 99%) - Button: Calculate</p> <p>Display Areas: - Left: Calculation steps with formulas and values - Right: T-distribution visualization - Bottom: Number line with interval marked - Below: Written interpretation template</p> <p>Behavior: - Validate inputs (n \u2265 2, s &gt; 0) - Display df warning if n &lt; 15 (check normality) - Show each calculation step when Calculate is pressed - Animate the interval appearing on the number line - Generate proper interpretation sentence</p> <p>Default Values: - x\u0304 = 8.2 - s = 3.1 - n = 25 - Confidence = 95%</p> <p>Implementation: p5.js with canvas-based input fields</p>"},{"location":"chapters/17-inference-for-means/#one-sample-t-test","title":"One-Sample T-Test","text":"<p>The one-sample t-test is used to test a hypothesis about a single population mean when \u03c3 is unknown.</p>"},{"location":"chapters/17-inference-for-means/#setting-up-the-test","title":"Setting Up the Test","text":"<p>Null hypothesis: \\( H_0: \\mu = \\mu_0 \\) (the population mean equals some specified value)</p> <p>Alternative hypothesis: - Two-sided: \\( H_a: \\mu \\neq \\mu_0 \\) - Right-tailed: \\( H_a: \\mu &gt; \\mu_0 \\) - Left-tailed: \\( H_a: \\mu &lt; \\mu_0 \\)</p>"},{"location":"chapters/17-inference-for-means/#the-test-statistic","title":"The Test Statistic","text":"\\[ t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}} \\] <p>This formula measures how many standard errors the sample mean is from the hypothesized mean. It follows a t-distribution with df = n - 1.</p>"},{"location":"chapters/17-inference-for-means/#finding-the-p-value","title":"Finding the P-Value","text":"<p>The p-value depends on the direction of the alternative:</p> <ul> <li>Two-sided (\\( H_a: \\mu \\neq \\mu_0 \\)): P = 2 \u00d7 P(T &gt; |t|)</li> <li>Right-tailed (\\( H_a: \\mu &gt; \\mu_0 \\)): P = P(T &gt; t)</li> <li>Left-tailed (\\( H_a: \\mu &lt; \\mu_0 \\)): P = P(T &lt; t)</li> </ul>"},{"location":"chapters/17-inference-for-means/#complete-example-sleep-study","title":"Complete Example: Sleep Study","text":"<p>Scenario: It's recommended that high school students get at least 8 hours of sleep per night. A health researcher suspects that students at a particular school get less than the recommended amount. She surveys a random sample of 36 students and finds they average 7.2 hours with a standard deviation of 1.8 hours. Test at \u03b1 = 0.05.</p> <p>Step 1: State hypotheses - \\( H_0: \\mu = 8 \\) (students get the recommended amount) - \\( H_a: \\mu &lt; 8 \\) (students get less than recommended) [left-tailed]</p> <p>Step 2: Check conditions - Random: Random sample of students \u2713 - Normal/Large Sample: n = 36 \u2265 30, so CLT applies \u2713 - Independence: Population of students &gt;&gt; 360 \u2713</p> <p>Step 3: Calculate test statistic</p> \\[ t = \\frac{7.2 - 8}{1.8 / \\sqrt{36}} = \\frac{-0.8}{0.3} = -2.67 \\] <p>Step 4: Find p-value - df = 36 - 1 = 35 - P-value = P(T &lt; -2.67) \u2248 0.006</p> <p>Step 5: Make conclusion Since p-value (0.006) &lt; \u03b1 (0.05), we reject H\u2080.</p> <p>Step 6: Interpret in context There is convincing statistical evidence that students at this school get less than the recommended 8 hours of sleep per night on average.</p>"},{"location":"chapters/17-inference-for-means/#two-sample-t-procedures-comparing-two-means","title":"Two-Sample T-Procedures: Comparing Two Means","text":"<p>Often we want to compare the means of two different groups\u2014does a new teaching method work better than the traditional one? Do students who exercise perform differently academically? These questions call for two-sample t-procedures.</p>"},{"location":"chapters/17-inference-for-means/#the-setup","title":"The Setup","text":"<p>We have two independent groups: - Group 1: sample size \\( n_1 \\), sample mean \\( \\bar{x}_1 \\), sample SD \\( s_1 \\) - Group 2: sample size \\( n_2 \\), sample mean \\( \\bar{x}_2 \\), sample SD \\( s_2 \\)</p> <p>We want to estimate or test \\( \\mu_1 - \\mu_2 \\), the difference between population means.</p>"},{"location":"chapters/17-inference-for-means/#two-sample-t-interval","title":"Two-Sample T-Interval","text":"<p>The two-sample t-interval for \\( \\mu_1 - \\mu_2 \\) is:</p> \\[ (\\bar{x}_1 - \\bar{x}_2) \\pm t^* \\cdot \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}} \\] <p>The degrees of freedom for this interval use a complicated formula (Welch's approximation). Most calculators and software compute this automatically. A conservative approach uses df = smaller of (n\u2081 - 1) and (n\u2082 - 1).</p>"},{"location":"chapters/17-inference-for-means/#two-sample-t-test","title":"Two-Sample T-Test","text":"<p>The two-sample t-test tests whether two population means are different.</p> <p>Hypotheses: - \\( H_0: \\mu_1 - \\mu_2 = 0 \\) (or equivalently, \\( \\mu_1 = \\mu_2 \\)) - \\( H_a: \\mu_1 - \\mu_2 \\neq 0 \\) (or &gt;, or &lt;)</p> <p>Test statistic:</p> \\[ t = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\]"},{"location":"chapters/17-inference-for-means/#conditions-for-two-sample-t-procedures","title":"Conditions for Two-Sample T-Procedures","text":"<p>The same three conditions apply, but now for BOTH samples:</p> <ol> <li>Random: Both samples must be randomly selected (or randomly assigned in an experiment)</li> <li>Normal/Large Sample: Both sampling distributions of \\( \\bar{x} \\) should be approximately normal</li> <li>Independence: Observations within each sample are independent; the two samples are independent of each other</li> </ol> <p>\"Time to squirrel away this key insight!\" Sylvia taps her notebook. \"The two samples MUST be independent of each other. If the same subjects appear in both groups, or if there's some natural pairing, you need a different approach\u2014paired data. We'll get to that soon!\"</p> Comparing... Example Method Two independent groups Boys vs. girls Two-sample t Same subjects, two conditions Before vs. after Paired t Matched pairs Twins, siblings Paired t"},{"location":"chapters/17-inference-for-means/#pooled-vs-unpooled-procedures","title":"Pooled vs. Unpooled Procedures","text":"<p>You may encounter two versions of two-sample t-procedures: pooled and unpooled.</p>"},{"location":"chapters/17-inference-for-means/#unpooled-welchs-procedure","title":"Unpooled (Welch's) Procedure","text":"<p>The formulas above are the unpooled (or Welch's) version. This is the default in AP Statistics and most modern software because:</p> <ul> <li>It doesn't assume equal variances in the two populations</li> <li>It's more robust to violations of assumptions</li> <li>The degrees of freedom calculation is more accurate</li> </ul>"},{"location":"chapters/17-inference-for-means/#pooled-procedure","title":"Pooled Procedure","text":"<p>The pooled version assumes that \\( \\sigma_1 = \\sigma_2 \\) (equal population variances). It combines (pools) the sample variances into a single estimate of the common variance.</p> <p>The pooled estimate is:</p> \\[ s_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2} \\] <p>With df = \\( n_1 + n_2 - 2 \\).</p>"},{"location":"chapters/17-inference-for-means/#which-to-use","title":"Which to Use?","text":"Situation Recommendation AP Statistics exam Use unpooled (two-sample t) unless told otherwise Software default Usually unpooled Sample SDs are very different Definitely unpooled Told variances are equal Can use pooled Randomized experiment with same variance Either is acceptable <p>When in Doubt, Use Unpooled</p> <p>The unpooled procedure is safer because it doesn't require the equal-variance assumption. When variances truly are equal, both methods give similar results. When variances differ, the pooled method can be misleading.</p>"},{"location":"chapters/17-inference-for-means/#diagram-two-sample-t-test-visualization","title":"Diagram: Two-Sample T-Test Visualization","text":"Two-Sample T-Test Visualization <p>Type: microsim</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Compare, differentiate</p> <p>Learning Objective: Students will compare two group means visually and statistically, understanding when the difference is statistically significant versus when overlap makes conclusions uncertain.</p> <p>Visual Elements: - Two dotplots or histograms showing sample data (side by side or stacked) - Vertical lines at each sample mean - Display of sample statistics for each group - Number line showing confidence interval for \u03bc\u2081 - \u03bc\u2082 - T-distribution with test statistic marked</p> <p>Interactive Controls: - Input fields for: n\u2081, x\u0304\u2081, s\u2081, n\u2082, x\u0304\u2082, s\u2082 - OR ability to generate random samples with specified parameters - Dropdown: Confidence level / significance level - Radio buttons: Alternative hypothesis direction - Button: Perform test</p> <p>Display Areas: - Top: Visual comparison of two groups - Middle: Summary statistics table - Bottom-left: Confidence interval for difference - Bottom-right: Hypothesis test results (t-statistic, df, p-value)</p> <p>Data Visibility: - Show both sample distributions - Mark means with clear visual indicators - Display difference between means prominently - Show whether CI for difference includes 0</p> <p>Behavior: - When user changes inputs, visualizations update - Highlight when p &lt; \u03b1 (statistically significant) - Show connection: if 0 is not in CI, test rejects H\u2080 - Display interpretation in words</p> <p>Default Values: - Group 1: n\u2081 = 30, x\u0304\u2081 = 78, s\u2081 = 10 - Group 2: n\u2082 = 32, x\u0304\u2082 = 72, s\u2082 = 12 - \u03b1 = 0.05</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/17-inference-for-means/#paired-data-and-the-paired-t-test","title":"Paired Data and the Paired T-Test","text":"<p>Sometimes the two samples aren't independent\u2014they're connected in some meaningful way. This is paired data, and it requires a different approach.</p>"},{"location":"chapters/17-inference-for-means/#what-is-paired-data","title":"What Is Paired Data?","text":"<p>Paired data occurs when each observation in one group is naturally linked to an observation in the other group. Common examples:</p> <ul> <li>Before/after measurements: The same subjects measured at two different times</li> <li>Matched pairs: Subjects are deliberately paired based on similar characteristics</li> <li>Twins or siblings: Each pair shares genetic or environmental factors</li> <li>Left/right measurements: Same person, different sides</li> </ul>"},{"location":"chapters/17-inference-for-means/#when-to-pair","title":"When to Pair","text":"<p>The key question for when to pair: Is there a natural connection between observations across groups?</p> Scenario Independent or Paired? Why? Compare test scores of class A vs. class B Independent Different students Compare pretest vs. posttest for same students Paired Same students Compare sleep of athletes vs. non-athletes Independent Different people Compare sleep on weekdays vs. weekends for same people Paired Same people <p>\"Don't worry\u2014every statistician drops an acorn sometimes when figuring this out!\" Sylvia laughs. \"I remember getting confused until I asked myself: 'Is there a natural one-to-one matching?' If each observation in Group 1 has a specific partner in Group 2, you've got paired data!\"</p>"},{"location":"chapters/17-inference-for-means/#the-paired-t-test","title":"The Paired T-Test","text":"<p>For paired data, we don't compare the two samples directly. Instead, we:</p> <ol> <li>Calculate the difference for each pair: \\( d = x_1 - x_2 \\)</li> <li>Treat these differences as a single sample</li> <li>Apply a one-sample t-test to the differences</li> </ol> <p>Hypotheses: - \\( H_0: \\mu_d = 0 \\) (the mean difference is zero) - \\( H_a: \\mu_d \\neq 0 \\) (or &gt; 0, or &lt; 0)</p> <p>Test statistic:</p> \\[ t = \\frac{\\bar{d} - 0}{s_d / \\sqrt{n}} \\] <p>Where: - \\( \\bar{d} \\) = mean of the differences - \\( s_d \\) = standard deviation of the differences - \\( n \\) = number of pairs</p> <p>Degrees of freedom: df = n - 1 (number of pairs minus 1)</p>"},{"location":"chapters/17-inference-for-means/#confidence-interval-for-mean-difference","title":"Confidence Interval for Mean Difference","text":"\\[ \\bar{d} \\pm t^* \\cdot \\frac{s_d}{\\sqrt{n}} \\]"},{"location":"chapters/17-inference-for-means/#complete-example-study-technique","title":"Complete Example: Study Technique","text":"<p>Scenario: Researchers want to test whether a new study technique improves test scores. They recruit 20 students and give them a pretest, teach them the technique, and give a posttest. Here are summary statistics for the differences (Post - Pre):</p> <ul> <li>n = 20 pairs</li> <li>Mean difference: \\( \\bar{d} = 4.2 \\) points</li> <li>SD of differences: \\( s_d = 6.5 \\) points</li> <li>Test at \u03b1 = 0.05</li> </ul> <p>Step 1: State hypotheses - \\( H_0: \\mu_d = 0 \\) (technique doesn't improve scores) - \\( H_a: \\mu_d &gt; 0 \\) (technique improves scores) [right-tailed]</p> <p>Step 2: Check conditions - Random: Assume students were randomly selected \u2713 - Normal: n = 20, check histogram of differences for approximate normality \u2713 - Independence: Differences are independent of each other \u2713</p> <p>Step 3: Calculate test statistic</p> \\[ t = \\frac{4.2 - 0}{6.5 / \\sqrt{20}} = \\frac{4.2}{1.454} = 2.89 \\] <p>Step 4: Find p-value - df = 20 - 1 = 19 - P-value = P(T &gt; 2.89) \u2248 0.0047</p> <p>Step 5: Make conclusion Since p-value (0.0047) &lt; \u03b1 (0.05), we reject H\u2080.</p> <p>Step 6: Interpret There is convincing statistical evidence that the new study technique improves test scores, on average.</p>"},{"location":"chapters/17-inference-for-means/#diagram-paired-vs-independent-data-decision-flowchart","title":"Diagram: Paired vs Independent Data Decision Flowchart","text":"Paired vs Independent Data Decision Flowchart <p>Type: infographic</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Differentiate, distinguish</p> <p>Learning Objective: Students will correctly identify whether a given scenario calls for paired or independent samples t-procedures by following a decision flowchart.</p> <p>Layout: Decision tree flowchart with yes/no branches</p> <p>Starting Question: \"Comparing two groups?\"</p> <p>Branch 1: \"Are the same individuals measured twice?\" - Yes \u2192 Paired data - No \u2192 Continue to Branch 2</p> <p>Branch 2: \"Are individuals deliberately matched into pairs?\" - Yes \u2192 Paired data - No \u2192 Continue to Branch 3</p> <p>Branch 3: \"Is there any natural one-to-one connection between observations?\" - Yes \u2192 Paired data - No \u2192 Independent samples</p> <p>End Nodes: - \"Paired data \u2192 Use paired t-test (analyze differences)\" - \"Independent samples \u2192 Use two-sample t-test\"</p> <p>Visual Style: - Diamond shapes for decision points - Rectangular boxes for conclusions - Green arrows for \"Yes\" - Orange arrows for \"No\" - Sylvia illustration at start with speech bubble</p> <p>Interactive Features: - Hover over each node for example scenario - Click end nodes for summary of appropriate procedure - Optional: Quiz mode where students classify scenarios</p> <p>Color Scheme: - Sylvia green for decision diamonds - Auburn accent for conclusion boxes - Cream background</p> <p>Implementation: HTML/CSS/JavaScript or p5.js</p>"},{"location":"chapters/17-inference-for-means/#why-pairing-matters-the-advantage-of-paired-design","title":"Why Pairing Matters: The Advantage of Paired Design","text":"<p>Why do we bother with pairing? Because it often gives us more power to detect real differences.</p>"},{"location":"chapters/17-inference-for-means/#the-key-insight","title":"The Key Insight","text":"<p>When we pair data, we control for variability between subjects. Consider measuring blood pressure before and after taking medication:</p> <ul> <li>Two-sample approach: We'd see huge variability because different people have different baseline blood pressures</li> <li>Paired approach: We focus on the CHANGE within each person, removing between-person variability</li> </ul> <p>By eliminating subject-to-subject variability, the differences tend to have less spread, leading to: - Smaller standard error - Narrower confidence intervals - More statistical power</p>"},{"location":"chapters/17-inference-for-means/#mathematical-comparison","title":"Mathematical Comparison","text":"<p>For independent samples, the SE of the difference is:</p> \\[ SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}} \\] <p>For paired data, the SE of the mean difference is:</p> \\[ SE = \\frac{s_d}{\\sqrt{n}} \\] <p>When subjects are consistent (their individual measurements are similar), \\( s_d \\) will be much smaller than the individual sample SDs, making paired procedures more powerful.</p> Design Type Controls for... Best when... Independent samples Nothing special Groups are naturally separate Paired data Between-subject variability Within-subject changes are the focus"},{"location":"chapters/17-inference-for-means/#robustness-of-t-procedures","title":"Robustness of T-Procedures","text":"<p>How well do t-procedures work when our conditions aren't perfectly met? This quality is called robustness.</p>"},{"location":"chapters/17-inference-for-means/#what-robustness-means","title":"What Robustness Means","text":"<p>A procedure is robust if it gives reasonably accurate results even when some assumptions are violated. T-procedures are considered quite robust, meaning:</p> <ul> <li>Confidence levels are approximately correct even when the population isn't exactly normal</li> <li>P-values are approximately valid even with moderate departures from normality</li> </ul>"},{"location":"chapters/17-inference-for-means/#guidelines-for-robustness","title":"Guidelines for Robustness","text":"<p>Sample size matters most:</p> <ul> <li> <p>n &lt; 15: The data should be close to normal with no outliers. T-procedures are NOT robust with very small samples from non-normal populations.</p> </li> <li> <p>15 \u2264 n &lt; 30: The procedures can handle moderate skewness but are sensitive to extreme outliers.</p> </li> <li> <p>n \u2265 30: The Central Limit Theorem provides robustness. Even fairly skewed distributions work well.</p> </li> <li> <p>n \u2265 40: Strong robustness. The procedures work for most real-world distributions.</p> </li> </ul> <p>What affects robustness most:</p> <ol> <li>Outliers: The biggest concern! Outliers affect both \\( \\bar{x} \\) and \\( s \\), potentially distorting results</li> <li>Extreme skewness: One-sided tails pull the mean away from the center</li> <li>Heavy tails: Populations with many extreme values</li> </ol> <p>What doesn't affect robustness much:</p> <ol> <li>Slight skewness: Especially with larger samples</li> <li>Non-normality with symmetric distributions: T-procedures handle these well</li> <li>Gaps in the data: Unless they indicate outliers</li> </ol> <p>Sylvia's Robustness Rule</p> <p>\"When in doubt, graph it out! Always look at your data before running inference. A boxplot or dotplot can reveal outliers and skewness. If you see major problems, you might need a larger sample or alternative methods.\"</p>"},{"location":"chapters/17-inference-for-means/#diagram-robustness-exploration-microsim","title":"Diagram: Robustness Exploration MicroSim","text":"Robustness Exploration MicroSim <p>Type: microsim</p> <p>Bloom Level: Evaluate (L5) Bloom Verb: Judge, assess</p> <p>Learning Objective: Students will assess how violations of the normality condition affect the reliability of t-procedures by simulating many samples from populations with different shapes and observing the actual confidence interval coverage rates.</p> <p>Data Visibility Requirements: - Show population distribution shape - Generate many (100+) samples of specified size - Calculate confidence interval for each sample - Track what percentage of intervals contain the true \u03bc - Compare to nominal confidence level</p> <p>Visual Elements: - Population distribution display (normal, skewed, uniform, with outliers) - Animation of sample CIs being generated - Running count of \"hits\" (CI contains \u03bc) vs \"misses\" - Bar chart comparing actual coverage to nominal level - Final summary statistics</p> <p>Interactive Controls: - Dropdown: Population shape (Normal, Right-skewed, Left-skewed, Uniform, With outliers) - Slider: Sample size (5, 10, 15, 20, 30, 50, 100) - Slider: Number of simulations (100, 500, 1000) - Button: Run simulation - Radio: Confidence level (90%, 95%, 99%)</p> <p>Display Areas: - Top: Population distribution visualization - Middle: Animation of samples and CIs - Bottom: Summary comparing actual vs. expected coverage</p> <p>Key Metrics Shown: - Nominal confidence level (e.g., 95%) - Actual coverage rate (e.g., 93.4%) - Whether the difference is concerning</p> <p>Expected Behavior: - Normal population: coverage \u2248 nominal at all sample sizes - Skewed population, small n: coverage &lt; nominal - Skewed population, large n: coverage \u2248 nominal (robustness!) - Outliers: coverage varies depending on severity</p> <p>Instructional Rationale: Simulation is appropriate for the Evaluate objective because students need to see empirical evidence of how robustness works. Seeing actual coverage rates helps them judge when to trust t-procedures.</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/17-inference-for-means/#introduction-to-regression-inference","title":"Introduction to Regression Inference","text":"<p>The final concepts in this chapter connect to regression\u2014specifically, making inferences about the slope of a linear relationship. While full regression analysis often has its own chapter, understanding the basics of inference for slopes fits naturally here because it uses t-procedures.</p>"},{"location":"chapters/17-inference-for-means/#the-regression-model","title":"The Regression Model","text":"<p>A regression model assumes that the relationship between an explanatory variable x and a response variable y follows:</p> \\[ y = \\alpha + \\beta x + \\epsilon \\] <p>Where: - \\( \\alpha \\) (alpha) = population y-intercept - \\( \\beta \\) (beta) = population slope (the slope parameter) - \\( \\epsilon \\) (epsilon) = random error term (assumed to be normally distributed)</p> <p>The regression line we calculate from sample data, \\( \\hat{y} = a + bx \\), estimates this true relationship.</p>"},{"location":"chapters/17-inference-for-means/#why-test-the-slope","title":"Why Test the Slope?","text":"<p>The most common inferential question about regression is: Is there a significant linear relationship between x and y?</p> <p>This translates to testing whether the true slope \u03b2 equals zero:</p> <ul> <li>\\( H_0: \\beta = 0 \\) (no linear relationship)</li> <li>\\( H_a: \\beta \\neq 0 \\) (there IS a linear relationship)</li> </ul> <p>If \u03b2 = 0, then y doesn't change as x changes\u2014there's no linear relationship. If we can reject this hypothesis, we have evidence of a genuine linear association.</p>"},{"location":"chapters/17-inference-for-means/#standard-error-of-the-slope","title":"Standard Error of the Slope","text":"<p>The standard error of the slope measures how much the sample slope b would vary from sample to sample:</p> \\[ SE_b = \\frac{s}{\\sqrt{\\sum(x_i - \\bar{x})^2}} \\] <p>Where \\( s \\) is the standard deviation of the residuals.</p> <p>This formula isn't on the AP formula sheet\u2014you'll use calculator or software output. But understanding what it means is important: smaller SE means more precise estimates of the true slope.</p>"},{"location":"chapters/17-inference-for-means/#t-test-for-the-slope","title":"T-Test for the Slope","text":"<p>The test statistic for testing \\( H_0: \\beta = 0 \\) is:</p> \\[ t = \\frac{b - 0}{SE_b} = \\frac{b}{SE_b} \\] <p>This follows a t-distribution with df = n - 2 (we estimate two parameters: slope and intercept).</p>"},{"location":"chapters/17-inference-for-means/#confidence-interval-for-the-slope","title":"Confidence Interval for the Slope","text":"\\[ b \\pm t^* \\cdot SE_b \\] <p>This interval tells us the range of plausible values for the true population slope.</p>"},{"location":"chapters/17-inference-for-means/#reading-computer-output","title":"Reading Computer Output","text":"<p>Most regression questions provide computer output. You need to identify:</p> Term What to Look For Slope estimate (b) Usually labeled \"Coef\" or \"Estimate\" for the x-variable SE of slope Usually labeled \"SE Coef\" or \"Std Error\" t-statistic Often provided, or calculate as b/SE p-value Usually labeled \"P\" or \"p-value\" df Typically n - 2 for simple linear regression"},{"location":"chapters/17-inference-for-means/#summary-choosing-the-right-t-procedure","title":"Summary: Choosing the Right T-Procedure","text":"<p>Let's bring it all together. Here's how to choose the appropriate t-procedure:</p> Question Type Parameter Procedure Test Statistic df Estimate/test one mean \u03bc One-sample t n - 1 Compare two independent means \u03bc\u2081 - \u03bc\u2082 Two-sample t Formula or conservative Compare paired measurements \u03bc_d Paired t n - 1 (# of pairs) Test slope of regression \u03b2 Regression t n - 2"},{"location":"chapters/17-inference-for-means/#decision-checklist","title":"Decision Checklist","text":"<p>When facing a problem involving means, ask yourself:</p> <ol> <li>How many groups?</li> <li>One group \u2192 One-sample t</li> <li> <p>Two groups \u2192 Continue to question 2</p> </li> <li> <p>Are the groups independent or paired?</p> </li> <li>Independent \u2192 Two-sample t</li> <li> <p>Paired \u2192 Paired t</p> </li> <li> <p>What do you want to do?</p> </li> <li>Estimate \u2192 Confidence interval</li> <li> <p>Test a claim \u2192 Hypothesis test</p> </li> <li> <p>Check conditions!</p> </li> <li>Random?</li> <li>Normal/Large Sample?</li> <li>Independent?</li> </ol> <p>\"Time to squirrel away this knowledge!\" Sylvia beams. \"You've got a whole toolkit now for inference about means. The key is matching the right tool to the situation. And remember\u2014always check those conditions before diving in!\"</p>"},{"location":"chapters/17-inference-for-means/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"chapters/17-inference-for-means/#one-sample-t-interval_1","title":"One-Sample T-Interval","text":"\\[ \\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}} \\quad \\text{where df} = n - 1 \\]"},{"location":"chapters/17-inference-for-means/#one-sample-t-test-statistic","title":"One-Sample T-Test Statistic","text":"\\[ t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}} \\quad \\text{where df} = n - 1 \\]"},{"location":"chapters/17-inference-for-means/#two-sample-t-interval-unpooled","title":"Two-Sample T-Interval (Unpooled)","text":"\\[ (\\bar{x}_1 - \\bar{x}_2) \\pm t^* \\cdot \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}} \\]"},{"location":"chapters/17-inference-for-means/#two-sample-t-test-statistic-unpooled","title":"Two-Sample T-Test Statistic (Unpooled)","text":"\\[ t = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\]"},{"location":"chapters/17-inference-for-means/#paired-t-interval","title":"Paired T-Interval","text":"\\[ \\bar{d} \\pm t^* \\cdot \\frac{s_d}{\\sqrt{n}} \\quad \\text{where df} = n - 1 \\]"},{"location":"chapters/17-inference-for-means/#paired-t-test-statistic","title":"Paired T-Test Statistic","text":"\\[ t = \\frac{\\bar{d} - 0}{s_d / \\sqrt{n}} \\quad \\text{where df} = n - 1 \\]"},{"location":"chapters/17-inference-for-means/#t-test-for-regression-slope","title":"T-Test for Regression Slope","text":"\\[ t = \\frac{b}{SE_b} \\quad \\text{where df} = n - 2 \\]"},{"location":"chapters/17-inference-for-means/#chapter-summary","title":"Chapter Summary","text":"<p>In this chapter, you learned how to extend statistical inference to population means using t-distributions. Let's recap the key ideas:</p> <p>The T-Distribution:</p> <ul> <li>Used when the population standard deviation is unknown (almost always)</li> <li>Has heavier tails than the normal distribution</li> <li>Approaches the normal distribution as sample size increases</li> <li>Shape determined by degrees of freedom</li> </ul> <p>Conditions for T-Procedures:</p> <ul> <li>Random: Data from random sample or randomized experiment</li> <li>Normal/Large Sample: Population normal OR n \u2265 30</li> <li>Independence: Observations are independent (10% condition for sampling)</li> </ul> <p>One-Sample Procedures:</p> <ul> <li>Use when estimating or testing one population mean</li> <li>df = n - 1</li> <li>Check conditions on the sample data</li> </ul> <p>Two-Sample Procedures:</p> <ul> <li>Use when comparing two independent groups</li> <li>Use unpooled (Welch's) approach unless told otherwise</li> <li>Check conditions on both samples</li> </ul> <p>Paired Procedures:</p> <ul> <li>Use when observations are naturally paired (before/after, matched pairs)</li> <li>Calculate differences first, then do one-sample analysis</li> <li>More powerful when subjects vary more than within-subject changes</li> </ul> <p>Robustness:</p> <ul> <li>T-procedures work reasonably well even when conditions aren't perfect</li> <li>Larger samples provide more robustness</li> <li>Watch out for outliers and extreme skewness with small samples</li> </ul> <p>Regression Inference:</p> <ul> <li>Test whether slope differs from zero to assess linear relationship</li> <li>Uses t-distribution with df = n - 2</li> <li>Usually read results from computer output</li> </ul> <p>You now have a complete toolkit for inference about means. These procedures are workhorses of statistical analysis, used in countless real-world applications from medical research to educational studies to quality control.</p> Acorn for Your Thoughts: Self-Check Questions <ol> <li>Why do we use the t-distribution instead of the normal distribution for inference about means?</li> </ol> <p>Because we have to estimate the population standard deviation using the sample standard deviation s. This introduces extra uncertainty that the t-distribution accounts for with its heavier tails.</p> <ol> <li>A researcher has 12 observations and wants to construct a 95% confidence interval for the mean. What degrees of freedom should she use?</li> </ol> <p>df = n - 1 = 12 - 1 = 11</p> <ol> <li>How would you decide whether to use a two-sample t-test or a paired t-test?</li> </ol> <p>Ask whether there's a natural one-to-one pairing between observations. If the same subjects are measured twice, if subjects are deliberately matched, or if there's any inherent connection between pairs\u2014use paired. If the groups are completely separate with no connection, use two-sample.</p> <ol> <li>Why are t-procedures considered \"robust\"?</li> </ol> <p>They give reasonably accurate results even when the population isn't perfectly normal, especially with larger sample sizes. The CLT helps ensure the sampling distribution is approximately normal even when the population isn't.</p> <ol> <li>What's the advantage of paired data over independent samples?</li> </ol> <p>Paired data controls for between-subject variability. When we look at differences within subjects, we eliminate the noise from comparing different individuals, often leading to smaller standard errors and more statistical power.</p>"},{"location":"chapters/17-inference-for-means/#looking-ahead","title":"Looking Ahead","text":"<p>In the next chapter, we'll explore inference for categorical data using chi-square tests. These methods let us analyze relationships between categorical variables and test whether observed frequencies match expected patterns. Get ready to expand your statistical toolkit even further!</p>"},{"location":"chapters/18-chi-square-and-regression-inference/","title":"Chi-Square and Regression Inference","text":""},{"location":"chapters/18-chi-square-and-regression-inference/#summary","title":"Summary","text":"<p>This chapter covers chi-square tests and inference for regression. Students will learn to perform goodness-of-fit tests, tests for homogeneity, and tests for independence using chi-square distributions. The chapter also covers inference for the slope of a regression line, including conditions and interpretation.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 22 concepts from the learning graph:</p> <ol> <li>Chi-Square Distribution</li> <li>Chi-Square Statistic</li> <li>Goodness-of-Fit Test</li> <li>GOF Hypotheses</li> <li>Expected Counts</li> <li>Observed Counts</li> <li>Calculating Chi-Square</li> <li>Conditions for Chi-Square</li> <li>GOF Conclusion</li> <li>Test for Homogeneity</li> <li>Homogeneity Setup</li> <li>Test for Independence</li> <li>Independence Setup</li> <li>Chi-Square Conclusion</li> <li>Inference for Slope</li> <li>T-Interval for Slope</li> <li>T-Test for Slope</li> <li>Conditions for Regression</li> <li>Linearity Condition</li> <li>Independence Condition</li> <li>Normality of Residuals</li> <li>Equal Variance Condition</li> </ol>"},{"location":"chapters/18-chi-square-and-regression-inference/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 7: Linear Regression</li> <li>Chapter 16: Hypothesis Testing</li> <li>Chapter 17: Inference for Means</li> </ul>"},{"location":"chapters/18-chi-square-and-regression-inference/#introduction-two-powerful-inference-tools","title":"Introduction: Two Powerful Inference Tools","text":"<p>Welcome to what might be the most versatile chapter in your AP Statistics journey! We're going to explore two incredibly useful inference techniques that you'll encounter constantly in real research: chi-square tests for categorical data and inference for regression slopes. These tools let us answer questions that our previous methods simply couldn't handle.</p> <p>Think about it this way: up until now, we've been working with quantitative data and proportions. But what happens when you want to test whether the distribution of M&amp;M colors in a bag matches what the company claims? Or whether there's a relationship between political party affiliation and opinion on climate change? Or whether the slope of a regression line is significantly different from zero? That's where chi-square tests and regression inference come to the rescue.</p> <p>As Sylvia likes to say, \"My tail's tingling\u2014we're onto something!\" These techniques open up a whole new world of statistical analysis. Let's crack this nut!</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-1-the-chi-square-distribution","title":"Part 1: The Chi-Square Distribution","text":"<p>Before we can run chi-square tests, we need to understand the distribution that makes them possible. The chi-square distribution (pronounced \"ky-square\" and written \\(\\chi^2\\)) is a probability distribution that arises naturally when we work with categorical data.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#what-makes-chi-square-special","title":"What Makes Chi-Square Special?","text":"<p>The chi-square distribution has some distinctive properties that set it apart from the normal and t-distributions we've worked with before:</p> <ul> <li>It only takes non-negative values (you can't have a negative chi-square statistic)</li> <li>It's right-skewed, with a long tail extending toward larger values</li> <li>Its shape depends on a parameter called degrees of freedom (df)</li> <li>As degrees of freedom increase, the distribution becomes more symmetric and approaches a normal distribution</li> </ul> Degrees of Freedom Shape Mean Spread 1 Highly right-skewed 1 Narrow 5 Moderately right-skewed 5 Medium 10 Slightly right-skewed 10 Wider 30+ Nearly symmetric df Wide <p>The mean of a chi-square distribution equals its degrees of freedom, which gives us a handy reference point. If we calculate a chi-square statistic that's much larger than the degrees of freedom, that suggests our observed data differs substantially from what we'd expect.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#diagram-chi-square-distribution-shapes","title":"Diagram: Chi-Square Distribution Shapes","text":"Chi-Square Distribution Shapes Interactive Visualization <p>Type: microsim</p> <p>Bloom Level: Understand (L2) Bloom Verb: Compare, contrast</p> <p>Learning Objective: Students will compare how the chi-square distribution's shape changes with different degrees of freedom, helping them understand why larger chi-square values are more extreme.</p> <p>Instructional Rationale: Comparing multiple distributions side-by-side helps students understand the parameter's effect on shape. A slider allows exploration without overwhelming animation.</p> <p>Visual Elements: - Single coordinate system showing chi-square distributions - X-axis: Chi-square values from 0 to 30 - Y-axis: Probability density - Multiple colored curves showing df = 2, 5, 10, 15, 20 - Vertical dashed line showing the mean for selected df - Shaded critical region in the right tail</p> <p>Interactive Controls: - Slider: Degrees of freedom (1 to 30) - Dropdown: Show single distribution or multiple for comparison - Checkbox: Show/hide critical value shading (alpha = 0.05) - Display: Current mean and critical value</p> <p>Canvas Layout: - Drawing area: 500px width, 350px height - Controls below the graph - Legend showing color coding for each df value</p> <p>Default Parameters: - Degrees of freedom: 5 - Show multiple distributions: enabled - Critical value shading: enabled</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#when-do-we-use-chi-square","title":"When Do We Use Chi-Square?","text":"<p>Chi-square tests are our go-to tools when we're working with categorical data\u2014data that falls into distinct groups or categories rather than being measured on a numerical scale. We'll use chi-square tests for three main purposes:</p> <ol> <li>Goodness-of-fit tests: Does our observed distribution match an expected distribution?</li> <li>Tests for homogeneity: Are the distributions the same across different populations?</li> <li>Tests for independence: Are two categorical variables related or independent?</li> </ol> <p>Sylvia's Study Tip</p> <p>Here's a quick way to remember when to use chi-square: if you're counting things in categories (like M&amp;M colors or survey responses), chi-square is probably your friend!</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-2-observed-and-expected-counts","title":"Part 2: Observed and Expected Counts","text":"<p>At the heart of every chi-square test is a comparison between what we observed in our data and what we expected to observe if some hypothesis were true.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#observed-counts","title":"Observed Counts","text":"<p>Observed counts are simply the actual counts we collect from our data. If you survey 200 students about their favorite pizza topping and count how many chose pepperoni, cheese, veggie, or other, those are your observed counts. Nothing fancy here\u2014just counting what you see.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#expected-counts","title":"Expected Counts","text":"<p>Expected counts are the counts we would expect to see if our null hypothesis were true. This is where things get interesting! The way we calculate expected counts depends on which type of chi-square test we're running:</p> <p>For a goodness-of-fit test:</p> \\[ \\text{Expected count} = n \\times p_i \\] <p>where \\(n\\) is the total sample size and \\(p_i\\) is the hypothesized proportion for category \\(i\\).</p> <p>For tests of homogeneity and independence:</p> \\[ \\text{Expected count} = \\frac{\\text{(row total)} \\times \\text{(column total)}}{\\text{grand total}} \\] <p>Let's look at a concrete example. Suppose a candy company claims their bags contain 20% red, 25% orange, 20% yellow, 15% green, and 20% blue candies. You buy a bag with 100 candies and find: 24 red, 20 orange, 18 yellow, 22 green, and 16 blue.</p> Color Observed Expected (100 \u00d7 proportion) Red 24 20 Orange 20 25 Yellow 18 20 Green 22 15 Blue 16 20 Total 100 100 <p>The expected counts represent what a \"perfect\" bag would look like if it exactly matched the company's claimed proportions. Our observed counts deviate from these expectations\u2014but is this deviation due to random chance, or is something more going on?</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-3-the-chi-square-statistic","title":"Part 3: The Chi-Square Statistic","text":"<p>The chi-square statistic measures how far our observed counts are from our expected counts. The formula is:</p> \\[ \\chi^2 = \\sum \\frac{(O - E)^2}{E} \\] <p>where: - \\(O\\) = observed count for each category - \\(E\\) = expected count for each category - The sum is taken over all categories</p> <p>Let's break down why this formula makes sense:</p> <ol> <li>(O - E): We find the difference between observed and expected</li> <li>(O - E)\u00b2: We square it so negative and positive differences don't cancel out</li> <li>\u00f7 E: We divide by expected to standardize (a difference of 5 means more when we expected 10 than when we expected 100)</li> <li>\u2211: We add up all these standardized squared differences</li> </ol>"},{"location":"chapters/18-chi-square-and-regression-inference/#diagram-chi-square-calculation-breakdown","title":"Diagram: Chi-Square Calculation Breakdown","text":"Chi-Square Calculation Step-by-Step Visualization <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate, demonstrate</p> <p>Learning Objective: Students will practice calculating chi-square statistics by working through each component of the formula with visual feedback.</p> <p>Instructional Rationale: Breaking down the calculation into visible steps with concrete numbers helps students understand what each part of the formula contributes to the final statistic.</p> <p>Data Visibility Requirements: - Stage 1: Show observed and expected counts side by side in a table - Stage 2: Show (O - E) for each category with color coding (positive = green, negative = red) - Stage 3: Show (O - E)\u00b2 for each category - Stage 4: Show (O - E)\u00b2/E for each category - Stage 5: Show sum of all contributions = final chi-square statistic</p> <p>Visual Elements: - Bar chart comparing observed (solid) vs expected (striped) counts - Calculation table showing each step - Running total accumulator for chi-square statistic - Color-coded contributions (larger contributions highlighted)</p> <p>Interactive Controls: - Input fields for observed counts (editable) - Button: \"Calculate Step by Step\" - Button: \"Reset to Example\" - Slider: Animation speed for step-through</p> <p>Canvas Layout: - Top: Bar chart (400px height) - Bottom: Calculation table - Right: Running total display</p> <p>Default Parameters: - Pre-loaded with candy color example - Animation speed: medium</p> <p>Implementation: p5.js with canvas-based controls and step-through animation</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#a-worked-example","title":"A Worked Example","text":"<p>Using our candy data, let's calculate the chi-square statistic:</p> Color O E O - E (O - E)\u00b2 (O - E)\u00b2/E Red 24 20 4 16 0.80 Orange 20 25 -5 25 1.00 Yellow 18 20 -2 4 0.20 Green 22 15 7 49 3.27 Blue 16 20 -4 16 0.80 \\[ \\chi^2 = 0.80 + 1.00 + 0.20 + 3.27 + 0.80 = 6.07 \\] <p>Notice that green contributed the most to our chi-square statistic (3.27 out of 6.07). This tells us the green category had the largest departure from expectations\u2014we observed 22 when we expected only 15.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-4-conditions-for-chi-square-tests","title":"Part 4: Conditions for Chi-Square Tests","text":"<p>Before we can trust the results of any chi-square test, we need to verify that certain conditions are met. These conditions ensure that our chi-square statistic actually follows a chi-square distribution.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#the-three-conditions","title":"The Three Conditions","text":"<ol> <li>Random: The data must come from a random sample or randomized experiment</li> <li> <p>This ensures our sample is representative and results can be generalized</p> </li> <li> <p>Independent: Observations must be independent of each other</p> </li> <li> <p>For sampling without replacement, check the 10% condition: sample size should be less than 10% of the population</p> </li> <li> <p>Large Counts: All expected counts must be at least 5</p> </li> <li>This ensures the chi-square approximation is valid</li> <li>Check EVERY expected count, not just the observed counts</li> </ol> <p>Common Mistake Alert</p> <p>Sylvia has seen many students check the observed counts instead of the expected counts for the large counts condition. Don't make this mistake! The condition specifically requires expected counts \u2265 5.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#what-if-conditions-arent-met","title":"What If Conditions Aren't Met?","text":"<p>If the large counts condition isn't satisfied, you have several options:</p> <ul> <li>Combine categories that are conceptually similar</li> <li>Collect more data (if possible)</li> <li>Use an alternative test like Fisher's exact test (beyond AP Statistics)</li> <li>Acknowledge the limitation in your conclusion</li> </ul>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-5-goodness-of-fit-test","title":"Part 5: Goodness-of-Fit Test","text":"<p>The goodness-of-fit test (often abbreviated as GOF test) determines whether a sample distribution matches a claimed or hypothesized distribution. It's called \"goodness-of-fit\" because we're testing how well our observed data \"fits\" the expected pattern.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#setting-up-gof-hypotheses","title":"Setting Up GOF Hypotheses","text":"<p>The hypotheses for a goodness-of-fit test are:</p> <ul> <li>H\u2080: The population distribution matches the claimed/hypothesized distribution</li> <li>H\u2090: The population distribution does NOT match the claimed/hypothesized distribution</li> </ul> <p>For our candy example: - H\u2080: The color proportions are 20% red, 25% orange, 20% yellow, 15% green, 20% blue - H\u2090: At least one of these proportions is different</p> <p>Notice that the alternative hypothesis is always two-sided in a goodness-of-fit test\u2014we're looking for ANY departure from the expected distribution, not a specific direction of change.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#degrees-of-freedom-for-gof","title":"Degrees of Freedom for GOF","text":"<p>For a goodness-of-fit test:</p> \\[ \\text{df} = (\\text{number of categories}) - 1 \\] <p>Why subtract 1? Because once we know the counts for all but one category, the last count is determined (they must sum to n). In our candy example with 5 colors, df = 5 - 1 = 4.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#completing-the-gof-test","title":"Completing the GOF Test","text":"<p>Let's finish our candy example. We calculated \\(\\chi^2 = 6.07\\) with df = 4.</p> <p>Using a chi-square table or calculator, we find the p-value: - P(\\(\\chi^2\\) &gt; 6.07 | df = 4) \u2248 0.194</p> <p>Since 0.194 &gt; 0.05 (using \u03b1 = 0.05), we fail to reject the null hypothesis.</p> <p>Conclusion: We do not have convincing evidence that the candy company's claimed color distribution is incorrect. The differences we observed could reasonably be due to random variation.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#diagram-goodness-of-fit-test-simulator","title":"Diagram: Goodness-of-Fit Test Simulator","text":"Interactive Goodness-of-Fit Test Simulator <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Execute, practice</p> <p>Learning Objective: Students will conduct complete goodness-of-fit tests by entering observed counts and hypothesized proportions, then interpreting the results.</p> <p>Instructional Rationale: An interactive simulator allows students to practice the complete GOF test workflow with immediate feedback on their calculations and conclusions.</p> <p>Visual Elements: - Input table for observed counts (3-8 categories) - Input fields for hypothesized proportions - Bar chart showing observed vs expected - Chi-square distribution with test statistic marked - Shaded p-value region - Results panel showing chi-square, df, p-value</p> <p>Interactive Controls: - Dropdown: Number of categories (3 to 8) - Text inputs: Category names - Number inputs: Observed counts - Number inputs: Hypothesized proportions (must sum to 1) - Button: \"Run Test\" - Radio buttons: Significance level (0.01, 0.05, 0.10) - Button: \"Load Example\" with preset scenarios</p> <p>Canvas Layout: - Left panel: Data entry (300px) - Right panel: Visualization and results (400px) - Bottom: Written conclusion template</p> <p>Default Parameters: - 5 categories - Pre-loaded with candy example - Significance level: 0.05</p> <p>Example Scenarios to Load: 1. Candy colors (company claim) 2. Dice fairness test 3. Birth day of week distribution 4. Mendel's pea genetics</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-6-tests-for-homogeneity","title":"Part 6: Tests for Homogeneity","text":"<p>While goodness-of-fit tests compare one sample to a hypothesized distribution, tests for homogeneity compare distributions across multiple populations or groups. The question becomes: \"Do these different groups have the same distribution of responses?\"</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#homogeneity-setup","title":"Homogeneity Setup","text":"<p>A homogeneity test typically involves: - Multiple populations or groups (the columns) - One categorical variable with multiple outcomes (the rows) - Independent random samples from each population</p> <p>For example, we might survey students from three different high schools and ask whether they plan to attend a 4-year college, community college, vocational school, or not pursue higher education. The test for homogeneity would tell us whether the distribution of educational plans is the same across all three schools.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#the-two-way-table","title":"The Two-Way Table","text":"<p>Data for homogeneity tests is organized in a two-way table (also called a contingency table):</p> Educational Plan School A School B School C Row Total 4-year college 85 72 91 248 Community college 42 58 39 139 Vocational 15 25 12 52 No higher ed 8 15 8 31 Column Total 150 170 150 470"},{"location":"chapters/18-chi-square-and-regression-inference/#hypotheses-for-homogeneity","title":"Hypotheses for Homogeneity","text":"<ul> <li>H\u2080: The distribution of [response variable] is the same across all [populations]</li> <li>H\u2090: The distribution of [response variable] is NOT the same across all [populations]</li> </ul> <p>For our example: - H\u2080: The distribution of educational plans is the same for students at all three schools - H\u2090: The distribution of educational plans differs among the three schools</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#calculating-expected-counts","title":"Calculating Expected Counts","text":"<p>For each cell in a two-way table:</p> \\[ E = \\frac{(\\text{row total}) \\times (\\text{column total})}{\\text{grand total}} \\] <p>This formula works because under the null hypothesis (same distribution for all groups), the expected proportion in each row should be the same for every column.</p> <p>For the \"4-year college, School A\" cell:</p> \\[ E = \\frac{248 \\times 150}{470} = 79.15 \\]"},{"location":"chapters/18-chi-square-and-regression-inference/#degrees-of-freedom-for-two-way-tables","title":"Degrees of Freedom for Two-Way Tables","text":"\\[ \\text{df} = (\\text{rows} - 1) \\times (\\text{columns} - 1) \\] <p>For our table with 4 rows and 3 columns: df = (4 - 1)(3 - 1) = 3 \u00d7 2 = 6</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-7-tests-for-independence","title":"Part 7: Tests for Independence","text":"<p>The test for independence looks superficially similar to the homogeneity test\u2014it also uses a two-way table and the same chi-square formula. However, there's a crucial conceptual difference:</p> Feature Homogeneity Test Independence Test Sampling Separate samples from each population One sample, two variables measured Question Same distribution across groups? Are the two variables related? Design Compare predetermined groups Explore relationship"},{"location":"chapters/18-chi-square-and-regression-inference/#independence-setup","title":"Independence Setup","text":"<p>For an independence test, we take ONE random sample and measure TWO categorical variables on each subject. We then test whether these variables are associated or independent.</p> <p>For example, surveying 500 randomly selected adults about: - Their exercise frequency (daily, weekly, rarely, never) - Their self-reported stress level (low, moderate, high)</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#hypotheses-for-independence","title":"Hypotheses for Independence","text":"<ul> <li>H\u2080: There is no association between [Variable 1] and [Variable 2] in the population (the variables are independent)</li> <li>H\u2090: There is an association between [Variable 1] and [Variable 2] in the population</li> </ul> <p>For our example: - H\u2080: Exercise frequency and stress level are independent - H\u2090: Exercise frequency and stress level are associated</p> <p>The calculations for expected counts, chi-square statistic, and degrees of freedom are identical to the homogeneity test. The interpretation, however, focuses on association rather than comparing distributions.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#diagram-homogeneity-vs-independence-comparison","title":"Diagram: Homogeneity vs Independence Comparison","text":"Comparing Homogeneity and Independence Tests <p>Type: infographic</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Differentiate, distinguish</p> <p>Learning Objective: Students will distinguish between tests for homogeneity and tests for independence by comparing their setups, hypotheses, and interpretations.</p> <p>Purpose: Help students understand when to use each test type based on study design</p> <p>Layout: Side-by-side comparison with interactive elements</p> <p>Left Panel - Homogeneity: - Visual: Multiple groups shown as separate boxes, each sampled independently - Arrow pointing to same categorical variable measured in each - Example: \"3 schools, asking each about college plans\" - Key phrase: \"Same distribution across groups?\"</p> <p>Right Panel - Independence: - Visual: One population box, two variables branching out - Shows single sample with two questions asked - Example: \"One sample, asking about exercise AND stress\" - Key phrase: \"Are variables associated?\"</p> <p>Interactive Elements: - Hover over each element for detailed explanations - Click examples to see hypothesis statements - Toggle between visual and text descriptions - Quiz mode: Given a scenario, identify which test applies</p> <p>Color Coding: - Blue: Homogeneity test elements - Green: Independence test elements - Orange: Shared elements (chi-square formula, expected count formula)</p> <p>Implementation: HTML/CSS/JavaScript with hover interactions</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-8-chi-square-conclusions","title":"Part 8: Chi-Square Conclusions","text":"<p>Regardless of which chi-square test you're performing, the conclusion follows the same pattern. Let's walk through how to draw and communicate your conclusions effectively.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#the-four-step-process","title":"The Four-Step Process","text":"<ol> <li>State the test and check conditions</li> <li>Identify: \"I will perform a chi-square test for [GOF/homogeneity/independence]\"</li> <li> <p>Verify: Random, Independent, Large Counts (all expected \u2265 5)</p> </li> <li> <p>Calculate the test statistic and p-value</p> </li> <li>Compute all expected counts</li> <li>Calculate \\(\\chi^2 = \\sum \\frac{(O-E)^2}{E}\\)</li> <li> <p>Find p-value using df = (k-1) for GOF or df = (r-1)(c-1) for two-way tables</p> </li> <li> <p>Make a decision</p> </li> <li>If p-value \u2264 \u03b1: Reject H\u2080</li> <li> <p>If p-value &gt; \u03b1: Fail to reject H\u2080</p> </li> <li> <p>State conclusion in context</p> </li> <li>Use language appropriate to your decision</li> <li>Connect back to the original question</li> <li>Mention practical implications if relevant</li> </ol>"},{"location":"chapters/18-chi-square-and-regression-inference/#template-conclusions","title":"Template Conclusions","text":"<p>When rejecting H\u2080 (significant result):</p> <p>\"Because the p-value of [p-value] is less than \u03b1 = [significance level], we reject the null hypothesis. We have convincing evidence that [restate H\u2090 in context].\"</p> <p>When failing to reject H\u2080:</p> <p>\"Because the p-value of [p-value] is greater than \u03b1 = [significance level], we fail to reject the null hypothesis. We do not have convincing evidence that [restate H\u2090 in context].\"</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#follow-up-analysis","title":"Follow-Up Analysis","text":"<p>When you reject H\u2080 in a chi-square test, it's often helpful to examine which categories contributed most to the chi-square statistic. Calculate the individual components \\(\\frac{(O-E)^2}{E}\\) and identify the largest contributors\u2014these indicate where the observed data departed most dramatically from expectations.</p> <p>Acorn for Your Thoughts</p> <p>Sylvia reminds you: \"A significant chi-square result tells you THAT something differs, but not exactly WHAT or WHY. Always follow up with exploratory analysis to understand the nature of the difference!\"</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-9-inference-for-regression-slope","title":"Part 9: Inference for Regression Slope","text":"<p>Now we shift gears from categorical data to regression. In Chapter 7, you learned how to find the least-squares regression line \\(\\hat{y} = a + bx\\). But how do we know if the slope \\(b\\) we calculated reflects a real relationship in the population, or if it could have occurred by chance?</p> <p>Inference for slope answers this question by constructing confidence intervals and hypothesis tests for the population slope parameter \\(\\beta\\).</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#the-regression-model","title":"The Regression Model","text":"<p>When we perform inference for regression, we assume the following model:</p> \\[ y = \\alpha + \\beta x + \\varepsilon \\] <p>where: - \\(\\alpha\\) = population y-intercept - \\(\\beta\\) = population slope (the true slope we're trying to estimate) - \\(\\varepsilon\\) = random error term (normally distributed with mean 0)</p> <p>Our sample statistics \\(a\\) and \\(b\\) are estimates of the population parameters \\(\\alpha\\) and \\(\\beta\\).</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#why-test-the-slope","title":"Why Test the Slope?","text":"<p>The slope \\(b\\) tells us how much y changes, on average, for each one-unit increase in x. If \\(\\beta = 0\\), that means x has no linear relationship with y\u2014knowing x tells us nothing about y. So our typical hypotheses are:</p> <ul> <li>H\u2080: \\(\\beta = 0\\) (no linear relationship)</li> <li>H\u2090: \\(\\beta \\neq 0\\) (there IS a linear relationship)</li> </ul> <p>We can also test one-sided alternatives (\\(\\beta &gt; 0\\) or \\(\\beta &lt; 0\\)) when we have directional predictions.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#diagram-sample-slope-variability","title":"Diagram: Sample Slope Variability","text":"Visualizing Sampling Distribution of the Slope <p>Type: microsim</p> <p>Bloom Level: Understand (L2) Bloom Verb: Explain, interpret</p> <p>Learning Objective: Students will understand that the sample slope varies from sample to sample and follows a t-distribution under repeated sampling.</p> <p>Instructional Rationale: Seeing multiple samples and their regression lines helps students viscerally understand sampling variability and why we need inference procedures.</p> <p>Data Visibility Requirements: - Stage 1: Show population regression line (true slope \u03b2) - Stage 2: Draw one random sample, show sample regression line - Stage 3: Record sample slope b - Stage 4: Repeat many times, build histogram of sample slopes - Stage 5: Show t-distribution overlay on histogram</p> <p>Visual Elements: - Left panel: Scatterplot with population line and current sample - Right panel: Histogram of sample slopes accumulating - Display: Current sample slope, mean of sample slopes, SE of sample slopes - True population slope marked on histogram</p> <p>Interactive Controls: - Button: \"Take One Sample\" - Button: \"Take 100 Samples\" - Slider: Sample size (10 to 100) - Slider: Population slope (-2 to 2) - Slider: Error standard deviation (affects scatter) - Button: \"Reset\"</p> <p>Canvas Layout: - Split view: Scatterplot (left), Histogram (right) - Controls at bottom - Statistics display at top</p> <p>Default Parameters: - Sample size: 30 - Population slope: 0.5 - Error SD: 2</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-10-conditions-for-regression-inference","title":"Part 10: Conditions for Regression Inference","text":"<p>Before performing inference on the slope, we must verify four important conditions, often remembered by the acronym LINE:</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#l-linearity-condition","title":"L - Linearity Condition","text":"<p>The relationship between x and y must be linear in the population.</p> <p>How to check: Create a residual plot (residuals vs. x or residuals vs. predicted values). If the relationship is linear, the residuals should scatter randomly around zero with no curved pattern.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#i-independence-condition","title":"I - Independence Condition","text":"<p>The observations must be independent of each other.</p> <p>How to check: - Know how the data was collected (random sampling or experiment) - For time series data, check for patterns in residuals over time - When sampling without replacement, verify the 10% condition</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#n-normality-of-residuals","title":"N - Normality of Residuals","text":"<p>For any given value of x, the y-values should be normally distributed around the regression line.</p> <p>How to check: - Create a histogram or normal probability plot of the residuals - Look for roughly symmetric, bell-shaped distribution - This condition is less critical with larger sample sizes (n \u2265 30) due to the Central Limit Theorem</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#e-equal-variance-condition","title":"E - Equal Variance Condition","text":"<p>The standard deviation of y should be the same for all values of x (also called homoscedasticity).</p> <p>How to check: In the residual plot, look for consistent vertical spread. Watch out for \"fan shapes\" or \"megaphones\" where spread increases or decreases across the x-axis.</p> Condition What to Check Red Flags Linearity Residual plot Curved pattern Independence Data collection method Time order patterns Normality Histogram of residuals Strong skewness, outliers Equal Variance Residual plot spread Fan or megaphone shape"},{"location":"chapters/18-chi-square-and-regression-inference/#diagram-checking-regression-conditions","title":"Diagram: Checking Regression Conditions","text":"Interactive Regression Conditions Checker <p>Type: microsim</p> <p>Bloom Level: Evaluate (L5) Bloom Verb: Assess, judge</p> <p>Learning Objective: Students will evaluate whether regression conditions are met by analyzing residual plots and histograms, identifying violations.</p> <p>Instructional Rationale: Learning to \"read\" residual plots is a critical skill. This simulator shows good and problematic patterns with immediate classification feedback.</p> <p>Visual Elements: - Main scatterplot with regression line - Residual plot (residuals vs x) - Histogram of residuals - Normal probability plot of residuals - Checklist of conditions with pass/fail indicators</p> <p>Interactive Controls: - Dropdown: Select scenario type   - \"Linear relationship, conditions met\"   - \"Curved relationship (nonlinear)\"   - \"Increasing variance (fan shape)\"   - \"Non-normal residuals (skewed)\"   - \"Outliers present\"   - \"Random scatter (good)\" - Button: \"Generate New Data\" for selected scenario - Checkboxes: Student self-assessment for each condition - Button: \"Check My Answers\"</p> <p>Scenario Data: Each scenario generates data with specific properties - Good: Random normal errors, constant variance - Curved: Quadratic relationship - Fan: SD proportional to x - Skewed: Chi-square errors - Outliers: Normal plus 2-3 extreme points</p> <p>Canvas Layout: - 2x2 grid of diagnostic plots - Condition checklist on right side - Scenario selector at top</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-11-t-test-for-slope","title":"Part 11: T-Test for Slope","text":"<p>When conditions are met, we use a t-test for the slope to test hypotheses about \\(\\beta\\).</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#the-test-statistic","title":"The Test Statistic","text":"\\[ t = \\frac{b - \\beta_0}{SE_b} \\] <p>where: - \\(b\\) = sample slope (from regression output) - \\(\\beta_0\\) = hypothesized slope (usually 0) - \\(SE_b\\) = standard error of the slope (from regression output)</p> <p>This follows a t-distribution with df = n - 2 (we subtract 2 because we estimated two parameters: the slope and intercept).</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#reading-computer-output","title":"Reading Computer Output","text":"<p>Most calculators and software provide the standard error of the slope and often the t-statistic and p-value directly. Here's what typical regression output looks like:</p> <pre><code>Predictor    Coef     SE Coef    T        P\nConstant    12.43     1.87       6.65    0.000\nHours        2.31     0.42       5.50    0.000\n\nS = 4.125   R-sq = 73.2%   R-sq(adj) = 71.8%\n</code></pre> <p>From this output: - Sample slope \\(b = 2.31\\) - Standard error \\(SE_b = 0.42\\) - t-statistic = 5.50 - p-value \u2248 0.000 (very small)</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#completing-the-t-test","title":"Completing the T-Test","text":"<p>Example: A researcher wants to know if study hours predict exam scores.</p> <p>Hypotheses: - H\u2080: \\(\\beta = 0\\) (study hours have no linear relationship with exam scores) - H\u2090: \\(\\beta \\neq 0\\) (study hours have a linear relationship with exam scores)</p> <p>From output: t = 5.50, p-value \u2248 0.000</p> <p>Conclusion: Because the p-value is essentially 0 (much less than \u03b1 = 0.05), we reject H\u2080. We have very strong evidence that there is a linear relationship between study hours and exam scores.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-12-t-interval-for-slope","title":"Part 12: T-Interval for Slope","text":"<p>We can also construct a confidence interval for the slope to estimate the range of plausible values for \\(\\beta\\).</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#the-formula","title":"The Formula","text":"\\[ b \\pm t^* \\times SE_b \\] <p>where: - \\(b\\) = sample slope - \\(t^*\\) = critical t-value for desired confidence level with df = n - 2 - \\(SE_b\\) = standard error of the slope</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#interpreting-the-interval","title":"Interpreting the Interval","text":"<p>Using our study hours example with b = 2.31, SE_b = 0.42, and n = 25:</p> <p>For a 95% confidence interval with df = 23: - \\(t^* = 2.069\\) - Interval: \\(2.31 \\pm 2.069(0.42) = 2.31 \\pm 0.87 = (1.44, 3.18)\\)</p> <p>Interpretation: We are 95% confident that the true slope of the population regression line is between 1.44 and 3.18. This means we're 95% confident that each additional hour of studying is associated with an increase of between 1.44 and 3.18 points on the exam, on average.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#confidence-interval-vs-hypothesis-test","title":"Confidence Interval vs. Hypothesis Test","text":"<p>Notice that our 95% confidence interval (1.44, 3.18) does not contain 0. This is consistent with rejecting H\u2080: \\(\\beta = 0\\) at \u03b1 = 0.05. In fact:</p> <ul> <li>If the CI does NOT contain 0 \u2192 Reject H\u2080 at the corresponding \u03b1</li> <li>If the CI DOES contain 0 \u2192 Fail to reject H\u2080</li> </ul> <p>This provides a nice connection between the two inference methods!</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#diagram-confidence-interval-for-slope-visualization","title":"Diagram: Confidence Interval for Slope Visualization","text":"Building Confidence Intervals for Slope <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate, construct</p> <p>Learning Objective: Students will construct and interpret confidence intervals for the regression slope, understanding how sample size and confidence level affect interval width.</p> <p>Instructional Rationale: Manipulating parameters and seeing immediate visual feedback helps students understand the relationships between sample size, confidence level, and interval precision.</p> <p>Visual Elements: - Scatterplot with regression line - \"Plausible slopes\" shown as a band of possible regression lines - Number line below showing confidence interval - Marker at 0 on number line (for hypothesis test connection) - Display of interval bounds and width</p> <p>Interactive Controls: - Slider: Sample size (10 to 200) - Dropdown: Confidence level (90%, 95%, 99%) - Slider: True population slope (for simulation) - Button: \"Generate New Sample\" - Button: \"Take 100 Samples\" (shows coverage) - Checkbox: Show individual intervals from repeated sampling</p> <p>Data Visibility: - Sample slope b - Standard error SE_b - Critical value t* - Margin of error - Final interval</p> <p>Canvas Layout: - Top: Scatterplot with regression line band - Bottom: Number line with interval - Right panel: Calculations shown step by step</p> <p>Default Parameters: - Sample size: 30 - Confidence level: 95% - Population slope: 2</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#part-13-putting-it-all-together","title":"Part 13: Putting It All Together","text":"<p>Let's work through a complete example that ties together everything we've learned about regression inference.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#complete-regression-inference-example","title":"Complete Regression Inference Example","text":"<p>Context: A coffee shop owner collects data on daily temperature (\u00b0F) and number of iced drinks sold. She wants to know if temperature is a useful predictor of iced drink sales.</p> <p>Data Summary (n = 40 days): - Sample slope: b = 3.2 drinks per degree - Sample intercept: a = -85 - Standard error of slope: SE_b = 0.58 - R\u00b2 = 0.67</p> <p>Step 1: Check Conditions</p> <p>Linearity: Residual plot shows random scatter around zero\u2014no curved pattern. \u2713</p> <p>Independence: Data collected on 40 randomly selected days over 6 months. The 10% condition is satisfied (40 &lt; 10% of all days). \u2713</p> <p>Normality: Histogram of residuals is approximately bell-shaped and symmetric. \u2713</p> <p>Equal Variance: Residual plot shows consistent spread across all temperature values. \u2713</p> <p>All conditions for regression inference are met.</p> <p>Step 2: State Hypotheses</p> <ul> <li>H\u2080: \\(\\beta = 0\\) (Temperature has no linear relationship with iced drink sales)</li> <li>H\u2090: \\(\\beta &gt; 0\\) (Higher temperatures are associated with more iced drink sales)</li> </ul> <p>Note: We use a one-sided test because the owner has a clear directional prediction.</p> <p>Step 3: Calculate Test Statistic</p> \\[ t = \\frac{b - 0}{SE_b} = \\frac{3.2 - 0}{0.58} = 5.52 \\] <p>With df = 40 - 2 = 38</p> <p>Step 4: Find P-Value</p> <p>Using technology: P(t &gt; 5.52 | df = 38) \u2248 0.0000015</p> <p>Step 5: Conclusion</p> <p>Because the p-value (\u2248 0.0000015) is much less than \u03b1 = 0.05, we reject H\u2080. We have very strong evidence that higher temperatures are associated with increased iced drink sales.</p> <p>Step 6: Confidence Interval</p> <p>For a 95% CI with df = 38, t* \u2248 2.024:</p> \\[ 3.2 \\pm 2.024(0.58) = 3.2 \\pm 1.17 = (2.03, 4.37) \\] <p>We are 95% confident that for each 1\u00b0F increase in temperature, the average number of iced drinks sold increases by between 2.03 and 4.37 drinks.</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#chapter-summary-key-takeaways","title":"Chapter Summary: Key Takeaways","text":"<p>Let's squirrel away the essential knowledge from this chapter!</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#chi-square-tests","title":"Chi-Square Tests","text":"Test Type Purpose Hypotheses df Goodness-of-Fit Does data match claimed distribution? H\u2080: Distribution matches k - 1 Homogeneity Same distribution across groups? H\u2080: Same distribution (r-1)(c-1) Independence Are two variables associated? H\u2080: Variables independent (r-1)(c-1) <p>Chi-Square Formula: [ \\chi^2 = \\sum \\frac{(O - E)^2}{E} ]</p> <p>Conditions: Random, Independent, Large Counts (all expected \u2265 5)</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#regression-inference","title":"Regression Inference","text":"<p>Conditions (LINE): - Linearity: Check residual plot for no pattern - Independence: Random sample, 10% condition - Normality: Residuals approximately normal - Equal variance: Consistent spread in residual plot</p> <p>T-Test for Slope: [ t = \\frac{b - \\beta_0}{SE_b}, \\quad df = n - 2 ]</p> <p>Confidence Interval for Slope: [ b \\pm t^* \\times SE_b ]</p> <p>You Did It!</p> <p>Congratulations! You've now mastered two of the most powerful tools in inferential statistics. Chi-square tests let you work with categorical data in ways that weren't possible before, and regression inference lets you make formal claims about relationships between quantitative variables. As Sylvia would say, \"That's a data point worth collecting!\"</p>"},{"location":"chapters/18-chi-square-and-regression-inference/#practice-problems","title":"Practice Problems","text":"<p>Test your understanding with these practice scenarios:</p> Practice 1: M&amp;M Colors <p>A student counts 52 brown, 23 red, 20 yellow, 18 orange, 18 blue, and 19 green M&amp;Ms in a large bag. The company claims the percentages should be 13% brown, 13% red, 14% yellow, 20% orange, 24% blue, and 16% green. Is there evidence that the distribution differs from the company's claim?</p> <p>Solution: This is a goodness-of-fit test. Calculate expected counts (n = 150), compute chi-square, find p-value with df = 5. The chi-square statistic is approximately 25.8, giving a p-value &lt; 0.001. Reject H\u2080\u2014there is convincing evidence the distribution differs from the claim.</p> Practice 2: Study Design <p>Researchers survey 400 randomly selected adults, asking about their education level (high school, some college, bachelor's, graduate) and their primary news source (TV, online, print, social media). They want to know if education level and news source preference are related.</p> <p>Which test should they use: homogeneity or independence?</p> <p>Solution: This is a test for independence. There is ONE sample of 400 adults, and TWO categorical variables (education level and news source) are measured on each person. A homogeneity test would require separate samples from each education level.</p> Practice 3: Regression Conditions <p>A residual plot shows that residuals have larger spread for larger x-values (a \"megaphone\" shape). Which condition is violated, and what are the implications?</p> <p>Solution: The Equal Variance (homoscedasticity) condition is violated. This means the standard error of the slope may be incorrect, making our t-tests and confidence intervals unreliable. Consider transforming the response variable (like taking a log) or using weighted least squares regression.</p> <p>\"Time to squirrel away this knowledge! You've learned some incredibly powerful tools in this chapter. Chi-square tests and regression inference will serve you well on the AP exam and beyond. Remember: always check your conditions, interpret your results in context, and never let the math obscure the meaning of your analysis.\" \u2014Sylvia</p>"},{"location":"chapters/19-communication-and-synthesis/","title":"Communication and Synthesis","text":""},{"location":"chapters/19-communication-and-synthesis/#summary","title":"Summary","text":"<p>This final chapter focuses on synthesizing statistical knowledge and communicating results effectively. Students will learn about the distinction between statistical and practical significance, effect sizes, study limitations, and how to write clear statistical reports. The chapter concludes with strategies for success on the AP Statistics exam.</p>"},{"location":"chapters/19-communication-and-synthesis/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 10 concepts from the learning graph:</p> <ol> <li>Regression Conclusion</li> <li>Stat vs Practical Sig</li> <li>Effect Size</li> <li>Sample Size Impact</li> <li>Study Limitations</li> <li>Generalizability</li> <li>Statistical Report Writing</li> <li>Communicating Results</li> <li>Four-Step Process</li> <li>AP Exam Strategies</li> </ol>"},{"location":"chapters/19-communication-and-synthesis/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 16: Hypothesis Testing</li> <li>Chapter 17: Inference for Means</li> <li>Chapter 18: Chi-Square and Regression Inference</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#introduction-the-final-piece-of-the-statistical-puzzle","title":"Introduction: The Final Piece of the Statistical Puzzle","text":"<p>Welcome to the final chapter of your AP Statistics journey! You've learned how to collect data, describe it with graphs and numbers, understand probability, and make inferences about populations. But here's the thing\u2014none of that matters if you can't communicate your findings clearly and thoughtfully to others.</p> <p>Think about it: what good is a brilliant analysis if no one understands it? Sylvia likes to say, \"A tree falling in the forest might not make a sound if no one's there, but a statistical result that's never communicated definitely doesn't make an impact.\" Throughout this chapter, we'll focus on the skills that transform you from someone who does statistics to someone who thinks statistically and shares insights with the world.</p> <p>Let's squirrel away the big ideas that will help you synthesize everything you've learned and prepare for success on the AP exam!</p>"},{"location":"chapters/19-communication-and-synthesis/#drawing-conclusions-from-regression-analysis","title":"Drawing Conclusions from Regression Analysis","text":"<p>Before we dive into communication and synthesis, let's make sure we can properly conclude a regression analysis. Drawing a regression conclusion means interpreting your t-test for the slope in the context of your research question.</p> <p>When you perform inference for the slope of a regression line, your conclusion should include:</p> <ul> <li>A decision about the null hypothesis (reject or fail to reject)</li> <li>The evidence that supports your decision (p-value compared to significance level)</li> <li>An interpretation in context of the original question</li> <li>A statement about the relationship between variables</li> </ul> Component What to Include Example Decision State whether you reject or fail to reject \\( H_0 \\) \"We reject the null hypothesis\" Evidence Report the p-value and compare to \\( \\alpha \\) \"because the p-value (0.003) is less than \\( \\alpha = 0.05 \\)\" Context Relate to the original variables \"There is convincing evidence of a linear relationship between study hours and exam scores\" Direction State whether slope is positive or negative \"Students who study more tend to score higher on exams\" <p>Here's a complete example of a regression conclusion:</p> <p>\"We reject the null hypothesis that there is no linear relationship between hours of sleep and test performance (t = 3.45, df = 28, p = 0.002). Since the p-value is less than our significance level of 0.05, we have convincing evidence that a linear relationship exists. The positive slope (b = 4.2) suggests that students who get more sleep tend to perform better on tests.\"</p> <p>Sylvia Says</p> <p>\"When writing regression conclusions, I always ask myself: Would someone who hasn't seen my data understand what I found and why it matters? If not, I haven't finished my job yet!\"</p>"},{"location":"chapters/19-communication-and-synthesis/#statistical-significance-vs-practical-significance","title":"Statistical Significance vs. Practical Significance","text":"<p>Here's where things get really interesting\u2014and where many students (and even some professionals!) stumble. Just because a result is statistically significant doesn't mean it's actually important in the real world.</p> <p>Statistical significance means we have enough evidence to conclude that an effect or relationship exists\u2014it's unlikely our results happened by chance alone. We typically reject the null hypothesis when the p-value falls below our chosen significance level (often 0.05).</p> <p>Practical significance asks a different question: Is this effect large enough to actually matter?</p> <p>Consider this example: A pharmaceutical company tests a new diet pill and finds that, on average, people taking the pill lose 0.5 pounds more than those taking a placebo over 12 weeks. With a sample size of 10,000 people, this difference is statistically significant (p &lt; 0.001). But would you spend money on a pill that helps you lose only half a pound in three months? Probably not\u2014the effect lacks practical significance.</p> Type of Significance Question It Answers Depends On Statistical Is the effect real (not due to chance)? Sample size, variability, effect size Practical Is the effect meaningful or useful? Context, cost, consequences <p>The relationship between these two types of significance creates four possible scenarios:</p> <ol> <li>Statistically significant AND practically significant: The best outcome\u2014you've found a real effect that matters</li> <li>Statistically significant but NOT practically significant: The effect is real but too small to care about (common with huge sample sizes)</li> <li>NOT statistically significant but practically significant: You might have found something important, but your sample was too small to detect it reliably</li> <li>Neither statistically nor practically significant: No real effect, or if there is one, it's too small to matter</li> </ol>"},{"location":"chapters/19-communication-and-synthesis/#diagram-statistical-vs-practical-significance-decision-matrix","title":"Diagram: Statistical vs. Practical Significance Decision Matrix","text":"Statistical vs. Practical Significance Decision Matrix <p>Type: infographic</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Distinguish</p> <p>Purpose: Help students distinguish between statistical and practical significance using a 2x2 decision matrix with real-world examples</p> <p>Learning Objective: Students will be able to classify study results into one of four categories based on their statistical and practical significance, and explain the implications of each classification.</p> <p>Layout: A 2x2 matrix grid in the center with four quadrants</p> <p>Matrix Structure: - X-axis: \"Practically Significant?\" (No | Yes) - Y-axis: \"Statistically Significant?\" (Yes on top | No on bottom)</p> <p>Quadrant Content: - Top-Left (Stat Yes, Practical No): \"Trivial Effect\" - Example: \"Diet pill: 0.5 lb loss, p &lt; 0.001, n=10,000\" - Top-Right (Stat Yes, Practical Yes): \"Meaningful Discovery!\" - Example: \"New treatment: 40% reduction in symptoms, p = 0.02\" - Bottom-Left (Stat No, Practical No): \"Nothing Here\" - Example: \"No effect detected, n=50\" - Bottom-Right (Stat No, Practical Yes): \"Need More Data\" - Example: \"Promising 25% improvement, p = 0.12, n=30\"</p> <p>Interactive Features: - Click each quadrant to reveal detailed explanation - Hover over examples to see more context - Color coding: Green for top-right (ideal), Yellow for bottom-right (promising), Orange for top-left (misleading), Gray for bottom-left</p> <p>Color Scheme: Green (#4CAF50), Yellow (#FFC107), Orange (#FF9800), Gray (#9E9E9E)</p> <p>Implementation: HTML/CSS/JavaScript with click and hover interactions</p> <p>Common Mistake Alert</p> <p>Don't confuse \"statistically significant\" with \"important\" or \"large.\" A tiny effect can be statistically significant with a large enough sample, and a large effect might not be statistically significant with a small sample.</p>"},{"location":"chapters/19-communication-and-synthesis/#understanding-effect-size","title":"Understanding Effect Size","text":"<p>So how do we measure whether an effect is practically significant? This is where effect size comes in. Effect size is a standardized measure of how large an effect is, independent of sample size.</p> <p>While p-values tell us whether an effect exists, effect sizes tell us how big that effect is. Think of it this way: a p-value is like asking \"Did something happen?\" while an effect size asks \"How much did it happen?\"</p>"},{"location":"chapters/19-communication-and-synthesis/#common-effect-size-measures","title":"Common Effect Size Measures","text":"<p>For comparing two means, we often use Cohen's d:</p> \\[ d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{\\text{pooled}}} \\] <p>where \\( s_{\\text{pooled}} \\) is the pooled standard deviation. Cohen's d tells us how many standard deviations apart the two groups are.</p> <p>For correlation and regression, \\( r^2 \\) (coefficient of determination) serves as an effect size, telling us what proportion of the variation in y is explained by x.</p> <p>Here are general guidelines for interpreting effect sizes:</p> Effect Size Cohen's d \\( r^2 \\) Interpretation Small 0.2 0.01 Subtle, may need special attention to notice Medium 0.5 0.09 Noticeable to careful observers Large 0.8 0.25 Obvious to casual observers <p>Context Matters</p> <p>These benchmarks are rough guidelines. A \"small\" effect size might be huge in some contexts (like a drug that prevents heart attacks) and meaningless in others. Always interpret effect sizes in the context of your specific situation.</p>"},{"location":"chapters/19-communication-and-synthesis/#diagram-effect-size-visualization-microsim","title":"Diagram: Effect Size Visualization MicroSim","text":"Effect Size Visualization MicroSim <p>Type: microsim</p> <p>Bloom Level: Understand (L2) Bloom Verb: Compare</p> <p>Purpose: Allow students to visually compare two distributions and see how effect size (Cohen's d) relates to the overlap between groups</p> <p>Learning Objective: Students will be able to explain what effect size means by manipulating the separation between two distributions and observing changes in both visual overlap and the Cohen's d value.</p> <p>Data Visibility Requirements: Stage 1: Show two overlapping normal distribution curves with the same mean Stage 2: As slider moves, show the second distribution shifting right Stage 3: Display Cohen's d calculation with actual values Stage 4: Show percentage overlap between distributions Stage 5: Label the effect size interpretation (small, medium, large)</p> <p>Instructional Rationale: Step-through exploration with visible calculations is appropriate because the Understand objective requires learners to see the connection between the numerical effect size and the visual separation of groups.</p> <p>Canvas Layout: - Main area: Two overlapping normal curves (different colors) - Control panel below the curves - Statistics display on the right side</p> <p>Visual Elements: - Group 1 distribution: Blue filled curve, mean = 100, SD = 15 - Group 2 distribution: Orange filled curve, mean adjustable, SD = 15 - Shaded overlap region - Vertical lines marking each mean - Labels showing mean values</p> <p>Interactive Controls: - Slider: \"Effect Size (Cohen's d)\" ranging from 0 to 2.0, step 0.1 - Display showing: Cohen's d value, percent overlap, interpretation label</p> <p>Default Parameters: - Both means start at 100 (d = 0) - Standard deviation = 15 for both groups - Canvas shows x-axis from 40 to 160</p> <p>Behavior: - Moving slider shifts Group 2 mean: mean_2 = 100 + (d * 15) - Overlap region updates in real-time - Interpretation label changes: d &lt; 0.3 = \"Small\", 0.3 &lt;= d &lt; 0.7 = \"Medium\", d &gt;= 0.7 = \"Large\" - Show calculation breakdown: d = (mean_2 - mean_1) / pooled_SD</p> <p>Implementation: p5.js with smooth animation for distribution movement</p>"},{"location":"chapters/19-communication-and-synthesis/#the-impact-of-sample-size","title":"The Impact of Sample Size","text":"<p>Sample size plays a crucial role in what you can detect and conclude. Understanding its effects helps you interpret results wisely and design better studies.</p> <p>Larger samples provide:</p> <ul> <li>More statistical power (ability to detect true effects)</li> <li>Narrower confidence intervals</li> <li>More precise estimates</li> <li>Greater ability to detect small effects</li> </ul> <p>But larger samples also mean:</p> <ul> <li>Trivially small effects may become \"statistically significant\"</li> <li>Greater cost and time to collect data</li> <li>Potential for detecting differences that don't matter practically</li> </ul> <p>The relationship between sample size and what we can detect creates an important pattern:</p> Sample Size Small Effect Medium Effect Large Effect Small (n &lt; 30) Unlikely to detect May detect Likely to detect Medium (n = 30-100) May detect Likely to detect Will detect Large (n &gt; 100) Likely to detect Will detect Will detect <p>This is why the distinction between statistical and practical significance becomes especially important with large samples. When you have thousands of observations, even tiny, meaningless differences can produce impressive-looking p-values.</p> <p>Consider the relationship between sample size and margin of error for a proportion:</p> \\[ \\text{Margin of Error} = z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\] <p>Notice that margin of error decreases as \\( n \\) increases\u2014specifically, you need to quadruple your sample size to cut the margin of error in half!</p>"},{"location":"chapters/19-communication-and-synthesis/#diagram-sample-size-and-margin-of-error-explorer","title":"Diagram: Sample Size and Margin of Error Explorer","text":"Sample Size and Margin of Error Explorer <p>Type: microsim</p> <p>Bloom Level: Apply (L3) Bloom Verb: Calculate</p> <p>Purpose: Demonstrate the relationship between sample size and margin of error, showing the diminishing returns of larger samples</p> <p>Learning Objective: Students will be able to predict how margin of error changes with sample size and calculate the sample size needed for a desired margin of error.</p> <p>Data Visibility Requirements: Stage 1: Show initial sample size and calculated margin of error Stage 2: Display the formula with current values substituted Stage 3: Show the resulting confidence interval graphically Stage 4: Track changes as user adjusts sample size</p> <p>Instructional Rationale: An interactive calculator is appropriate for the Apply level because students need to manipulate inputs and observe outputs to build intuition about the mathematical relationship.</p> <p>Canvas Layout: - Top section: Formula display with live values - Middle: Visual confidence interval representation - Bottom: Controls and results display</p> <p>Visual Elements: - Horizontal bar showing confidence interval centered on sample proportion - Margin of error shown as distance from center to edge - Curve showing ME vs n relationship - Current point highlighted on the curve</p> <p>Interactive Controls: - Slider: Sample size n (10 to 2000, logarithmic scale) - Slider: Sample proportion p-hat (0.1 to 0.9) - Dropdown: Confidence level (90%, 95%, 99%) - Display: Margin of error, confidence interval bounds</p> <p>Default Parameters: - n = 100 - p-hat = 0.5 - Confidence level = 95%</p> <p>Behavior: - Formula updates with current values in real-time - Confidence interval bar width changes with margin of error - Curve plot updates to show current position - Display message when sample size is insufficient for normal approximation</p> <p>Calculations to Display: - z value for selected confidence level - Margin of error = z * sqrt(p-hat*(1-p-hat)/n) - Lower bound = p-hat - ME - Upper bound = p-hat + ME</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/19-communication-and-synthesis/#recognizing-study-limitations","title":"Recognizing Study Limitations","text":"<p>Every study has limitations\u2014and acknowledging them honestly is a sign of good statistical thinking, not weakness. Understanding limitations helps us interpret results appropriately and avoid overgeneralizing our conclusions.</p> <p>Common study limitations fall into several categories:</p>"},{"location":"chapters/19-communication-and-synthesis/#design-limitations","title":"Design Limitations","text":"<ul> <li>Observational vs. Experimental: Remember, only randomized experiments can establish causation. If your study is observational, you cannot claim that one variable causes changes in another.</li> <li>Sampling Method: Was the sample truly random? Convenience samples and voluntary response samples introduce bias.</li> <li>Confounding Variables: Were there variables that could explain the relationship you observed?</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#measurement-limitations","title":"Measurement Limitations","text":"<ul> <li>Response Bias: Did respondents answer honestly? Sensitive topics often produce inaccurate responses.</li> <li>Measurement Error: How precise were your measuring instruments or survey questions?</li> <li>Missing Data: Did nonresponse bias affect your results?</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#statistical-limitations","title":"Statistical Limitations","text":"<ul> <li>Sample Size: Was the sample large enough to detect the effect you were looking for?</li> <li>Multiple Comparisons: Did you test many hypotheses, increasing the chance of false positives?</li> <li>Assumptions Violated: Were the conditions for your inference procedure actually met?</li> </ul> <p>Here's a checklist for evaluating study limitations:</p> <ul> <li>[ ] Was random sampling used? If not, can results generalize to a larger population?</li> <li>[ ] Was random assignment used? If not, can we make causal claims?</li> <li>[ ] Were confounding variables controlled or acknowledged?</li> <li>[ ] Is the sample size adequate for the analysis performed?</li> <li>[ ] Were measurement methods reliable and valid?</li> <li>[ ] What sources of bias might exist?</li> <li>[ ] Were conditions for inference procedures checked and met?</li> </ul> <p>Sylvia's Study Limitation Reminder</p> <p>\"I've learned that the best researchers aren't those who claim their studies are perfect\u2014they're the ones who can clearly explain what their studies CAN'T tell us. That kind of honesty builds trust!\"</p>"},{"location":"chapters/19-communication-and-synthesis/#generalizability-who-can-we-apply-our-results-to","title":"Generalizability: Who Can We Apply Our Results To?","text":"<p>Generalizability refers to the extent to which our findings can be applied to populations or situations beyond our specific study. It's about asking: \"Who else does this apply to?\"</p> <p>The scope of your generalization depends on how your data was collected:</p> Data Collection Method Can Generalize To Random sample from population The entire population Convenience sample Only the sample itself (with caution) Specific subgroup studied Only that subgroup Random assignment to treatments Causal effects in similar populations"},{"location":"chapters/19-communication-and-synthesis/#factors-affecting-generalizability","title":"Factors Affecting Generalizability","text":"<ol> <li> <p>Sampling Frame: Did your sampling method actually reach all members of your target population?</p> </li> <li> <p>Response Rate: High nonresponse can limit generalizability if nonresponders differ from responders.</p> </li> <li> <p>Time and Place: Results from one time or location may not apply to others. A study of college students in 2025 might not generalize to students in 1995.</p> </li> <li> <p>Subject Characteristics: If you studied only one demographic group, be careful generalizing to others.</p> </li> </ol> <p>Consider this example: A researcher studies the effect of a new teaching method on calculus performance using students at a private university. Even with random assignment to treatment groups, we should be cautious about generalizing to:</p> <ul> <li>Students at public universities</li> <li>Students in other countries</li> <li>Students learning subjects other than calculus</li> <li>Students in future years with different preparation</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#diagram-generalizability-target-diagram","title":"Diagram: Generalizability Target Diagram","text":"Generalizability Target Diagram <p>Type: infographic</p> <p>Bloom Level: Evaluate (L5) Bloom Verb: Assess</p> <p>Purpose: Visualize the levels of generalizability from a specific sample outward to broader populations</p> <p>Learning Objective: Students will be able to assess how far beyond their sample they can reasonably generalize their findings based on their sampling method.</p> <p>Layout: Concentric circles (target diagram) representing levels of generalization</p> <p>Circles (inside to outside): 1. Center: \"Your Sample\" (e.g., \"50 students in Mr. Johnson's AP Stats class\") 2. Ring 1: \"Sampling Frame\" (e.g., \"Students in local school district\") 3. Ring 2: \"Target Population\" (e.g., \"All AP Statistics students\") 4. Ring 3: \"Broader Population\" (e.g., \"All high school students\") 5. Outer Ring: \"Universal Claims\" (e.g., \"All students everywhere\")</p> <p>Visual Features: - Color gradient from strong (center, green) to weak (outer, red) - Arrows showing which rings random sampling allows you to reach - Dashed lines indicating uncertain generalization - Warning icons at outer rings</p> <p>Interactive Features: - Click each ring to see examples of valid and invalid generalizations - Toggle between different study scenarios to see how generalizability changes - Hover for detailed explanations of why each ring is/isn't reachable</p> <p>Scenarios to Toggle: 1. Random sample from district \u2192 Can generalize to district 2. Convenience sample from one class \u2192 Can only describe that class 3. National random sample \u2192 Can generalize nationally</p> <p>Color Scheme: Green (strong evidence) to Yellow (moderate) to Red (weak/no evidence)</p> <p>Implementation: SVG with JavaScript click and hover handlers</p>"},{"location":"chapters/19-communication-and-synthesis/#writing-effective-statistical-reports","title":"Writing Effective Statistical Reports","text":"<p>Being able to write clear statistical reports is one of the most valuable skills you'll develop in this course. Whether you're writing a lab report, a research paper, or an answer on the AP exam, your goal is to communicate your statistical thinking clearly and completely.</p>"},{"location":"chapters/19-communication-and-synthesis/#components-of-a-statistical-report","title":"Components of a Statistical Report","text":"<p>A complete statistical report typically includes:</p> <ol> <li>Introduction: State the research question and why it matters</li> <li>Data Description: Explain how data was collected and describe the variables</li> <li>Exploratory Analysis: Present relevant graphs and summary statistics</li> <li>Methods: Describe the statistical procedures you'll use and why</li> <li>Results: Report numerical findings with appropriate interpretation</li> <li>Conclusions: Answer the research question and discuss limitations</li> </ol>"},{"location":"chapters/19-communication-and-synthesis/#writing-about-results","title":"Writing About Results","text":"<p>When presenting statistical results, include:</p> <ul> <li>The name of the test or procedure used</li> <li>The test statistic and its value</li> <li>The p-value or confidence interval</li> <li>Your conclusion in context</li> <li>Any relevant effect size measures</li> </ul> <p>Here's an example of poor vs. good statistical writing:</p> <p>Poor: \"The p-value was 0.03 so we reject the null hypothesis.\"</p> <p>Good: \"We performed a two-sample t-test to compare mean test scores between students who used the new study app (n = 45, mean = 82.3, SD = 8.2) and those who did not (n = 48, mean = 76.1, SD = 9.1). The test yielded t = 3.42 with df = 89.7 and p = 0.001. Since p &lt; 0.05, we reject the null hypothesis and conclude that there is convincing evidence of a difference in mean test scores. Students using the app scored an average of 6.2 points higher, with a 95% confidence interval for the difference of (2.6, 9.8) points.\"</p>"},{"location":"chapters/19-communication-and-synthesis/#key-phrases-for-ap-statistics","title":"Key Phrases for AP Statistics","text":"<p>Memorize these phrases for hypothesis testing conclusions:</p> <ul> <li>\"There is (or is not) convincing evidence that...\"</li> <li>\"We reject (or fail to reject) the null hypothesis...\"</li> <li>\"Since the p-value is less than (or greater than) \u03b1...\"</li> <li>\"We are X% confident that the true [parameter] is between...\"</li> </ul> <p>Avoid These Common Writing Errors</p> <ul> <li>Don't say \"accept the null hypothesis\"\u2014say \"fail to reject\"</li> <li>Don't say \"the probability that the null hypothesis is true\"\u2014that's not what p-value means</li> <li>Don't confuse sample statistics with population parameters</li> <li>Don't forget to state your conclusion in context!</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#communicating-results-to-different-audiences","title":"Communicating Results to Different Audiences","text":"<p>Effective communication means tailoring your message to your audience. The way you explain results to a statistics professor differs from how you'd explain them to a business manager or a newspaper reader.</p>"},{"location":"chapters/19-communication-and-synthesis/#audience-specific-communication","title":"Audience-Specific Communication","text":"Audience Focus On Avoid Statistical experts Technical details, methodology, assumptions Over-explaining basics Professionals in the field Practical implications, effect sizes Excessive jargon General public Real-world meaning, visualizations Technical terminology AP exam graders Complete reasoning, correct terminology Vague or incomplete answers"},{"location":"chapters/19-communication-and-synthesis/#visual-communication","title":"Visual Communication","text":"<p>Graphs and charts can communicate results more effectively than tables of numbers. When presenting results visually:</p> <ul> <li>Choose the right graph type for your data</li> <li>Label axes clearly with units</li> <li>Include informative titles</li> <li>Highlight the key finding</li> <li>Keep designs simple and uncluttered</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#diagram-audience-communication-matcher","title":"Diagram: Audience Communication Matcher","text":"Audience Communication Matcher <p>Type: microsim</p> <p>Bloom Level: Analyze (L4) Bloom Verb: Differentiate</p> <p>Purpose: Help students learn to tailor statistical communication to different audiences by matching explanations to audiences</p> <p>Learning Objective: Students will be able to differentiate between appropriate and inappropriate ways to communicate statistical findings to various audiences.</p> <p>Data Visibility Requirements: Stage 1: Present a statistical finding (e.g., \"Study found p = 0.02 for difference in means\") Stage 2: Show four different ways to communicate this finding Stage 3: Reveal which explanation matches which audience Stage 4: Provide feedback on correct/incorrect matches</p> <p>Instructional Rationale: A matching/classification activity is appropriate for the Analyze level because students must examine the characteristics of different explanations and determine which fits each audience.</p> <p>Canvas Layout: - Left side: List of 4 audience types as drop zones - Right side: Draggable explanation cards - Bottom: Score display and feedback area</p> <p>Audiences: 1. Statistics professor 2. Business manager 3. Newspaper reader 4. AP exam grader</p> <p>Example Finding: \"A study comparing two teaching methods found a mean difference of 8 points (p = 0.02, 95% CI: 2.1 to 13.9 points)\"</p> <p>Explanation Cards: 1. \"We rejected H0: \u03bc1 = \u03bc2 at \u03b1 = 0.05 using a two-sample t-test. The 95% CI for \u03bc1 - \u03bc2 is (2.1, 13.9).\" 2. \"Students using the new method scored 8 points higher on average. We're 95% confident the true improvement is between 2 and 14 points.\" 3. \"New teaching method boosts test scores! Students improved by about 8 points.\" 4. \"Since p = 0.02 &lt; 0.05, we reject H0 and conclude there is convincing evidence of a difference in mean scores. The new method produced scores averaging 8 points higher.\"</p> <p>Interactive Features: - Drag and drop explanation cards to audience drop zones - Check button to verify answers - Feedback explains why each match is correct or incorrect - Score tracking across multiple rounds</p> <p>New scenarios generated after each round with different statistical contexts</p> <p>Implementation: p5.js with drag-and-drop functionality</p>"},{"location":"chapters/19-communication-and-synthesis/#the-four-step-process-for-inference","title":"The Four-Step Process for Inference","text":"<p>The AP Statistics exam expects you to follow a consistent process when answering inference questions. This four-step process ensures you include all required elements and earn full credit.</p>"},{"location":"chapters/19-communication-and-synthesis/#the-four-steps","title":"The Four Steps","text":"<p>Step 1: STATE</p> <ul> <li>State the hypotheses (for hypothesis tests) OR</li> <li>Define the parameter and confidence level (for confidence intervals)</li> <li>Name the procedure you will use</li> </ul> <p>Step 2: PLAN</p> <ul> <li>Identify the appropriate inference procedure</li> <li>Check conditions:</li> <li>Random: Was the data collected randomly?</li> <li>Independent: Is the sample less than 10% of the population? (or independent groups?)</li> <li>Normal: Is the sampling distribution approximately normal?</li> </ul> <p>Step 3: DO</p> <ul> <li>Calculate the test statistic and p-value (for hypothesis tests) OR</li> <li>Calculate the confidence interval</li> <li>Show your work with formulas and substitutions</li> </ul> <p>Step 4: CONCLUDE</p> <ul> <li>Make a decision about the hypothesis (for tests)</li> <li>Interpret the interval (for confidence intervals)</li> <li>Answer in context of the original problem</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#four-step-process-example","title":"Four-Step Process Example","text":"<p>Problem: A random sample of 150 customers found that 42 preferred the new product design. Is there convincing evidence that more than 25% of all customers prefer the new design? Use \u03b1 = 0.05.</p> <p>STATE: - H\u2080: p = 0.25 (25% of all customers prefer the new design) - H\u2090: p &gt; 0.25 (More than 25% prefer the new design) - We will perform a one-proportion z-test.</p> <p>PLAN: - Random: \u2713 The sample was randomly selected - Independent: \u2713 150 is less than 10% of all customers (assuming more than 1,500 customers) - Normal: \u2713 np\u2080 = 150(0.25) = 37.5 \u2265 10 and n(1-p\u2080) = 150(0.75) = 112.5 \u2265 10</p> <p>DO: - Sample proportion: \\( \\hat{p} = \\frac{42}{150} = 0.28 \\) - Standard error: \\( SE = \\sqrt{\\frac{0.25(0.75)}{150}} = 0.0354 \\) - Test statistic: \\( z = \\frac{0.28 - 0.25}{0.0354} = 0.847 \\) - P-value: P(Z &gt; 0.847) = 0.198</p> <p>CONCLUDE: Since the p-value (0.198) is greater than \u03b1 = 0.05, we fail to reject the null hypothesis. There is not convincing evidence that more than 25% of all customers prefer the new product design.</p>"},{"location":"chapters/19-communication-and-synthesis/#diagram-four-step-process-interactive-flowchart","title":"Diagram: Four-Step Process Interactive Flowchart","text":"Four-Step Process Interactive Flowchart <p>Type: workflow</p> <p>Bloom Level: Apply (L3) Bloom Verb: Execute</p> <p>Purpose: Guide students through the four-step process with prompts and examples for each step</p> <p>Learning Objective: Students will be able to execute the complete four-step process for inference problems by following the structured workflow.</p> <p>Visual Layout: Vertical flowchart with four main boxes connected by arrows</p> <p>Steps with Hover Content: 1. STATE (Green box)  - Hover: \"Define parameters, state hypotheses (H\u2080 and H\u2090), or specify confidence level\"  - Checklist: Parameter defined? Hypotheses stated? Procedure named?</p> <ol> <li>PLAN (Blue box)</li> <li>Hover: \"Identify procedure and verify conditions\"</li> <li>Sub-boxes: Random, Independent, Normal</li> <li> <p>Checklist for each condition with example language</p> </li> <li> <p>DO (Orange box)</p> </li> <li>Hover: \"Perform calculations with all work shown\"</li> <li>Show formulas for test statistic and p-value</li> <li> <p>Branching paths for different procedure types</p> </li> <li> <p>CONCLUDE (Purple box)</p> </li> <li>Hover: \"State decision in context of the problem\"</li> <li>Decision diamond: Is p-value &lt; \u03b1?</li> <li>Template phrases for each outcome</li> </ol> <p>Interactive Features: - Click each step to expand with detailed guidance - Toggle between \"Hypothesis Test\" and \"Confidence Interval\" modes - Practice mode: Enter values and get feedback on conclusion wording - Highlight which conditions apply to different procedures</p> <p>Color Scheme: Each step has distinct color for easy reference - State: Sylvia Green (#2E7D32) - Plan: Blue (#1976D2) - Do: Orange (#F57C00) - Conclude: Purple (#7B1FA2)</p> <p>Implementation: HTML/CSS/JavaScript with expandable sections</p> <p>Sylvia's Four-Step Reminder</p> <p>\"I remember the four steps with the mnemonic: 'Some People Don't Care'\u2014State, Plan, Do, Conclude. But trust me, AP graders DEFINITELY care if you skip a step! My tail gets all puffy just thinking about losing points for forgetting to check conditions.\"</p>"},{"location":"chapters/19-communication-and-synthesis/#ap-exam-strategies-for-success","title":"AP Exam Strategies for Success","text":"<p>You've learned the content\u2014now let's make sure you can show what you know on exam day. These strategies have helped countless students maximize their scores.</p>"},{"location":"chapters/19-communication-and-synthesis/#general-exam-strategies","title":"General Exam Strategies","text":"<ol> <li> <p>Read carefully: Many mistakes come from misreading the question. Underline key words.</p> </li> <li> <p>Show your work: Partial credit exists! Write down formulas before substituting numbers.</p> </li> <li> <p>Answer in context: Generic answers lose points. Always refer back to the specific scenario.</p> </li> <li> <p>Manage your time: Don't spend too long on any single question. Move on and come back.</p> </li> <li> <p>Use your calculator wisely: Know what outputs mean and how to interpret them.</p> </li> </ol>"},{"location":"chapters/19-communication-and-synthesis/#multiple-choice-tips","title":"Multiple Choice Tips","text":"<ul> <li>Eliminate obviously wrong answers first</li> <li>Watch for answers that are \"close but wrong\" (common student errors)</li> <li>If stuck, look for patterns in the answer choices</li> <li>Never leave a question blank\u2014there's no penalty for guessing</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#free-response-tips","title":"Free Response Tips","text":"<ul> <li>Read all parts of the question before starting</li> <li>Answer what's asked, not what you wish was asked</li> <li>Use complete sentences when interpretation is required</li> <li>Draw graphs when they help your explanation</li> <li>Don't erase work unless you have something better to replace it</li> </ul>"},{"location":"chapters/19-communication-and-synthesis/#common-point-losers-to-avoid","title":"Common Point-Losers to Avoid","text":"Mistake Why It Costs Points How to Avoid Saying \"accept H\u2080\" This is statistically incorrect Always say \"fail to reject H\u2080\" Not checking conditions Can't do inference without them Always include the Plan step Vague conclusions Doesn't show understanding Include specific context Wrong direction of p-value comparison Shows conceptual confusion Remember: reject when p &lt; \u03b1 Forgetting units Shows incomplete interpretation Always include units in context"},{"location":"chapters/19-communication-and-synthesis/#time-management-by-section","title":"Time Management by Section","text":"Section Questions Time Strategy Multiple Choice 40 90 min ~2 min each, mark difficult ones to return Free Response 6 90 min ~13 min each, with 5 min review at end"},{"location":"chapters/19-communication-and-synthesis/#diagram-ap-exam-preparation-checklist","title":"Diagram: AP Exam Preparation Checklist","text":"AP Exam Preparation Checklist <p>Type: infographic</p> <p>Bloom Level: Remember (L1) Bloom Verb: Recall</p> <p>Purpose: Provide an interactive checklist of essential formulas, concepts, and strategies for AP exam preparation</p> <p>Learning Objective: Students will be able to recall the essential elements needed for AP Statistics success by working through an organized checklist.</p> <p>Layout: Categorized accordion-style checklist with progress tracking</p> <p>Categories: 1. Essential Formulas  - Mean, standard deviation  - z-score, t-statistic  - Confidence interval format  - Margin of error formulas</p> <ol> <li>Condition Checks (with mnemonics)</li> <li>Random (how to verify)</li> <li>Independent (10% rule)</li> <li> <p>Normal (np \u2265 10, n(1-p) \u2265 10, n \u2265 30)</p> </li> <li> <p>Key Phrases to Memorize</p> </li> <li>Confidence interval interpretation</li> <li>Hypothesis test conclusion language</li> <li> <p>P-value interpretation</p> </li> <li> <p>Calculator Skills</p> </li> <li>1-PropZTest, 2-PropZTest</li> <li>T-Test, 2-SampTTest</li> <li>LinRegTTest</li> <li> <p>normalcdf, invNorm, tcdf, invT</p> </li> <li> <p>Common Mistakes to Avoid</p> </li> <li>List of frequent errors with correct alternatives</li> </ol> <p>Interactive Features: - Check boxes to track completion - Progress bar showing overall readiness - Click category to expand/collapse - Star items for personal focus areas - Export checklist as PDF for offline study</p> <p>Visual Style: - Clean, organized layout - Color-coded categories matching the four-step process colors - Check mark animations when completing items - Percentage complete displayed prominently</p> <p>Implementation: HTML/CSS/JavaScript with localStorage for progress persistence</p>"},{"location":"chapters/19-communication-and-synthesis/#putting-it-all-together-a-complete-statistical-investigation","title":"Putting It All Together: A Complete Statistical Investigation","text":"<p>Let's walk through a complete example that demonstrates everything we've covered in this chapter\u2014and throughout the entire course.</p> <p>Scenario: A school administrator wants to know if a new attendance policy has reduced tardiness. Before the policy, the school recorded an average of 45 tardies per day. After implementing the policy for one semester, a random sample of 40 days showed a mean of 38.2 tardies with a standard deviation of 12.4.</p>"},{"location":"chapters/19-communication-and-synthesis/#complete-analysis","title":"Complete Analysis","text":"<p>Research Question: Has the new attendance policy reduced the mean number of daily tardies?</p> <p>Exploratory Analysis: - The sample mean (38.2) is lower than the previous average (45) - The difference is 6.8 tardies per day - With SD = 12.4 and n = 40, we have reasonable sample size</p> <p>Four-Step Inference Process:</p> <p>STATE: - H\u2080: \u03bc = 45 (The mean number of daily tardies is still 45) - H\u2090: \u03bc &lt; 45 (The mean number of daily tardies has decreased) - We'll use a one-sample t-test at \u03b1 = 0.05</p> <p>PLAN: - Random: \u2713 Days were randomly sampled - Independent: \u2713 40 days &lt; 10% of all school days (at least 400 in school history) - Normal: \u2713 n = 40 \u2265 30, so CLT applies</p> <p>DO: [ t = \\frac{38.2 - 45}{12.4/\\sqrt{40}} = \\frac{-6.8}{1.96} = -3.47 ]</p> <p>With df = 39, P-value = P(t &lt; -3.47) \u2248 0.0007</p> <p>CONCLUDE: Since p = 0.0007 &lt; 0.05, we reject H\u2080. There is convincing evidence that the new attendance policy has reduced the mean number of daily tardies.</p> <p>Effect Size and Practical Significance:</p> <p>Cohen's d \u2248 6.8/12.4 = 0.55 (medium effect)</p> <p>A reduction of about 7 tardies per day represents roughly a 15% decrease. Given the minimal cost of implementing the policy, this appears to be both statistically and practically significant.</p> <p>Limitations: - This is an observational study (no random assignment), so we cannot definitively claim the policy caused the reduction - Other factors may have changed during the semester (weather, time of year) - Results may not generalize to other schools with different populations</p> <p>Communication: \"After implementing the new attendance policy, the school saw a statistically significant reduction in daily tardies, from an average of 45 to about 38 per day (t = -3.47, p &lt; 0.001). This 15% reduction represents a medium-sized effect and appears practically meaningful for improving school climate.\"</p>"},{"location":"chapters/19-communication-and-synthesis/#chapter-summary","title":"Chapter Summary","text":"<p>Congratulations\u2014you've reached the end of our statistical journey together! Let's squirrel away the key ideas from this final chapter:</p> <p>Key Concepts Covered:</p> <ol> <li> <p>Regression Conclusions require stating your decision, providing evidence, and interpreting in context</p> </li> <li> <p>Statistical vs. Practical Significance are different questions\u2014statistical significance asks \"Is it real?\" while practical significance asks \"Does it matter?\"</p> </li> <li> <p>Effect Size measures how large an effect is, independent of sample size</p> </li> <li> <p>Sample Size affects what you can detect\u2014larger samples can find smaller effects but may flag trivial differences</p> </li> <li> <p>Study Limitations should always be acknowledged honestly\u2014they include design, measurement, and statistical issues</p> </li> <li> <p>Generalizability depends on how data was collected\u2014random samples allow broader generalization</p> </li> <li> <p>Statistical Report Writing should be clear, complete, and tailored to your audience</p> </li> <li> <p>Communicating Results means adjusting your message for who's listening</p> </li> <li> <p>The Four-Step Process (State, Plan, Do, Conclude) is essential for AP exam success</p> </li> <li> <p>AP Exam Strategies include showing your work, answering in context, and managing time wisely</p> </li> </ol> <p>Sylvia's Final Thought</p> <p>\"You did it! You've learned to think statistically\u2014to look at data with curiosity, to question claims with healthy skepticism, and to draw conclusions with appropriate confidence. That's a superpower that will serve you well beyond any exam. Now go forth and crunch those numbers! My tail is tingling with pride. \ud83d\udc3f\ufe0f\"</p>"},{"location":"chapters/19-communication-and-synthesis/#practice-problems","title":"Practice Problems","text":"Problem 1: Statistical vs. Practical Significance <p>A study of 50,000 participants found that people who drink coffee have blood pressure that averages 0.3 mmHg lower than non-coffee drinkers (p &lt; 0.001).</p> <p>a) Is this result statistically significant?</p> <p>b) Is this result practically significant? Explain.</p> <p>Answer: a) Yes, the result is statistically significant (p &lt; 0.001 is less than typical \u03b1 levels).</p> <p>b) This result is NOT practically significant. A difference of 0.3 mmHg is far too small to affect health outcomes or medical decisions. Normal blood pressure fluctuates by much more than this throughout the day. The statistical significance is likely due to the very large sample size detecting a trivially small difference.</p> Problem 2: Four-Step Process <p>A researcher claims that at least 40% of adults exercise regularly. A random sample of 200 adults found that 72 exercise regularly. Test this claim at the 0.05 significance level.</p> <p>Answer:</p> <p>STATE: H\u2080: p = 0.40; H\u2090: p &lt; 0.40; One-proportion z-test</p> <p>PLAN: Random \u2713 (stated); Independent \u2713 (200 &lt; 10% of adults); Normal \u2713 (np\u2080 = 80 \u2265 10, n(1-p\u2080) = 120 \u2265 10)</p> <p>DO: p\u0302 = 72/200 = 0.36; z = (0.36 - 0.40)/\u221a(0.40\u00d70.60/200) = -1.15; P-value = 0.125</p> <p>CONCLUDE: Since p-value (0.125) &gt; \u03b1 (0.05), we fail to reject H\u2080. There is not convincing evidence that less than 40% of adults exercise regularly.</p> Problem 3: Generalizability <p>A study of students at three large state universities found that those who study in groups perform better on exams than those who study alone. Discuss the generalizability of this finding.</p> <p>Answer: The findings may generalize to:</p> <ul> <li>Students at similar large state universities</li> <li>Courses similar to those studied</li> </ul> <p>The findings may NOT generalize to:</p> <ul> <li>Students at small colleges or private universities (different culture)</li> <li>K-12 students or graduate students (different developmental stages)</li> <li>Students in very different fields (e.g., if study was in STEM, may not apply to arts)</li> <li>Online/remote learners (different context)</li> </ul> <p>Additionally, if this was observational, we cannot claim group study causes better performance\u2014students who choose group study may differ in other ways from those who study alone.</p> Problem 4: Writing a Conclusion <p>Write an appropriate conclusion for a 95% confidence interval of (0.52, 0.68) for the proportion of voters who support a new education policy.</p> <p>Answer: \"We are 95% confident that the true proportion of all voters who support the new education policy is between 0.52 and 0.68 (or 52% and 68%). Since this entire interval is above 0.50, we have evidence that a majority of voters support the policy.\"</p>"},{"location":"learning-graph/","title":"Learning Graph for AP Statistics","text":"<p>This section contains the learning graph for this textbook. A learning graph is a graph of concepts used in this textbook. Each concept is represented by a node in a network graph. Concepts are connected by directed edges that indicate what concepts each node depends on before that concept is understood by the student.</p> <p>A learning graph is the foundational data structure for intelligent textbooks that can recommend learning paths. A learning graph is like a roadmap of concepts to help students arrive at their learning goals.</p> <p>At the left of the learning graph are prerequisite or foundational concepts. They have no outbound edges. They only have inbound edges for other concepts that depend on understanding these foundational prerequisite concepts. At the far right we have the most advanced concepts in the course. To master these concepts you must understand all the concepts that they point to.</p> <p>Here are other files used by the learning graph.</p>"},{"location":"learning-graph/#course-description","title":"Course Description","text":"<p>We use the Course Description as the source document for the concepts that are included in this course. The course description uses the 2001 Bloom taxonomy to order learning objectives.</p>"},{"location":"learning-graph/#list-of-concepts","title":"List of Concepts","text":"<p>We use generative AI to convert the course description into a Concept List. Each concept is in the form of a short Title Case label with most labels under 32 characters long.</p>"},{"location":"learning-graph/#concept-dependency-list","title":"Concept Dependency List","text":"<p>We next use generative AI to create a Directed Acyclic Graph (DAG). DAGs do not have cycles where concepts depend on themselves. We provide the DAG in two formats. One is a CSV file and the other format is a JSON file that uses the vis-network JavaScript library format. The vis-network format uses <code>nodes</code>, <code>edges</code> and <code>metadata</code> elements with edges containing <code>from</code> and <code>to</code> properties. This makes it easy for you to view and edit the learning graph using an editor built with the vis-network tools.</p>"},{"location":"learning-graph/#analysis-documentation","title":"Analysis &amp; Documentation","text":""},{"location":"learning-graph/#course-description-quality-assessment","title":"Course Description Quality Assessment","text":"<p>This report rates the overall quality of the course description for the purpose of generating a learning graph.</p> <ul> <li>Course description fields and content depth analysis</li> <li>Validates course description has sufficient depth for generating 300 concepts</li> <li>Compares course description against similar courses</li> <li>Identifies content gaps and strengths</li> <li>Suggests areas of improvement</li> </ul> <p>View the Course Description Quality Assessment</p>"},{"location":"learning-graph/#learning-graph-quality-validation","title":"Learning Graph Quality Validation","text":"<p>This report gives you an overall assessment of the quality of the learning graph. It uses graph algorithms to look for specific quality patterns in the graph.</p> <ul> <li>Graph structure validation - all concepts are connected</li> <li>DAG validation (no cycles detected)</li> <li>Foundational concepts: 2 entry points (Statistics, Random Phenomenon)</li> <li>Indegree distribution analysis</li> <li>Longest dependency chain: 22 steps</li> <li>Connectivity: 100% of nodes connected to the main cluster</li> </ul> <p>View the Learning Graph Quality Validation</p>"},{"location":"learning-graph/#concept-taxonomy","title":"Concept Taxonomy","text":"<p>In order to see patterns in the learning graph, it is useful to assign colors to each concept based on the concept type. We use generative AI to create 14 categories for our concepts and then place each concept into a single primary classifier.</p> <ul> <li>A concept classifier taxonomy with 14 categories</li> <li>Category organization - foundational elements first, communication and capstone concepts last</li> <li>Balanced categories (2% - 23% each)</li> <li>All categories under 30% threshold</li> <li>Pedagogical flow recommendations</li> <li>Clear 3-5 letter abbreviations for use in CSV file</li> </ul> <p>View the Concept Taxonomy</p>"},{"location":"learning-graph/#taxonomy-distribution","title":"Taxonomy Distribution","text":"<p>This report shows how many concepts fit into each category of the taxonomy. Our goal is a somewhat balanced taxonomy where each category holds an appropriate number of concepts. We also don't want any category to contain over 30% of our concepts.</p> <ul> <li>Statistical breakdown</li> <li>Detailed concept listing by category</li> <li>Visual distribution table</li> <li>Balance verification</li> </ul> <p>View the Taxonomy Distribution Report</p>"},{"location":"learning-graph/chapter-content-generation-report/","title":"Chapter Content Generation Report","text":"<p>Generated: 2026-02-06 Skill Version: Chapter Content Generator v0.04 Target Audience: High school students preparing for AP Statistics Reading Level: Senior High (Grades 10-12)</p>"},{"location":"learning-graph/chapter-content-generation-report/#summary","title":"Summary","text":"<p>This report summarizes the chapter content generation sessions for the AP Statistics course. All chapters were generated using the Chapter Content Generator skill with Sylvia the Statistical Squirrel as the narrative anchor.</p>"},{"location":"learning-graph/chapter-content-generation-report/#chapter-generation-details","title":"Chapter Generation Details","text":"Ch Chapter Name Concepts Words Tokens Time Notes 4 Numerical Summaries 18 5,135 ~40,000* 2:48 7 MicroSim specs 5 Standardization and Normal Distributions 18 4,867 ~40,000* 2:53 6 MicroSim specs 6 Scatterplots and Association 9 4,880 24,500 5:29** Parallel batch 1 7 Linear Regression 16 4,959 24,600 5:29** Parallel batch 1 8 Causation and Study Design 9 6,069 56,500 5:29** Parallel batch 1 9 Probability Fundamentals 19 5,591 69,200 8:00** Parallel batch 2 10 Conditional Probability and Independence 5 4,683 55,700 8:00** Parallel batch 2 11 Sampling and Bias 19 4,800 24,500 8:00** Parallel batch 2 12 Experimental Design 18 5,858 45,500 3:44 7 diagram/MicroSim specs 13 Random Variables 23 5,636 38,500 3:06 BINS mnemonic included 14 Sampling Distributions 17 5,408 42,500 2:57 5 MicroSim specs 15 Confidence Intervals 16 6,109 47,500 3:30 6 MicroSim specs, 11 tables 16 Hypothesis Testing 22 8,484 55,000 4:30 Extended length for 22 concepts 17 Inference for Means 18 7,028 25,000 3:56 6 MicroSim specs 18 Chi-Square and Regression Inference 22 6,062 45,500 3:23 Chi-square + regression 19 Communication and Synthesis 10 6,356 45,000 3:36 AP exam strategies <p>* Estimated - token usage not recorded in original log</p> <p>** Batch time - parallel chapters recorded total batch elapsed time, not individual chapter time</p>"},{"location":"learning-graph/chapter-content-generation-report/#totals","title":"Totals","text":"Metric Total Chapters Generated 16 Concepts Covered 259 Total Words 91,925 Total Tokens ~679,500 Total Wall-Clock Time ~48 minutes*** <p>*** Sequential chapters: ~35 min; Parallel batch 1 (Ch 6-8): ~5.5 min; Parallel batch 2 (Ch 9-11): ~8 min</p>"},{"location":"learning-graph/chapter-content-generation-report/#token-prediction-analysis","title":"Token Prediction Analysis","text":"<p>Can we predict token usage based on chapter characteristics? This interactive analysis compares three potential predictors.</p>"},{"location":"learning-graph/chapter-content-generation-report/#regression-comparison","title":"Regression Comparison","text":"Predictor Formula R\u00b2 Concepts Tokens = 331 \u00d7 Concepts + 37.4k 1.6% Words Tokens = 1.1 \u00d7 Words + 36.6k 0.3% MicroSims Tokens = -4.4k \u00d7 MicroSims + 67.7k 5.6%"},{"location":"learning-graph/chapter-content-generation-report/#key-finding","title":"Key Finding","text":"<p>None of these variables are good predictors of token usage.</p> <p>Even the best predictor (MicroSims) explains only 5.6% of the variance. Interestingly, the MicroSims relationship is negative - chapters with more MicroSim specifications actually used fewer tokens on average.</p>"},{"location":"learning-graph/chapter-content-generation-report/#what-actually-drives-token-usage","title":"What Actually Drives Token Usage?","text":"<p>The analysis suggests token consumption is driven by factors not captured in these metrics:</p> <ul> <li>Context loading overhead - Fixed cost regardless of chapter size</li> <li>Agent reasoning complexity - Some topics require more \"thinking\"</li> <li>Execution mode - Parallel vs sequential agent behavior differs</li> <li>Example generation - Worked examples vary in complexity</li> </ul>"},{"location":"learning-graph/chapter-content-generation-report/#concept-coverage","title":"Concept Coverage","text":"<p>All chapters achieved 100% concept coverage from their respective learning graph sections.</p> Coverage Chapters 100% All 16 chapters"},{"location":"learning-graph/chapter-content-generation-report/#content-elements-summary","title":"Content Elements Summary","text":"<p>Based on log file data, typical chapter content includes:</p> <ul> <li>Markdown Tables: 8-18 per chapter</li> <li>Markdown Lists: 15-25 per chapter</li> <li>MicroSim Specifications: 4-7 per chapter</li> <li>LaTeX Equations: 15-50 per chapter</li> <li>Admonitions: 4-8 per chapter</li> <li>Practice Problems: 3-7 per chapter</li> </ul>"},{"location":"learning-graph/chapter-content-generation-report/#execution-modes","title":"Execution Modes","text":"Mode Chapters Sequential (single chapter) 4, 5, 12, 13, 14, 15, 16, 17, 18, 19 Parallel (3 chapters) 6-7-8, 9-10-11"},{"location":"learning-graph/chapter-content-generation-report/#notes","title":"Notes","text":"<ol> <li> <p>Chapters 1-3: No generation logs found - these chapters may have been created manually or through a different process.</p> </li> <li> <p>Token Estimates: Chapters 4 and 5 did not include token usage in their logs; estimates (~40,000 each) are based on comparable chapters.</p> </li> <li> <p>LaTeX Formatting: All chapters use backslash delimiters (<code>\\(</code> <code>\\)</code> for inline, <code>\\[</code> <code>\\]</code> for display) as required by project conventions.</p> </li> <li> <p>Sylvia Integration: All chapters include Sylvia the Statistical Squirrel with signature phrases and encouraging tone.</p> </li> <li> <p>MicroSim Specifications: Chapters include detailed specifications for interactive visualizations that require implementation using the microsim-generator skill.</p> </li> </ol> <p>Report generated from session logs in <code>/logs/ch-*.md</code></p>"},{"location":"learning-graph/concept-list/","title":"AP Statistics Concept List","text":"<p>This document contains 300 concepts for the AP Statistics learning graph.</p>"},{"location":"learning-graph/concept-list/#concepts-1-300","title":"Concepts (1-300)","text":"<ol> <li>Statistics</li> <li>Data</li> <li>Variable</li> <li>Observation</li> <li>Dataset</li> <li>Categorical Variable</li> <li>Quantitative Variable</li> <li>Discrete Variable</li> <li>Continuous Variable</li> <li>Population</li> <li>Sample</li> <li>Parameter</li> <li>Statistic</li> <li>Distribution</li> <li>Frequency Table</li> <li>Relative Frequency</li> <li>Cumulative Frequency</li> <li>Bar Graph</li> <li>Pie Chart</li> <li>Dotplot</li> <li>Stemplot</li> <li>Histogram</li> <li>Choosing Bin Width</li> <li>Shape of Distribution</li> <li>Symmetric Distribution</li> <li>Skewed Left</li> <li>Skewed Right</li> <li>Unimodal Distribution</li> <li>Bimodal Distribution</li> <li>Uniform Distribution</li> <li>Outlier</li> <li>Identifying Outliers</li> <li>Center of Distribution</li> <li>Spread of Distribution</li> <li>Mean</li> <li>Median</li> <li>Mode</li> <li>Resistant Measure</li> <li>Comparing Mean and Median</li> <li>Range</li> <li>Interquartile Range</li> <li>Quartiles</li> <li>Five-Number Summary</li> <li>Boxplot</li> <li>Modified Boxplot</li> <li>Comparing Distributions</li> <li>Standard Deviation</li> <li>Variance</li> <li>Calculating Variance</li> <li>Percentile</li> <li>Z-Score</li> <li>Calculating Z-Scores</li> <li>Interpreting Z-Scores</li> <li>Standardization</li> <li>Comparing with Z-Scores</li> <li>Normal Distribution</li> <li>Parameters of Normal</li> <li>Empirical Rule</li> <li>68-95-99.7 Rule</li> <li>Standard Normal Curve</li> <li>Normal Table</li> <li>Finding Normal Probs</li> <li>Inverse Normal Calcs</li> <li>Normal Probability Plot</li> <li>Assessing Normality</li> <li>Density Curve</li> <li>Area Under Curve</li> <li>Technology for Normal</li> <li>Two-Way Table</li> <li>Marginal Distribution</li> <li>Conditional Distribution</li> <li>Calculating Conditionals</li> <li>Association</li> <li>Simpson's Paradox</li> <li>Scatterplot</li> <li>Describing Scatterplots</li> <li>Explanatory Variable</li> <li>Response Variable</li> <li>Direction of Association</li> <li>Positive Association</li> <li>Negative Association</li> <li>Form of Association</li> <li>Linear Form</li> <li>Nonlinear Form</li> <li>Strength of Association</li> <li>Correlation Coefficient</li> <li>Calculating Correlation</li> <li>Properties of Correlation</li> <li>Correlation Limitations</li> <li>Least Squares Regression</li> <li>Regression Line</li> <li>Regression Equation</li> <li>Slope Interpretation</li> <li>Y-Intercept Interpretation</li> <li>Making Predictions</li> <li>Extrapolation Dangers</li> <li>Residual</li> <li>Calculating Residuals</li> <li>Residual Plot</li> <li>Interpreting Residuals</li> <li>Coefficient of Determination</li> <li>R-Squared Interpretation</li> <li>Influential Point</li> <li>Leverage</li> <li>Outliers in Regression</li> <li>Lurking Variable</li> <li>Causation</li> <li>Correlation vs Causation</li> <li>Observational Study</li> <li>Experiment</li> <li>Comparing Studies</li> <li>Experimental Units</li> <li>Subjects</li> <li>Treatment</li> <li>Factor</li> <li>Levels of a Factor</li> <li>Placebo</li> <li>Placebo Effect</li> <li>Control Group</li> <li>Comparison in Experiments</li> <li>Blinding</li> <li>Single-Blind Experiment</li> <li>Double-Blind Experiment</li> <li>Random Assignment</li> <li>Why Randomize</li> <li>Randomized Block Design</li> <li>Matched Pairs Design</li> <li>Completely Randomized Design</li> <li>Replication</li> <li>Confounding Variable</li> <li>Identifying Confounding</li> <li>Bias</li> <li>Sources of Bias</li> <li>Census</li> <li>Simple Random Sample</li> <li>Random Number Generator</li> <li>Stratified Random Sample</li> <li>When to Stratify</li> <li>Cluster Sample</li> <li>Systematic Sample</li> <li>Convenience Sample</li> <li>Voluntary Response Sample</li> <li>Undercoverage</li> <li>Nonresponse Bias</li> <li>Response Bias</li> <li>Wording of Questions</li> <li>Designing Surveys</li> <li>Random Phenomenon</li> <li>Probability</li> <li>Probability Rules</li> <li>Sample Space</li> <li>Event</li> <li>Complement of Event</li> <li>Mutually Exclusive Events</li> <li>Disjoint Events</li> <li>Independent Events</li> <li>Dependent Events</li> <li>Addition Rule</li> <li>General Addition Rule</li> <li>Multiplication Rule</li> <li>General Multiplication Rule</li> <li>Conditional Probability</li> <li>Calculating Conditionals</li> <li>Bayes Intuition</li> <li>Tree Diagram</li> <li>Using Tree Diagrams</li> <li>Venn Diagram</li> <li>Using Venn Diagrams</li> <li>Simulation</li> <li>Designing Simulations</li> <li>Random Digit Table</li> <li>Law of Large Numbers</li> <li>Random Variable</li> <li>Discrete Random Variable</li> <li>Probability Distribution</li> <li>Valid Distribution</li> <li>Expected Value</li> <li>Calculating Expected Value</li> <li>Variance of Random Variable</li> <li>Standard Deviation of RV</li> <li>Linear Transformation</li> <li>Combining Random Variables</li> <li>Sum of Random Variables</li> <li>Difference of RVs</li> <li>Binomial Setting</li> <li>Binomial Conditions</li> <li>Binomial Distribution</li> <li>Binomial Probability</li> <li>Binomial Formula</li> <li>Binomial Mean</li> <li>Binomial Standard Dev</li> <li>Geometric Setting</li> <li>Geometric Distribution</li> <li>Geometric Probability</li> <li>Geometric Mean</li> <li>Sampling Variability</li> <li>Sampling Distribution</li> <li>Unbiased Estimator</li> <li>Biased Estimator</li> <li>Sample Proportion</li> <li>Sampling Dist of Proportion</li> <li>Mean of Sample Proportion</li> <li>SD of Sample Proportion</li> <li>Conditions for Proportion SD</li> <li>Sample Mean</li> <li>Sampling Dist of Mean</li> <li>Mean of Sample Mean</li> <li>SD of Sample Mean</li> <li>Central Limit Theorem</li> <li>CLT Conditions</li> <li>Normal Approximation</li> <li>Statistical Inference</li> <li>Point Estimate</li> <li>Interval Estimate</li> <li>Confidence Interval</li> <li>Margin of Error</li> <li>Confidence Level</li> <li>Interpreting Confidence</li> <li>Critical Value</li> <li>Z Critical Values</li> <li>Standard Error</li> <li>CI for One Proportion</li> <li>Conditions for CI Proportion</li> <li>Interpreting CI</li> <li>CI Width Factors</li> <li>Sample Size for CI</li> <li>CI for Difference in Props</li> <li>Pooled Proportion</li> <li>Hypothesis Test</li> <li>Null Hypothesis</li> <li>Alternative Hypothesis</li> <li>Writing Hypotheses</li> <li>One-Sided Test</li> <li>Two-Sided Test</li> <li>Test Statistic</li> <li>P-Value</li> <li>Calculating P-Values</li> <li>Interpreting P-Values</li> <li>Significance Level</li> <li>Choosing Alpha</li> <li>Statistical Significance</li> <li>Making Conclusions</li> <li>Type I Error</li> <li>Type II Error</li> <li>Error Tradeoffs</li> <li>Power of a Test</li> <li>Factors Affecting Power</li> <li>Test for One Proportion</li> <li>Conditions for Z-Test</li> <li>Test for Two Proportions</li> <li>T-Distribution</li> <li>T vs Z Distribution</li> <li>Degrees of Freedom</li> <li>T Critical Values</li> <li>One-Sample T-Interval</li> <li>Conditions for T-Procedures</li> <li>One-Sample T-Test</li> <li>Two-Sample T-Interval</li> <li>Two-Sample T-Test</li> <li>Pooled vs Unpooled</li> <li>Paired T-Test</li> <li>Paired Data</li> <li>When to Pair</li> <li>Robustness</li> <li>Chi-Square Distribution</li> <li>Chi-Square Statistic</li> <li>Goodness-of-Fit Test</li> <li>GOF Hypotheses</li> <li>Expected Counts</li> <li>Observed Counts</li> <li>Calculating Chi-Square</li> <li>Conditions for Chi-Square</li> <li>GOF Conclusion</li> <li>Test for Homogeneity</li> <li>Homogeneity Setup</li> <li>Test for Independence</li> <li>Independence Setup</li> <li>Chi-Square Conclusion</li> <li>Inference for Slope</li> <li>Regression Model</li> <li>Slope Parameter</li> <li>T-Interval for Slope</li> <li>T-Test for Slope</li> <li>Standard Error of Slope</li> <li>Conditions for Regression</li> <li>Linearity Condition</li> <li>Independence Condition</li> <li>Normality of Residuals</li> <li>Equal Variance Condition</li> <li>Regression Conclusion</li> <li>Practical Significance</li> <li>Stat vs Practical Sig</li> <li>Effect Size</li> <li>Sample Size Impact</li> <li>Study Limitations</li> <li>Generalizability</li> <li>Statistical Report Writing</li> <li>Communicating Results</li> <li>Four-Step Process</li> <li>AP Exam Strategies</li> </ol>"},{"location":"learning-graph/concept-taxonomy/","title":"Concept Taxonomy","text":"<p>This document defines the categorical taxonomy for organizing the 300 AP Statistics concepts.</p>"},{"location":"learning-graph/concept-taxonomy/#taxonomy-categories","title":"Taxonomy Categories","text":"TaxonomyID Category Name Description FOUND Foundations Core statistical terminology, data types, and fundamental concepts that underpin all other learning EDA1 Univariate Analysis Concepts related to exploring, summarizing, and visualizing single-variable data EDA2 Bivariate Analysis Concepts for exploring relationships between two variables including scatterplots and correlation REG Regression Linear regression concepts including least squares, residuals, and model interpretation STUDY Study Design Concepts for designing studies, experiments, sampling methods, and understanding bias PROB Probability Probability rules, events, conditional probability, and probability models RAND Random Variables Discrete random variables, expected value, and named distributions (binomial, geometric) SAMP Sampling Distributions Sampling variability, sampling distributions, and the Central Limit Theorem CIPR CI for Proportions Confidence intervals for one and two proportions HTPR HT for Proportions Hypothesis testing concepts and tests for proportions TMEA T-Procedures for Means T-distribution, confidence intervals, and hypothesis tests for means CHISQ Chi-Square Tests Chi-square distribution and tests for categorical data REGF Regression Inference Inference for regression slopes and model conditions COMM Communication Statistical report writing, interpreting results, and exam strategies"},{"location":"learning-graph/concept-taxonomy/#category-descriptions","title":"Category Descriptions","text":""},{"location":"learning-graph/concept-taxonomy/#found-foundations","title":"FOUND - Foundations","text":"<p>Core building blocks including: statistics, data, variables (categorical, quantitative, discrete, continuous), population, sample, parameter, statistic. These concepts have few or no dependencies.</p>"},{"location":"learning-graph/concept-taxonomy/#eda1-univariate-analysis","title":"EDA1 - Univariate Analysis","text":"<p>Exploratory data analysis for single variables: distributions, graphical displays (histograms, boxplots, stemplots), measures of center (mean, median, mode), measures of spread (range, IQR, standard deviation), shape descriptions, outliers, normal distributions, z-scores.</p>"},{"location":"learning-graph/concept-taxonomy/#eda2-bivariate-analysis","title":"EDA2 - Bivariate Analysis","text":"<p>Two-variable relationships: two-way tables, marginal and conditional distributions, scatterplots, direction/form/strength of association, correlation coefficient.</p>"},{"location":"learning-graph/concept-taxonomy/#reg-regression","title":"REG - Regression","text":"<p>Linear modeling: least squares regression, regression equation, slope and intercept interpretation, residuals, residual plots, coefficient of determination (R\u00b2), influential points, extrapolation dangers.</p>"},{"location":"learning-graph/concept-taxonomy/#study-study-design","title":"STUDY - Study Design","text":"<p>Data collection methods: observational studies vs experiments, treatments, random assignment, experimental designs (completely randomized, randomized block, matched pairs), blinding, confounding, sampling methods (SRS, stratified, cluster, systematic), bias types.</p>"},{"location":"learning-graph/concept-taxonomy/#prob-probability","title":"PROB - Probability","text":"<p>Probability foundations: sample space, events, probability rules (addition, multiplication), conditional probability, independence, tree diagrams, Venn diagrams, simulation, Law of Large Numbers.</p>"},{"location":"learning-graph/concept-taxonomy/#rand-random-variables","title":"RAND - Random Variables","text":"<p>Random variable theory: discrete random variables, probability distributions, expected value, variance, combining random variables, binomial distribution, geometric distribution.</p>"},{"location":"learning-graph/concept-taxonomy/#samp-sampling-distributions","title":"SAMP - Sampling Distributions","text":"<p>Sampling theory: sampling variability, sampling distributions of proportions and means, unbiased estimators, Central Limit Theorem, normal approximation.</p>"},{"location":"learning-graph/concept-taxonomy/#cipr-ci-for-proportions","title":"CIPR - CI for Proportions","text":"<p>Inference for proportions (confidence intervals): point estimates, margin of error, confidence level, critical values, standard error, conditions, interpretation, sample size determination.</p>"},{"location":"learning-graph/concept-taxonomy/#htpr-ht-for-proportions","title":"HTPR - HT for Proportions","text":"<p>Hypothesis testing fundamentals: null and alternative hypotheses, test statistics, p-values, significance level, Type I and II errors, power, tests for one and two proportions.</p>"},{"location":"learning-graph/concept-taxonomy/#tmea-t-procedures-for-means","title":"TMEA - T-Procedures for Means","text":"<p>T-distribution based inference: degrees of freedom, one-sample and two-sample t-intervals, one-sample and two-sample t-tests, paired t-procedures, robustness.</p>"},{"location":"learning-graph/concept-taxonomy/#chisq-chi-square-tests","title":"CHISQ - Chi-Square Tests","text":"<p>Categorical data inference: chi-square distribution, chi-square statistic, expected and observed counts, goodness-of-fit test, test for homogeneity, test for independence.</p>"},{"location":"learning-graph/concept-taxonomy/#regf-regression-inference","title":"REGF - Regression Inference","text":"<p>Inference for regression: t-interval and t-test for slope, standard error of slope, conditions for regression inference (LINE), interpreting regression output.</p>"},{"location":"learning-graph/concept-taxonomy/#comm-communication","title":"COMM - Communication","text":"<p>Statistical communication: practical vs statistical significance, effect size, study limitations, generalizability, report writing, four-step inference process, AP exam strategies.</p>"},{"location":"learning-graph/course-description-assessment/","title":"Course Description Quality Assessment","text":"<p>Date: 2026-02-06 Course: AP Statistics Quality Score: 100/100</p>"},{"location":"learning-graph/course-description-assessment/#summary","title":"Summary","text":"<p>The AP Statistics course description is excellent and fully meets all requirements for generating a comprehensive learning graph with 200+ concepts.</p>"},{"location":"learning-graph/course-description-assessment/#scoring-breakdown","title":"Scoring Breakdown","text":"Element Points Assessment Title 5/5 \"AP Statistics\" - clear and descriptive Target Audience 5/5 High-school students preparing for AP exam, with relevant fields of interest listed Prerequisites 5/5 Algebra I and II, graphing skills, numerical reasoning - clearly stated; explicitly notes calculus is NOT required Main Topics Covered 10/10 9 comprehensive units with detailed subtopics covering the full AP Statistics curriculum Topics Excluded 5/5 Clear \"Concepts NOT Covered\" section listing 9 exclusions (Bayesian inference, time series, etc.) Learning Outcomes Header 5/5 Properly structured with \"Learning Objectives Sorted by the Six Levels of the 2001 Bloom Taxonomy\" Remember Level 10/10 4 specific, actionable outcomes (recall definitions, identify variable types, recognize symbols, recall formulas) Understand Level 10/10 4 specific outcomes (explain distributions, interpret graphs, describe sampling purpose, explain confidence intervals) Apply Level 10/10 5 specific outcomes (construct graphs, calculate probabilities, perform CI calculations, conduct hypothesis tests, use technology) Analyze Level 10/10 5 specific outcomes (compare distributions, distinguish correlation/causation, evaluate study design, analyze residuals, check assumptions) Evaluate Level 10/10 5 specific outcomes (assess methods, critique conclusions, judge evidence strength, evaluate limitations, interpret practical significance) Create Level 10/10 5 specific outcomes including capstone ideas (design studies, develop arguments, write reports, communicate findings, propose improvements) Descriptive Context 5/5 Excellent overview emphasizing statistical thinking, real-world data, and conceptual understanding <p>Total: 100/100</p>"},{"location":"learning-graph/course-description-assessment/#strengths","title":"Strengths","text":"<ol> <li>Complete Bloom's Taxonomy Coverage: All six cognitive levels are represented with 3-5 specific outcomes each</li> <li>Clear Scope Definition: Both included and excluded topics are explicitly listed</li> <li>Well-Structured Units: 9 units align with the College Board AP Statistics framework</li> <li>Real-World Emphasis: Consistent focus on data-driven reasoning and practical applications</li> <li>Appropriate Prerequisites: Clearly states what students need (and don't need - calculus)</li> </ol>"},{"location":"learning-graph/course-description-assessment/#estimated-concept-count","title":"Estimated Concept Count","text":"<p>Based on this course description, I estimate we can generate 200+ distinct concepts covering:</p> <ul> <li>~25 foundational concepts (variables, data types, basic terminology)</li> <li>~35 exploratory data analysis concepts (graphs, summaries, distributions)</li> <li>~25 study design and data collection concepts</li> <li>~30 probability and random variable concepts</li> <li>~25 sampling distribution concepts</li> <li>~40 inference concepts (confidence intervals, hypothesis tests, chi-square, regression)</li> <li>~20 interpretation and communication concepts</li> </ul>"},{"location":"learning-graph/course-description-assessment/#comparison-with-similar-courses","title":"Comparison with Similar Courses","text":"<p>This course description is above average compared to typical AP Statistics course descriptions:</p> <ul> <li>Most AP Statistics syllabi have 5-7 units; this has 9 well-defined units</li> <li>Learning outcomes are often vague; these are specific and measurable</li> <li>Exclusions are rarely documented; this clearly defines scope boundaries</li> </ul>"},{"location":"learning-graph/course-description-assessment/#recommendation","title":"Recommendation","text":"<p>Proceed with learning graph generation. This course description provides an excellent foundation for creating a comprehensive, pedagogically sound learning graph.</p>"},{"location":"learning-graph/quality-metrics/","title":"Learning Graph Quality Metrics Report","text":""},{"location":"learning-graph/quality-metrics/#overview","title":"Overview","text":"<ul> <li>Total Concepts: 300</li> <li>Foundational Concepts (no dependencies): 2</li> <li>Concepts with Dependencies: 298</li> <li>Average Dependencies per Concept: 1.69</li> </ul>"},{"location":"learning-graph/quality-metrics/#graph-structure-validation","title":"Graph Structure Validation","text":"<ul> <li>Valid DAG Structure: \u274c No</li> <li>Self-Dependencies: None detected \u2705</li> <li>Cycles Detected: 0</li> </ul>"},{"location":"learning-graph/quality-metrics/#foundational-concepts","title":"Foundational Concepts","text":"<p>These concepts have no prerequisites:</p> <ul> <li>1: Statistics</li> <li>148: Random Phenomenon</li> </ul>"},{"location":"learning-graph/quality-metrics/#dependency-chain-analysis","title":"Dependency Chain Analysis","text":"<ul> <li>Maximum Dependency Chain Length: 22</li> </ul>"},{"location":"learning-graph/quality-metrics/#longest-learning-path","title":"Longest Learning Path:","text":"<ol> <li>Statistics (ID: 1)</li> <li>Data (ID: 2)</li> <li>Variable (ID: 3)</li> <li>Distribution (ID: 14)</li> <li>Center of Distribution (ID: 33)</li> <li>Mean (ID: 35)</li> <li>Standard Deviation (ID: 47)</li> <li>Variance (ID: 48)</li> <li>Variance of Random Variable (ID: 179)</li> <li>Standard Deviation of RV (ID: 180)</li> <li>SD of Sample Proportion (ID: 203)</li> <li>Standard Error (ID: 221)</li> <li>Margin of Error (ID: 216)</li> <li>Confidence Interval (ID: 215)</li> <li>Confidence Level (ID: 217)</li> <li>Critical Value (ID: 219)</li> <li>Z Critical Values (ID: 220)</li> <li>CI for One Proportion (ID: 222)</li> <li>Interpreting CI (ID: 224)</li> <li>Communicating Results (ID: 298)</li> <li>Four-Step Process (ID: 299)</li> <li>AP Exam Strategies (ID: 300)</li> </ol>"},{"location":"learning-graph/quality-metrics/#orphaned-nodes-analysis","title":"Orphaned Nodes Analysis","text":"<ul> <li>Total Orphaned Nodes: 108</li> </ul> <p>Concepts that are not prerequisites for any other concept:</p> <ul> <li>5: Dataset</li> <li>9: Continuous Variable</li> <li>17: Cumulative Frequency</li> <li>18: Bar Graph</li> <li>19: Pie Chart</li> <li>20: Dotplot</li> <li>21: Stemplot</li> <li>23: Choosing Bin Width</li> <li>26: Skewed Left</li> <li>27: Skewed Right</li> <li>28: Unimodal Distribution</li> <li>29: Bimodal Distribution</li> <li>30: Uniform Distribution</li> <li>37: Mode</li> <li>38: Resistant Measure</li> <li>39: Comparing Mean and Median</li> <li>45: Modified Boxplot</li> <li>46: Comparing Distributions</li> <li>49: Calculating Variance</li> <li>55: Comparing with Z-Scores</li> </ul> <p>...and 88 more</p>"},{"location":"learning-graph/quality-metrics/#connected-components","title":"Connected Components","text":"<ul> <li>Number of Connected Components: 1</li> </ul> <p>\u2705 All concepts are connected in a single graph.</p>"},{"location":"learning-graph/quality-metrics/#indegree-analysis","title":"Indegree Analysis","text":"<p>Top 10 concepts that are prerequisites for the most other concepts:</p> Rank Concept ID Concept Label Indegree 1 11 Sample 11 2 14 Distribution 10 3 24 Shape of Distribution 9 4 132 Bias 9 5 7 Quantitative Variable 8 6 35 Mean 8 7 56 Normal Distribution 7 8 110 Experiment 7 9 175 Probability Distribution 7 10 229 Hypothesis Test 7"},{"location":"learning-graph/quality-metrics/#outdegree-distribution","title":"Outdegree Distribution","text":"Dependencies Number of Concepts 0 2 1 129 2 140 3 22 4 6 5 1"},{"location":"learning-graph/quality-metrics/#recommendations","title":"Recommendations","text":"<ul> <li>\u26a0\ufe0f Many orphaned nodes (108): Consider if these should be prerequisites for advanced concepts</li> <li>\u2139\ufe0f Long dependency chains (22): Ensure students can follow extended learning paths</li> </ul> <p>Report generated by learning-graph-reports/analyze_graph.py</p>"},{"location":"learning-graph/taxonomy-distribution/","title":"Taxonomy Distribution Report","text":""},{"location":"learning-graph/taxonomy-distribution/#overview","title":"Overview","text":"<ul> <li>Total Concepts: 300</li> <li>Number of Taxonomies: 14</li> <li>Average Concepts per Taxonomy: 21.4</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#distribution-summary","title":"Distribution Summary","text":"Category TaxonomyID Count Percentage Status Univariate Analysis EDA1 68 22.7% \u2705 Foundations FOUND 51 17.0% \u2705 Study Design STUDY 35 11.7% \u2705 Regression REG 30 10.0% \u2705 Probability PROB 24 8.0% \u2705 HT for Proportions HTPR 20 6.7% \u2705 CI for Proportions CIPR 17 5.7% \u2705 Bivariate Analysis EDA2 11 3.7% \u2705 Chi-Square Tests CHISQ 11 3.7% \u2705 Random Variables RAND 9 3.0% \u2705 Sampling Distributions SAMP 7 2.3% \u2139\ufe0f Under Communication COMM 7 2.3% \u2139\ufe0f Under T-Procedures for Means TMEA 6 2.0% \u2139\ufe0f Under Regression Inference REGF 4 1.3% \u2139\ufe0f Under"},{"location":"learning-graph/taxonomy-distribution/#visual-distribution","title":"Visual Distribution","text":"<pre><code>EDA1   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  68 ( 22.7%)\nFOUND  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  51 ( 17.0%)\nSTUDY  \u2588\u2588\u2588\u2588\u2588  35 ( 11.7%)\nREG    \u2588\u2588\u2588\u2588\u2588  30 ( 10.0%)\nPROB   \u2588\u2588\u2588\u2588  24 (  8.0%)\nHTPR   \u2588\u2588\u2588  20 (  6.7%)\nCIPR   \u2588\u2588  17 (  5.7%)\nEDA2   \u2588  11 (  3.7%)\nCHISQ  \u2588  11 (  3.7%)\nRAND   \u2588   9 (  3.0%)\nSAMP   \u2588   7 (  2.3%)\nCOMM   \u2588   7 (  2.3%)\nTMEA   \u2588   6 (  2.0%)\nREGF      4 (  1.3%)\n</code></pre>"},{"location":"learning-graph/taxonomy-distribution/#balance-analysis","title":"Balance Analysis","text":""},{"location":"learning-graph/taxonomy-distribution/#no-over-represented-categories","title":"\u2705 No Over-Represented Categories","text":"<p>All categories are under the 30% threshold. Good balance!</p>"},{"location":"learning-graph/taxonomy-distribution/#i-under-represented-categories-3","title":"\u2139\ufe0f Under-Represented Categories (&lt;3%)","text":"<ul> <li>Sampling Distributions (SAMP): 7 concepts (2.3%)</li> <li>Note: Small categories are acceptable for specialized topics</li> <li>Communication (COMM): 7 concepts (2.3%)</li> <li>Note: Small categories are acceptable for specialized topics</li> <li>T-Procedures for Means (TMEA): 6 concepts (2.0%)</li> <li>Note: Small categories are acceptable for specialized topics</li> <li>Regression Inference (REGF): 4 concepts (1.3%)</li> <li>Note: Small categories are acceptable for specialized topics</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#category-details","title":"Category Details","text":""},{"location":"learning-graph/taxonomy-distribution/#univariate-analysis-eda1","title":"Univariate Analysis (EDA1)","text":"<p>Count: 68 concepts (22.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Frequency Table</li> </ol> </li> <li> <ol> <li>Relative Frequency</li> </ol> </li> <li> <ol> <li>Cumulative Frequency</li> </ol> </li> <li> <ol> <li>Bar Graph</li> </ol> </li> <li> <ol> <li>Pie Chart</li> </ol> </li> <li> <ol> <li>Dotplot</li> </ol> </li> <li> <ol> <li>Stemplot</li> </ol> </li> <li> <ol> <li>Histogram</li> </ol> </li> <li> <ol> <li>Choosing Bin Width</li> </ol> </li> <li> <ol> <li>Shape of Distribution</li> </ol> </li> <li> <ol> <li>Symmetric Distribution</li> </ol> </li> <li> <ol> <li>Skewed Left</li> </ol> </li> <li> <ol> <li>Skewed Right</li> </ol> </li> <li> <ol> <li>Unimodal Distribution</li> </ol> </li> <li> <ol> <li>Bimodal Distribution</li> </ol> </li> <li>...and 53 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#foundations-found","title":"Foundations (FOUND)","text":"<p>Count: 51 concepts (17.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Statistics</li> </ol> </li> <li> <ol> <li>Data</li> </ol> </li> <li> <ol> <li>Variable</li> </ol> </li> <li> <ol> <li>Observation</li> </ol> </li> <li> <ol> <li>Dataset</li> </ol> </li> <li> <ol> <li>Categorical Variable</li> </ol> </li> <li> <ol> <li>Quantitative Variable</li> </ol> </li> <li> <ol> <li>Discrete Variable</li> </ol> </li> <li> <ol> <li>Continuous Variable</li> </ol> </li> <li> <ol> <li>Population</li> </ol> </li> <li> <ol> <li>Sample</li> </ol> </li> <li> <ol> <li>Parameter</li> </ol> </li> <li> <ol> <li>Statistic</li> </ol> </li> <li> <ol> <li>Distribution</li> </ol> </li> <li> <ol> <li>Parameters of Normal</li> </ol> </li> <li>...and 36 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#study-design-study","title":"Study Design (STUDY)","text":"<p>Count: 35 concepts (11.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Experiment</li> </ol> </li> <li> <ol> <li>Comparing Studies</li> </ol> </li> <li> <ol> <li>Experimental Units</li> </ol> </li> <li> <ol> <li>Subjects</li> </ol> </li> <li> <ol> <li>Treatment</li> </ol> </li> <li> <ol> <li>Factor</li> </ol> </li> <li> <ol> <li>Levels of a Factor</li> </ol> </li> <li> <ol> <li>Placebo</li> </ol> </li> <li> <ol> <li>Placebo Effect</li> </ol> </li> <li> <ol> <li>Control Group</li> </ol> </li> <li> <ol> <li>Comparison in Experiments</li> </ol> </li> <li> <ol> <li>Blinding</li> </ol> </li> <li> <ol> <li>Single-Blind Experiment</li> </ol> </li> <li> <ol> <li>Double-Blind Experiment</li> </ol> </li> <li> <ol> <li>Random Assignment</li> </ol> </li> <li>...and 20 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#regression-reg","title":"Regression (REG)","text":"<p>Count: 30 concepts (10.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Scatterplot</li> </ol> </li> <li> <ol> <li>Describing Scatterplots</li> </ol> </li> <li> <ol> <li>Linear Form</li> </ol> </li> <li> <ol> <li>Nonlinear Form</li> </ol> </li> <li> <ol> <li>Correlation Coefficient</li> </ol> </li> <li> <ol> <li>Calculating Correlation</li> </ol> </li> <li> <ol> <li>Properties of Correlation</li> </ol> </li> <li> <ol> <li>Correlation Limitations</li> </ol> </li> <li> <ol> <li>Least Squares Regression</li> </ol> </li> <li> <ol> <li>Regression Line</li> </ol> </li> <li> <ol> <li>Regression Equation</li> </ol> </li> <li> <ol> <li>Slope Interpretation</li> </ol> </li> <li> <ol> <li>Y-Intercept Interpretation</li> </ol> </li> <li> <ol> <li>Making Predictions</li> </ol> </li> <li> <ol> <li>Extrapolation Dangers</li> </ol> </li> <li>...and 15 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#probability-prob","title":"Probability (PROB)","text":"<p>Count: 24 concepts (8.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Random Phenomenon</li> </ol> </li> <li> <ol> <li>Probability</li> </ol> </li> <li> <ol> <li>Probability Rules</li> </ol> </li> <li> <ol> <li>Event</li> </ol> </li> <li> <ol> <li>Complement of Event</li> </ol> </li> <li> <ol> <li>Mutually Exclusive Events</li> </ol> </li> <li> <ol> <li>Disjoint Events</li> </ol> </li> <li> <ol> <li>Independent Events</li> </ol> </li> <li> <ol> <li>Dependent Events</li> </ol> </li> <li> <ol> <li>Addition Rule</li> </ol> </li> <li> <ol> <li>General Addition Rule</li> </ol> </li> <li> <ol> <li>Multiplication Rule</li> </ol> </li> <li> <ol> <li>General Multiplication Rule</li> </ol> </li> <li> <ol> <li>Bayes Intuition</li> </ol> </li> <li> <ol> <li>Tree Diagram</li> </ol> </li> <li>...and 9 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#ht-for-proportions-htpr","title":"HT for Proportions (HTPR)","text":"<p>Count: 20 concepts (6.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Hypothesis Test</li> </ol> </li> <li> <ol> <li>Null Hypothesis</li> </ol> </li> <li> <ol> <li>Alternative Hypothesis</li> </ol> </li> <li> <ol> <li>Writing Hypotheses</li> </ol> </li> <li> <ol> <li>One-Sided Test</li> </ol> </li> <li> <ol> <li>Two-Sided Test</li> </ol> </li> <li> <ol> <li>P-Value</li> </ol> </li> <li> <ol> <li>Calculating P-Values</li> </ol> </li> <li> <ol> <li>Interpreting P-Values</li> </ol> </li> <li> <ol> <li>Significance Level</li> </ol> </li> <li> <ol> <li>Choosing Alpha</li> </ol> </li> <li> <ol> <li>Making Conclusions</li> </ol> </li> <li> <ol> <li>Type I Error</li> </ol> </li> <li> <ol> <li>Type II Error</li> </ol> </li> <li> <ol> <li>Error Tradeoffs</li> </ol> </li> <li>...and 5 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#ci-for-proportions-cipr","title":"CI for Proportions (CIPR)","text":"<p>Count: 17 concepts (5.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Point Estimate</li> </ol> </li> <li> <ol> <li>Interval Estimate</li> </ol> </li> <li> <ol> <li>Confidence Interval</li> </ol> </li> <li> <ol> <li>Margin of Error</li> </ol> </li> <li> <ol> <li>Confidence Level</li> </ol> </li> <li> <ol> <li>Interpreting Confidence</li> </ol> </li> <li> <ol> <li>Critical Value</li> </ol> </li> <li> <ol> <li>Z Critical Values</li> </ol> </li> <li> <ol> <li>Standard Error</li> </ol> </li> <li> <ol> <li>CI for One Proportion</li> </ol> </li> <li> <ol> <li>Conditions for CI Proportion</li> </ol> </li> <li> <ol> <li>Interpreting CI</li> </ol> </li> <li> <ol> <li>CI for Difference in Props</li> </ol> </li> <li> <ol> <li>Pooled Proportion</li> </ol> </li> <li> <ol> <li>Test for One Proportion</li> </ol> </li> <li>...and 2 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#bivariate-analysis-eda2","title":"Bivariate Analysis (EDA2)","text":"<p>Count: 11 concepts (3.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Two-Way Table</li> </ol> </li> <li> <ol> <li>Calculating Conditionals</li> </ol> </li> <li> <ol> <li>Association</li> </ol> </li> <li> <ol> <li>Simpson's Paradox</li> </ol> </li> <li> <ol> <li>Direction of Association</li> </ol> </li> <li> <ol> <li>Positive Association</li> </ol> </li> <li> <ol> <li>Negative Association</li> </ol> </li> <li> <ol> <li>Form of Association</li> </ol> </li> <li> <ol> <li>Strength of Association</li> </ol> </li> <li> <ol> <li>Conditional Probability</li> </ol> </li> <li> <ol> <li>Calculating Conditionals</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#chi-square-tests-chisq","title":"Chi-Square Tests (CHISQ)","text":"<p>Count: 11 concepts (3.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Goodness-of-Fit Test</li> </ol> </li> <li> <ol> <li>GOF Hypotheses</li> </ol> </li> <li> <ol> <li>Expected Counts</li> </ol> </li> <li> <ol> <li>Observed Counts</li> </ol> </li> <li> <ol> <li>Calculating Chi-Square</li> </ol> </li> <li> <ol> <li>Conditions for Chi-Square</li> </ol> </li> <li> <ol> <li>GOF Conclusion</li> </ol> </li> <li> <ol> <li>Homogeneity Setup</li> </ol> </li> <li> <ol> <li>Independence Setup</li> </ol> </li> <li> <ol> <li>Chi-Square Conclusion</li> </ol> </li> <li> <ol> <li>Independence Condition</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#random-variables-rand","title":"Random Variables (RAND)","text":"<p>Count: 9 concepts (3.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Expected Value</li> </ol> </li> <li> <ol> <li>Calculating Expected Value</li> </ol> </li> <li> <ol> <li>Linear Transformation</li> </ol> </li> <li> <ol> <li>Difference of RVs</li> </ol> </li> <li> <ol> <li>Binomial Setting</li> </ol> </li> <li> <ol> <li>Binomial Conditions</li> </ol> </li> <li> <ol> <li>Binomial Formula</li> </ol> </li> <li> <ol> <li>Binomial Standard Dev</li> </ol> </li> <li> <ol> <li>Geometric Setting</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#sampling-distributions-samp","title":"Sampling Distributions (SAMP)","text":"<p>Count: 7 concepts (2.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Sampling Variability</li> </ol> </li> <li> <ol> <li>Sampling Distribution</li> </ol> </li> <li> <ol> <li>Sampling Dist of Proportion</li> </ol> </li> <li> <ol> <li>Conditions for Proportion SD</li> </ol> </li> <li> <ol> <li>Sampling Dist of Mean</li> </ol> </li> <li> <ol> <li>Central Limit Theorem</li> </ol> </li> <li> <ol> <li>CLT Conditions</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#communication-comm","title":"Communication (COMM)","text":"<p>Count: 7 concepts (2.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Stat vs Practical Sig</li> </ol> </li> <li> <ol> <li>Effect Size</li> </ol> </li> <li> <ol> <li>Study Limitations</li> </ol> </li> <li> <ol> <li>Generalizability</li> </ol> </li> <li> <ol> <li>Communicating Results</li> </ol> </li> <li> <ol> <li>Four-Step Process</li> </ol> </li> <li> <ol> <li>AP Exam Strategies</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#t-procedures-for-means-tmea","title":"T-Procedures for Means (TMEA)","text":"<p>Count: 6 concepts (2.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Degrees of Freedom</li> </ol> </li> <li> <ol> <li>Conditions for T-Procedures</li> </ol> </li> <li> <ol> <li>Pooled vs Unpooled</li> </ol> </li> <li> <ol> <li>Paired T-Test</li> </ol> </li> <li> <ol> <li>When to Pair</li> </ol> </li> <li> <ol> <li>Robustness</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#regression-inference-regf","title":"Regression Inference (REGF)","text":"<p>Count: 4 concepts (1.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Inference for Slope</li> </ol> </li> <li> <ol> <li>T-Interval for Slope</li> </ol> </li> <li> <ol> <li>T-Test for Slope</li> </ol> </li> <li> <ol> <li>Linearity Condition</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#recommendations","title":"Recommendations","text":"<ul> <li>\u2705 Good balance: Categories are reasonably distributed (spread: 21.3%)</li> <li>\u2705 MISC category minimal: Good categorization specificity</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#educational-use-recommendations","title":"Educational Use Recommendations","text":"<ul> <li>Use taxonomy categories for color-coding in graph visualizations</li> <li>Design curriculum modules based on taxonomy groupings</li> <li>Create filtered views for focused learning paths</li> <li>Use categories for assessment organization</li> <li>Enable navigation by topic area in interactive tools</li> </ul> <p>Report generated by learning-graph-reports/taxonomy_distribution.py</p>"},{"location":"prompts/cover/","title":"Generate Cover Image","text":""},{"location":"prompts/cover/#skill","title":"Skill","text":"<p>Prompt</p> <p>Use the /book-installer cover generator guide for manual copy into a image generator</p>"},{"location":"prompts/cover/#output","title":"Output","text":"<p>Professional textbook cover for \"Statistics\" course. Place the title text \"Statistics\" in the center of the image. Modern educational design with a clean blue and white color scheme. Visual elements include: a bell curve/normal distribution graph, scattered data points forming a pattern, a histogram, a pie chart, and subtle mathematical symbols. Background features a montage of abstract data visualization elements. The design should be sophisticated yet approachable for high school students. No text on the image other than the title.</p>"},{"location":"prompts/generate-chapter-content/","title":"Generate Chapter Content","text":"<p>Prompt</p> <p>Run the /chapter-content-generator skill on chapters 1,2 and 3 in parallel - Audience: High school students preparing for AP Statistics - Reading Level: Senior High (Grades 10-12)</p> <p>Prompt</p> <p>Run the /chapter-content-generator skill on chapters 5,6,7 and 8 in parallel Audience: High school students preparing for AP Statistics Reading Level: Senior High (Grades 10-12) Log the session details into logs/ch-{N}.md for each chapter where N is the chapter number</p> <p>Run the /chapter-content-generator skill on chapters 9,10,11 in parallel Audience: High school students preparing for AP Statistics Reading Level: Senior High (Grades 10-12) Log the session details into logs/ch-{NN}.md for each chapter where N is the chapter number and include the number of tokens used in the log files</p> <p>Run the /chapter-content-generator skill on chapters 12,13,14,15,16 in parallel Audience: High school students preparing for AP Statistics Reading Level: Senior High (Grades 10-12) Log the session details into logs/ch-{NN}.md for each chapter where NN is the chapter number and include the number of tokens used in the log files</p> <p>Run the /chapter-content-generator skill on chapters 17, 18 and 19 in parallel Audience: High school students preparing for AP Statistics Reading Level: Senior High (Grades 10-12) Log the session details into logs/ch-{NN}.md for each chapter where NN is the chapter number and include the number of tokens used in the log files</p>"},{"location":"prompts/generate-microsims/","title":"Generate MicroSims","text":"<p>Run the /microsim-genenerator skill in parallel on all of the #### Diagram elements in chapters 4 and 5. Use the content of the  element to get the MicroSim specification for each diagram.  Remember to place the iframe after the #### Diagram header and before the  in the chapter content when done. <p>When generating the index.md file, remember to place the link to Edit in the p5.js Editor if the MicroSim was a p5.js MicroSim.</p> <p>Run the /microsim-genenerator skill in parallel on all of the #### Diagram elements in chapters 6, 7, 8 and 9. Use the content of the  element to get the MicroSim specification for each diagram.  Remember to place the iframe after the #### Diagram header and before the  in the chapter content when done. <p>When generating the index.md file, remember to place the link to Edit in the p5.js Editor if the MicroSim was a p5.js MicroSim.</p> <p>After each microsim has been generated, run the /microsim-utils capture screen image skill being careful to pass the height of the iframe in the index.md file as the height parameter to the bk-capture-screenshot program to get the correct height of the image.</p>"},{"location":"sims/","title":"List of MicroSims for AP Statistics","text":"<p>Interactive Micro Simulations to help students learn statistics fundamentals through hands-on exploration.</p> <ul> <li> <p>Addition Rule Visualizer</p> <p></p> <p>Interactive Venn diagram for visualizing and calculating P(A or B) using the addition rule, with support for mutually exclusive events.</p> </li> <li> <p>Association Detector Visualization</p> <p></p> <p>Interactive MicroSim for comparing conditional distributions using side-by-side 100% stacked bar charts to identify evidence of association between categorical variables.</p> </li> <li> <p>Association Strength Spectrum</p> <p></p> <p>An interactive MicroSim that helps students classify associations between categorical variables as strong, moderate, weak, or none by visualizing two-way tables and segmented bar charts.</p> </li> <li> <p>Bar Graph Builder</p> <p></p> <p>An interactive MicroSim where students construct bar graphs from categorical data by entering category names and frequencies, with options for vertical/horizontal orientation.</p> </li> <li> <p>Boxplot Builder</p> <p></p> <p>An interactive MicroSim for constructing and interpreting boxplots by connecting numerical summary statistics to their visual representation with step-by-step animation.</p> </li> <li> <p>Boxplot Comparison</p> <p></p> <p>Side-by-side boxplot comparison tool for analyzing distributions across 2-4 groups with pre-loaded datasets and summary statistics.</p> </li> <li> <p>Chapter 2 Concept Map</p> <p></p> <p>An interactive concept map showing the hierarchy of key concepts in Chapter 2, including Organizing Data, Single Variable Displays, Two Variable Analysis, and Association.</p> </li> <li> <p>Density Curve Area Explorer</p> <p></p> <p>Interactive visualization showing that area under a density curve represents probability, with draggable boundary lines and multiple curve types.</p> </li> <li> <p>Discrete vs Continuous Number Line</p> <p></p> <p>An interactive MicroSim that helps students distinguish between discrete and continuous variables by visualizing how values can be plotted on a number line.</p> </li> <li> <p>Distribution Shape Gallery</p> <p></p> <p>An interactive infographic showing three types of distribution shapes - unimodal, bimodal, and uniform - with real-world examples, hover tooltips, and a quiz mode.</p> </li> <li> <p>Empirical Rule (68-95-99.7)</p> <p></p> <p>Interactive demonstration of the 68-95-99.7 rule for normal distributions with animated regions and real-world examples.</p> </li> <li> <p>Frequency Table Explorer</p> <p></p> <p>An interactive MicroSim where students practice calculating relative frequencies and percentages from raw frequency data using adjustable sliders.</p> </li> <li> <p>Interactive Histogram Explorer</p> <p></p> <p>An interactive MicroSim where students examine how changing bin width affects histogram appearance, with multiple datasets and display options.</p> </li> <li> <p>Household Income Boxplot Explorer</p> <p></p> <p>Interactive MicroSim that uses a boxplot to summarize household incomes and highlight right-skew.</p> </li> <li> <p>Interactive Dotplot Builder</p> <p></p> <p>An interactive MicroSim where students click on a number line to add data points and construct a dotplot, demonstrating how dotplots visualize quantitative data.</p> </li> <li> <p>Law of Large Numbers Demonstrator</p> <p></p> <p>Interactive visualization demonstrating how empirical probability converges to theoretical probability as the number of trials increases.</p> </li> <li> <p>Mean as Balance Point</p> <p></p> <p>Interactive visualization showing the mean as the balance point of a distribution, with draggable data points and real-time mean calculation.</p> </li> <li> <p>Mean vs Median Skewness</p> <p></p> <p>Interactive visualization showing how mean and median positions differ based on distribution shape, with outlier buttons to demonstrate resistance.</p> </li> <li> <p>Normal Distribution Explorer</p> <p></p> <p>Interactive visualization showing how mean (\u03bc) and standard deviation (\u03c3) affect the shape and position of a normal distribution curve.</p> </li> <li> <p>Normal Probability Calculator</p> <p></p> <p>Interactive calculator for computing probabilities from normal distributions with draggable boundary markers and step-by-step solutions.</p> </li> <li> <p>Normal Probability Plot Explorer</p> <p></p> <p>Interactive visualization for assessing normality using histograms and QQ plots with multiple distribution types and sample sizes.</p> </li> <li> <p>Outlier Detection</p> <p></p> <p>Interactive visualization of the 1.5 \u00d7 IQR rule for identifying outliers with adjustable multiplier and fence calculations.</p> </li> <li> <p>Outlier Detective Game</p> <p></p> <p>An interactive game where students identify outliers in real-world datasets by examining visual separation in dotplots and histograms.</p> </li> <li> <p>Parameter vs Statistic Comparison</p> <p></p> <p>An interactive MicroSim demonstrating the difference between population parameters and sample statistics, showing how statistics vary while parameters remain fixed.</p> </li> <li> <p>Pie Chart vs Bar Graph Comparison</p> <p></p> <p>An interactive MicroSim that displays the same data as both a pie chart and bar graph, helping students analyze when each visualization type is most effective.</p> </li> <li> <p>Population and Sample Visualization</p> <p></p> <p>An interactive MicroSim that demonstrates the relationship between a population and a sample by letting students select individuals from a population.</p> </li> <li> <p>Probability Simulation Lab</p> <p></p> <p>Interactive simulation for estimating probabilities through repeated trials, demonstrating how empirical probability converges to theoretical probability.</p> </li> <li> <p>Quartile Visualization</p> <p></p> <p>Interactive visualization showing how quartiles divide data into four equal parts with color-coded regions and adjustable sample size.</p> </li> <li> <p>Skewness Explorer</p> <p></p> <p>Interactive MicroSim where students classify distributions as symmetric, skewed left, or skewed right by examining histograms with real-world contexts.</p> </li> <li> <p>SOCS Description Builder</p> <p></p> <p>An interactive MicroSim where students compose complete distribution descriptions using the SOCS framework (Shape, Outliers, Center, Spread).</p> </li> <li> <p>Sample Space Explorer</p> <p></p> <p>Interactive visualization for exploring sample spaces of common probability experiments including dice rolls, coin flips, and card draws.</p> </li> <li> <p>Standard Deviation Calculator</p> <p></p> <p>Step-by-step variance and standard deviation calculator showing the complete calculation process with visual representation.</p> </li> <li> <p>Stemplot Constructor</p> <p></p> <p>An interactive MicroSim where students interpret how data values decompose into stems and leaves to build a stemplot visualization.</p> </li> <li> <p>Study Design Concept Map</p> <p></p> <p>Interactive concept map showing how foundational statistics concepts connect in the context of a real research study about sleep and academic performance.</p> </li> <li> <p>Symmetric Distribution Identifier</p> <p></p> <p>An interactive quiz MicroSim where students learn to recognize symmetric and asymmetric distributions by comparing histogram shapes.</p> </li> <li> <p>Test Scores Boxplot Explorer</p> <p></p> <p>Interactive MicroSim that uses boxplots to summarize exam scores and compare two class sections.</p> </li> <li> <p>Two-Way Table Calculator</p> <p></p> <p>An interactive calculator for computing marginal and conditional distributions from a two-way (contingency) table with editable cells.</p> </li> <li> <p>Variable Types Concept Map</p> <p></p> <p>An interactive concept map showing the hierarchy of variable types in statistics, including categorical and quantitative variables.</p> </li> <li> <p>Venn Diagram Problem Solver</p> <p></p> <p>Interactive tool for solving probability problems using Venn diagrams, calculating counts and probabilities for overlapping events.</p> </li> <li> <p>Z-Score Calculator</p> <p></p> <p>Interactive z-score calculator and visualizer showing value position on a normal distribution curve with real-world presets.</p> </li> </ul>"},{"location":"sims/addition-rule-visualizer/","title":"Addition Rule Visualizer","text":"<p>Run the Addition Rule Visualizer Fullscreen</p> <p>Edit this MicroSim in the p5.js Editor</p>"},{"location":"sims/addition-rule-visualizer/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive visualization demonstrates the addition rule for probability using a dynamic Venn diagram. Students can adjust P(A), P(B), and P(A\u2229B) using sliders and immediately see how these values affect P(A or B). The mutually exclusive toggle shows the special case where P(A\u2229B) = 0.</p>"},{"location":"sims/addition-rule-visualizer/#how-to-use","title":"How to Use","text":"<ol> <li>Adjust the sliders for P(A), P(B), and P(A\u2229B)</li> <li>Observe the Venn diagram update to show the relationship between events</li> <li>Check \"Mutually Exclusive\" to see what happens when events can't occur together</li> <li>Toggle \"Show Steps\" to see the full calculation</li> </ol>"},{"location":"sims/addition-rule-visualizer/#key-formulas","title":"Key Formulas","text":"<ul> <li>General Addition Rule: P(A or B) = P(A) + P(B) - P(A and B)</li> <li>For Mutually Exclusive Events: P(A or B) = P(A) + P(B)</li> </ul>"},{"location":"sims/addition-rule-visualizer/#learning-objectives","title":"Learning Objectives","text":"<p>After using this MicroSim, students will be able to:</p> <ul> <li>Apply the addition rule to calculate P(A or B)</li> <li>Understand why we subtract P(A\u2229B) to avoid double-counting</li> <li>Recognize when events are mutually exclusive and apply the simplified rule</li> <li>Visualize probability relationships using Venn diagrams</li> </ul>"},{"location":"sims/addition-rule-visualizer/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/addition-rule-visualizer/main.html\" height=\"452px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/addition-rule-visualizer/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/addition-rule-visualizer/#introduction-5-minutes","title":"Introduction (5 minutes)","text":"<p>Review the concept of \"or\" in probability (inclusive or). Explain why simply adding probabilities can lead to overcounting.</p>"},{"location":"sims/addition-rule-visualizer/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<p>Walk through examples with different P(A), P(B), and P(A\u2229B) values. Show how the intersection affects the total.</p>"},{"location":"sims/addition-rule-visualizer/#practice-activities-10-minutes","title":"Practice Activities (10 minutes)","text":"<p>Give students specific probability scenarios and have them predict P(A or B) before checking with the visualization.</p>"},{"location":"sims/addition-rule-visualizer/#assessment","title":"Assessment","text":"<p>Students explain in their own words why we subtract the intersection and when we don't need to.</p>"},{"location":"sims/addition-rule-visualizer/#references","title":"References","text":"<ul> <li>Chapter 9: Probability Fundamentals</li> <li>Concepts: Addition Rule, General Addition Rule, Mutually Exclusive Events</li> </ul>"},{"location":"sims/association-detector/","title":"Association Detector Visualization","text":"<p>Run Association Detector in Fullscreen</p> <p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/association-detector/main.html\" height=\"522px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/association-detector/#description","title":"Description","text":"<p>This MicroSim helps students understand association between categorical variables by comparing conditional distributions visually. When we have a two-way table (also called a contingency table), one key question is: \"Does the distribution of one variable depend on the value of the other variable?\"</p> <p>The visualization displays:</p> <ul> <li>Two horizontal 100% stacked bar charts: Each bar represents the conditional distribution for one level of the row variable (e.g., Freshmen/Sophomores vs. Juniors/Seniors)</li> <li>Color-coded segments: Each segment shows the percentage of responses in that category (e.g., Fall, Winter, Spring, Summer)</li> <li>Difference indicators: Visual arrows highlight the largest difference between the two distributions</li> </ul>"},{"location":"sims/association-detector/#how-to-use","title":"How to Use","text":"<ol> <li>Observe the default data: The initial display shows Season preference by Grade Level with a moderate association</li> <li>Compare the bars: If the bars look nearly identical, there is little evidence of association. If they look quite different, the variables may be associated</li> <li>Use presets: Click \"Strong,\" \"None,\" or \"Moderate\" to see examples of different association strengths</li> <li>Edit the data: Click on any cell in the two-way table to enter your own values</li> <li>Toggle options: Use the \"Show %\" button to display/hide percentage labels, and \"Highlight\" to show/hide difference indicators</li> </ol>"},{"location":"sims/association-detector/#key-concepts","title":"Key Concepts","text":"<ul> <li>Conditional Distribution: The distribution of one variable for a specific value of another variable</li> <li>Association: Two variables are associated if the conditional distribution of one variable changes depending on the value of the other</li> <li>No Association: If conditional distributions are nearly identical across all levels, the variables are independent</li> </ul>"},{"location":"sims/association-detector/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/association-detector/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this lesson, students will be able to:</p> <ol> <li>Compare conditional distributions displayed as 100% stacked bar charts</li> <li>Differentiate between data showing strong, moderate, and no association</li> <li>Interpret percentage differences as evidence for or against association</li> <li>Explain in their own words what it means for two categorical variables to be associated</li> </ol>"},{"location":"sims/association-detector/#target-audience","title":"Target Audience","text":"<ul> <li>AP Statistics students</li> <li>Introductory college statistics students</li> <li>Grade level: 10-12 and undergraduate</li> </ul>"},{"location":"sims/association-detector/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of categorical variables and two-way tables</li> <li>Ability to calculate and interpret percentages</li> <li>Familiarity with bar charts</li> </ul>"},{"location":"sims/association-detector/#duration","title":"Duration","text":"<p>20-30 minutes</p>"},{"location":"sims/association-detector/#activities","title":"Activities","text":"<p>Warm-Up (5 minutes)</p> <ol> <li>Display the MicroSim with \"No association\" preset</li> <li>Ask: \"If you didn't know whether a student was a Freshman or Senior, would knowing their grade level help you predict their favorite season?\"</li> <li>Guide students to notice that the bars look identical when there's no association</li> </ol> <p>Exploration (10-15 minutes)</p> <ol> <li>Switch to \"Strong association\" preset</li> <li>Discussion questions:</li> <li>\"How are these bars different from the 'No association' example?\"</li> <li>\"Which season shows the biggest difference between grade levels?\"</li> <li> <p>\"If I told you a student's favorite season was Summer, could you guess their grade level?\"</p> </li> <li> <p>Have students experiment with \"Moderate\" association and describe the differences</p> </li> <li> <p>Challenge: \"Create your own data where Freshmen prefer Spring and Seniors prefer Fall\"</p> </li> </ol> <p>Analysis (10 minutes)</p> <ol> <li>Students enter their own data scenarios and analyze results</li> <li>Journal prompt: \"Describe in your own words what makes two categorical variables 'associated' versus 'independent'\"</li> <li>Group discussion: Share real-world examples where association between categorical variables matters</li> </ol>"},{"location":"sims/association-detector/#assessment-suggestions","title":"Assessment Suggestions","text":"<p>Formative Assessment</p> <ul> <li>Observe student explanations during pair discussions</li> <li>Check journal responses for understanding of key concepts</li> </ul> <p>Summative Assessment</p> <p>Present students with a new two-way table (without the visualization) and ask them to:</p> <ol> <li>Sketch what the 100% stacked bars would look like</li> <li>Predict whether there is strong, moderate, or no association</li> <li>Explain their reasoning using percentage comparisons</li> </ol>"},{"location":"sims/association-detector/#references","title":"References","text":"<ol> <li> <p>Wikipedia: Contingency Table - Background on two-way tables and tests for independence</p> </li> <li> <p>Khan Academy: Two-way Tables - Video lessons on analyzing categorical data relationships</p> </li> <li> <p>OpenStax Statistics: Contingency Tables - College-level treatment of association and chi-square tests</p> </li> <li> <p>AP Statistics Course Framework - College Board standards for exploring categorical data (Unit 1)</p> </li> </ol>"},{"location":"sims/association-strength-spectrum/","title":"Strength of Association Spectrum","text":"<p>Run the Strength of Association Spectrum MicroSim Fullscreen</p>"},{"location":"sims/association-strength-spectrum/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive visualization helps you understand how to classify the strength of association between two categorical variables. As you adjust the strength slider or select presets, watch how the two-way table data, segmented bar chart, and strength meter all change together.</p>"},{"location":"sims/association-strength-spectrum/#what-you-will-learn","title":"What You Will Learn","text":"<ul> <li>How to recognize no association (independence) between variables</li> <li>How to identify weak, moderate, and strong associations</li> <li>How conditional percentages in segmented bars reveal association strength</li> <li>Why perfect association is rare in real-world data</li> </ul>"},{"location":"sims/association-strength-spectrum/#how-to-use-this-microsim","title":"How to Use This MicroSim","text":"<ol> <li>Move the slider to smoothly transition between association strengths</li> <li>Click preset labels (None, Weak, Moderate, Strong, Perfect) to jump to specific examples</li> <li>Click Randomize to explore random association strengths</li> <li>Watch the left panel to see how the two-way table and segmented bars change</li> <li>Watch the right panel to see the strength meter and read the description</li> </ol>"},{"location":"sims/association-strength-spectrum/#iframe-embed-code","title":"Iframe Embed Code","text":"<p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/association-strength-spectrum/main.html\" height=\"482px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/association-strength-spectrum/#concepts-illustrated","title":"Concepts Illustrated","text":""},{"location":"sims/association-strength-spectrum/#two-way-tables","title":"Two-Way Tables","text":"<p>The two-way table shows counts for two categorical variables: - Rows: Treatment groups (A and B) - Columns: Outcomes (Success and Failure)</p> <p>When there is no association, both treatment groups have similar success rates (around 50%). As association strength increases, the success rates diverge.</p>"},{"location":"sims/association-strength-spectrum/#segmented-bar-charts","title":"Segmented Bar Charts","text":"<p>The segmented bar chart shows conditional percentages. Each bar represents 100% of one treatment group, divided into success (green) and failure (coral) portions.</p> <ul> <li>No association: Bars look nearly identical</li> <li>Strong association: Bars look very different</li> </ul>"},{"location":"sims/association-strength-spectrum/#the-strength-meter","title":"The Strength Meter","text":"<p>The vertical meter on the right provides a quick visual reference: - 0% = No association (complete independence) - 50% = Moderate association - 100% = Perfect association (one variable completely determines the other)</p>"},{"location":"sims/association-strength-spectrum/#key-insights","title":"Key Insights","text":"<p>Sylvia Says</p> <p>\"Here's a handy rule of thumb: if the segmented bars look basically the same, there's little to no association. But when those bars start looking really different from each other? That's when you know one variable is telling you something useful about the other!\"</p> <ol> <li> <p>Independence means equal conditional distributions: When variables are independent, knowing one tells you nothing about the other.</p> </li> <li> <p>Association is about pattern, not causation: Even strong association does not prove that one variable causes changes in the other.</p> </li> <li> <p>Real data is messy: Perfect association almost never occurs in practice. Most real associations are moderate or weak.</p> </li> </ol>"},{"location":"sims/association-strength-spectrum/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/association-strength-spectrum/#learning-objective","title":"Learning Objective","text":"<p>Students will be able to classify the strength of association between two categorical variables as none, weak, moderate, strong, or perfect by examining two-way tables and segmented bar charts.</p>"},{"location":"sims/association-strength-spectrum/#grade-level","title":"Grade Level","text":"<p>High School (AP Statistics) / Introductory College Statistics</p>"},{"location":"sims/association-strength-spectrum/#duration","title":"Duration","text":"<p>15-20 minutes</p>"},{"location":"sims/association-strength-spectrum/#warm-up-activity-3-minutes","title":"Warm-Up Activity (3 minutes)","text":"<p>Ask students: \"If I told you someone is in Treatment Group A, would that help you predict their outcome? How would you know?\"</p>"},{"location":"sims/association-strength-spectrum/#guided-exploration-8-minutes","title":"Guided Exploration (8 minutes)","text":"<ol> <li>Start with the slider at 0% (No Association). Point out that both groups have identical 50% success rates.</li> <li>Slowly move to 50% (Moderate). Ask: \"How have the bars changed?\"</li> <li>Move to 100% (Perfect). Discuss why this is unrealistic in real research.</li> <li>Click Randomize several times. Have students classify each result before checking the meter.</li> </ol>"},{"location":"sims/association-strength-spectrum/#practice-activity-5-minutes","title":"Practice Activity (5 minutes)","text":"<p>Have students work in pairs: - One student sets a random strength - The other must classify it as None/Weak/Moderate/Strong/Perfect based only on the table and bars - Check against the meter - Switch roles and repeat</p>"},{"location":"sims/association-strength-spectrum/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>When the segmented bars look almost identical, what does this tell you about association?</li> <li>A study finds Treatment A has 65% success and Treatment B has 35% success. How would you classify this association?</li> <li>Why is perfect association (100%) rare in real research?</li> </ol>"},{"location":"sims/association-strength-spectrum/#extension","title":"Extension","text":"<p>Have students collect real two-way table data (e.g., from surveys) and estimate the association strength before calculating it formally.</p>"},{"location":"sims/association-strength-spectrum/#references","title":"References","text":"<ul> <li>AP Statistics Course Description</li> <li>Moore, D. S., &amp; Notz, W. I. (2020). Statistics: Concepts and Controversies (10th ed.). W.H. Freeman.</li> <li>De Veaux, R. D., Velleman, P. F., &amp; Bock, D. E. (2021). Stats: Data and Models (5th ed.). Pearson.</li> </ul>"},{"location":"sims/bar-graph-builder/","title":"Bar Graph Builder","text":"<p>Run the Bar Graph Builder MicroSim Fullscreen</p>"},{"location":"sims/bar-graph-builder/#about-this-microsim","title":"About This MicroSim","text":"<p>Welcome to the Bar Graph Builder. This interactive tool lets you construct your own bar graphs from categorical data. Enter category names and frequencies, then watch your graph update in real time.</p> <p>As Sylvia would say: \"Let's crack this nut! Building bar graphs is like organizing your acorn stash - once you see the piles, you can compare them at a glance.\"</p>"},{"location":"sims/bar-graph-builder/#how-to-use","title":"How to Use","text":"<ol> <li>Enter Data: Click on any category name or frequency value in the right panel to edit it</li> <li>Add Categories: Click \"Add Category\" to add up to 6 categories</li> <li>Remove Categories: Click \"Remove\" to delete the last category</li> <li>Change Display:</li> <li>Toggle between Frequency (raw counts) and Relative Frequency (percentages)</li> <li>Switch between Vertical and Horizontal bar orientations</li> <li>Change Color: Click the color swatch to choose a different bar color</li> </ol>"},{"location":"sims/bar-graph-builder/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<p>Place the following line in your website to include this in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/bar-graph-builder/main.html\" height=\"502px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/bar-graph-builder/#description","title":"Description","text":"<p>This MicroSim supports the learning objective: Students will construct bar graphs from categorical data. At Bloom's Taxonomy Apply level (L3), students actively construct and demonstrate their understanding by:</p> <ul> <li>Entering their own category names and frequency values</li> <li>Observing how the bar graph updates immediately</li> <li>Comparing frequency vs. relative frequency representations</li> <li>Switching between vertical and horizontal orientations to see how the same data can be displayed differently</li> </ul> <p>The default dataset shows seasonal preferences: Spring (8), Summer (22), Fall (14), Winter (6). Students can modify this data or create entirely new datasets to explore bar graph construction.</p>"},{"location":"sims/bar-graph-builder/#key-concepts-demonstrated","title":"Key Concepts Demonstrated","text":"<ul> <li>Categorical Variables: Bar graphs display data for categorical (qualitative) variables</li> <li>Frequency: The count of observations in each category</li> <li>Relative Frequency: The proportion or percentage of observations in each category (all bars sum to 100%)</li> <li>Bar Height/Length: Represents the frequency or relative frequency</li> <li>Axis Labels: Proper labeling of category axis and frequency axis</li> <li>Graph Orientation: Vertical bars (column chart) vs. horizontal bars</li> </ul>"},{"location":"sims/bar-graph-builder/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/bar-graph-builder/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ol> <li>Construct a bar graph from a given set of categorical data</li> <li>Distinguish between frequency and relative frequency displays</li> <li>Interpret bar heights/lengths as representations of data values</li> <li>Choose appropriate graph orientations for different contexts</li> </ol>"},{"location":"sims/bar-graph-builder/#warm-up-activity-5-minutes","title":"Warm-Up Activity (5 minutes)","text":"<p>Ask students: \"What's your favorite season?\" Collect a quick show of hands and record the counts on the board. Then show how the default MicroSim data represents similar seasonal preference data.</p>"},{"location":"sims/bar-graph-builder/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<ol> <li>Walk through the default dataset together</li> <li>Ask prediction questions: \"If I change Summer from 22 to 10, what will happen to the bars?\"</li> <li>Switch to relative frequency view and discuss: \"Why might percentages be more useful than raw counts?\"</li> <li>Switch to horizontal orientation: \"When might horizontal bars be preferred?\"</li> </ol>"},{"location":"sims/bar-graph-builder/#independent-practice-15-minutes","title":"Independent Practice (15 minutes)","text":"<p>Have students:</p> <ol> <li>Create a bar graph for their own dataset (favorite colors, pet types, etc.)</li> <li>Answer these questions in their notes:</li> <li>Which category has the highest frequency?</li> <li>What percentage does your smallest category represent?</li> <li>Does vertical or horizontal better display your data? Why?</li> </ol>"},{"location":"sims/bar-graph-builder/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>What type of variable is displayed in a bar graph? (categorical/qualitative)</li> <li>What happens to the relative frequency bars when you add a new category?</li> <li>Why do all relative frequency percentages sum to 100%?</li> <li>How is a bar graph different from a histogram?</li> </ol>"},{"location":"sims/bar-graph-builder/#extension-activities","title":"Extension Activities","text":"<ul> <li>Data Collection: Have students collect real data from classmates and build a bar graph</li> <li>Comparison: Create two bar graphs with the same categories but different data to compare distributions</li> <li>Critical Thinking: Discuss how bar order (alphabetical vs. by frequency) affects interpretation</li> </ul>"},{"location":"sims/bar-graph-builder/#references","title":"References","text":"<ul> <li>OpenIntro Statistics, Chapter 2: Summarizing Data</li> <li>Khan Academy: Reading Bar Graphs</li> <li>p5.js Reference Documentation</li> </ul> <p>Acorn for your thoughts: Notice how the tallest bar jumps out at you? That's the mode - the most frequent category. Bar graphs make finding the mode as easy as spotting the biggest acorn pile! - Sylvia</p>"},{"location":"sims/boxplot-builder/","title":"Boxplot Builder","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/boxplot-builder/#about-this-microsim","title":"About This MicroSim","text":"<p>Build boxplots interactively and understand how each component relates to the five-number summary.</p>"},{"location":"sims/boxplot-builder/#how-to-use","title":"How to Use","text":"<ul> <li>Drag data points to see the boxplot update in real-time</li> <li>Click Build Step-by-Step to see the construction process</li> <li>Choose different distribution types (symmetric, right-skewed, left-skewed)</li> <li>Toggle Labels and Table to customize the display</li> </ul>"},{"location":"sims/boxplot-builder/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/boxplot-builder/#learning-objective","title":"Learning Objective","text":"<p>Students will construct and interpret boxplots by connecting numerical summary statistics to their visual representation (Bloom's Taxonomy: Applying, Creating).</p>"},{"location":"sims/boxplot-builder/#activities","title":"Activities","text":"<ol> <li>Build a boxplot step-by-step to understand each component</li> <li>Create symmetric vs. skewed distributions and observe the boxplot shape</li> <li>Predict how moving a point will change the boxplot before dragging it</li> </ol>"},{"location":"sims/boxplot-comparison/","title":"Boxplot Comparison","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/boxplot-comparison/#about-this-microsim","title":"About This MicroSim","text":"<p>Compare distributions across multiple groups using side-by-side boxplots.</p>"},{"location":"sims/boxplot-comparison/#how-to-use","title":"How to Use","text":"<ul> <li>Select different datasets to explore various comparison scenarios</li> <li>Click on a boxplot to see its detailed five-number summary</li> <li>Toggle Show Outliers to display individual outlier points</li> <li>Toggle Connect Medians to visually compare centers across groups</li> </ul>"},{"location":"sims/boxplot-comparison/#what-to-compare","title":"What to Compare","text":"<ul> <li>Centers: Which group has the highest/lowest median?</li> <li>Spreads: Which group has the most/least variability (widest/narrowest box)?</li> <li>Shapes: Are some distributions symmetric while others are skewed?</li> <li>Outliers: Does one group have more unusual values?</li> </ul>"},{"location":"sims/boxplot-comparison/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/boxplot-comparison/#learning-objective","title":"Learning Objective","text":"<p>Students will compare distributions across multiple groups by analyzing side-by-side boxplots (Bloom's Taxonomy: Analyzing, Evaluating).</p>"},{"location":"sims/chapter-2-concept-map/","title":"Chapter 2 Concept Map: Displaying Categorical Data","text":"<p>Run the Chapter 2 Concept Map Fullscreen</p>"},{"location":"sims/chapter-2-concept-map/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/chapter-2-concept-map/main.html\" height=\"572px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/chapter-2-concept-map/#description","title":"Description","text":"<p>This interactive concept map provides a visual overview of all the key concepts covered in Chapter 2: Displaying Categorical Data. The hierarchical structure shows how concepts relate to each other and builds understanding of the chapter's organization.</p>"},{"location":"sims/chapter-2-concept-map/#main-branches","title":"Main Branches","text":"<p>The concept map has four main branches stemming from the root concept:</p> <ol> <li>Organizing Data (Blue) - Methods for arranging raw categorical data</li> <li>Frequency Table</li> <li>Relative Frequency</li> <li> <p>Cumulative Frequency</p> </li> <li> <p>Single Variable Displays (Green) - Visual representations for one variable</p> </li> <li>Bar Graph</li> <li> <p>Pie Chart</p> </li> <li> <p>Two Variable Analysis (Orange) - Examining relationships between two categorical variables</p> </li> <li> <p>Two-Way Table</p> <ul> <li>Marginal Distribution</li> <li>Conditional Distribution</li> </ul> </li> <li> <p>Association (Purple) - Understanding relationships between variables</p> </li> <li>Direction (Positive / Negative)</li> <li>Strength</li> </ol>"},{"location":"sims/chapter-2-concept-map/#interactive-features","title":"Interactive Features","text":"<ul> <li>Hover over any node to see its definition in a tooltip</li> <li>Click on a node to highlight its branch (ancestors and descendants) while dimming other nodes</li> <li>Click again on the same node or anywhere else to clear the selection and show all branches</li> <li>Color-coded branches help distinguish between different concept themes</li> </ul> <p>The color scheme reinforces the organization:</p> <ul> <li>Blue nodes relate to organizing and summarizing data</li> <li>Green nodes represent graphical displays</li> <li>Orange nodes cover two-variable analysis</li> <li>Purple nodes deal with association concepts</li> </ul>"},{"location":"sims/chapter-2-concept-map/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/chapter-2-concept-map/#learning-objective","title":"Learning Objective","text":"<p>Students will identify and recognize the key concepts in Chapter 2 and understand how they relate to each other in a hierarchical structure.</p>"},{"location":"sims/chapter-2-concept-map/#blooms-taxonomy-level","title":"Bloom's Taxonomy Level","text":"<p>Remember (L1) - Recognize, identify</p>"},{"location":"sims/chapter-2-concept-map/#grade-level","title":"Grade Level","text":"<p>High School (AP Statistics) or Undergraduate Introduction to Statistics</p>"},{"location":"sims/chapter-2-concept-map/#prerequisites","title":"Prerequisites","text":"<ul> <li>Reading of Chapter 2 introduction</li> <li>Basic understanding of what categorical data means</li> </ul>"},{"location":"sims/chapter-2-concept-map/#duration","title":"Duration","text":"<p>10-15 minutes</p>"},{"location":"sims/chapter-2-concept-map/#activities","title":"Activities","text":"<ol> <li> <p>Orientation (3 minutes): Have students explore the concept map by hovering over each main branch to understand the four major themes of the chapter.</p> </li> <li> <p>Concept Exploration (5 minutes): Students click on each main branch one at a time to focus on that section. For each branch, have them:</p> </li> <li>Read the definitions of all concepts in that branch</li> <li>Identify which concepts are sub-concepts of others</li> <li> <p>Note any concepts they want to learn more about</p> </li> <li> <p>Connection Building (5 minutes): Ask students to consider:</p> </li> <li>Which organizing method (frequency table, relative frequency, cumulative frequency) might be used with which display?</li> <li>How does a two-way table connect to the idea of association?</li> <li> <p>Why are \"direction\" and \"strength\" important when describing associations?</p> </li> <li> <p>Preview Discussion (2 minutes): Use the concept map to preview the chapter structure and set expectations for what students will learn.</p> </li> </ol>"},{"location":"sims/chapter-2-concept-map/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>What are the four main branches of concepts in Chapter 2?</li> <li>What is the difference between marginal and conditional distribution?</li> <li>Name two ways to display a single categorical variable.</li> <li>What two aspects describe an association between variables?</li> </ol>"},{"location":"sims/chapter-2-concept-map/#extension","title":"Extension","text":"<p>Have students return to this concept map after completing the chapter and see if they can now explain each concept without looking at the definitions.</p>"},{"location":"sims/chapter-2-concept-map/#references","title":"References","text":"<ul> <li>AP Statistics Course Description - College Board</li> <li>Displaying Categorical Data - Khan Academy</li> <li>Moore, D. S., &amp; Notz, W. I. (2020). Statistics: Concepts and Controversies (10th ed.). W.H. Freeman.</li> <li>De Veaux, R. D., Velleman, P. F., &amp; Bock, D. E. (2021). Stats: Data and Models (5th ed.). Pearson.</li> </ul>"},{"location":"sims/density-curve-area/","title":"Density Curve Area Explorer","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/density-curve-area/#about-this-microsim","title":"About This MicroSim","text":"<p>Explore how the area under a density curve represents probability.</p>"},{"location":"sims/density-curve-area/#how-to-use","title":"How to Use","text":"<ul> <li>Drag the vertical boundary lines to change the shaded region</li> <li>Select different curve types: Normal, Uniform, Right-skewed</li> <li>Toggle Show Full Area = 1 to see that the total area always equals 1</li> </ul>"},{"location":"sims/density-curve-area/#key-insights","title":"Key Insights","text":"<ul> <li>The area under a density curve between two values represents the proportion/probability</li> <li>The total area under any density curve equals exactly 1 (100%)</li> <li>Different curve shapes have different area distributions</li> </ul>"},{"location":"sims/density-curve-area/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/density-curve-area/#learning-objective","title":"Learning Objective","text":"<p>Students will understand that area under a density curve represents probability by shading regions and observing the corresponding proportions (Bloom's Taxonomy: Understanding).</p>"},{"location":"sims/discrete-continuous-numberline/","title":"Discrete vs Continuous Number Line","text":"<p>Run the Discrete vs Continuous Number Line MicroSim Fullscreen</p>"},{"location":"sims/discrete-continuous-numberline/#embed-this-microsim","title":"Embed This MicroSim","text":"<p>Place the following line in your website to include this in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/discrete-continuous-numberline/main.html\" height=\"302px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/discrete-continuous-numberline/#description","title":"Description","text":"<p>This MicroSim provides an interactive visualization that helps students understand the fundamental difference between discrete and continuous variables. The simulation displays two horizontal number lines stacked vertically:</p> <p>Discrete Number Line (Top): Labeled \"Number of Pets\" with a range of 0-10. This line shows only integer values as clickable blue dots. When students click between integers, the marker automatically snaps to the nearest whole number with visual feedback, demonstrating that discrete variables can only take on specific, countable values.</p> <p>Continuous Number Line (Bottom): Labeled \"Height in Inches\" with a range of 60-72 inches. This line displays a smooth gradient bar. When students click anywhere on this line, a marker is placed at the exact position, and the precise value (to two decimal places) is displayed, illustrating that continuous variables can take on any value within a range.</p> <p>The key learning moment occurs when students try to click \"between\" values on the discrete line and observe the snap behavior, compared to clicking anywhere on the continuous line and seeing exact decimal values.</p>"},{"location":"sims/discrete-continuous-numberline/#how-to-use","title":"How to Use","text":"<ol> <li> <p>Click on the discrete line (top) to place markers. Notice how clicking between integers snaps to the nearest whole number.</p> </li> <li> <p>Click on the continuous line (bottom) to place markers. Notice how you can place markers at any position, and the exact decimal value is displayed.</p> </li> <li> <p>Toggle \"Show Examples\" to see pre-placed example values on each line.</p> </li> <li> <p>Click \"Reset\" to clear all markers and start fresh.</p> </li> </ol>"},{"location":"sims/discrete-continuous-numberline/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/discrete-continuous-numberline/#learning-objective","title":"Learning Objective","text":"<p>Students will distinguish between discrete and continuous variables by visualizing how values can be plotted on a number line and observing the different behaviors when placing markers.</p>"},{"location":"sims/discrete-continuous-numberline/#blooms-taxonomy-level","title":"Bloom's Taxonomy Level","text":"<p>Understand (L2) - Students compare and contrast discrete and continuous variable behavior through direct interaction.</p>"},{"location":"sims/discrete-continuous-numberline/#duration","title":"Duration","text":"<p>5-10 minutes for initial exploration; can be extended with discussion activities.</p>"},{"location":"sims/discrete-continuous-numberline/#warm-up-activity-2-minutes","title":"Warm-Up Activity (2 minutes)","text":"<p>Ask students: \"If I asked you how many pets you have, could you answer '2.5 pets'? What about your height - could you be 66.5 inches tall?\" Let students share their thinking.</p>"},{"location":"sims/discrete-continuous-numberline/#guided-exploration-5-minutes","title":"Guided Exploration (5 minutes)","text":"<ol> <li> <p>Have students click on the discrete line first. Ask them to try clicking exactly between two numbers. What happens?</p> </li> <li> <p>Have students click on the continuous line. Ask them to try to place a marker at exactly 65.5 inches. Then 65.55 inches. Can they do it?</p> </li> <li> <p>Discuss: Why does the pet line snap to whole numbers? Why can the height line accept any value?</p> </li> </ol>"},{"location":"sims/discrete-continuous-numberline/#discussion-questions","title":"Discussion Questions","text":"<ul> <li> <p>What are other examples of discrete variables in your life? (Number of siblings, number of classes, shoe sizes in US system)</p> </li> <li> <p>What are other examples of continuous variables? (Temperature, time, weight, distance)</p> </li> <li> <p>Could a variable that seems discrete sometimes be treated as continuous? (Think about age - we say \"16 years old\" but really we're 16.347... years old)</p> </li> </ul>"},{"location":"sims/discrete-continuous-numberline/#assessment","title":"Assessment","text":"<p>Have students classify the following as discrete or continuous:</p> <ol> <li>Number of students in a class (discrete)</li> <li>Amount of water in a glass (continuous)</li> <li>Number of text messages sent (discrete)</li> <li>Speed of a car (continuous)</li> <li>Number of pages in a book (discrete)</li> <li>Room temperature (continuous)</li> </ol>"},{"location":"sims/discrete-continuous-numberline/#extension-activity","title":"Extension Activity","text":"<p>Challenge students to think of a variable that could be argued as either discrete or continuous depending on context (e.g., money - discrete at the cent level, but often treated as continuous in economics).</p>"},{"location":"sims/discrete-continuous-numberline/#references","title":"References","text":"<ul> <li>AP Statistics Course Description</li> <li>Khan Academy: Discrete and Continuous Random Variables</li> <li>Statistics by Jim: Discrete vs Continuous Data</li> </ul>"},{"location":"sims/distribution-shape-gallery/","title":"Distribution Shape Gallery","text":"<p>Run the Distribution Shape Gallery Fullscreen</p> <p>You can include this MicroSim on your website using the following iframe:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/distribution-shape-gallery/main.html\" height=\"452px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/distribution-shape-gallery/#description","title":"Description","text":"<p>Let's crack this nut! When you look at a histogram, the overall shape tells you a story about your data. This MicroSim introduces you to three of the most common distribution shapes you will encounter in statistics.</p>"},{"location":"sims/distribution-shape-gallery/#the-three-distribution-types","title":"The Three Distribution Types","text":"<p>Unimodal (Blue): This is the \"one hill\" distribution. Think of it like a mountain with a single peak. The data clusters around one central value, with fewer and fewer observations as you move away from the center. This is probably the shape you will see most often in the real world.</p> <p>Bimodal (Purple): Two peaks? That usually means two different groups are hiding in your data! When you see this shape, it's often a clue that your data might actually be a mixture of two separate populations. Sylvia loves this one because it's like finding two different species of acorns in the same pile.</p> <p>Uniform (Green): The \"flat top\" distribution. Every value is equally likely, which is surprisingly rare in nature but common in games of chance. When you roll a fair die many times, each number from 1 to 6 should appear about the same number of times.</p>"},{"location":"sims/distribution-shape-gallery/#how-to-use-this-microsim","title":"How to Use This MicroSim","text":"<ol> <li>Explore the Gallery: Hover over each distribution to see additional real-world examples in the tooltip.</li> <li>Click to Enlarge: Click on any distribution to see a larger view with all five examples listed.</li> <li>Shuffle Examples: Click the \"Shuffle Examples\" button to see different real-world scenarios for each type.</li> <li>Test Yourself: Click \"Quiz Mode\" to practice identifying distribution types from real-world scenarios.</li> </ol>"},{"location":"sims/distribution-shape-gallery/#what-to-notice","title":"What to Notice","text":"<p>Each histogram has its peak regions shaded to highlight where the data concentrates. For unimodal distributions, there's one shaded region in the center. For bimodal, you'll see two. For uniform, there's no shading because the data is spread evenly, with no concentration anywhere.</p> <p>Acorn for your thoughts? As you explore, think about data you encounter in your own life. What shape would the distribution of your quiz scores have? What about the ages of people at a family reunion?</p>"},{"location":"sims/distribution-shape-gallery/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/distribution-shape-gallery/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ol> <li>Identify the three main distribution shapes: unimodal, bimodal, and uniform</li> <li>Describe the key visual feature that distinguishes each shape</li> <li>Match real-world examples to the appropriate distribution type</li> <li>Explain what a distribution shape might reveal about the underlying data</li> </ol>"},{"location":"sims/distribution-shape-gallery/#target-audience","title":"Target Audience","text":"<ul> <li>High school students (grades 9-12)</li> <li>College introductory statistics students</li> <li>AP Statistics students (Unit 1: Exploring One-Variable Data)</li> </ul>"},{"location":"sims/distribution-shape-gallery/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of histograms and frequency distributions</li> <li>Familiarity with the concept of data variability</li> </ul>"},{"location":"sims/distribution-shape-gallery/#duration","title":"Duration","text":"<p>10-15 minutes</p>"},{"location":"sims/distribution-shape-gallery/#blooms-taxonomy-level","title":"Bloom's Taxonomy Level","text":"<p>Remember (Level 1) - Students recognize and identify distribution shapes from visual examples</p>"},{"location":"sims/distribution-shape-gallery/#activities","title":"Activities","text":""},{"location":"sims/distribution-shape-gallery/#activity-1-gallery-exploration-3-4-minutes","title":"Activity 1: Gallery Exploration (3-4 minutes)","text":"<ol> <li>Have students hover over each distribution type and read the tooltip examples.</li> <li>Ask: \"Which examples were most surprising to you? Why?\"</li> <li>Click on each distribution to view the enlarged panel with all examples.</li> </ol>"},{"location":"sims/distribution-shape-gallery/#activity-2-shuffle-and-predict-3-4-minutes","title":"Activity 2: Shuffle and Predict (3-4 minutes)","text":"<ol> <li>Click \"Shuffle Examples\" to generate new scenarios.</li> <li>Before reading the labels, have students predict which distribution type matches each example.</li> <li>Discussion: \"What clues helped you make your predictions?\"</li> </ol>"},{"location":"sims/distribution-shape-gallery/#activity-3-quiz-mode-challenge-5-7-minutes","title":"Activity 3: Quiz Mode Challenge (5-7 minutes)","text":"<ol> <li>Enter Quiz Mode and answer at least 5 questions.</li> <li>Track your accuracy as a class.</li> <li>Discussion: \"Which distribution type was hardest to identify? Why?\"</li> </ol>"},{"location":"sims/distribution-shape-gallery/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>A histogram of times between eruptions of a geyser shows two distinct peaks. What type of distribution is this?</li> <li>If you rolled a fair 20-sided die 1,000 times and made a histogram, what shape would you expect?</li> <li>Why might data about commute times in a city show a bimodal distribution?</li> <li>Give an example of data from your daily life that would likely be unimodal.</li> </ol>"},{"location":"sims/distribution-shape-gallery/#common-misconceptions","title":"Common Misconceptions","text":"<ul> <li>\"Bimodal always means exactly two peaks.\" Not quite! Bimodal means approximately two prominent peaks, but the peaks don't need to be identical in height.</li> <li>\"Uniform distributions are boring.\" They're actually fascinating because perfect uniformity is rare in nature. When you see it, it often indicates a designed or artificial process.</li> <li>\"The shape tells me everything about the data.\" Shape is just one aspect. You also need to consider center, spread, and outliers.</li> </ul>"},{"location":"sims/distribution-shape-gallery/#extension-activities","title":"Extension Activities","text":"<ol> <li>Have students collect their own data (e.g., shoe sizes in the class) and identify the distribution shape.</li> <li>Research Old Faithful geyser eruption data and explain why it's bimodal.</li> <li>Brainstorm situations where knowing the distribution shape would affect decision-making.</li> </ol>"},{"location":"sims/distribution-shape-gallery/#references","title":"References","text":"<ol> <li> <p>AP Statistics Course Framework - College Board - Official curriculum including Unit 1: Exploring One-Variable Data.</p> </li> <li> <p>Describing Shape of Distributions - Khan Academy - Video lesson on identifying distribution shapes.</p> </li> <li> <p>Old Faithful Geyser Data - Yellowstone National Park - Classic bimodal dataset used in statistics education.</p> </li> <li> <p>Distribution Shapes - NIST Engineering Statistics Handbook - Technical reference for distribution characteristics.</p> </li> </ol>"},{"location":"sims/empirical-rule/","title":"Empirical Rule (68-95-99.7)","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/empirical-rule/#about-this-microsim","title":"About This MicroSim","text":"<p>Visualize the Empirical Rule (also called the 68-95-99.7 Rule) for normal distributions.</p>"},{"location":"sims/empirical-rule/#how-to-use","title":"How to Use","text":"<ul> <li>Click 1\u03c3, 2\u03c3, or 3\u03c3 buttons to see cumulative regions</li> <li>Each click animates the region filling from the mean outward</li> <li>Use \u25c0 \u25b6 arrows to switch between real-world examples (IQ, Heights, Test Scores)</li> <li>Click Animate to see all three regions build sequentially</li> <li>Click Clear to reset the view</li> </ul>"},{"location":"sims/empirical-rule/#key-insights","title":"Key Insights","text":"<ul> <li>68% of data falls within \u00b11 standard deviation of the mean</li> <li>95% of data falls within \u00b12 standard deviations</li> <li>99.7% of data falls within \u00b13 standard deviations</li> <li>Values beyond 3\u03c3 are extremely rare (&lt;0.3%)</li> </ul>"},{"location":"sims/empirical-rule/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/empirical-rule/#learning-objective","title":"Learning Objective","text":"<p>Students will apply the 68-95-99.7 rule to estimate proportions and identify unusual values in normally distributed data (Bloom's Taxonomy: Applying, Evaluating).</p>"},{"location":"sims/frequency-table-explorer/","title":"Frequency Table Explorer","text":"<p>Run the Frequency Table Explorer MicroSim Fullscreen</p> <p>Edit the Frequency Table Explorer MicroSim with the p5.js editor</p> <p>Place the following line in your website to include this in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/frequency-table-explorer/main.html\" height=\"452px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/frequency-table-explorer/#description","title":"Description","text":"<p>This interactive MicroSim helps students understand how frequency tables work and how to calculate relative frequencies and percentages from raw count data.</p> <p>Key Features:</p> <ul> <li>Adjustable Sliders: Drag the sliders next to each category to change frequency values (0-50)</li> <li>Real-Time Calculations: Watch relative frequencies and percentages update instantly as you adjust values</li> <li>Visual Bars: See proportional bars that represent each category's share of the total</li> <li>Show Steps Toggle: Click \"Show Steps\" to see the calculation process (frequency/total = relative frequency, then multiply by 100 for percentage)</li> <li>Multiple Datasets: Switch between three different categorical datasets (Favorite Season, Pet Preference, Transportation Mode)</li> <li>Reset Button: Return to default values anytime</li> </ul> <p>How to Use:</p> <ol> <li>Start by observing the default frequencies: 8, 22, 14, 6 (total = 50)</li> <li>Notice how each relative frequency is calculated by dividing the frequency by the total</li> <li>Click \"Show Steps\" to see the mathematical process</li> <li>Drag sliders to explore how changing one frequency affects all the percentages</li> <li>Try making all categories equal - what percentage does each get?</li> <li>Switch datasets to practice with different category labels</li> </ol>"},{"location":"sims/frequency-table-explorer/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/frequency-table-explorer/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ol> <li>Calculate relative frequencies by dividing individual frequencies by the total</li> <li>Convert relative frequencies to percentages by multiplying by 100</li> <li>Verify that all relative frequencies sum to 1.000 and all percentages sum to 100%</li> <li>Interpret frequency tables in context of categorical data</li> </ol>"},{"location":"sims/frequency-table-explorer/#target-audience","title":"Target Audience","text":"<ul> <li>AP Statistics students (Chapter 2: Displaying Categorical Data)</li> <li>High school students (grades 9-12)</li> <li>College introductory statistics</li> </ul>"},{"location":"sims/frequency-table-explorer/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of fractions and decimals</li> <li>Basic division skills</li> <li>Familiarity with percentages</li> </ul>"},{"location":"sims/frequency-table-explorer/#warm-up-activity-5-minutes","title":"Warm-Up Activity (5 minutes)","text":"<p>Ask students: \"If a class has 30 students and 12 prefer summer as their favorite season, what fraction of the class prefers summer? What percentage is that?\"</p>"},{"location":"sims/frequency-table-explorer/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<ol> <li>Display the MicroSim with default values</li> <li>Point out the column structure: Category, Frequency, Relative Frequency, Percentage</li> <li>Demonstrate how 22/50 = 0.440 and 0.440 x 100 = 44.0%</li> <li>Click \"Show Steps\" to reveal the calculation process</li> <li>Ask: \"What do all the relative frequencies add up to?\"</li> </ol>"},{"location":"sims/frequency-table-explorer/#independent-practice-15-minutes","title":"Independent Practice (15 minutes)","text":"<p>Have students complete these challenges:</p> <ol> <li>Equal Distribution: Adjust sliders so each category has the same frequency. What percentage does each get?</li> <li>Dominant Category: Make one category have 80% of the total. What frequencies achieve this?</li> <li>Real Data: Survey your table for favorite seasons and enter the data. Calculate if your results match the MicroSim.</li> </ol>"},{"location":"sims/frequency-table-explorer/#discussion-questions","title":"Discussion Questions","text":"<ol> <li>Why do relative frequencies always sum to 1.000?</li> <li>When might relative frequencies be more useful than raw frequencies?</li> <li>How does sample size affect the interpretation of percentages?</li> </ol>"},{"location":"sims/frequency-table-explorer/#assessment","title":"Assessment","text":"<p>Quick Check: If a frequency table has total n = 80 and one category has frequency 20:</p> <ul> <li>What is the relative frequency? (Answer: 0.250)</li> <li>What is the percentage? (Answer: 25.0%)</li> </ul>"},{"location":"sims/frequency-table-explorer/#extension-activities","title":"Extension Activities","text":"<ol> <li>Create a frequency table from class survey data on transportation to school</li> <li>Compare two different sample sizes with the same proportions</li> <li>Discuss how rounding affects the \"100% check\"</li> </ol>"},{"location":"sims/frequency-table-explorer/#references","title":"References","text":"<ol> <li> <p>Khan Academy: Reading and Creating Frequency Tables - Khan Academy - Video tutorial on frequency table fundamentals</p> </li> <li> <p>College Board AP Statistics Course Description - 2024 - College Board - Official AP Statistics curriculum framework including frequency distributions</p> </li> <li> <p>OpenIntro Statistics - 2022 - OpenIntro - Free statistics textbook with extensive coverage of categorical data displays</p> </li> <li> <p>p5.js Reference - p5.js Foundation - Documentation for the JavaScript library used in this MicroSim</p> </li> </ol>"},{"location":"sims/guess-correlation/","title":"Guess the Correlation","text":"<p>Run the Guess the Correlation MicroSim Fullscreen</p>"},{"location":"sims/guess-correlation/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive game helps you develop intuition for the correlation coefficient r by challenging you to estimate its value from scatterplots. The more you practice, the better you will become at recognizing patterns that indicate strong, moderate, weak, or no correlation.</p>"},{"location":"sims/guess-correlation/#what-you-will-learn","title":"What You Will Learn","text":"<ul> <li>How to visually estimate the strength of a linear relationship</li> <li>The difference between positive and negative correlations</li> <li>What scatterplots look like for different r-values (-1 to +1)</li> <li>How sample size affects the apparent clarity of correlation</li> </ul>"},{"location":"sims/guess-correlation/#how-to-use-this-microsim","title":"How to Use This MicroSim","text":"<ol> <li>Examine the scatterplot carefully. Look at the overall pattern and spread of points.</li> <li>Adjust the slider to select your estimate of the correlation coefficient r (from -1 to +1).</li> <li>Click \"Check Answer\" to see how close your guess was to the actual r-value.</li> <li>Click \"New Plot\" to generate a fresh scatterplot and try again.</li> <li>Change difficulty to practice with different sample sizes:</li> <li>Easy: 50 points (clearer patterns)</li> <li>Medium: 30 points (moderate scatter)</li> <li>Hard: 20 points (subtle patterns, more challenging)</li> </ol>"},{"location":"sims/guess-correlation/#scoring","title":"Scoring","text":"<ul> <li>Excellent! Your guess is within 0.1 of the actual r-value. Streak increases!</li> <li>Good estimate! Your guess is within 0.2 of the actual r-value. Streak increases!</li> <li>Keep practicing! Your guess is off by more than 0.2. Streak resets to 0.</li> </ul> <p>Track your current streak and try to beat your high score!</p>"},{"location":"sims/guess-correlation/#iframe-embed-code","title":"Iframe Embed Code","text":"<p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/guess-correlation/main.html\" height=\"502px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/guess-correlation/#concepts-illustrated","title":"Concepts Illustrated","text":""},{"location":"sims/guess-correlation/#the-correlation-coefficient-r","title":"The Correlation Coefficient (r)","text":"<p>The correlation coefficient r measures the strength and direction of the linear relationship between two quantitative variables:</p> <ul> <li>r = +1: Perfect positive linear relationship</li> <li>r = 0: No linear relationship</li> <li>r = -1: Perfect negative linear relationship</li> </ul>"},{"location":"sims/guess-correlation/#visual-patterns-to-look-for","title":"Visual Patterns to Look For","text":"r-value Range Visual Pattern 0.8 to 1.0 Points tightly clustered along a line 0.5 to 0.8 Clear trend with moderate scatter 0.2 to 0.5 Weak trend, substantial scatter -0.2 to 0.2 No obvious pattern, cloud of points -0.5 to -0.2 Weak downward trend -0.8 to -0.5 Clear downward trend -1.0 to -0.8 Tight negative linear pattern"},{"location":"sims/guess-correlation/#sample-size-effects","title":"Sample Size Effects","text":"<p>With smaller samples, the correlation can appear more or less extreme than the true relationship. This is why the \"Hard\" difficulty (n=20) is more challenging. Points naturally cluster in ways that can be misleading.</p>"},{"location":"sims/guess-correlation/#key-insights","title":"Key Insights","text":"<p>Sylvia Says</p> <p>\"Here is a trick I use: imagine drawing an ellipse around all the points. The skinnier that ellipse, the stronger the correlation! A nearly circular cloud means r is close to zero, while a long, thin cigar shape means r is close to +1 or -1. My tail is shaped kind of like a strong correlation, actually!\"</p> <ol> <li> <p>Direction is easy, strength is tricky: Most people can quickly tell if a correlation is positive or negative, but estimating the exact strength takes practice.</p> </li> <li> <p>Outliers can fool you: A single outlier can make r appear weaker than the main pattern suggests.</p> </li> <li> <p>Sample size matters: Fewer points mean more uncertainty in your visual estimate.</p> </li> <li> <p>Perfect correlation is rare: In real data, you almost never see r = 1 or r = -1.</p> </li> </ol>"},{"location":"sims/guess-correlation/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/guess-correlation/#learning-objective","title":"Learning Objective","text":"<p>Students will be able to evaluate (Bloom Level 5) scatterplots and estimate correlation values, developing intuition for what different r-values look like visually.</p>"},{"location":"sims/guess-correlation/#grade-level","title":"Grade Level","text":"<p>High School (AP Statistics) / Introductory College Statistics</p>"},{"location":"sims/guess-correlation/#duration","title":"Duration","text":"<p>20-25 minutes</p>"},{"location":"sims/guess-correlation/#warm-up-activity-3-minutes","title":"Warm-Up Activity (3 minutes)","text":"<p>Ask students: \"If I showed you a scatterplot, what visual features would tell you whether two variables are strongly related?\"</p>"},{"location":"sims/guess-correlation/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<ol> <li>Start on Easy difficulty. Generate a plot and think aloud about your estimation process.</li> <li>Point out the slope (positive vs. negative) and the spread (tight vs. scattered).</li> <li>Make a guess, check the answer, and discuss the feedback.</li> <li>Repeat with 3-4 more plots, gradually involving students in the estimation.</li> <li>Switch to Medium difficulty and discuss how the smaller sample size affects perception.</li> </ol>"},{"location":"sims/guess-correlation/#practice-activity-8-minutes","title":"Practice Activity (8 minutes)","text":"<p>Have students work individually or in pairs:</p> <ul> <li>Each student aims to build a streak of at least 3 correct guesses (within 0.2).</li> <li>Challenge: Can anyone reach a streak of 5 on Hard difficulty?</li> <li>Encourage students to verbalize their reasoning: \"I think this is about 0.6 because...\"</li> </ul>"},{"location":"sims/guess-correlation/#assessment-questions","title":"Assessment Questions","text":"<ol> <li> <p>A scatterplot shows points forming a loose downward trend. You estimate r = -0.4. The actual r = -0.55. Was your estimate reasonable? Why?</p> </li> <li> <p>Why is it harder to estimate r accurately with only 20 data points compared to 50?</p> </li> <li> <p>Two students look at the same scatterplot. One guesses r = 0.7, the other guesses r = 0.3. What visual features might they be interpreting differently?</p> </li> <li> <p>Can a scatterplot with r = 0 still show a strong pattern? Explain.</p> </li> </ol>"},{"location":"sims/guess-correlation/#extension-activities","title":"Extension Activities","text":"<ol> <li> <p>Create Your Own Challenge: Have students describe a scatterplot in words (without seeing it) and have a partner guess the r-value based on the description.</p> </li> <li> <p>Real Data Practice: Find real scatterplots online and have students estimate r before looking up the actual value.</p> </li> <li> <p>Discussion: Why do statisticians calculate r precisely rather than just estimating visually?</p> </li> </ol>"},{"location":"sims/guess-correlation/#technical-notes","title":"Technical Notes","text":"<p>This MicroSim generates correlated bivariate normal data using the Cholesky decomposition method:</p> \\[ y = r \\cdot x + \\sqrt{1 - r^2} \\cdot z \\] <p>where x and z are independent standard normal variables. This ensures the generated data has approximately the target correlation.</p> <p>The actual r-value displayed is calculated from the generated data using the Pearson correlation formula, so it may differ slightly from the target due to random sampling.</p>"},{"location":"sims/guess-correlation/#references","title":"References","text":"<ul> <li>Pearson Correlation Coefficient - Wikipedia</li> <li>Moore, D. S., &amp; Notz, W. I. (2020). Statistics: Concepts and Controversies (10th ed.). W.H. Freeman.</li> <li>De Veaux, R. D., Velleman, P. F., &amp; Bock, D. E. (2021). Stats: Data and Models (5th ed.). Pearson.</li> <li>Guess the Correlation Game - Inspiration for this educational MicroSim</li> </ul>"},{"location":"sims/histogram-explorer/","title":"Interactive Histogram Explorer","text":"<p>Run the Histogram Explorer MicroSim Fullscreen</p> <p>Edit the Histogram Explorer MicroSim with the p5.js editor</p>"},{"location":"sims/histogram-explorer/#iframe-embed-code","title":"Iframe Embed Code","text":"<p>Place the following line in your website to include this MicroSim in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/histogram-explorer/main.html\" height=\"552px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/histogram-explorer/#description","title":"Description","text":"<p>This interactive histogram explorer helps students understand one of the most important concepts in data visualization: how bin width choices affect the appearance and interpretation of histograms. By manipulating the bin width slider, students can observe how the same dataset can look dramatically different depending on binning decisions.</p> <p>Key features:</p> <ul> <li>Bin Width Slider (2-20): Adjust to see how narrower bins reveal more detail while wider bins show broader patterns</li> <li>Multiple Datasets: Test Scores (n=40), Heights (n=100), Temperatures (n=365), and a bimodal Custom dataset (n=50)</li> <li>Frequency vs Relative Frequency: Toggle between count-based and proportion-based displays</li> <li>Show Data Points: Overlay the actual data values below the histogram</li> <li>Hover Highlighting: Move your mouse over bars to see exact counts</li> <li>Visual Warnings: The MicroSim warns when bin widths may be too narrow (losing the pattern) or too wide (losing detail)</li> <li>Statistics Panel: Displays n, min, max, range, and current number of bins</li> </ul>"},{"location":"sims/histogram-explorer/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/histogram-explorer/#learning-objective","title":"Learning Objective","text":"<p>Students will be able to examine how changing bin width affects histogram appearance by manipulating the bin width slider and observing how the shape, pattern visibility, and interpretability of the histogram changes.</p> <p>Bloom's Taxonomy Level: Analyze (L4)</p> <p>Bloom's Verb: Examine</p>"},{"location":"sims/histogram-explorer/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of what a histogram represents</li> <li>Familiarity with frequency and relative frequency concepts</li> <li>Basic knowledge of data distribution shapes (symmetric, skewed, bimodal)</li> </ul>"},{"location":"sims/histogram-explorer/#suggested-duration","title":"Suggested Duration","text":"<p>15-20 minutes for guided exploration</p>"},{"location":"sims/histogram-explorer/#classroom-activities","title":"Classroom Activities","text":""},{"location":"sims/histogram-explorer/#activity-1-discover-the-goldilocks-zone-5-minutes","title":"Activity 1: Discover the Goldilocks Zone (5 minutes)","text":"<ol> <li>Start with the Test Scores dataset at the default bin width of 10</li> <li>Have students drag the slider all the way left (bin width = 2) and describe what they see</li> <li>Then drag all the way right (bin width = 20) and describe again</li> <li>Ask: \"Which bin width tells the best story about this data? Why?\"</li> </ol>"},{"location":"sims/histogram-explorer/#activity-2-dataset-comparison-5-minutes","title":"Activity 2: Dataset Comparison (5 minutes)","text":"<ol> <li>Keep bin width at 10 and switch between all four datasets</li> <li>For each dataset, ask students to adjust the bin width until they find the most informative view</li> <li>Discuss: \"Why might different datasets need different bin widths?\"</li> </ol>"},{"location":"sims/histogram-explorer/#activity-3-pattern-recognition-5-minutes","title":"Activity 3: Pattern Recognition (5 minutes)","text":"<ol> <li>Select the Custom dataset (which is bimodal)</li> <li>Start at bin width 20 - can students see that it's bimodal?</li> <li>Gradually decrease bin width - at what point do two peaks become visible?</li> <li>Discuss: \"How might using the wrong bin width lead to incorrect conclusions?\"</li> </ol>"},{"location":"sims/histogram-explorer/#discussion-questions","title":"Discussion Questions","text":"<ol> <li>What happens to the number of bins as you increase the bin width?</li> <li>Why might relative frequency be more useful than raw frequency when comparing different-sized datasets?</li> <li>How does the Temperatures dataset differ from the Test Scores dataset in shape?</li> <li>What real-world decisions might depend on choosing an appropriate bin width?</li> </ol>"},{"location":"sims/histogram-explorer/#assessment-opportunities","title":"Assessment Opportunities","text":"<ul> <li>Have students sketch the same dataset at three different bin widths and explain which they would use in a report</li> <li>Ask students to predict what a histogram will look like before changing the bin width</li> <li>Have students identify when the warning messages appear and explain why</li> </ul>"},{"location":"sims/histogram-explorer/#common-misconceptions-to-address","title":"Common Misconceptions to Address","text":"<ul> <li>More bins = more accurate: Explain that too many bins can create noise and hide patterns</li> <li>Bin width is objective: Emphasize that bin width is a choice that affects interpretation</li> <li>Histograms show individual values: Clarify that histograms show frequencies within ranges, not individual data points</li> </ul>"},{"location":"sims/histogram-explorer/#references","title":"References","text":"<ul> <li>AP Statistics Course and Exam Description</li> <li>Guidelines for Assessment and Instruction in Statistics Education (GAISE)</li> <li>Sturges, H.A. (1926). \"The Choice of a Class Interval\". Journal of the American Statistical Association.</li> </ul>"},{"location":"sims/histogram-explorer/#technical-notes","title":"Technical Notes","text":"<ul> <li>Built with p5.js 1.11.10</li> <li>Uses canvas-based controls for iframe compatibility</li> <li>Width-responsive design adapts to container size</li> <li>Drawing height: 400px, Control height: 150px, Total: 550px</li> </ul> <p>Reminder: Create a screenshot named <code>histogram-explorer.png</code> for social media previews.</p>"},{"location":"sims/household-income-boxplot/","title":"Household Income Boxplot Explorer","text":"<p>Run the Household Income Boxplot Explorer MicroSim Fullscreen</p>"},{"location":"sims/household-income-boxplot/#iframe-embed-code","title":"Iframe Embed Code","text":"<p>Place the following line in your website to include this MicroSim in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/household-income-boxplot/main.html\" height=\"620px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/household-income-boxplot/#about-this-microsim","title":"About This MicroSim","text":"<p>Sylvia says: \"I love a boxplot because it tells the whole story without making me count every acorn. The long whisker here is a big clue that a few households earn way more than most.\"</p> <p>This MicroSim simulates household incomes in a city (in thousands of dollars). The distribution is intentionally right-skewed, so the median sits closer to Q1 than Q3, and the mean typically sits above the median. Toggle the high-income outlier to see how a long upper whisker highlights inequality.</p> <p>Key features:</p> <ul> <li>Right-skewed income data generated each time you click \u201cNew city sample\u201d</li> <li>Five-number summary shown beneath the plot</li> <li>Mean marker to compare mean vs median</li> <li>Outlier toggle to emphasize long upper whiskers</li> <li>Individual points overlay to reveal household-level variation</li> </ul>"},{"location":"sims/household-income-boxplot/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/household-income-boxplot/#learning-objective","title":"Learning Objective","text":"<p>Students will interpret a right-skewed boxplot by identifying the five-number summary and comparing mean and median.</p> <p>Bloom's Taxonomy Level: Analyze (L4)</p> <p>Bloom's Verb: Interpret</p>"},{"location":"sims/household-income-boxplot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of quartiles and median</li> <li>Familiarity with boxplots</li> </ul>"},{"location":"sims/household-income-boxplot/#suggested-duration","title":"Suggested Duration","text":"<p>10-15 minutes for guided exploration</p>"},{"location":"sims/household-income-boxplot/#classroom-activities","title":"Classroom Activities","text":""},{"location":"sims/household-income-boxplot/#activity-1-spot-the-skew-5-minutes","title":"Activity 1: Spot the Skew (5 minutes)","text":"<ol> <li>Load the default view and ask students: \"Which whisker is longer?\"</li> <li>Have them explain what the long upper whisker implies about very high incomes.</li> <li>Ask: \"Where is the median compared to Q1 and Q3?\"</li> </ol>"},{"location":"sims/household-income-boxplot/#activity-2-mean-vs-median-5-minutes","title":"Activity 2: Mean vs Median (5 minutes)","text":"<ol> <li>Keep the mean marker visible.</li> <li>Ask: \"Is the mean above or below the median? Why?\"</li> <li>Increase the inequality slider and observe how the mean moves.</li> </ol>"},{"location":"sims/household-income-boxplot/#activity-3-inequality-without-raw-data-3-minutes","title":"Activity 3: Inequality Without Raw Data (3 minutes)","text":"<ol> <li>Hide the individual points.</li> <li>Ask: \"What can we say about inequality just from the boxplot?\"</li> <li>Toggle the outlier and discuss the change in the maximum.</li> </ol>"},{"location":"sims/household-income-boxplot/#discussion-questions","title":"Discussion Questions","text":"<ol> <li>Why does the median stay closer to Q1 in a right-skewed distribution?</li> <li>How does a single high-income outlier affect the maximum and whisker length?</li> <li>What does the distance between Q1 and Q3 tell you about typical households?</li> </ol>"},{"location":"sims/household-income-boxplot/#assessment-opportunities","title":"Assessment Opportunities","text":"<ul> <li>Quick write: \"Describe the distribution using center and spread.\"</li> <li>Compare two boxplots (before/after higher inequality) and interpret the change.</li> </ul>"},{"location":"sims/household-income-boxplot/#common-misconceptions-to-address","title":"Common Misconceptions to Address","text":"<ul> <li>The mean equals the median: Show how skew pushes the mean upward.</li> <li>Whiskers are averages: Clarify they show data ranges, not means.</li> <li>Small box means low values: Emphasize that box size shows spread, not level.</li> </ul>"},{"location":"sims/household-income-boxplot/#technical-notes","title":"Technical Notes","text":"<ul> <li>Built with Plotly.js</li> <li>Responsive layout for iframe embedding</li> <li>Incomes generated from a log-normal model and clamped to realistic bounds</li> </ul> <p>Reminder: Create a screenshot named <code>household-income-boxplot.png</code> for social media previews.</p>"},{"location":"sims/interactive-dotplot-builder/","title":"Interactive Dotplot Builder","text":"<p>Run the Interactive Dotplot Builder MicroSim Fullscreen</p> <p>Edit the Interactive Dotplot Builder MicroSim with the p5.js Editor</p> <p>Place the following line in your website to include this in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/interactive-dotplot-builder/main.html\" height=\"432px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/interactive-dotplot-builder/#description","title":"Description","text":"<p>This MicroSim helps students understand how dotplots are constructed by allowing them to click on a number line to add individual data points. Each click places a dot at the nearest integer value, and dots stack vertically when multiple observations share the same value. This hands-on approach reinforces the concept that each dot represents one observation in the dataset.</p> <p>How to Use:</p> <ol> <li>Add Data Points: Click anywhere on or above the number line to add a dot at the nearest integer value (0-15)</li> <li>Clear All: Remove all data points and start fresh</li> <li>Load Sample Data: Load a pre-made dataset of study hours to see a typical distribution</li> <li>Random Data: Generate 10-20 random values to explore different distributions</li> <li>Dot Size: Use the radio buttons to adjust dot size for better visibility</li> </ol> <p>The display panel shows the current count of observations, the dataset values, and basic statistics (minimum, maximum, and range).</p>"},{"location":"sims/interactive-dotplot-builder/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/interactive-dotplot-builder/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ul> <li>Demonstrate how to construct a dotplot by placing individual data points on a number line</li> <li>Explain that each dot represents one observation in the dataset</li> <li>Identify clusters, gaps, and the overall shape of a distribution</li> <li>Describe the spread of data using minimum, maximum, and range</li> </ul>"},{"location":"sims/interactive-dotplot-builder/#target-audience","title":"Target Audience","text":"<ul> <li>High school students in introductory statistics (AP Statistics)</li> <li>College students in introductory statistics courses</li> <li>Grade level: 9-12 and undergraduate</li> </ul>"},{"location":"sims/interactive-dotplot-builder/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of quantitative vs. categorical data</li> <li>Familiarity with number lines</li> <li>Basic understanding of what a dataset is</li> </ul>"},{"location":"sims/interactive-dotplot-builder/#activities","title":"Activities","text":"<p>Activity 1: Build Your Own Dotplot (10 minutes)</p> <ol> <li>Clear the dotplot and create your own dataset by clicking to add at least 15 data points</li> <li>Try to create a dataset that shows: a symmetric distribution, then clear and create one with a skewed distribution</li> <li>Observe how the shape changes as you add more points</li> </ol> <p>Activity 2: Explore the Sample Data (5 minutes)</p> <ol> <li>Click \"Load Sample Data\" to see study hours data</li> <li>Identify the mode (most common value), any clusters, and any gaps</li> <li>Discuss: What can you conclude about students' study habits from this distribution?</li> </ol> <p>Activity 3: Random Data Investigation (10 minutes)</p> <ol> <li>Click \"Random Data\" several times and observe different distributions</li> <li>For each random dataset, describe: the shape, the center (approximately), and the spread</li> <li>Compare: Do random datasets tend to look similar or different? Why?</li> </ol>"},{"location":"sims/interactive-dotplot-builder/#assessment","title":"Assessment","text":"<ul> <li>Ask students to sketch a dotplot by hand after using the interactive version</li> <li>Have students describe a distribution shown in the MicroSim using statistical vocabulary</li> <li>Quiz: Given a list of data values, have students predict what the dotplot will look like before clicking \"Load Sample Data\"</li> </ul>"},{"location":"sims/interactive-dotplot-builder/#references","title":"References","text":"<ol> <li> <p>Dotplots - Wikipedia - General reference on dotplots as a statistical visualization method</p> </li> <li> <p>AP Statistics Course Description - College Board - Official course framework including dotplot construction skills</p> </li> <li> <p>p5.js Reference - Documentation for the p5.js library used in this MicroSim</p> </li> </ol>"},{"location":"sims/law-large-numbers/","title":"Law of Large Numbers Demonstrator","text":"<p>Run the Law of Large Numbers Demonstrator Fullscreen</p> <p>Edit this MicroSim in the p5.js Editor</p>"},{"location":"sims/law-large-numbers/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive demonstration shows the Law of Large Numbers in action. Students can set the true probability P(H) using a slider and then flip virtual coins to observe how the observed proportion converges to the true probability as the number of trials increases. The convergence graph uses color coding to show how close the current proportion is to the true value.</p>"},{"location":"sims/law-large-numbers/#how-to-use","title":"How to Use","text":"<ol> <li>Set the true probability P(H) using the slider (default 0.5)</li> <li>Click \"Flip 1\" to see individual coin flips</li> <li>Click \"Flip 10\", \"Flip 100\" to quickly accumulate trials</li> <li>Click \"Flip Until Stable\" to run until within 0.01 of true P</li> <li>Observe the graph showing convergence over time</li> <li>Watch the color change from red (far from P) to green (close to P)</li> </ol>"},{"location":"sims/law-large-numbers/#key-concepts","title":"Key Concepts","text":"<ul> <li>Law of Large Numbers: As trials increase, the observed proportion converges to the true probability</li> <li>Short-run variability: Early results can deviate significantly from the true probability</li> <li>Long-run stability: With enough trials, the proportion stabilizes near the true value</li> </ul>"},{"location":"sims/law-large-numbers/#learning-objectives","title":"Learning Objectives","text":"<p>After using this MicroSim, students will be able to:</p> <ul> <li>Explain the Law of Large Numbers in their own words</li> <li>Observe how short-term randomness becomes long-term regularity</li> <li>Avoid the Gambler's Fallacy (past results don't affect future independent trials)</li> <li>Understand why sample size matters for reliable estimates</li> </ul>"},{"location":"sims/law-large-numbers/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/law-large-numbers/main.html\" height=\"452px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/law-large-numbers/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/law-large-numbers/#introduction-5-minutes","title":"Introduction (5 minutes)","text":"<p>Ask: \"If you flip a fair coin 10 times, will you always get exactly 5 heads?\" Lead into the concept of variability.</p>"},{"location":"sims/law-large-numbers/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<p>Demonstrate with different true probabilities. Note how the graph \"settles down\" with more trials.</p>"},{"location":"sims/law-large-numbers/#practice-activities-10-minutes","title":"Practice Activities (10 minutes)","text":"<p>Have students predict how many trials they'll need to get within 0.05 of the true probability for different P values.</p>"},{"location":"sims/law-large-numbers/#common-misconceptions","title":"Common Misconceptions","text":"<p>Address the Gambler's Fallacy: Getting 5 heads in a row doesn't make tails \"due\" on the next flip.</p>"},{"location":"sims/law-large-numbers/#assessment","title":"Assessment","text":"<p>Students explain why casinos always win in the long run, connecting to the Law of Large Numbers.</p>"},{"location":"sims/law-large-numbers/#references","title":"References","text":"<ul> <li>Chapter 9: Probability Fundamentals</li> <li>Concepts: Law of Large Numbers</li> </ul>"},{"location":"sims/mean-balance-point/","title":"Mean as Balance Point","text":"<p>Run the Mean as Balance Point MicroSim Fullscreen</p> <p>Edit this MicroSim in the p5.js Editor</p>"},{"location":"sims/mean-balance-point/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive visualization helps students understand that the mean represents the balance point of a distribution. Just like weights on a seesaw, data points exert \"torque\" around the mean, and the mean is the unique position where these forces balance.</p>"},{"location":"sims/mean-balance-point/#how-to-use","title":"How to Use","text":"<ul> <li>Drag data points left or right to see the mean update in real-time</li> <li>Click on the number line to add new data points</li> <li>Double-click a point to remove it</li> <li>Toggle Show Calculation to see the sum and division</li> </ul>"},{"location":"sims/mean-balance-point/#key-insights","title":"Key Insights","text":"<ol> <li>Moving a point farther from the center causes a larger shift in the mean</li> <li>Adding an extreme value dramatically shifts the balance point</li> <li>The beam tilts toward the \"heavier\" side until the fulcrum is at the mean</li> <li>The mean is sensitive to outliers - one extreme value can pull it significantly</li> </ol>"},{"location":"sims/mean-balance-point/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/mean-balance-point/#learning-objective","title":"Learning Objective","text":"<p>Students will understand that the mean represents the balance point of a distribution by manipulating data points and observing how the mean shifts in response (Bloom's Taxonomy: Understanding).</p>"},{"location":"sims/mean-balance-point/#activities","title":"Activities","text":"<ol> <li>Exploration (5 min): Let students freely manipulate points to develop intuition</li> <li>Prediction (5 min): Before moving a point, ask students to predict which direction the mean will shift</li> <li>Outlier Investigation (5 min): Add an extreme value (like 95) and observe the dramatic shift</li> <li>Discussion: Why is the median sometimes preferred over the mean?</li> </ol>"},{"location":"sims/mean-balance-point/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>If all data points are at the same location, where is the mean?</li> <li>What happens to the mean when you add a point at 0? At 100?</li> <li>If you have points at 20, 30, 40, and 50, where should you add a fifth point to make the mean exactly 40?</li> </ol>"},{"location":"sims/mean-balance-point/#references","title":"References","text":"<ul> <li>Khan Academy: Mean, Median, and Mode</li> <li>OpenStax Introductory Statistics, Chapter 2</li> </ul>"},{"location":"sims/mean-median-skewness/","title":"Mean vs Median Skewness","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/mean-median-skewness/#about-this-microsim","title":"About This MicroSim","text":"<p>Explore the relationship between the mean and median in different distribution shapes.</p>"},{"location":"sims/mean-median-skewness/#how-to-use","title":"How to Use","text":"<ul> <li>Click Symmetric, Right-skewed, or Left-skewed to see preset distributions</li> <li>Add outliers to see how they affect the mean (but not the median!)</li> <li>Observe how the relationship changes: Mean &gt; Median, Mean &lt; Median, or Mean \u2248 Median</li> </ul>"},{"location":"sims/mean-median-skewness/#key-insights","title":"Key Insights","text":"<ul> <li>Symmetric: Mean \u2248 Median</li> <li>Right-skewed: Mean &gt; Median (pulled toward the long right tail)</li> <li>Left-skewed: Mean &lt; Median (pulled toward the long left tail)</li> <li>The median is resistant to outliers; the mean is not</li> </ul>"},{"location":"sims/mean-median-skewness/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/mean-median-skewness/#learning-objective","title":"Learning Objective","text":"<p>Students will predict the relative positions of mean and median based on distribution shape (Bloom's Taxonomy: Analyzing, Evaluating).</p>"},{"location":"sims/normal-distribution-explorer/","title":"Normal Distribution Parameter Explorer","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/normal-distribution-explorer/#about-this-microsim","title":"About This MicroSim","text":"<p>Explore how the mean (\u03bc) and standard deviation (\u03c3) parameters shape a normal distribution curve.</p>"},{"location":"sims/normal-distribution-explorer/#how-to-use","title":"How to Use","text":"<ul> <li>Adjust \u03bc\u2081 slider to shift the curve left or right (changes center)</li> <li>Adjust \u03c3\u2081 slider to make the curve wider/flatter or narrower/taller</li> <li>Click Compare to add a second curve for side-by-side comparison</li> <li>Use Reset to return to default values</li> </ul>"},{"location":"sims/normal-distribution-explorer/#key-insights","title":"Key Insights","text":"<ul> <li>Mean (\u03bc) determines the center/peak location of the curve</li> <li>Standard deviation (\u03c3) determines the spread/width</li> <li>Larger \u03c3 \u2192 wider, shorter curve (more spread out)</li> <li>Smaller \u03c3 \u2192 narrower, taller curve (more concentrated)</li> <li>Total area under any normal curve always equals 1</li> </ul>"},{"location":"sims/normal-distribution-explorer/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/normal-distribution-explorer/#learning-objective","title":"Learning Objective","text":"<p>Students will predict how changes to \u03bc and \u03c3 will affect the shape and position of a normal distribution curve (Bloom's Taxonomy: Understanding, Analyzing).</p>"},{"location":"sims/normal-probability-calc/","title":"Normal Probability Calculator","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/normal-probability-calc/#about-this-microsim","title":"About This MicroSim","text":"<p>Calculate probabilities for normal distributions with interactive visualization.</p>"},{"location":"sims/normal-probability-calc/#how-to-use","title":"How to Use","text":"<ul> <li>Select query type: P(X &lt; a), P(X &gt; a), or P(a &lt; X &lt; b)</li> <li>Drag the orange marker(s) to change boundary values</li> <li>Adjust \u03bc and \u03c3 sliders to change distribution parameters</li> <li>See both z-scores and probabilities update in real time</li> </ul>"},{"location":"sims/normal-probability-calc/#key-insights","title":"Key Insights","text":"<ul> <li>Left-tail probability P(X &lt; a): Area from negative infinity to a</li> <li>Right-tail probability P(X &gt; a): Area from a to positive infinity</li> <li>Between probability P(a &lt; X &lt; b): Area between two values</li> <li>Probabilities are shown as both decimals and percentages</li> <li>Z-scores show how many SDs each value is from the mean</li> </ul>"},{"location":"sims/normal-probability-calc/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/normal-probability-calc/#learning-objective","title":"Learning Objective","text":"<p>Students will calculate and interpret probabilities from normal distributions using the standard normal curve (Bloom's Taxonomy: Applying, Analyzing).</p>"},{"location":"sims/normal-probability-plot/","title":"Normal Probability Plot Explorer","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/normal-probability-plot/#about-this-microsim","title":"About This MicroSim","text":"<p>Assess whether data follows a normal distribution by comparing histograms and normal probability plots (QQ plots).</p>"},{"location":"sims/normal-probability-plot/#how-to-use","title":"How to Use","text":"<ul> <li>Select a dataset type: Approximately Normal, Right Skewed, Left Skewed, Heavy Tails, Light Tails, Uniform, or Bimodal</li> <li>Adjust sample size (n) slider from 20 to 200</li> <li>Click New Sample to generate fresh random data</li> <li>Toggle Ref Line to show/hide the reference line on QQ plot</li> <li>Toggle Overlay to show/hide ideal normal curve on histogram</li> </ul>"},{"location":"sims/normal-probability-plot/#key-insights","title":"Key Insights","text":"<ul> <li>Normal data: Points cluster tightly around the reference line in QQ plot</li> <li>Right-skewed: Points curve upward at the right end</li> <li>Left-skewed: Points curve downward at the left end</li> <li>Heavy tails: S-shaped curve (deviations at both ends)</li> <li>Light tails: Points cluster more tightly than expected</li> <li>The \"Normality Verdict\" provides automatic assessment with explanation</li> </ul>"},{"location":"sims/normal-probability-plot/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/normal-probability-plot/#learning-objective","title":"Learning Objective","text":"<p>Students will assess whether data follows a normal distribution by interpreting histograms and normal probability plots (Bloom's Taxonomy: Analyzing, Evaluating).</p>"},{"location":"sims/outlier-detection/","title":"Outlier Detection","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/outlier-detection/#about-this-microsim","title":"About This MicroSim","text":"<p>Explore how the 1.5 \u00d7 IQR rule identifies potential outliers. The fences define boundaries, and any points beyond them are flagged as outliers.</p>"},{"location":"sims/outlier-detection/#how-to-use","title":"How to Use","text":"<ul> <li>Drag points to change their values and see outlier status update in real-time</li> <li>Adjust the Multiplier slider (default 1.5) to see how fence positions change</li> <li>Toggle Show Calculations to see the fence formulas</li> <li>Toggle Modified Boxplot to compare standard vs. modified whisker placement</li> </ul>"},{"location":"sims/outlier-detection/#key-insights","title":"Key Insights","text":"<ul> <li>Outliers are values below Q1 - 1.5\u00d7IQR or above Q3 + 1.5\u00d7IQR</li> <li>The 1.5 multiplier is a convention, not a law</li> <li>Modified boxplots show outliers as individual points</li> </ul>"},{"location":"sims/outlier-detection/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/outlier-detection/#learning-objective","title":"Learning Objective","text":"<p>Students will apply the 1.5 \u00d7 IQR rule to identify potential outliers in a dataset (Bloom's Taxonomy: Applying, Analyzing).</p>"},{"location":"sims/outlier-detective/","title":"Outlier Detective Game","text":"<p>Run the Outlier Detective Game Fullscreen</p>"},{"location":"sims/outlier-detective/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<p>Place the following line in your website to include this MicroSim in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/outlier-detective/main.html\" height=\"462px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/outlier-detective/#about-this-microsim","title":"About This MicroSim","text":"<p>The Outlier Detective Game is an engaging way for students to develop their ability to identify outliers in datasets. Instead of memorizing rules like \"1.5 times the IQR,\" students build intuition by examining data points visually and considering real-world context.</p> <p>Each challenge presents a dataset with a story: test scores where one student was absent, ages at a birthday party including a parent chaperone, marathon times with an elite runner mixed in, or rainfall data that includes a hurricane day. Students must click on the points they believe are outliers, then submit their answer for scoring.</p>"},{"location":"sims/outlier-detective/#game-features","title":"Game Features","text":"<ul> <li>10 rounds of outlier detection challenges</li> <li>Scoring system: +10 points for correct identifications, -5 for false positives</li> <li>Three difficulty levels: Easy shows obvious outliers, Hard may have none at all</li> <li>Two view modes: Dotplot for detailed point inspection, Histogram for distribution shape</li> <li>Real-world contexts: Each dataset tells a story that explains why outliers might exist</li> <li>Immediate feedback: See which points you correctly identified, missed, or incorrectly selected</li> </ul>"},{"location":"sims/outlier-detective/#controls","title":"Controls","text":"Control Function Dotplot/Histogram Toggle between visualization types Difficulty slider Easy (1-2 outliers), Medium (0-2), Hard (0-3, sometimes none) Submit Answer Check your selections and earn points Reveal Correct Show the actual outliers without scoring Next Challenge Move to the next round"},{"location":"sims/outlier-detective/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/outlier-detective/#learning-objective","title":"Learning Objective","text":"<p>Students will distinguish between outliers and non-outliers by examining visual separation in data displays and considering the context of the data collection.</p>"},{"location":"sims/outlier-detective/#blooms-taxonomy-level","title":"Bloom's Taxonomy Level","text":"<p>Analyze (Level 4) - Students analyze datasets to distinguish between data points that are part of the main distribution versus those that are unusually far from the center.</p>"},{"location":"sims/outlier-detective/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of dotplots and histograms</li> <li>Basic concept of data distribution and spread</li> <li>Familiarity with terms like \"center\" and \"variability\"</li> </ul>"},{"location":"sims/outlier-detective/#suggested-activities","title":"Suggested Activities","text":"<p>Individual Exploration (10 minutes)</p> <ol> <li>Have students play 5 rounds on Easy difficulty</li> <li>Ask: \"What visual patterns help you spot outliers?\"</li> <li>Discuss: Why do outliers exist in real datasets?</li> </ol> <p>Class Discussion (10 minutes)</p> <p>Switch to Medium or Hard difficulty and project for the class:</p> <ul> <li>Before revealing answers, have students vote on which points are outliers</li> <li>Discuss why some cases are ambiguous</li> <li>Connect to the formal IQR rule without making it the focus</li> </ul> <p>Critical Thinking Extension</p> <p>Present these questions after gameplay:</p> <ol> <li>\"A student got a 0 on a test. Is this always an outlier? What if many students failed?\"</li> <li>\"In the birthday party example, the parent's age is unusual. But is it an error? Should we remove it from our analysis?\"</li> <li>\"What's the difference between an outlier and a data entry error?\"</li> </ol>"},{"location":"sims/outlier-detective/#assessment","title":"Assessment","text":"<p>Formative assessment occurs naturally through the game's scoring system. For summative assessment, consider:</p> <ul> <li>Have students explain their reasoning for 2-3 specific cases</li> <li>Ask students to create their own \"outlier scenario\" with context</li> <li>Present a borderline case and have students argue both sides</li> </ul>"},{"location":"sims/outlier-detective/#differentiation","title":"Differentiation","text":"<ul> <li>Struggling students: Start with Easy mode, focus on the most extreme examples</li> <li>Advanced students: Challenge them to explain why Hard mode sometimes has no outliers</li> <li>Visual learners: Emphasize the dotplot view</li> <li>Analytical learners: Use histogram view to discuss distribution shape</li> </ul>"},{"location":"sims/outlier-detective/#references","title":"References","text":"<ul> <li>AP Statistics: Describing Distributions</li> <li>Identifying Outliers: IQR Rule</li> <li>Chapter 3: Displaying Quantitative Data</li> </ul> <p>Note: Remember to capture a screenshot of this MicroSim and save it as <code>outlier-detective.png</code> in this folder for social media previews.</p>"},{"location":"sims/parameter-statistic-compare/","title":"Parameter vs Statistic Comparison","text":"<p>Run the Parameter vs Statistic MicroSim Fullscreen</p> <p>Edit in the p5.js Editor</p> <p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/parameter-statistic-compare/main.html\" height=\"402px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/parameter-statistic-compare/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive simulation helps students understand one of the most fundamental distinctions in statistics: the difference between a parameter (a fixed value describing a population) and a statistic (a calculated value from a sample that varies from sample to sample).</p> <p>The simulation displays:</p> <ul> <li> <p>Left Panel (Population): A histogram showing all 200 values in the population, with the population mean (parameter, shown as the Greek letter mu) marked with a red vertical line. This value never changes.</p> </li> <li> <p>Middle Panel (Sample): A histogram of the current random sample drawn from the population, with the sample mean (statistic, shown as x-bar) marked with an orange vertical line. This value changes each time you draw a new sample.</p> </li> <li> <p>Right Panel (Comparison &amp; History): Shows the difference between the current sample mean and population mean, plus a dot plot tracking all previous sample means so students can see the variability of statistics around the fixed parameter.</p> </li> </ul>"},{"location":"sims/parameter-statistic-compare/#how-to-use","title":"How to Use","text":"<ol> <li>Draw New Sample: Click this button to randomly select a new sample from the population and calculate its mean</li> <li>Sample Size Slider: Adjust to see how sample size affects how close statistics tend to be to the parameter (larger samples produce less variable statistics)</li> <li>Reset: Generate a fresh population and clear the history to start over</li> </ol>"},{"location":"sims/parameter-statistic-compare/#key-insights","title":"Key Insights","text":"<ul> <li>The population mean (parameter) is fixed at 70 and never changes</li> <li>Each sample mean (statistic) varies depending on which individuals happen to be selected</li> <li>As you draw more samples, the dot plot builds up showing the sampling distribution of the mean</li> <li>Larger sample sizes produce sample means that cluster more tightly around the true population mean</li> </ul>"},{"location":"sims/parameter-statistic-compare/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/parameter-statistic-compare/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ol> <li>Define and distinguish between a parameter and a statistic</li> <li>Explain why statistics vary from sample to sample while parameters remain fixed</li> <li>Predict how sample size affects the variability of sample statistics</li> <li>Use proper notation (mu for population mean, x-bar for sample mean)</li> </ol>"},{"location":"sims/parameter-statistic-compare/#target-audience","title":"Target Audience","text":"<ul> <li>AP Statistics students (high school)</li> <li>Introductory statistics college students</li> <li>Anyone learning the foundations of statistical inference</li> </ul>"},{"location":"sims/parameter-statistic-compare/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of mean (average)</li> <li>Basic familiarity with histograms</li> <li>Concept of a sample vs. a population</li> </ul>"},{"location":"sims/parameter-statistic-compare/#classroom-activities","title":"Classroom Activities","text":"<p>Activity 1: Predict and Observe (10 minutes)</p> <ol> <li>Before drawing any samples, ask students: \"If the population mean is 70, what do you predict the sample mean will be?\"</li> <li>Have students draw 5 samples and record each sample mean</li> <li>Discuss: Why are the sample means different each time?</li> </ol> <p>Activity 2: Sample Size Investigation (15 minutes)</p> <ol> <li>Set sample size to 10 and draw 10 samples, observing the spread of dots</li> <li>Reset and repeat with sample size 50</li> <li>Reset and repeat with sample size 100</li> <li>Compare the three dot plots: What pattern do you notice?</li> </ol> <p>Activity 3: Real-World Connection (10 minutes)</p> <p>Discuss: \"Imagine the population is all students at your school and the variable is height. Why would surveying 10 students give a different average than surveying 100 students? Which would you trust more to estimate the true average height of all students?\"</p>"},{"location":"sims/parameter-statistic-compare/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>What is the difference between a parameter and a statistic?</li> <li>If you drew two random samples of size 25 from the same population, would you expect them to have the same mean? Explain.</li> <li>How does increasing sample size affect the variability of the sample mean?</li> <li>In this simulation, which symbol represents the parameter? Which represents the statistic?</li> </ol>"},{"location":"sims/parameter-statistic-compare/#references","title":"References","text":"<ol> <li> <p>Wikipedia: Statistical Parameter - Comprehensive overview of statistical parameters and their role in probability distributions and statistical inference</p> </li> <li> <p>Khan Academy: Population Parameters vs Sample Statistics - Interactive lessons and practice problems on distinguishing parameters from statistics</p> </li> <li> <p>OpenIntro Statistics - Free open-source textbook with extensive coverage of sampling distributions and statistical inference</p> </li> <li> <p>p5.js Reference - Documentation for the p5.js library used to build this interactive simulation</p> </li> </ol>"},{"location":"sims/pie-vs-bar-comparison/","title":"Pie Chart vs Bar Graph Comparison","text":"<p>Run the Pie Chart vs Bar Graph Comparison MicroSim Fullscreen</p>"},{"location":"sims/pie-vs-bar-comparison/#about-this-microsim","title":"About This MicroSim","text":"<p>Sylvia says: \"Acorn for your thoughts - which chart makes the data easier to read? That's exactly what we're exploring here! This MicroSim puts a pie chart and bar graph side by side, showing the exact same data. Your job is to play detective and figure out when each chart type shines.\"</p> <p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/pie-vs-bar-comparison/main.html\" height=\"542px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/pie-vs-bar-comparison/#how-to-use","title":"How to Use","text":"<ol> <li>Adjust the sliders to change the values for each category (Cat A through Cat D)</li> <li>Select a preset from the dropdown to see different data scenarios:</li> <li>Easy to compare: Values with clear differences</li> <li>Similar values: Nearly equal values - notice which chart makes differences easier to spot</li> <li>Many categories: More categories to compare (expands to 6)</li> <li>One dominant: One category dominates - see how each chart handles this</li> <li>Toggle display options:</li> <li>Show %: Display percentages on both charts</li> <li>Values: Display raw values</li> </ol>"},{"location":"sims/pie-vs-bar-comparison/#what-to-look-for","title":"What to Look For","text":"<p>As you experiment, ask yourself these questions:</p> <ul> <li>When values are similar, which chart makes it easier to spot small differences?</li> <li>When one category dominates, does the pie chart or bar graph communicate this better?</li> <li>For comparing exact values, which chart gives you more precision?</li> <li>For understanding \"part of a whole\", which chart works better?</li> </ul>"},{"location":"sims/pie-vs-bar-comparison/#key-insights","title":"Key Insights","text":"<p>After exploring, you'll discover that:</p> <ul> <li>Pie charts work well for showing proportions and \"part of a whole\" relationships, especially when one or two categories dominate</li> <li>Bar graphs excel at comparing exact values, especially when differences are small</li> <li>Similar values are notoriously hard to compare in pie charts - the wedges look almost identical!</li> <li>Many categories become cluttered in pie charts but remain clear in bar graphs</li> </ul>"},{"location":"sims/pie-vs-bar-comparison/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/pie-vs-bar-comparison/#learning-objective","title":"Learning Objective","text":"<p>Students will be able to compare and contrast the effectiveness of pie charts versus bar graphs for different data distributions, and analyze which visualization type best supports specific data interpretation tasks.</p>"},{"location":"sims/pie-vs-bar-comparison/#grade-level","title":"Grade Level","text":"<p>High School (Grades 9-12), AP Statistics</p>"},{"location":"sims/pie-vs-bar-comparison/#duration","title":"Duration","text":"<p>15-20 minutes</p>"},{"location":"sims/pie-vs-bar-comparison/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of categorical data</li> <li>Familiarity with basic chart reading</li> </ul>"},{"location":"sims/pie-vs-bar-comparison/#activities","title":"Activities","text":""},{"location":"sims/pie-vs-bar-comparison/#activity-1-first-impressions-5-minutes","title":"Activity 1: First Impressions (5 minutes)","text":"<ol> <li>Load the MicroSim with default values</li> <li>Have students write down which chart feels easier to read and why</li> <li>Discuss: What makes one chart \"easier\" than another?</li> </ol>"},{"location":"sims/pie-vs-bar-comparison/#activity-2-preset-exploration-5-minutes","title":"Activity 2: Preset Exploration (5 minutes)","text":"<ol> <li>Have students try each preset in order</li> <li>For each preset, ask: \"Which chart communicates the data more effectively?\"</li> <li>Students record observations in a table:</li> </ol> Preset Better Chart Why? Easy to compare Similar values Many categories One dominant"},{"location":"sims/pie-vs-bar-comparison/#activity-3-create-your-own-scenario-5-minutes","title":"Activity 3: Create Your Own Scenario (5 minutes)","text":"<ol> <li>Challenge students to create slider values that make the pie chart clearly better</li> <li>Then create values that make the bar graph clearly better</li> <li>Share discoveries with a partner</li> </ol>"},{"location":"sims/pie-vs-bar-comparison/#activity-4-real-world-application-5-minutes","title":"Activity 4: Real-World Application (5 minutes)","text":"<p>Discuss: Given what you've learned, which chart would you use for:</p> <ul> <li>Showing how a household budget is divided among categories?</li> <li>Comparing test scores across five classes?</li> <li>Showing market share of the top two companies?</li> <li>Displaying survey results with many response options?</li> </ul>"},{"location":"sims/pie-vs-bar-comparison/#assessment-questions","title":"Assessment Questions","text":"<ol> <li> <p>A survey shows that 47% of students prefer pizza, 44% prefer tacos, and 9% prefer salad. Which chart would better show the close race between pizza and tacos? Explain your reasoning.</p> </li> <li> <p>Your data has 8 categories with values ranging from 5% to 18%. Explain why a bar graph would be more appropriate than a pie chart.</p> </li> <li> <p>Create a scenario where a pie chart would be the better choice. Describe the data and explain your reasoning.</p> </li> </ol>"},{"location":"sims/pie-vs-bar-comparison/#extension-activities","title":"Extension Activities","text":"<ul> <li>Have students find real-world examples of pie charts and bar graphs and critique whether the appropriate chart type was used</li> <li>Create guidelines for when to use each chart type</li> <li>Explore what happens with negative values (which only bar graphs can show)</li> </ul>"},{"location":"sims/pie-vs-bar-comparison/#references","title":"References","text":"<ul> <li>AP Statistics Course and Exam Description - Unit 1: Exploring One-Variable Data</li> <li>Data Visualization Best Practices - Comprehensive guide to choosing chart types</li> <li>Stephen Few's \"Show Me the Numbers\" - Foundational work on effective data visualization</li> </ul>"},{"location":"sims/population-sample-visual/","title":"Population and Sample Visualization","text":"<p>Run the Population and Sample Visualization Fullscreen</p> <p>You can include this MicroSim on your website using the following iframe:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/population-sample-visual/main.html\" height=\"452px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/population-sample-visual/#description","title":"Description","text":"<p>Let's crack this nut! This MicroSim helps you understand one of the most fundamental concepts in statistics: the relationship between a population and a sample.</p> <p>Imagine you want to know the average height of all students at Lincoln High School. You could measure every single student, but that would take forever. Instead, statisticians select a smaller group, a sample, to represent the whole population. This MicroSim lets you experience that process firsthand.</p>"},{"location":"sims/population-sample-visual/#what-you-see","title":"What You See","text":"<ul> <li>Population Area (left): All 90 students at Lincoln High School are shown as small person icons. Notice they have different heights and shirt colors, just like real people.</li> <li>Sample Panel (right): This shows the individuals you have selected for your sample.</li> <li>Statistics Display: Shows the population size, your sample size, and what percentage of the population your sample represents.</li> </ul>"},{"location":"sims/population-sample-visual/#how-to-use-it","title":"How to Use It","text":"<ol> <li>Click on individuals in the population area to add or remove them from your sample. Selected individuals turn bright orange with a glow effect.</li> <li>Random Sample button: Click this to randomly select individuals. This simulates how statisticians often choose samples to avoid bias.</li> <li>Clear Sample button: Removes all selections so you can start fresh.</li> <li>Sample Size slider: Adjust how many individuals the Random Sample button will select (from 5 to 25).</li> </ol>"},{"location":"sims/population-sample-visual/#key-concepts-to-notice","title":"Key Concepts to Notice","text":"<ul> <li>A sample is always smaller than the population.</li> <li>The sample percentage shows what fraction of the population you are studying.</li> <li>Random sampling helps ensure your sample represents the whole population fairly.</li> </ul> <p>Acorn for your thoughts? Try clicking individuals one by one. Do you notice yourself picking certain types of people? That is called selection bias, and it is exactly why random sampling is so important.</p>"},{"location":"sims/population-sample-visual/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/population-sample-visual/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ol> <li>Explain the difference between a population and a sample</li> <li>Demonstrate how to select a random sample from a population</li> <li>Calculate and interpret sample percentage</li> <li>Recognize the importance of random sampling to avoid bias</li> </ol>"},{"location":"sims/population-sample-visual/#target-audience","title":"Target Audience","text":"<ul> <li>High school students (grades 9-12)</li> <li>College introductory statistics students</li> <li>AP Statistics students</li> </ul>"},{"location":"sims/population-sample-visual/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of percentages</li> <li>Familiarity with the concept of data collection</li> </ul>"},{"location":"sims/population-sample-visual/#duration","title":"Duration","text":"<p>15-20 minutes</p>"},{"location":"sims/population-sample-visual/#activities","title":"Activities","text":""},{"location":"sims/population-sample-visual/#activity-1-explore-the-visualization-5-minutes","title":"Activity 1: Explore the Visualization (5 minutes)","text":"<ol> <li>Ask students to click on several individuals to add them to their sample.</li> <li>Have them observe how the statistics update in real-time.</li> <li>Discussion question: \"What happens to the percentage as you add more people?\"</li> </ol>"},{"location":"sims/population-sample-visual/#activity-2-manual-vs-random-selection-5-minutes","title":"Activity 2: Manual vs Random Selection (5 minutes)","text":"<ol> <li>Have students manually select 10 individuals they think best represent the school.</li> <li>Click \"Clear Sample\" and then click \"Random Sample\" with the slider set to 10.</li> <li>Discussion question: \"Which method do you think gives a more fair representation? Why?\"</li> </ol>"},{"location":"sims/population-sample-visual/#activity-3-sample-size-exploration-5-minutes","title":"Activity 3: Sample Size Exploration (5 minutes)","text":"<ol> <li>Use the slider to try different sample sizes (5, 10, 15, 20, 25).</li> <li>Click \"Random Sample\" several times at each size.</li> <li>Discussion question: \"How does sample size affect how well the sample might represent the population?\"</li> </ol>"},{"location":"sims/population-sample-visual/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>If the population is 90 and your sample is 15, what percentage of the population did you sample?</li> <li>Why might a researcher choose random sampling instead of picking individuals they think are representative?</li> <li>What are some limitations of using a sample instead of measuring the entire population?</li> </ol>"},{"location":"sims/population-sample-visual/#common-misconceptions","title":"Common Misconceptions","text":"<ul> <li>\"A bigger sample is always better.\" While larger samples are often more representative, they also require more resources. The key is finding a balance.</li> <li>\"My hand-picked sample is just as good as a random sample.\" Personal selection often introduces unconscious biases.</li> </ul>"},{"location":"sims/population-sample-visual/#references","title":"References","text":"<ol> <li> <p>Population vs Sample - Khan Academy - Educational video explaining the difference between populations and samples.</p> </li> <li> <p>Simple Random Sampling - Stat Trek - Comprehensive overview of random sampling methods and their importance.</p> </li> <li> <p>AP Statistics Course Description - College Board - Official AP Statistics curriculum framework covering sampling methods.</p> </li> </ol>"},{"location":"sims/probability-simulation-lab/","title":"Probability Simulation Lab","text":"<p>Run the Probability Simulation Lab Fullscreen</p> <p>Edit this MicroSim in the p5.js Editor</p>"},{"location":"sims/probability-simulation-lab/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive simulation allows students to estimate probabilities through repeated trials. Students can choose from preset scenarios (Free Throws, Coin Flips, Dice Rolls) and observe how the estimated probability converges toward the theoretical probability as the number of trials increases.</p>"},{"location":"sims/probability-simulation-lab/#how-to-use","title":"How to Use","text":"<ol> <li>Select a scenario from the dropdown menu</li> <li>Click \"Run 1\" to see a single trial with detailed outcomes</li> <li>Click \"Run 100\" or \"Run 1000\" to quickly accumulate trials</li> <li>Adjust speed to control animation rate</li> <li>Watch the graph as the estimated probability converges</li> </ol>"},{"location":"sims/probability-simulation-lab/#scenarios","title":"Scenarios","text":"<ul> <li>Free Throws: P(success) = 0.7, success = at least 4 makes in 5 shots</li> <li>Coin Flips: P(success) = 0.5, success = at least 2 heads in 3 flips</li> <li>Dice Rolls: P(success) = 1/6, success = at least 1 six in 6 rolls</li> </ul>"},{"location":"sims/probability-simulation-lab/#learning-objectives","title":"Learning Objectives","text":"<p>After using this MicroSim, students will be able to:</p> <ul> <li>Design simulations to estimate probabilities</li> <li>Understand how more trials lead to more accurate estimates</li> <li>Compare empirical probability to theoretical probability</li> <li>Apply the concept of convergence to real-world scenarios</li> </ul>"},{"location":"sims/probability-simulation-lab/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/probability-simulation-lab/main.html\" height=\"502px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/probability-simulation-lab/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/probability-simulation-lab/#introduction-5-minutes","title":"Introduction (5 minutes)","text":"<p>Discuss why simulations are useful when theoretical calculations are complex. Introduce the scenarios.</p>"},{"location":"sims/probability-simulation-lab/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<p>Run simulations together, making predictions about convergence at 10, 100, and 1000 trials.</p>"},{"location":"sims/probability-simulation-lab/#practice-activities-15-minutes","title":"Practice Activities (15 minutes)","text":"<p>Have students run their own simulations and record how close their estimate gets to the theoretical value at different trial counts.</p>"},{"location":"sims/probability-simulation-lab/#assessment","title":"Assessment","text":"<p>Students explain why simulations work and describe the relationship between trial count and estimate accuracy.</p>"},{"location":"sims/probability-simulation-lab/#references","title":"References","text":"<ul> <li>Chapter 9: Probability Fundamentals</li> <li>Concepts: Simulation, Designing Simulations</li> </ul>"},{"location":"sims/quartile-visualization/","title":"Understanding Quartiles","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/quartile-visualization/#about-this-microsim","title":"About This MicroSim","text":"<p>This visualization shows how quartiles divide a distribution into four equal parts: - Q1 (First Quartile): 25% of data falls below this value - Q2 (Median): 50% of data falls below this value - Q3 (Third Quartile): 75% of data falls below this value</p>"},{"location":"sims/quartile-visualization/#how-to-use","title":"How to Use","text":"<ul> <li>Adjust the Sample Size slider to see how quartiles change with more or fewer points</li> <li>Click Randomize to generate a new random dataset</li> <li>Toggle between Even Spacing and Realistic Data modes</li> <li>Hover over regions to highlight them</li> <li>Click on Q1, Median, or Q3 markers to see calculation details</li> </ul>"},{"location":"sims/quartile-visualization/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/quartile-visualization/#learning-objective","title":"Learning Objective","text":"<p>Students will identify and interpret quartiles as values that divide a distribution into four equal parts (Bloom's Taxonomy: Understanding).</p>"},{"location":"sims/quartile-visualization/#discussion-questions","title":"Discussion Questions","text":"<ol> <li>Why does each colored region contain approximately 25% of the data?</li> <li>What happens to the quartile positions when you increase the sample size?</li> <li>How would outliers affect the quartile positions?</li> </ol>"},{"location":"sims/sample-space-explorer/","title":"Sample Space Explorer","text":"<p>Run the Sample Space Explorer Fullscreen</p> <p>Edit this MicroSim in the p5.js Editor</p>"},{"location":"sims/sample-space-explorer/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive visualization helps students understand sample spaces and events for common random phenomena. Students can explore different scenarios (single die roll, two coin flips, two dice sum, and card suits) and select outcomes to define events. The probability is calculated in real-time as students add or remove outcomes from their event.</p>"},{"location":"sims/sample-space-explorer/#how-to-use","title":"How to Use","text":"<ol> <li>Select a phenomenon from the dropdown menu</li> <li>Click on outcomes to add them to your event (highlighted in green)</li> <li>Watch the probability update in real-time as P(Event) = favorable/total</li> <li>Reset to clear your selection and try different events</li> </ol>"},{"location":"sims/sample-space-explorer/#learning-objectives","title":"Learning Objectives","text":"<p>After using this MicroSim, students will be able to:</p> <ul> <li>Identify sample spaces for common random phenomena</li> <li>Define events as subsets of sample spaces</li> <li>Calculate probabilities using the classical definition P(Event) = favorable outcomes / total outcomes</li> <li>Understand how different phenomena have different sample space structures</li> </ul>"},{"location":"sims/sample-space-explorer/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/sample-space-explorer/main.html\" height=\"452px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/sample-space-explorer/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/sample-space-explorer/#introduction-5-minutes","title":"Introduction (5 minutes)","text":"<p>Introduce the concept of sample space as the complete set of all possible outcomes. Discuss how probability is calculated by counting favorable outcomes.</p>"},{"location":"sims/sample-space-explorer/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<p>Have students explore each phenomenon type, predicting what events will have probability 1/2, 1/3, etc.</p>"},{"location":"sims/sample-space-explorer/#practice-activities-10-minutes","title":"Practice Activities (10 minutes)","text":"<p>Challenge students to select events with specific probabilities (e.g., \"Create an event with probability 0.5 for a die roll\").</p>"},{"location":"sims/sample-space-explorer/#assessment","title":"Assessment","text":"<p>Students can demonstrate understanding by correctly identifying sample space sizes and calculating event probabilities.</p>"},{"location":"sims/sample-space-explorer/#references","title":"References","text":"<ul> <li>Chapter 9: Probability Fundamentals</li> <li>Concept: Sample Space, Event, Probability</li> </ul>"},{"location":"sims/scatterplot-builder/","title":"Scatterplot Builder","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/scatterplot-builder/#about-this-microsim","title":"About This MicroSim","text":"<p>Build scatterplots interactively by clicking rows in a data table. Each click plots the corresponding point on the coordinate plane, helping you visualize how paired observations become positions on a graph.</p>"},{"location":"sims/scatterplot-builder/#how-to-use","title":"How to Use","text":"<ul> <li>Click a row in the data table to plot that point on the scatterplot</li> <li>Hover over points in the scatterplot to see their exact coordinates</li> <li>Use the dropdown to switch between three different datasets</li> <li>Click Clear to reset and start over</li> <li>Click Show All to display all points at once</li> <li>Toggle Hide Grid/Show Grid to customize the display</li> </ul>"},{"location":"sims/scatterplot-builder/#learning-objectives","title":"Learning Objectives","text":"<p>Students will demonstrate understanding of scatterplot construction by:</p> <ul> <li>Placing data points at correct coordinate positions</li> <li>Interpreting how x and y values determine point location</li> <li>Recognizing patterns that emerge when all points are plotted</li> </ul>"},{"location":"sims/scatterplot-builder/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/scatterplot-builder/#learning-objective","title":"Learning Objective","text":"<p>Students will understand (Bloom Level 2) scatterplot construction by placing data points and interpreting their positions on a coordinate plane.</p>"},{"location":"sims/scatterplot-builder/#warm-up-discussion-5-minutes","title":"Warm-Up Discussion (5 minutes)","text":"<p>Ask students: \"If I tell you someone studied for 5 hours and got an 80 on a test, where would that information go on a graph?\" Use this to introduce the concept of paired data and coordinate positioning.</p>"},{"location":"sims/scatterplot-builder/#guided-exploration-15-minutes","title":"Guided Exploration (15 minutes)","text":"<ol> <li>Start with Hours Studied/Test Score dataset</li> <li>Have students predict where the first point will appear before clicking</li> <li>Click each row one at a time, discussing the x and y positions</li> <li> <p>Ask: \"What happens as we move down the table?\"</p> </li> <li> <p>Identify the pattern</p> </li> <li>Once all points are plotted, ask: \"What pattern do you see?\"</li> <li> <p>Introduce vocabulary: positive association, direction, form</p> </li> <li> <p>Compare datasets</p> </li> <li>Switch to Temperature/Ice Cream Sales</li> <li>Discuss: \"What pattern do you expect? Why?\"</li> </ol>"},{"location":"sims/scatterplot-builder/#independent-practice-10-minutes","title":"Independent Practice (10 minutes)","text":"<p>Have students:</p> <ol> <li>Clear the scatterplot and rebuild it from scratch</li> <li>Hover over each point to verify coordinates match the table</li> <li>Describe the pattern they observe in writing</li> </ol>"},{"location":"sims/scatterplot-builder/#extension-activities","title":"Extension Activities","text":"<ul> <li>Prediction challenge: Show 8 of 10 points and have students predict where the last two should go</li> <li>Pattern recognition: Use all three datasets and rank them by strength of association</li> <li>Real-world connection: Have students collect their own paired data (e.g., shoe size vs. height)</li> </ul>"},{"location":"sims/scatterplot-builder/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>If a data point has coordinates (6, 75), what does the 6 represent? What does the 75 represent?</li> <li>When you see points going from lower-left to upper-right, what kind of association is that?</li> <li>Why is it helpful to plot data as a scatterplot instead of just looking at a table?</li> </ol>"},{"location":"sims/scatterplot-builder/#technical-details","title":"Technical Details","text":"<ul> <li>Canvas size: 700 x 450 (responsive width)</li> <li>Draw height: 350px</li> <li>Control height: 100px</li> <li>Iframe height: 452px (includes 2px border)</li> <li>Library: p5.js with canvas-based controls</li> </ul>"},{"location":"sims/scatterplot-builder/#references","title":"References","text":"<ul> <li>Moore, D. S., Notz, W. I., &amp; Fligner, M. A. (2021). The Basic Practice of Statistics (9th ed.). W. H. Freeman.</li> <li>Agresti, A., &amp; Franklin, C. (2018). Statistics: The Art and Science of Learning from Data (4th ed.). Pearson.</li> <li>Common Core State Standards for Mathematics - Statistics and Probability (S-ID)</li> </ul>"},{"location":"sims/skewness-explorer/","title":"Skewness Explorer","text":"<p>Run the Skewness Explorer MicroSim Fullscreen</p> <p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/skewness-explorer/main.html\" height=\"482px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/skewness-explorer/#about-this-microsim","title":"About This MicroSim","text":"<p>The Skewness Explorer is an interactive visualization designed to help students classify distributions as symmetric, skewed left, or skewed right. Understanding skewness is a fundamental skill in statistics that helps students describe the shape of data distributions and make appropriate choices about summary statistics.</p>"},{"location":"sims/skewness-explorer/#how-to-use","title":"How to Use","text":"<ol> <li> <p>Examine the Histogram: Look at the shape of the distribution displayed. Notice where the peak is located and which direction the tail extends.</p> </li> <li> <p>Classify the Distribution: Click one of the three classification buttons:</p> </li> <li>Skewed Left: The left tail is longer (data bunches on the right)</li> <li>Symmetric: Both tails are approximately equal length</li> <li> <p>Skewed Right: The right tail is longer (data bunches on the left)</p> </li> <li> <p>Use Hints: Click \"Show Hint\" to highlight the tails and see which one is longer.</p> </li> <li> <p>Check Your Answer: Click \"Show Answer\" if you need to see the correct classification.</p> </li> <li> <p>Practice More: Click \"Next Example\" to generate a new distribution.</p> </li> <li> <p>Explore Modes:</p> </li> <li>Real-World Mode: See distributions with context (e.g., household income, exam scores)</li> <li>Random Mode: Adjust the skewness slider to create custom distributions</li> </ol>"},{"location":"sims/skewness-explorer/#key-concepts","title":"Key Concepts","text":"<ul> <li> <p>Skewed Right (Positive Skew): The right tail is longer. Common examples include income, home prices, and wait times. The mean is pulled toward the tail.</p> </li> <li> <p>Skewed Left (Negative Skew): The left tail is longer. Common examples include easy exam scores and retirement ages. The mean is pulled toward the tail.</p> </li> <li> <p>Symmetric: Both tails are equal. The mean and median are approximately equal. Common examples include heights and measurement errors.</p> </li> </ul>"},{"location":"sims/skewness-explorer/#tips-for-classification","title":"Tips for Classification","text":"<ul> <li>Look at the tails, not the peak</li> <li>Ask yourself: \"Which direction does the longer tail point?\"</li> <li>The skew is named for the direction of the tail, not the peak</li> <li>Remember: \"The tail tells the tale!\"</li> </ul>"},{"location":"sims/skewness-explorer/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/skewness-explorer/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this lesson, students will be able to:</p> <ol> <li>Identify whether a distribution is symmetric, skewed left, or skewed right by examining a histogram</li> <li>Explain the relationship between tail direction and skewness classification</li> <li>Connect real-world contexts to their typical distribution shapes</li> <li>Predict how skewness affects the relationship between mean and median</li> </ol>"},{"location":"sims/skewness-explorer/#target-audience","title":"Target Audience","text":"<ul> <li>AP Statistics students</li> <li>College introductory statistics courses</li> <li>Students in Chapter 3: Displaying Quantitative Data</li> </ul>"},{"location":"sims/skewness-explorer/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of histograms</li> <li>Basic vocabulary: distribution, shape, center</li> </ul>"},{"location":"sims/skewness-explorer/#suggested-activities","title":"Suggested Activities","text":"<p>Activity 1: Warm-Up Classification (5 minutes)</p> <p>Have students work individually through 5 examples in Real-World mode, recording their answers and streak. Discuss any commonly missed examples as a class.</p> <p>Activity 2: Context Connections (10 minutes)</p> <p>In pairs, students brainstorm why each real-world context has its typical skew:</p> <ul> <li>Why is household income right-skewed?</li> <li>Why are easy exam scores left-skewed?</li> <li>Why are adult heights approximately symmetric?</li> </ul> <p>Activity 3: Custom Exploration (5 minutes)</p> <p>Switch to Random mode. Students adjust the slider to:</p> <ul> <li>Create a perfectly symmetric distribution (skewness = 0)</li> <li>Create a strongly right-skewed distribution (skewness &gt; 1.5)</li> <li>Create a moderately left-skewed distribution (skewness between -0.5 and -1)</li> </ul> <p>Activity 4: Mean vs. Median Discussion (5 minutes)</p> <p>For each type of skewness, predict:</p> <ul> <li>Is the mean greater than, less than, or equal to the median?</li> <li>Where would you expect the mean to be located on the histogram?</li> </ul>"},{"location":"sims/skewness-explorer/#assessment-suggestions","title":"Assessment Suggestions","text":"<ol> <li>Quick Check: Show 5 histograms and have students classify each</li> <li>Exit Ticket: Given a real-world scenario, predict the skewness and explain why</li> <li>Extended Response: Explain why income data is typically right-skewed and why this matters for choosing between mean and median income as a summary statistic</li> </ol>"},{"location":"sims/skewness-explorer/#blooms-taxonomy-alignment","title":"Bloom's Taxonomy Alignment","text":"<ul> <li>Remember: Recall that skewness describes distribution shape</li> <li>Understand: Classify distributions by their skewness (primary objective)</li> <li>Apply: Predict skewness for new real-world contexts</li> <li>Analyze: Explain why certain contexts produce specific skewness patterns</li> </ul>"},{"location":"sims/skewness-explorer/#references","title":"References","text":"<ol> <li> <p>Wikipedia: Skewness - Comprehensive overview of skewness measures and their mathematical properties</p> </li> <li> <p>Khan Academy: Describing Shape of Distributions - Interactive lessons on distribution shapes and their relationship to center measures</p> </li> <li> <p>AP Statistics Course Framework - College Board curriculum standards for displaying and describing quantitative data</p> </li> </ol> <p>Reminder: Please create a screenshot of this MicroSim named <code>skewness-explorer.png</code> and add it to this directory for social media previews.</p>"},{"location":"sims/socs-description-builder/","title":"SOCS Description Builder","text":"<p>Run the SOCS Description Builder Fullscreen</p> <p>You can include this MicroSim on your website using the following iframe:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/socs-description-builder/main.html\" height=\"552\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/socs-description-builder/#about-this-microsim","title":"About This MicroSim","text":"<p>The SOCS Description Builder helps students practice composing complete, professional distribution descriptions using the SOCS framework. SOCS stands for:</p> <ul> <li>Shape: Is the distribution symmetric, skewed left, or skewed right?</li> <li>Outliers: Are there any unusual values far from the main group?</li> <li>Center: What is a typical value? (usually median for skewed data)</li> <li>Spread: How much do the values vary? (often measured by IQR)</li> </ul>"},{"location":"sims/socs-description-builder/#how-to-use","title":"How to Use","text":"<ol> <li>Observe the histogram on the left side showing a real-world dataset</li> <li>Select SOCS components using the dropdowns on the right:</li> <li>Choose the shape (symmetric, skewed left, skewed right)</li> <li>Identify any outliers (none, low, high, or both)</li> <li>Enter an estimate for the center value</li> <li>Enter an estimate for the spread</li> <li>Optionally select the modality (unimodal, bimodal, uniform)</li> <li>Watch your description build in real-time in the preview panel</li> <li>Click \"Generate Description\" when you've completed all components</li> <li>Click \"Compare to Expert\" to see how your description matches an expert response</li> <li>Click \"New Dataset\" to practice with a different distribution</li> </ol>"},{"location":"sims/socs-description-builder/#sample-contexts","title":"Sample Contexts","text":"<p>The MicroSim includes various real-world contexts:</p> <ul> <li>Coffee wait times (typically skewed right with high outliers)</li> <li>Easy exam scores (typically skewed left with low outliers)</li> <li>Mixed heights (bimodal distribution from mixed groups)</li> <li>Commute times (skewed right with occasional long delays)</li> <li>Product ratings (skewed left as most customers are satisfied)</li> <li>Uniform random (flat distribution with no clear peaks)</li> </ul>"},{"location":"sims/socs-description-builder/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/socs-description-builder/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ol> <li>Identify the four components of a complete distribution description (SOCS)</li> <li>Recognize different distribution shapes from histograms</li> <li>Distinguish between unimodal, bimodal, and uniform distributions</li> <li>Identify potential outliers in a distribution</li> <li>Estimate appropriate measures of center and spread</li> <li>Compose coherent, professional descriptions of distributions</li> </ol>"},{"location":"sims/socs-description-builder/#target-audience","title":"Target Audience","text":"<ul> <li>AP Statistics students (Chapter 3: Displaying Quantitative Data)</li> <li>College introductory statistics students</li> <li>Data science beginners learning exploratory data analysis</li> </ul>"},{"location":"sims/socs-description-builder/#prerequisites","title":"Prerequisites","text":"<p>Before using this MicroSim, students should understand:</p> <ul> <li>How to read and interpret histograms</li> <li>The difference between mean and median</li> <li>Basic concepts of variability (range, IQR)</li> <li>What outliers are and how they affect distributions</li> </ul>"},{"location":"sims/socs-description-builder/#suggested-activities","title":"Suggested Activities","text":"<p>Activity 1: Guided Practice (15 minutes)</p> <ol> <li>Project the MicroSim for the class</li> <li>Generate a new dataset and analyze it together</li> <li>Model the thinking process: \"I see the bars are taller on the left and trail off to the right, so this is skewed right...\"</li> <li>Complete each SOCS component with class input</li> <li>Compare to the expert description and discuss any differences</li> </ol> <p>Activity 2: Independent Practice (20 minutes)</p> <ol> <li>Students work individually or in pairs</li> <li>Complete at least 5 different datasets</li> <li>Record their scores for each attempt</li> <li>Goal: Achieve 80% or higher on at least 3 datasets</li> </ol> <p>Activity 3: Peer Review (15 minutes)</p> <ol> <li>Partners take turns describing distributions</li> <li>One student analyzes while the other checks using \"Compare to Expert\"</li> <li>Discuss discrepancies and refine understanding</li> </ol>"},{"location":"sims/socs-description-builder/#assessment-suggestions","title":"Assessment Suggestions","text":"<ul> <li>Formative: Monitor scores during independent practice (aim for 75%+)</li> <li>Exit Ticket: Give students a new histogram (paper) and have them write a complete SOCS description</li> <li>Quiz Question: \"Which of the following is a complete description of the distribution?\" (multiple choice with SOCS checklist)</li> </ul>"},{"location":"sims/socs-description-builder/#common-misconceptions-to-address","title":"Common Misconceptions to Address","text":"<ol> <li>Confusing skewness direction: The tail points in the direction of the skew</li> <li>Forgetting context: Always use the variable name and units</li> <li>Using mean for skewed data: Median is more appropriate when skewed</li> <li>Ignoring outliers: They should always be mentioned (even if there are none)</li> <li>Vague spread descriptions: Use specific measures like IQR, not just \"spread out\"</li> </ol>"},{"location":"sims/socs-description-builder/#extension-activities","title":"Extension Activities","text":"<ul> <li>Have students collect their own data and create SOCS descriptions</li> <li>Compare how different descriptions of the same data emphasize different features</li> <li>Discuss when different measures of center/spread are most appropriate</li> </ul>"},{"location":"sims/socs-description-builder/#references","title":"References","text":"<ol> <li> <p>AP Statistics Course Description - College Board - The official curriculum guide for AP Statistics, including standards for describing distributions.</p> </li> <li> <p>Introduction to the Practice of Statistics - Moore, McCabe, and Craig - 2021 - The textbook that popularized the SOCS framework for teaching distribution descriptions.</p> </li> <li> <p>Teaching Statistics: A Bag of Tricks - Gelman and Nolan - 2017 - Practical strategies for teaching statistical concepts including distribution descriptions.</p> </li> <li> <p>Guidelines for Assessment and Instruction in Statistics Education (GAISE) - American Statistical Association - 2016 - Framework for statistics education emphasizing conceptual understanding.</p> </li> </ol>"},{"location":"sims/std-dev-calculator/","title":"Standard Deviation Calculator","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/std-dev-calculator/#about-this-microsim","title":"About This MicroSim","text":"<p>Walk through the calculation of variance and standard deviation step by step.</p>"},{"location":"sims/std-dev-calculator/#how-to-use","title":"How to Use","text":"<ul> <li>Click Next Step to advance through each calculation step</li> <li>Click Show All to see the complete solution</li> <li>Toggle between Sample (n-1) and Population (n) formulas</li> <li>Choose different preset datasets to practice with</li> </ul>"},{"location":"sims/std-dev-calculator/#the-six-steps","title":"The Six Steps","text":"<ol> <li>Calculate the mean</li> <li>Find each deviation from the mean</li> <li>Square each deviation</li> <li>Sum the squared deviations</li> <li>Divide by (n-1) for sample variance</li> <li>Take the square root for standard deviation</li> </ol>"},{"location":"sims/std-dev-calculator/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/std-dev-calculator/#learning-objective","title":"Learning Objective","text":"<p>Students will calculate variance and standard deviation by following a systematic procedure and understanding each step's purpose (Bloom's Taxonomy: Applying, Understanding).</p>"},{"location":"sims/stemplot-constructor/","title":"Stemplot Constructor","text":"<p>Run the Stemplot Constructor MicroSim Fullscreen</p> <p>Edit the Stemplot Constructor MicroSim with the p5.js editor</p>"},{"location":"sims/stemplot-constructor/#about-this-microsim","title":"About This MicroSim","text":"<p>Sylvia pops up from behind a pile of acorns: \"Let's crack this nut! Stemplots are one of my favorite ways to organize data because they let you see the actual numbers while also showing the shape of the distribution. It's like having your acorns sorted AND counted at the same time!\"</p> <p>This interactive MicroSim helps you understand how a stemplot (also called a stem-and-leaf plot) is constructed. You will see exactly how each data value gets split into its stem (the leading digit) and leaf (the trailing digit), then watch as the leaf gets placed in the correct sorted position.</p>"},{"location":"sims/stemplot-constructor/#how-to-use","title":"How to Use","text":"<ol> <li>Enter Your Own Values: Type a two-digit number (0-99) in the input box and click \"Add Value\" to see it decompose and join the stemplot</li> <li>Step Through: Load a sample dataset and watch values being added one at a time - perfect for understanding the process</li> <li>Auto-Build: Watch the entire dataset animate automatically at your chosen speed</li> <li>Clear: Reset the stemplot to start fresh</li> <li>Dataset Dropdown: Choose from Quiz Scores, Ages, or Heights sample datasets</li> <li>Speed Slider: Adjust animation speed from 500ms (fast) to 2000ms (slow)</li> </ol>"},{"location":"sims/stemplot-constructor/#decomposition-animation","title":"Decomposition Animation","text":"<p>When a value like 85 is added, you will see:</p> <ol> <li>The value 85 highlighted in yellow</li> <li>An arrow showing the split: 8 (stem) and 5 (leaf)</li> <li>The leaf 5 being placed in the row for stem 8, in sorted order</li> </ol> <p>The key at the bottom reminds you: 8 | 5 means 85</p>"},{"location":"sims/stemplot-constructor/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<p>Place the following line in your website to include this in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/stemplot-constructor/main.html\" height=\"522px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/stemplot-constructor/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/stemplot-constructor/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ul> <li>Interpret how a two-digit data value decomposes into a stem and a leaf</li> <li>Explain why the leaf is the last digit and the stem contains the remaining leading digit(s)</li> <li>Predict where a new value will be placed in an existing stemplot</li> <li>Construct a stemplot from a small dataset by hand</li> </ul>"},{"location":"sims/stemplot-constructor/#warm-up-5-minutes","title":"Warm-Up (5 minutes)","text":"<p>Sylvia's tip: \"Acorn for your thoughts? Before we dive in, try this: take the number 73 and split it into tens and ones. The tens digit becomes the stem, and the ones digit becomes the leaf. Now you're thinking like a statistician!\"</p> <ol> <li>Ask students: \"If I have the value 47, what would be the stem? What would be the leaf?\"</li> <li>Have students practice splitting 3-4 values mentally before using the MicroSim</li> </ol>"},{"location":"sims/stemplot-constructor/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<ol> <li>Load the \"Quiz Scores\" dataset</li> <li>Click \"Step Through\" and pause after each value to discuss:</li> <li>What stem row does this value belong to?</li> <li>Where in the row should the leaf go (sorted order)?</li> <li>After 5-6 values, have students predict where the next value will go</li> </ol>"},{"location":"sims/stemplot-constructor/#independent-practice-10-minutes","title":"Independent Practice (10 minutes)","text":"<ol> <li>Students clear the stemplot and enter their own values (5-10 values)</li> <li>Challenge: Can they create a stemplot that shows a symmetric distribution? A skewed distribution?</li> <li>Use \"Auto-Build\" with the speed slider to check understanding with a full dataset</li> </ol>"},{"location":"sims/stemplot-constructor/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>The value 62 is added to a stemplot. What is the stem? What is the leaf?</li> <li>In a stemplot, you see: <code>7 | 2 4 8</code>. What three values does this represent?</li> <li>Why do we sort the leaves in each row from smallest to largest?</li> <li>A stemplot has stems 4, 5, 6, 7. What range of values could be in this dataset?</li> </ol>"},{"location":"sims/stemplot-constructor/#extension","title":"Extension","text":"<p>\"Now that's a data point worth collecting!\" - Sylvia</p> <p>For advanced students: Discuss what happens with three-digit values (like test scores out of 200). How would you modify the stem? What about decimal values?</p>"},{"location":"sims/stemplot-constructor/#concepts-covered","title":"Concepts Covered","text":"<ul> <li>Stemplot (stem-and-leaf plot)</li> <li>Data decomposition</li> <li>Place value in statistics</li> <li>Ordered data visualization</li> <li>Distribution shape</li> </ul>"},{"location":"sims/stemplot-constructor/#references","title":"References","text":"<ul> <li>Chapter 3: Displaying Quantitative Data - Stemplots section</li> <li>Khan Academy: Stem and Leaf Plots</li> <li>OpenIntro Statistics: Graphical Summaries</li> </ul> <p>Reminder: Please create a screenshot of this MicroSim named <code>stemplot-constructor.png</code> and place it in this folder for social media previews.</p>"},{"location":"sims/study-design-map/","title":"Study Design Concept Map","text":"<p>View Study Design Concept Map Fullscreen</p>"},{"location":"sims/study-design-map/#embed-this-visualization","title":"Embed This Visualization","text":"<p>Place the following line in your website to include this visualization:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/study-design-map/main.html\" height=\"500px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/study-design-map/#overview","title":"Overview","text":"<p>This interactive concept map helps you see how all the foundational statistics concepts from Chapter 1 fit together. Using a real research study about sleep and academic performance as our example, you can explore how population connects to sample, how parameters relate to statistics, and how different types of variables work together in research design.</p> <p>The hub-and-spoke layout places the \"Study\" at the center, with major concepts branching outward. Color coding helps you quickly identify concept categories:</p> <ul> <li>Blue: Population-related concepts (population, parameter)</li> <li>Orange: Sample-related concepts (sample, statistic, distribution)</li> <li>Green: Variable types (quantitative, categorical, continuous, discrete)</li> <li>Purple: Relationship concepts (explanatory and response variables)</li> </ul>"},{"location":"sims/study-design-map/#how-to-use","title":"How to Use","text":"<ol> <li>Click any node to see its definition and a concrete example from the sleep study</li> <li>Watch the highlighting - related concepts illuminate when you select a node</li> <li>Follow the arrows to understand how information flows between concepts</li> <li>Click \"Reset View\" to return to the starting state</li> </ol>"},{"location":"sims/study-design-map/#key-concepts","title":"Key Concepts","text":""},{"location":"sims/study-design-map/#population-and-sample","title":"Population and Sample","text":"<p>The study starts with a population (all U.S. high school students) that we want to learn about. Since we cannot study everyone, we collect data from a sample (500 randomly selected students). The sample should represent the population.</p>"},{"location":"sims/study-design-map/#parameters-and-statistics","title":"Parameters and Statistics","text":"<p>A parameter is a number describing the population (like the true average sleep hours for ALL students - unknown). A statistic is a number calculated from the sample (like 6.8 hours average in our sample). Statistics estimate parameters.</p>"},{"location":"sims/study-design-map/#variables","title":"Variables","text":"<p>Variables are characteristics we measure. They can be:</p> <ul> <li>Quantitative (numerical): Further divided into continuous (any value) and discrete (countable values)</li> <li>Categorical (groups): Like grade level or school type</li> </ul>"},{"location":"sims/study-design-map/#explanatory-and-response","title":"Explanatory and Response","text":"<p>In studies looking for relationships, the explanatory variable (sleep hours) is what we think might cause changes in the response variable (GPA).</p>"},{"location":"sims/study-design-map/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/study-design-map/#learning-objectives","title":"Learning Objectives","text":"<p>After using this visualization, students will be able to:</p> <ol> <li>Identify the hierarchical relationships between population, sample, parameter, and statistic</li> <li>Classify variables as quantitative or categorical, and quantitative variables as continuous or discrete</li> <li>Distinguish between explanatory and response variables in a research context</li> <li>Explain how the concepts work together in a complete study design</li> </ol>"},{"location":"sims/study-design-map/#activities","title":"Activities","text":"<ol> <li>Concept Exploration (5 min): Click through each node, reading definitions and examples</li> <li>Connection Tracing (5 min): Start at \"Population\" and trace all paths to understand the study structure</li> <li>Variable Classification (5 min): For a new research scenario, use the map to classify variables correctly</li> </ol>"},{"location":"sims/study-design-map/#assessment","title":"Assessment","text":"<ul> <li>Can students trace the path from population to statistic and explain each step?</li> <li>Can students correctly categorize new variables using the variable hierarchy?</li> <li>Can students identify which variable is explanatory vs. response in a new scenario?</li> </ul>"},{"location":"sims/study-design-map/#editing-node-positions","title":"Editing Node Positions","text":"<p>To edit node positions for better layout:</p> <ol> <li>Open main.html with <code>?enable-save=true</code> parameter</li> <li>Drag nodes to desired positions</li> <li>Click \"Save Node Positions\" to download updated data</li> <li>Update the JavaScript file with new coordinates</li> </ol>"},{"location":"sims/study-design-map/#references","title":"References","text":"<ul> <li>OpenStax Introductory Statistics, Chapter 1: Sampling and Data</li> <li>vis-network Documentation</li> <li>Common Core State Standards for Mathematics: Statistics and Probability</li> </ul>"},{"location":"sims/symmetric-distribution/","title":"Symmetric Distribution Identifier","text":"<p>Run the Symmetric Distribution Identifier Fullscreen</p> <p>Edit in the p5.js Editor</p> <p>You can include this MicroSim on your website using the following iframe:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/symmetric-distribution/main.html\" height=\"402px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/symmetric-distribution/#description","title":"Description","text":"<p>This interactive MicroSim helps students develop the ability to recognize symmetric distributions by visual comparison of histogram shapes. The simulation generates random distributions that are either symmetric (where the left and right sides mirror each other around a center line) or asymmetric (skewed or unbalanced).</p> <p>How to Use:</p> <ol> <li> <p>Observe the Histogram: Each histogram shows 10-15 bars representing data distribution. A vertical dashed red line marks the center.</p> </li> <li> <p>Make Your Classification: Click \"Symmetric\" if you think the left and right sides are mirror images, or \"Not Symmetric\" if they differ.</p> </li> <li> <p>Use the Fold Feature: Click \"Show Fold\" to see the right side of the histogram fold over onto the left side. If the distribution is truly symmetric, the folded bars will align with the original bars.</p> </li> <li> <p>Track Your Progress: Your score updates after each answer. After 10 questions, you will see your final results.</p> </li> <li> <p>Adjust Difficulty:</p> </li> <li>Easy: Clear differences between symmetric and asymmetric distributions</li> <li>Medium: Subtle differences with some noise</li> <li>Hard: Very subtle asymmetries that require careful observation</li> </ol> <p>Distribution Types You Will See:</p> <ul> <li>Normal (bell-shaped): Symmetric, peaks in the middle</li> <li>Uniform: Roughly equal bar heights across the distribution</li> <li>Bimodal: Two peaks that may be symmetric or asymmetric</li> <li>Skewed: Tail extends longer on one side (asymmetric)</li> </ul>"},{"location":"sims/symmetric-distribution/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/symmetric-distribution/#learning-objectives","title":"Learning Objectives","text":"<p>By completing this MicroSim activity, students will be able to:</p> <ol> <li>Recognize symmetric distributions by visually comparing left and right sides of histograms (Bloom Level 1: Remember)</li> <li>Identify the center of a distribution and use it as a reference for symmetry assessment</li> <li>Distinguish between different distribution shapes (normal, uniform, bimodal, skewed)</li> </ol>"},{"location":"sims/symmetric-distribution/#target-audience","title":"Target Audience","text":"<ul> <li>AP Statistics students (Chapter 3: Displaying Quantitative Data)</li> <li>High school students in introductory statistics courses</li> <li>College students in Statistics 101</li> </ul>"},{"location":"sims/symmetric-distribution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of histograms and how they represent data</li> <li>Familiarity with the concept of frequency distributions</li> </ul>"},{"location":"sims/symmetric-distribution/#classroom-activities","title":"Classroom Activities","text":"<p>Activity 1: Introduction (5 minutes)</p> <ul> <li>Introduce the concept of symmetry in distributions</li> <li>Explain that symmetric distributions have matching shapes on both sides of the center</li> <li>Demonstrate the fold animation concept: if you fold a symmetric distribution at its center, both sides match</li> </ul> <p>Activity 2: Guided Practice (10 minutes)</p> <ul> <li>Project the MicroSim for the class</li> <li>Work through 3-4 examples together on Easy mode</li> <li>Discuss what features make a distribution symmetric or asymmetric</li> <li>Use the \"Show Fold\" button to verify answers visually</li> </ul> <p>Activity 3: Independent Practice (10 minutes)</p> <ul> <li>Students complete the 10-question quiz on their own devices</li> <li>Start on Easy, then progress to Medium as confidence builds</li> <li>Record final scores for self-assessment</li> </ul> <p>Activity 4: Discussion (5 minutes)</p> <ul> <li>Ask students to share strategies for identifying symmetry</li> <li>Discuss common mistakes and how to avoid them</li> <li>Connect to real-world examples of symmetric data (heights, IQ scores) vs. skewed data (income, home prices)</li> </ul>"},{"location":"sims/symmetric-distribution/#assessment-suggestions","title":"Assessment Suggestions","text":"<ul> <li>Formative: Use quiz scores to gauge understanding (aim for 70%+ on Medium difficulty)</li> <li>Summative: Include histogram symmetry identification questions on unit tests</li> <li>Extension: Have students create their own examples of symmetric and asymmetric datasets</li> </ul>"},{"location":"sims/symmetric-distribution/#differentiation","title":"Differentiation","text":"<ul> <li>Struggling students: Focus on Easy mode, use fold animation frequently</li> <li>Advanced students: Challenge them to achieve 90%+ on Hard mode without using the fold feature</li> </ul>"},{"location":"sims/symmetric-distribution/#references","title":"References","text":"<ol> <li>AP Statistics Course Framework - College Board - Official curriculum guidelines for symmetry and distribution shape</li> <li>OpenIntro Statistics - Chapter on Examining Numerical Data - Free textbook with distribution shape concepts</li> <li>Khan Academy: Describing Distributions - Video lessons on distribution shapes and symmetry</li> </ol>"},{"location":"sims/test-scores-boxplot/","title":"Test Scores Boxplot Explorer","text":"<p>Run the Test Scores Boxplot Explorer MicroSim Fullscreen</p>"},{"location":"sims/test-scores-boxplot/#iframe-embed-code","title":"Iframe Embed Code","text":"<p>Place the following line in your website to include this MicroSim in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/test-scores-boxplot/main.html\" height=\"620px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/test-scores-boxplot/#about-this-microsim","title":"About This MicroSim","text":"<p>Sylvia says: \"Acorn for your thoughts? A boxplot is like a snack-sized summary. You get the center and spread all at once, plus those extremes that make you go, 'Wait, who scored a 5?'\"</p> <p>This MicroSim models test scores from a 100-point exam. It shows the full five-number summary in a single boxplot, making the minimum, Q1, median, Q3, and maximum easy to spot. Toggle Section B to compare two classes or two versions of the same exam.</p> <p>Key features:</p> <ul> <li>Five-number summary displayed in real time</li> <li>Low outlier toggle to show how the minimum can shift</li> <li>Individual scores overlay for student-level context</li> <li>Section comparison to highlight differences between classes</li> <li>Randomized class scores for repeated practice</li> </ul>"},{"location":"sims/test-scores-boxplot/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/test-scores-boxplot/#learning-objective","title":"Learning Objective","text":"<p>Students will interpret a boxplot by identifying the minimum, Q1, median, Q3, and maximum and comparing two class sections.</p> <p>Bloom's Taxonomy Level: Analyze (L4)</p> <p>Bloom's Verb: Interpret</p>"},{"location":"sims/test-scores-boxplot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of quartiles and median</li> <li>Familiarity with boxplots</li> </ul>"},{"location":"sims/test-scores-boxplot/#suggested-duration","title":"Suggested Duration","text":"<p>10-15 minutes for guided exploration</p>"},{"location":"sims/test-scores-boxplot/#classroom-activities","title":"Classroom Activities","text":""},{"location":"sims/test-scores-boxplot/#activity-1-five-number-scavenger-hunt-5-minutes","title":"Activity 1: Five-Number Scavenger Hunt (5 minutes)","text":"<ol> <li>Start with the default class scores and point to each part of the boxplot.</li> <li>Ask students to identify the minimum, Q1, median, Q3, and maximum.</li> <li>Toggle the low outlier and ask: \"Which summary value changed the most?\"</li> </ol>"},{"location":"sims/test-scores-boxplot/#activity-2-section-face-off-5-minutes","title":"Activity 2: Section Face-Off (5 minutes)","text":"<ol> <li>Enable Section B and adjust the averages.</li> <li>Ask: \"Which class has the higher typical score? Which is more spread out?\"</li> <li>Have students justify their answer using quartiles and the median.</li> </ol>"},{"location":"sims/test-scores-boxplot/#activity-3-real-world-connection-3-minutes","title":"Activity 3: Real-World Connection (3 minutes)","text":"<ol> <li>Ask students to imagine two different exam versions.</li> <li>Adjust the spreads so one section has more variability.</li> <li>Discuss: \"Which exam seems harder? Why?\"</li> </ol>"},{"location":"sims/test-scores-boxplot/#discussion-questions","title":"Discussion Questions","text":"<ol> <li>If the median is higher but the spread is larger, how would you describe the class performance?</li> <li>How does a low outlier affect the minimum without changing the median much?</li> <li>Why might two sections have similar medians but different Q1 values?</li> </ol>"},{"location":"sims/test-scores-boxplot/#assessment-opportunities","title":"Assessment Opportunities","text":"<ul> <li>Quick exit ticket: \"Circle the median on a drawn boxplot and explain what it means.\"</li> <li>Compare two boxplots and write a 2-sentence interpretation of center and spread.</li> </ul>"},{"location":"sims/test-scores-boxplot/#common-misconceptions-to-address","title":"Common Misconceptions to Address","text":"<ul> <li>The box is the average: Clarify that the box spans the middle 50% of scores, not the mean.</li> <li>Outliers change the median: Show how the median can stay stable even with a very low minimum.</li> <li>Wider box means higher scores: Emphasize that width (or length) shows spread, not performance.</li> </ul>"},{"location":"sims/test-scores-boxplot/#technical-notes","title":"Technical Notes","text":"<ul> <li>Built with Plotly.js</li> <li>Responsive layout for iframe embedding</li> <li>Default scores generated from a normal distribution and clamped to 0-100</li> </ul> <p>Reminder: Create a screenshot named <code>test-scores-boxplot.png</code> for social media previews.</p>"},{"location":"sims/token-prediction/","title":"Token Prediction Analysis","text":"<p>Which factor best predicts how many tokens are needed to generate a chapter? This interactive MicroSim compares three potential predictors: number of concepts, word count, and number of MicroSims.</p> <p>View Fullscreen</p>"},{"location":"sims/token-prediction/#regression-comparison-results","title":"Regression Comparison Results","text":"Predictor R\u00b2 Interpretation Concepts 1.6% Very weak predictor Words 0.3% Essentially no relationship MicroSims 5.6% Weak but best of the three"},{"location":"sims/token-prediction/#key-finding","title":"Key Finding","text":"<p>None of these variables are good predictors of token usage.</p> <p>Even the best predictor (MicroSims) explains only 5.6% of the variance. This means ~94% of the variation in token usage is explained by other factors not captured in these metrics.</p>"},{"location":"sims/token-prediction/#what-this-tells-us","title":"What This Tells Us","text":"<p>The analysis reveals that token consumption during chapter generation is driven by factors beyond simple metrics:</p> <ol> <li>Context loading overhead - The skill loads course descriptions, learning graphs, and reference files regardless of chapter size</li> <li>Agent reasoning complexity - Some topics require more \"thinking\" even with fewer concepts</li> <li>Example generation - Worked examples vary in complexity independent of concept count</li> <li>Parallel vs sequential execution - Agent behavior differs based on execution mode</li> </ol>"},{"location":"sims/token-prediction/#interesting-observations","title":"Interesting Observations","text":"<p>Looking at specific outliers:</p> <ul> <li>Chapter 9 (Probability Fundamentals): 69,200 tokens for 19 concepts and 5,591 words - highest token usage</li> <li>Chapter 17 (Inference for Means): Only 25,000 tokens for 18 concepts and 7,028 words - very efficient</li> <li>Chapter 10 (Conditional Probability): 55,700 tokens for just 5 concepts - highest tokens-per-concept ratio</li> </ul>"},{"location":"sims/token-prediction/#features","title":"Features","text":"<ul> <li>Interactive toggle - Switch between Concepts, Words, and MicroSims views</li> <li>Side-by-side R\u00b2 comparison - See all three R\u00b2 values at once</li> <li>Dynamic regression line - Updates with each predictor selection</li> <li>Rich tooltips - Hover over points to see all chapter metrics</li> </ul>"},{"location":"sims/token-prediction/#data-source","title":"Data Source","text":"<p>Data extracted from chapter generation logs (<code>/logs/ch-*.md</code>) for chapters 6-19, excluding chapters with estimated values.</p>"},{"location":"sims/token-prediction/#references","title":"References","text":"<ul> <li>Chart.js Documentation</li> <li>Linear Regression</li> <li>Coefficient of Determination (R\u00b2)</li> </ul>"},{"location":"sims/two-way-table-calculator/","title":"Two-Way Table Distribution Calculator","text":"<p>Run the Two-Way Table Calculator Fullscreen</p>"},{"location":"sims/two-way-table-calculator/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive calculator helps you practice computing marginal and conditional distributions from a two-way (contingency) table. You can edit the cell values directly and see how the distributions change.</p>"},{"location":"sims/two-way-table-calculator/#how-to-use","title":"How to Use","text":"<ol> <li> <p>Edit Cell Values: Click on any data cell in the table to edit its value (0-100). Press Enter to confirm or Tab to move to the next cell.</p> </li> <li> <p>Choose Distribution Type: Use the buttons at the bottom to select which distribution to calculate:</p> </li> <li>Marginal Row: Proportion of each grade level (Freshman/Sophomore) across all seasons</li> <li>Marginal Col: Proportion of each season across all grade levels</li> <li>Cond|Row1: Conditional distribution of seasons given Freshman</li> <li> <p>Cond|Row2: Conditional distribution of seasons given Sophomore</p> </li> <li> <p>Toggle Steps: Click \"Steps On/Off\" to show or hide the calculation formulas.</p> </li> <li> <p>Example Data: Click \"Example\" to reset to the default dataset.</p> </li> </ol>"},{"location":"sims/two-way-table-calculator/#key-concepts","title":"Key Concepts","text":"<ul> <li> <p>Marginal Distribution: The distribution of one variable, ignoring the other. Found by dividing row or column totals by the grand total.</p> </li> <li> <p>Conditional Distribution: The distribution of one variable given a specific value of another variable. Found by dividing cell values by the conditioning row or column total.</p> </li> </ul>"},{"location":"sims/two-way-table-calculator/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<p>Place the following line in your website to include this in your course:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/two-way-table-calculator/main.html\" height=\"552px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/two-way-table-calculator/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/two-way-table-calculator/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this activity, students will be able to:</p> <ol> <li>Calculate marginal distributions from a two-way table</li> <li>Calculate conditional distributions given a specific row or column value</li> <li>Explain the difference between marginal and conditional distributions</li> <li>Interpret proportions in the context of categorical data</li> </ol>"},{"location":"sims/two-way-table-calculator/#blooms-taxonomy-level","title":"Bloom's Taxonomy Level","text":"<p>Apply (L3) - Students calculate and execute distribution computations.</p>"},{"location":"sims/two-way-table-calculator/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of proportions and percentages</li> <li>Basic knowledge of categorical variables</li> <li>Familiarity with frequency tables</li> </ul>"},{"location":"sims/two-way-table-calculator/#suggested-activities","title":"Suggested Activities","text":""},{"location":"sims/two-way-table-calculator/#warm-up-5-minutes","title":"Warm-Up (5 minutes)","text":"<p>Have students enter their own data: Ask the class \"How many of you prefer each season?\" Record responses by grade level in the table.</p>"},{"location":"sims/two-way-table-calculator/#guided-practice-10-minutes","title":"Guided Practice (10 minutes)","text":"<ol> <li>Start with the Example data showing season preferences by grade level</li> <li>Walk through calculating the marginal distribution of grade level step-by-step</li> <li>Show how the proportions sum to 1.000</li> </ol>"},{"location":"sims/two-way-table-calculator/#independent-practice-15-minutes","title":"Independent Practice (15 minutes)","text":"<p>Have students:</p> <ol> <li>Calculate the marginal distribution of seasons</li> <li>Calculate the conditional distribution of seasons given Freshman</li> <li>Compare: Do Freshmen and Sophomores have similar season preferences?</li> </ol>"},{"location":"sims/two-way-table-calculator/#discussion-questions","title":"Discussion Questions","text":"<ul> <li>\"What does it mean if the conditional distributions are the same for both rows?\"</li> <li>\"How would you describe the relationship between grade level and season preference using these distributions?\"</li> <li>\"When would you use a marginal vs. conditional distribution?\"</li> </ul>"},{"location":"sims/two-way-table-calculator/#assessment-ideas","title":"Assessment Ideas","text":"<ol> <li>Give students a new two-way table and ask them to calculate specific distributions without the calculator</li> <li>Present two conditional distributions and ask students to interpret whether the variables appear associated</li> <li>Have students collect their own categorical data and analyze it using this tool</li> </ol>"},{"location":"sims/two-way-table-calculator/#common-misconceptions","title":"Common Misconceptions","text":"<ul> <li>Confusing marginal and conditional distributions</li> <li>Dividing by the wrong total (grand total vs. row/column total)</li> <li>Forgetting that conditional distributions should sum to 1.000</li> </ul>"},{"location":"sims/two-way-table-calculator/#references","title":"References","text":"<ul> <li>Chapter 2: Displaying Categorical Data</li> <li>AP Statistics: Exploring Two-Variable Data</li> <li>Khan Academy: Two-Way Tables</li> </ul>"},{"location":"sims/variable-types-concept-map/","title":"Variable Types Concept Map","text":"<p>Run the Variable Types Concept Map Fullscreen</p>"},{"location":"sims/variable-types-concept-map/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<p>You can include this MicroSim on your website using the following <code>iframe</code>:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/variable-types-concept-map/main.html\" height=\"402px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/variable-types-concept-map/#description","title":"Description","text":"<p>This interactive concept map helps students understand the fundamental classification of variables in statistics. The hierarchical structure clearly shows how variables branch into two main categories:</p> <ul> <li>Categorical Variables: Variables that name categories or groups, where values are labels rather than numbers (like eye color, zip code, or blood type)</li> <li>Quantitative Variables: Variables with numerical values that represent quantities or amounts</li> </ul> <p>Quantitative variables are further subdivided into:</p> <ul> <li>Discrete Variables: Can only take specific, countable values (often integers), like the number of children or cars owned</li> <li>Continuous Variables: Can take any value within a range, including decimals, like height, weight, or temperature</li> </ul>"},{"location":"sims/variable-types-concept-map/#interactive-features","title":"Interactive Features","text":"<ul> <li>Hover over any node to see its definition and 3-4 examples</li> <li>Click on a node to highlight its branch (ancestors and descendants) while dimming other nodes</li> <li>Click again on the same node to clear the selection and show all branches</li> </ul> <p>The color-coded branches help reinforce the classification structure:</p> <ul> <li>Purple/indigo for the root \"Variable\" node</li> <li>Green for the Categorical branch</li> <li>Orange/yellow shades for the Quantitative branch and its children</li> </ul>"},{"location":"sims/variable-types-concept-map/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/variable-types-concept-map/#learning-objective","title":"Learning Objective","text":"<p>Students will be able to classify variables into categorical and quantitative types, and further subdivide quantitative variables into discrete and continuous.</p>"},{"location":"sims/variable-types-concept-map/#grade-level","title":"Grade Level","text":"<p>High School (AP Statistics) or Undergraduate Introduction to Statistics</p>"},{"location":"sims/variable-types-concept-map/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of what data and variables are</li> <li>Basic familiarity with numbers vs. categories</li> </ul>"},{"location":"sims/variable-types-concept-map/#duration","title":"Duration","text":"<p>15-20 minutes</p>"},{"location":"sims/variable-types-concept-map/#activities","title":"Activities","text":"<ol> <li> <p>Exploration (5 minutes): Have students hover over each node to read definitions and examples. Ask them to notice the hierarchical structure.</p> </li> <li> <p>Classification Practice (10 minutes): Present the following variables and have students classify each:</p> </li> <li>Number of siblings (Quantitative - Discrete)</li> <li>Favorite sport (Categorical)</li> <li>Time to run a mile (Quantitative - Continuous)</li> <li>Letter grade (Categorical)</li> <li>Temperature in Fahrenheit (Quantitative - Continuous)</li> <li> <p>Number of text messages sent today (Quantitative - Discrete)</p> </li> <li> <p>Discussion (5 minutes): Ask students why it matters whether a variable is categorical vs. quantitative, or discrete vs. continuous. Connect to how we might display and analyze each type differently.</p> </li> </ol>"},{"location":"sims/variable-types-concept-map/#assessment-questions","title":"Assessment Questions","text":"<ol> <li>What is the key difference between categorical and quantitative variables?</li> <li>Give an example of a discrete variable that is NOT a count.</li> <li>Can a variable that uses numbers (like zip codes) be categorical? Explain.</li> <li>Why might the same characteristic be measured as discrete or continuous depending on how we collect the data?</li> </ol>"},{"location":"sims/variable-types-concept-map/#extension","title":"Extension","text":"<p>Have students create their own examples for each category from a dataset they encounter in their daily lives (sports statistics, social media metrics, health data, etc.).</p>"},{"location":"sims/variable-types-concept-map/#references","title":"References","text":"<ul> <li>AP Statistics Course Description - College Board</li> <li>Types of Variables - Khan Academy</li> <li>Agresti, A., &amp; Franklin, C. (2018). Statistics: The Art and Science of Learning from Data (4th ed.). Pearson.</li> </ul>"},{"location":"sims/venn-diagram-solver/","title":"Venn Diagram Problem Solver","text":"<p>Run the Venn Diagram Problem Solver Fullscreen</p> <p>Edit this MicroSim in the p5.js Editor</p>"},{"location":"sims/venn-diagram-solver/#about-this-microsim","title":"About This MicroSim","text":"<p>This interactive tool helps students organize information and solve probability problems using Venn diagrams. Students can input total count, n(A), n(B), and n(A\u2229B), and the visualization automatically calculates all four regions. The tool includes preset scenarios for common problem types.</p>"},{"location":"sims/venn-diagram-solver/#how-to-use","title":"How to Use","text":"<ol> <li>Select a scenario from the dropdown or use custom values</li> <li>Use keyboard shortcuts to adjust values: T (total), A (n(A)), B (n(B)), I (intersection)</li> <li>Press arrow keys while holding a letter key to increment/decrement</li> <li>Click regions to highlight them</li> <li>Verify that the sum of all regions equals the total</li> </ol>"},{"location":"sims/venn-diagram-solver/#regions-calculated","title":"Regions Calculated","text":"<ul> <li>A only: n(A) - n(A\u2229B)</li> <li>B only: n(B) - n(A\u2229B)</li> <li>Both A and B: n(A\u2229B)</li> <li>Neither: Total - (A only) - (B only) - (Both)</li> </ul>"},{"location":"sims/venn-diagram-solver/#learning-objectives","title":"Learning Objectives","text":"<p>After using this MicroSim, students will be able to:</p> <ul> <li>Organize probability information using Venn diagrams</li> <li>Calculate counts for each region of a two-set Venn diagram</li> <li>Convert counts to probabilities</li> <li>Verify their work by checking that regions sum to the total</li> </ul>"},{"location":"sims/venn-diagram-solver/#embedding-this-microsim","title":"Embedding This MicroSim","text":"<pre><code>&lt;iframe src=\"https://dmccreary.github.io/statistics-course/sims/venn-diagram-solver/main.html\" height=\"502px\" width=\"100%\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/venn-diagram-solver/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/venn-diagram-solver/#introduction-5-minutes","title":"Introduction (5 minutes)","text":"<p>Review Venn diagram structure and the four distinct regions. Emphasize the importance of starting with the intersection.</p>"},{"location":"sims/venn-diagram-solver/#guided-exploration-10-minutes","title":"Guided Exploration (10 minutes)","text":"<p>Work through the \"Language Classes\" preset, showing how to fill in each region systematically.</p>"},{"location":"sims/venn-diagram-solver/#practice-activities-15-minutes","title":"Practice Activities (15 minutes)","text":"<p>Have students solve problems from each preset scenario, then create their own scenarios.</p>"},{"location":"sims/venn-diagram-solver/#assessment","title":"Assessment","text":"<p>Students complete Venn diagram problems independently and explain their calculation process.</p>"},{"location":"sims/venn-diagram-solver/#references","title":"References","text":"<ul> <li>Chapter 9: Probability Fundamentals</li> <li>Concepts: Venn Diagram, Using Venn Diagrams</li> </ul>"},{"location":"sims/z-score-calculator/","title":"Z-Score Calculator and Visualizer","text":"<p>Run Fullscreen</p> <p>Edit in p5.js Editor</p>"},{"location":"sims/z-score-calculator/#about-this-microsim","title":"About This MicroSim","text":"<p>Calculate and visualize z-scores with an interactive normal distribution curve.</p>"},{"location":"sims/z-score-calculator/#how-to-use","title":"How to Use","text":"<ul> <li>Drag the marker along the curve to change the raw value (x)</li> <li>Use preset buttons to load different real-world examples (IQ, SAT, Heights)</li> <li>Adjust \u03bc (mean) and \u03c3 (standard deviation) sliders to change distribution parameters</li> <li>Watch the z-score calculation update in real time</li> </ul>"},{"location":"sims/z-score-calculator/#key-insights","title":"Key Insights","text":"<ul> <li>Z-score formula: z = (x - \u03bc) / \u03c3</li> <li>Z-score tells you how many standard deviations a value is from the mean</li> <li>Positive z-scores are above the mean; negative z-scores are below</li> <li>|z| &lt; 2 is typical; |z| &gt; 2 is unusual; |z| &gt; 3 is very rare</li> </ul>"},{"location":"sims/z-score-calculator/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/z-score-calculator/#learning-objective","title":"Learning Objective","text":"<p>Students will calculate z-scores from raw values and interpret their meaning in the context of a normal distribution (Bloom's Taxonomy: Applying, Analyzing).</p>"}]}